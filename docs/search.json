[
  {
    "objectID": "06-EDA.html#pré-requis",
    "href": "06-EDA.html#pré-requis",
    "title": "6  Exploration statistique des données",
    "section": "6.1 Pré-requis",
    "text": "6.1 Pré-requis\nLa première étape de toute analyse de données est l’exploration. Avant de se lancer dans des tests statistiques et des procédures complexes, et à supposer que les données dont vous disposez sont déjà dans un format approprié, il est toujours très utile :\n\nd’explorer visuellement les données dont on dispose en faisant des graphiques nombreux et variés, afin de comprendre, notamment quelle est la distribution des variables numériques, quelles sont les catégories les plus représentées pour les variables qualitatives (ou facteurs), quelles sont les relations les plus marquantes entre variables numériques et/ou catégorielles, etc. Vous avez appris au Chapitre 3 comment produire toutes sortes de graphiques avec le package ggplot2. Il va maintenant falloir vous poser la question du choix des graphiques à produire du point de vue de l’exploration statistique de données inconnues.\nd’explorer les données en calculant des indices de statistiques descriptives. Ces indices relèvent en général de 2 catégories : les indices de position (e.g. moyennes, médianes, quartiles…) et les indices de dispersion (e.g. variance, écart-type, intervalle inter-quartiles…). Nous avons déjà vu comment utiliser la fonction summarise() et son argument .by pour calculer des moyennes ou des effectifs pour plusieurs sous-groupes de nos jeux de données. Dans ce chapitre, nous allons aller plus loin, et nous découvrirons d’une part comment obtenir d’autres indices statistiques pertinents, et d’autres fonctions encore plus utiles que summarise().\n\nNous verrons dans le Chapitre 7 comment calculer des indices d’incertitude (Section 7.4 et Section 7.5). Attention, il ne faudra pas confondre indices de dispersion et indices d’incertitude. Et enfin, avant de passer aux tests statistiques, nous verrons comment visualiser dispersion et incertitude au Chapitre 8.\nAfin d’explorer ces questions, nous aurons besoin des packages suivants :\n\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(palmerpenguins)\nlibrary(nycflights13)\n\nComme vous le savez maintenant, les packages du tidyverse (Wickham 2023) permettent de manipuler facilement des tableaux de données et de réaliser des graphiques. Charger le tidyverse permet d’accéder, entre autres, aux packages readr (Wickham, Hester, et Bryan 2023), pour importer facilement des fichiers .csv au format tibble, tidyr (Wickham, Vaughan, et Girlich 2023) et dplyr (Wickham, François, et al. 2023) pour manipuler des tableaux de données ou encore ggplot2 (Wickham, Chang, et al. 2023) pour produire des graphiques. Le package skimr (Waring et al. 2022) permet de calculer des résumés de données très informatifs. Les packages palmerpenguins (Horst, Hill, et Gorman 2022) et nycflights13 (Wickham 2021) fournissent des jeux de données qui seront faciles à manipuler pour illustrer ce chapitre (et les suivants).\n\n\n\n\n\n\nImportant\n\n\n\nSi vous avez déjà installé le tidyverse ou dplyr avant le printemps 2023, ré-installez dplyr avec install.packages(\"dplyr\"). Ce package a en effet été mis à jour tout récemment, et nous aurons besoin de sa toute dernière version (v1.1.0) pour utiliser certaines fonctions. Chargez-le ensuite en mémoire avec library(dplyr).\n\n\n\n\n\n\n\n\nAttention\n\n\n\nPensez à installer tous les packages listés ci-dessous avant de les charger en mémoire si vous ne l’avez pas déjà fait. Si vous ne savez plus comment faire, consultez d’urgence la Section 1.4\n\n\nPour travailler dans de bonnes conditions, et puisque nous abordons maintenant les statistiques à proprement parler, je vous conseille de créez un nouveau script dans le même dossier que votre Rproject. Là encore, si vous ne savez plus comment faire consultez la Section 1.3."
  },
  {
    "objectID": "06-EDA.html#créer-des-résumés-avec-la-fonction-summarise",
    "href": "06-EDA.html#créer-des-résumés-avec-la-fonction-summarise",
    "title": "6  Exploration statistique des données",
    "section": "6.2 Créer des résumés avec la fonction summarise()",
    "text": "6.2 Créer des résumés avec la fonction summarise()\nComme nous l’avons vu au semestre 3, le package dplyr fournit plusieurs fonctions qui portent le nom de verbes et qui permettent d’effectuer des manipulations simples mais qui peuvent devenir très puissantes lorsqu’on les combine. Nous avons ainsi vu les fonctions suivantes :\n\nselect() : pour sélectionner ou exclure certaines colonnes (variables) d’un tableau de données\nfilter() : pour trier des lignes d’un tableau de données selon des critères ou conditions choisis par l’utilisateur\nmutate() : pour transformer des variables existantes, ou pour créer de nouvelles colonnes dans un tableau de données\narrange() : pour trier des tableaux de données par ordre croissants ou décroissants\n\nSi vous ne savez plus comment utiliser ces fonctions, relisez le chapitre 4 du livre en ligne de Biométrie du semestre 3.\nÀ ces 4 verbes, nous allons ici ajouter :\n\nsummarise() : pour créer des résumés de données simples à partir des colonnes d’un tableau\nreframe() : pour créer des résumés de données plus élaborés à partir des colonnes d’un tableau\ncount() : pour compter le nombre d’observations pour chaque niveau d’un facteur (ou modalité d’une variable catégorielle)\ngroup_by() : pour effectuer des opérations pour chaque niveau d’un facteur (ou modalité d’une variable catégorielle)\n\nCette dernière fonction group_by() a été rendue presque obsolète par une mise à jour récente du package dplyr qui introduit un nouvel argument pour plusieurs fonctions, dont summarise() : l’argument .by. Un peu comme group-by(), ce nouvel argument permet d’effectuer des opérations pour chaque niveau d’un facteur (ou modalité d’une variable catégorielle). À notre niveau, les différences entre la fonction group_by() et l’argument .by ne sont pas importantes. Nous utiliserons donc de préférence la notation la plus simple, celle de l’argument .by.\nVoyons comment on utilise ces fonctions pour calculer des indices de statistiques descriptives pour les variables du tableau penguins :\n\n# affichage du tableau\npenguins\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n6.2.1 Principe de la fonction summarise()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6.1: Schéma de la fonction summarise() tiré de la ‘cheatsheet’ de dplyr et tidyr\n\n\n\n\nLa Figure 6.1 ci-dessus indique comment travaille la fonction summarise() : elle prend plusieurs valeurs (potentiellement, un très grand nombre) et les réduit à une unique valeur qui les résume. La valeur qui résume les données est choisie par l’utilisateur. Il peut s’agir par exemple d’un calcul de moyenne, de quartile ou de variance, il peut s’agir de calculer une somme, ou d’extraire la valeur maximale ou minimale, ou encore, il peut tout simplement s’agir de déterminer un nombre d’observations. Mais le fonctionnement est toujours le même : la fonction summarise() ne renvoie qu’une unique valeur pour une variable donnée (ou pour chaque modalité d’une variable catégorielle).\nAinsi, pour connaître la moyenne de la longueur du bec des manchots de l’île de Palmer, il suffit d’utiliser le tableau penguins du package palmerpenguins et sa variable bill_length_mm que nous avons déjà utilisée au semestre 3 :\n\npenguins %&gt;%\n  summarise(moyenne = mean(bill_length_mm))\n\n# A tibble: 1 × 1\n  moyenne\n    &lt;dbl&gt;\n1      NA\n\n\nLa fonction mean() permet de calculer une moyenne. Ici, la valeur retournée est NA car 2 individus n’ont pas été mesurés, et le tableau contient donc des valeurs manquantes :\n\npenguins %&gt;%\n  filter(is.na(bill_length_mm))\n\n# A tibble: 2 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen             NA            NA                NA          NA\n2 Gentoo  Biscoe                NA            NA                NA          NA\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nPour obtenir la valeur souhaitée, il faut indiquer à R d’exclure les valeurs manquantes lors du calcul de moyenne :\n\npenguins %&gt;%\n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  moyenne\n    &lt;dbl&gt;\n1    43.9\n\n\nLa longueur moyenne du bec des manchots (toutes espèces confondues) est donc de 43.9 millimètres.\nDe la même façon, on peut demander plusieurs calculs d’indices à la fois, par exemple la moyenne et l’écart-type (avec la fonction sd()) de la longueur des becs :\n\npenguins %&gt;%\n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            ecart_type = sd(bill_length_mm, na.rm = TRUE))\n\n# A tibble: 1 × 2\n  moyenne ecart_type\n    &lt;dbl&gt;      &lt;dbl&gt;\n1    43.9       5.46\n\n\nIci, l’écart-type vaut 5.5 millimètres.\nLa fonction summarise() permet donc de calculer des indices statistiques variés, et permet aussi d’accéder à plusieurs variables à la fois. Par exemple. pour calculer les moyennes, médianes, minima et maxima des longueurs de nageoires et de masses corporelles, on peut procéder ainsi :\n\npenguins %&gt;% \n  summarise(moy_flip = mean(flipper_length_mm, na.rm = TRUE),\n            med_flip = median(flipper_length_mm, na.rm = TRUE),\n            min_flip = min(flipper_length_mm, na.rm = TRUE),\n            max_flip = max(flipper_length_mm, na.rm = TRUE),\n            moy_mass = mean(body_mass_g, na.rm = TRUE),\n            med_mass = median(body_mass_g, na.rm = TRUE),\n            min_mass = min(body_mass_g, na.rm = TRUE),\n            max_mass = max(body_mass_g, na.rm = TRUE))\n\n# A tibble: 1 × 8\n  moy_flip med_flip min_flip max_flip moy_mass med_mass min_mass max_mass\n     &lt;dbl&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;\n1     201.      197      172      231    4202.     4050     2700     6300\n\n\nLa fonction summarise() est donc très utile pour produire des résumés informatifs des données, mais nos exemples ne sont ici pas très pertinents puisque nous avons jusqu’ici calculé des indices sans distinguer les espèces. Si les 3 espèces de manchots ont des caractéristiques très différentes, calculer des moyennes toutes espèces confondues n’a pas de sens. Voyons maintenant comment obtenir ces même indices pour chaque espèce.\n\n\n6.2.2 Intérêt de l’argument .by\nLa fonction summarise() devient particulièrement puissante lorsqu’on y ajoute l’argument .by :\n\n\n\n\n\nFigure 6.2: Fonctionnement de l’argument .by travaillant de concert avec summarise(), tiré de la ‘cheatsheet’ de dplyr et tidyr\n\n\n\n\nComme son nom l’indique, l’argument .by permet de créer des sous-groupes dans un tableau, afin que le résumé des données soit calculé pour chacun des sous-groupes plutôt que sur l’ensemble du tableau. En ce sens, son fonctionnement est analogue à celui des facets de ggplot2 qui permettent de scinder les données d’un graphique en plusieurs sous-groupes.\nPour revenir à l’exemple de la longueur du bec des manchots, imaginons que nous souhaitions calculer les moyennes et les écart-types pour chacune des trois espèces. Voilà comment procéder :\n\npenguins %&gt;%\n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            ecart_type = sd(bill_length_mm, na.rm = TRUE),\n            .by = species)\n\n# A tibble: 3 × 3\n  species   moyenne ecart_type\n  &lt;fct&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 Adelie       38.8       2.66\n2 Gentoo       47.5       3.08\n3 Chinstrap    48.8       3.34\n\n\nIci, les étapes sont les suivantes :\n\nOn prend le tableau penguins, puis\nOn résume les données sous la forme de moyennes et d’écart-types\nOn demande un calcul pour chaque modalité de la variable species\n\nLà où nous avions auparavant une seule valeur de moyenne et d’écart-type pour l’ensemble des individus du tableau de données, nous avons maintenant une valeur de moyenne et d’écart-type pour chaque modalité de la variable espèce. Puisque le facteur species contient 3 modalités (Adelie, Chinstrap et Gentoo), le résumé des données contient maintenant 3 lignes.\nCette syntaxe très simple est presque équivalente à celle de la fonction group_by() :\n\npenguins %&gt;%\n  group_by(species) %&gt;% \n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            ecart_type = sd(bill_length_mm, na.rm = TRUE))\n\n# A tibble: 3 × 3\n  species   moyenne ecart_type\n  &lt;fct&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 Adelie       38.8       2.66\n2 Chinstrap    48.8       3.34\n3 Gentoo       47.5       3.08\n\n\nLes valeurs obtenues sont les mêmes, mais d’une part, les commandes sont fournies avec une syntaxe et dans un ordre différents :\n\nOn prend le tableau penguins, puis\nOn groupe les données par espèce, puis\nOn résume les données sous la forme de moyennes et d’écart-types\n\nEt l’objet obtenu au final n’est pas strictement identique : avec la fonction group_by(), et dans certaines situations, la tibble obtenu conserve l’information du regroupement effectué, ce qui peut être utile dans certaines situations, mais pose parfois problème et cause l’affichage de messages d’avertissements dans la console. Ce comportement n’est pas observé avec l’argument .by qui ne groupe les données qu’au moment du calcul des indices dans la fonction summarise() et n’en conserve pas la trace ensuite. C’est la raison pour laquelle nous privilégierons cette méthode.\nPour aller plus loin, ajoutons à ce résumé 2 variables supplémentaires : le nombre de mesures et l’erreur standard (notée \\(se\\)), qui peut être calculée de la façon suivante :\n\\[se \\approx \\frac{s}{\\sqrt{n}}\\]\navec \\(s\\), l’écart-type de l’échantillon et \\(n\\), la taille de l’échantillon (plus d’informations sur cette statistique très importante dans la Chapitre 7). Nous allons donc calculer ici ces résumés, et nous donnerons un nom au tableau créé pour pouvoir ré-utiliser ces statistiques descriptives :\n\nstats_esp &lt;- penguins %&gt;%\n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            ecart_type = sd(bill_length_mm, na.rm = TRUE),\n            nb_obs = n(),\n            erreur_std = ecart_type / sqrt(nb_obs),\n            .by = species)\n\nstats_esp\n\n# A tibble: 3 × 5\n  species   moyenne ecart_type nb_obs erreur_std\n  &lt;fct&gt;       &lt;dbl&gt;      &lt;dbl&gt;  &lt;int&gt;      &lt;dbl&gt;\n1 Adelie       38.8       2.66    152      0.216\n2 Gentoo       47.5       3.08    124      0.277\n3 Chinstrap    48.8       3.34     68      0.405\n\n\nVous constatez ici que nous avons 4 statistiques descriptives pour chaque espèce. Deux choses sont importantes à retenir ici :\n\non peut obtenir le nombre d’observations dans chaque sous-groupe d’un tableau groupé en utilisant la fonction n(). Cette fonction n’a besoin d’aucun argument : elle détermine automatiquement la taille des groupes créés par .by (ou par la fonction group_by()).\non peut créer de nouvelles variables en utilisant le nom de variables créées auparavant. Ainsi, nous avons créé la variable erreur_std en utilisant deux variables créées au préalable : ecart-type et nb_obs\n\n\n\n6.2.3 Grouper par plus d’une variable\nJusqu’ici, nous avons groupé les données par espèce. Il est tout à fait possible de grouper les données par plus d’une variable, par exemple, par espèce et par sexe :\n\nstats_esp_sex &lt;- penguins %&gt;%\n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            ecart_type = sd(bill_length_mm, na.rm = TRUE),\n            nb_obs = n(),\n            erreur_std = ecart_type / sqrt(nb_obs),\n            .by = c(species, sex))\n\nstats_esp_sex\n\n# A tibble: 8 × 6\n  species   sex    moyenne ecart_type nb_obs erreur_std\n  &lt;fct&gt;     &lt;fct&gt;    &lt;dbl&gt;      &lt;dbl&gt;  &lt;int&gt;      &lt;dbl&gt;\n1 Adelie    male      40.4       2.28     73      0.267\n2 Adelie    female    37.3       2.03     73      0.237\n3 Adelie    &lt;NA&gt;      37.8       2.80      6      1.14 \n4 Gentoo    female    45.6       2.05     58      0.269\n5 Gentoo    male      49.5       2.72     61      0.348\n6 Gentoo    &lt;NA&gt;      45.6       1.37      5      0.615\n7 Chinstrap female    46.6       3.11     34      0.533\n8 Chinstrap male      51.1       1.56     34      0.268\n\n\nEn plus de la variable species, la tableau stats_esp_sex contient une variable sex. Les statistiques que nous avons calculées plus tôt sont maintenant disponibles pour chaque espèce et chaque sexe. D’ailleurs, puisque le sexe de certains individus est inconnu, nous avons également des lignes pour lesquelles le sexe affiché est NA. Pour les éliminer, il suffit de retirer les lignes du tableau pour lesquelles le sexe des individus est inconnu avant de recalculer les mêmes indices :\n\nstats_esp_sex2 &lt;- penguins %&gt;%\n  filter(!is.na(sex)) %&gt;% \n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            ecart_type = sd(bill_length_mm, na.rm = TRUE),\n            nb_obs = n(),\n            erreur_std = ecart_type / sqrt(nb_obs),\n            .by = c(species, sex))\n\nstats_esp_sex2\n\n# A tibble: 6 × 6\n  species   sex    moyenne ecart_type nb_obs erreur_std\n  &lt;fct&gt;     &lt;fct&gt;    &lt;dbl&gt;      &lt;dbl&gt;  &lt;int&gt;      &lt;dbl&gt;\n1 Adelie    male      40.4       2.28     73      0.267\n2 Adelie    female    37.3       2.03     73      0.237\n3 Gentoo    female    45.6       2.05     58      0.269\n4 Gentoo    male      49.5       2.72     61      0.348\n5 Chinstrap female    46.6       3.11     34      0.533\n6 Chinstrap male      51.1       1.56     34      0.268\n\n\nSi vous ne comprenez pas la commande filter(!is.na(sex)), je vous encourage vivement à consulter cette section du livre en ligne de Biométrie du semestre 3.\nEnfin, lorsque nous groupons par plusieurs variables, il peut être utile de présenter les résultats sous la forme d’un tableau large (grâce à la fonction pivot_wider()) pour l’intégration dans un rapport par exemple. La fonction pivot_wider() permet de passer d’un tableau qui possède ce format :\n\npenguins %&gt;%\n  filter(!is.na(sex)) %&gt;% \n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            .by = c(species, sex))\n\n# A tibble: 6 × 3\n  species   sex    moyenne\n  &lt;fct&gt;     &lt;fct&gt;    &lt;dbl&gt;\n1 Adelie    male      40.4\n2 Adelie    female    37.3\n3 Gentoo    female    45.6\n4 Gentoo    male      49.5\n5 Chinstrap female    46.6\n6 Chinstrap male      51.1\n\n\nà un tableau sous ce format :\n\npenguins %&gt;%\n  filter(!is.na(sex)) %&gt;% \n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            .by = c(species, sex)) %&gt;% \n  pivot_wider(names_from = sex,\n              values_from = moyenne)\n\n# A tibble: 3 × 3\n  species    male female\n  &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 Adelie     40.4   37.3\n2 Gentoo     49.5   45.6\n3 Chinstrap  51.1   46.6\n\n\nSous cette forme, les données ne sont plus “rangées”, c’est à dire que nous n’avons plus une observation par ligne et une variable par colonne. En effet ici, la variable sex est maintenant “étalée” dans 2 colonnes distinctes : chaque modalité du facteur de départ (female et male) est utilisée en tant que titre de nouvelles colonnes, et la variable moyenne est répartie dans deux colonnes. Ce format de tableau n’est pas idéal pour les statistiques ou les représentations graphiques, mais il est plus synthétique, et donc plus facile à inclure dans un rapport ou un compte-rendu.\n\n\n6.2.4 Un raccourci pratique pour compter des effectifs\nIl est extrêmement fréquent d’avoir à grouper des données en fonction d’une variable catégorielle puis d’avoir à compter le nombre d’observations de chaque modalité avec n() :\n\npenguins %&gt;% \n  summarise(effectif = n(), \n            .by = species)\n\n# A tibble: 3 × 2\n  species   effectif\n  &lt;fct&gt;        &lt;int&gt;\n1 Adelie         152\n2 Gentoo         124\n3 Chinstrap       68\n\n\nou encore :\n\npenguins %&gt;% \n  group_by(species) %&gt;% \n  summarise(effectif = n())\n\n# A tibble: 3 × 2\n  species   effectif\n  &lt;fct&gt;        &lt;int&gt;\n1 Adelie         152\n2 Chinstrap       68\n3 Gentoo         124\n\n\nCes deux opérations sont tellement fréquentes (regrouper puis compter) que le package dplyr nous fournit un raccourci : la fonction count().\nLe code ci-dessus est équivalent à celui-ci :\n\npenguins %&gt;% \n  count(species)\n\n# A tibble: 3 × 2\n  species       n\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\nNotez qu’avec la fonction count(), la colonne qui contient les comptages s’appelle toujours n par défaut. Comme avec .by et group_by(), il est bien sûr possible d’utiliser count() avec plusieurs variables :\n\npenguins %&gt;% \n  count(species, sex)\n\n# A tibble: 8 × 3\n  species   sex        n\n  &lt;fct&gt;     &lt;fct&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    &lt;NA&gt;       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    &lt;NA&gt;       5\n\n\n\npenguins %&gt;% \n  filter(!is.na(sex)) %&gt;% \n  count(species, sex)\n\n# A tibble: 6 × 3\n  species   sex        n\n  &lt;fct&gt;     &lt;fct&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Chinstrap female    34\n4 Chinstrap male      34\n5 Gentoo    female    58\n6 Gentoo    male      61\n\n\nEt il est évidemment possible de présenter le résultats sous un format de tableau large :\n\npenguins %&gt;% \n  filter(!is.na(sex)) %&gt;% \n  count(species, sex) %&gt;% \n  pivot_wider(names_from = sex,\n              values_from = n)\n\n# A tibble: 3 × 3\n  species   female  male\n  &lt;fct&gt;      &lt;int&gt; &lt;int&gt;\n1 Adelie        73    73\n2 Chinstrap     34    34\n3 Gentoo        58    61\n\n\nVous connaissez maintenant plusieurs méthodes pour calculer à la main des statistiques descriptives pour des variables entières, ou pour des sous-groupes de lignes (par espèce, par sexe, par sexe et par espèce…). Globalement, toutes les fonctions de R qui prennent une série de chiffres en guise d’argument, et qui renvoient une valeur unique, peuvent être utilisées avec la fonction summarise(). En particulier, vous pouvez utiliser les fonctions suivantes pour faire des analyses exploratoires :\n\nmean() : calcul de la moyenne\nmedian() : calcul de la médiane\nmin() : affichage de la valeur minimale\nmax() : affichage de la valeur minimale\nn_distinct() : calcul du nombre de valeurs différentes\nn() : calcul du nombre d’observations\nvar() : calcul de la variance\nsd() : calcul de l’écart-type\nIQR() : calcul de l’intervalle inter-quartiles\n\nEt la liste n’est bien sûr pas exhaustive\n\n\n6.2.5 Exercices\n\nAvec le tableau diamonds du package ggplot2, faites un tableau indiquant combien de diamants de chaque couleur on dispose. Vous devriez obtenir le tableau suivant :\n\n\n\n# A tibble: 7 × 2\n  color     n\n  &lt;ord&gt; &lt;int&gt;\n1 D      6775\n2 E      9797\n3 F      9542\n4 G     11292\n5 H      8304\n6 I      5422\n7 J      2808\n\n\n\nExaminez le tableau weather du package nycflights13 et lisez son fichier d’aide pour comprendre à quoi correspondent les données et comment elles ont été acquises.\nÀ partir du tableau weather faites un tableau indiquant les vitesses de vents minimales, maximales et moyennes, enregistrées chaque mois dans chaque aéroport de New York. Indice : les 3 aéroports de New York sont Newark, LaGuardia Airport et John F. Kennedy, notés respectivement EWR, LGA et JFK dans la variable origin. Votre tableau devrait ressembler à ceci :\n\n\n\n# A tibble: 36 × 5\n   origin month max_wind min_wind moy_wind\n   &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 EWR        1     42.6        0     9.87\n 2 EWR        2   1048.         0    12.2 \n 3 EWR        3     29.9        0    11.6 \n 4 EWR        4     25.3        0     9.63\n 5 EWR        5     33.4        0     8.49\n 6 EWR        6     34.5        0     9.55\n 7 EWR        7     20.7        0     9.15\n 8 EWR        8     21.9        0     7.62\n 9 EWR        9     23.0        0     8.03\n10 EWR       10     26.5        0     8.32\n# ℹ 26 more rows\n\n\n\nSachant que les vitesses du vent sont exprimées en miles par heure, certaines valeurs sont-elles surprenantes ? À l’aide de la fonction filter(), éliminez la ou les valeurs aberrantes. Vous devriez obtenir ce tableau :\n\n\n\n# A tibble: 36 × 5\n   origin month max_wind min_wind moy_wind\n   &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 EWR        1     42.6        0     9.87\n 2 EWR        2     31.1        0    10.7 \n 3 EWR        3     29.9        0    11.6 \n 4 EWR        4     25.3        0     9.63\n 5 EWR        5     33.4        0     8.49\n 6 EWR        6     34.5        0     9.55\n 7 EWR        7     20.7        0     9.15\n 8 EWR        8     21.9        0     7.62\n 9 EWR        9     23.0        0     8.03\n10 EWR       10     26.5        0     8.32\n# ℹ 26 more rows\n\n\n\nEn utilisant les données de vitesse de vent du tableau weather, produisez le graphique suivant :\n\n\n\n\n\n\nIndications :\n\nles vitesses de vent aberrantes ont été éliminées grâce à la fonction filter()\nla fonction geom_jitter() a été utilisée avec l’argument height = 0\nla transparence des points est fixée à 0.2\n\n\nÀ votre avis :\n\n\npourquoi les points sont-ils organisés en bandes horizontales ?\npourquoi n’y a-t-il jamais de vent entre 0 et environ 3 miles à l’heure (mph) ?\nSachant qu’en divisant des mph par 1.151 on obtient des vitesses en nœuds, que nous apprend cette commande :\n\n\nsort(unique(weather$wind_speed)) / 1.151\n\n [1]   0.000000   2.999427   3.999235   4.999044   5.998853   6.998662\n [7]   7.998471   8.998280   9.998089  10.997897  11.997706  12.997515\n[13]  13.997324  14.997133  15.996942  16.996751  17.996560  18.996368\n[19]  19.996177  20.995986  21.995795  22.995604  23.995413  24.995222\n[25]  25.995030  26.994839  27.994648  28.994457  29.994266  30.994075\n[31]  31.993884  32.993692  33.993501  34.993310  36.992928 910.825873"
  },
  {
    "objectID": "06-EDA.html#sec-pivot",
    "href": "06-EDA.html#sec-pivot",
    "title": "6  Exploration statistique des données",
    "section": "6.3 Les fonctions pivot_wider() et pivot_longer()",
    "text": "6.3 Les fonctions pivot_wider() et pivot_longer()\n\n6.3.1 Du format long au format large : pivot_wider()\nComme nous venons de le voir, la fonction pivot_wider() permet de passer d’un tableau au format long à un tableau au format large, qui contient donc moins de lignes mais plus de colonnes.\nPar exemple, lorsque l’on dispose d’un tableau contenant un résumé de données pour plusieurs catégories et sous-catégories, il peut être utile de le transformer au format large pour l’intégrer dans un rapport (la présentation en est ainsi plus synthétique) ou pour faire certains types de graphiques. Par exemple, avec ce tableau de résumé de données :\n\nresum &lt;- penguins %&gt;% \n  filter(!is.na(sex)) %&gt;% \n  count(species, sex)\n\nresum\n\n# A tibble: 6 × 3\n  species   sex        n\n  &lt;fct&gt;     &lt;fct&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Chinstrap female    34\n4 Chinstrap male      34\n5 Gentoo    female    58\n6 Gentoo    male      61\n\n\nLa présentation au format large serait plus appropriée dans un compte-rendu de TP :\n\nresum_large1 &lt;- resum %&gt;% \n  pivot_wider(names_from = sex,\n              values_from = n)\n\nresum_large1\n\n# A tibble: 3 × 3\n  species   female  male\n  &lt;fct&gt;      &lt;int&gt; &lt;int&gt;\n1 Adelie        73    73\n2 Chinstrap     34    34\n3 Gentoo        58    61\n\n\nL’argument names_from permet d’indiquer dans quelle colonne du tableau de départ aller cherche les noms de colonnes pour le nouveau tableau. Ici, on va chercher dans la colonne sex les noms de colonne du futur tableau (female et male). L’argument values_from permet d’indiquer dans quelle colonne du tableau de départ on souhaite aller chercher les valeurs que l’on souhaite mettre dans les nouvelles colonnes du futur tableau (ici, les effectifs stockés dans la colonne n).\nLe terme “tableau large” peut-être trompeur car le tableau obtenu n’a pas forcément plus de colonnes que le tableau d’origine. En tous cas, il a toujours moins de lignes que le tableau de départ. Ici, resum avait 6 lignes et 3 colonnes, resum_large1 possède 3 lignes et 3 colonnes.\nSi on souhaite avoir les espèces en colonnes et les sexes en lignes, on peut taper ceci :\n\nresum_large2 &lt;- resum %&gt;% \n  pivot_wider(names_from = species, \n              values_from = n)\n\nresum_large2\n\n# A tibble: 2 × 4\n  sex    Adelie Chinstrap Gentoo\n  &lt;fct&gt;   &lt;int&gt;     &lt;int&gt;  &lt;int&gt;\n1 female     73        34     58\n2 male       73        34     61\n\n\nCette fois, resum_large2 possède 2 lignes et 4 colonnes. Le caractère “large” de ce nouveau tableau est ici bien apparent. Notez bien que ce sont toujours les mêmes données qui figurent dans ces 3 objets : seule la présentation change.\n\n\n6.3.2 Du format large au format long : pivot_longer()\nÀ l’inverse, on dispose parfois de données au format large alors que la plupart des fonctions graphiques et statistiques de R requièrent des données au format long, c’est à dire, des tableaux dans lesquels il y a une correspondance stricte entre colonnes et variables : une variable est contenue dans une seule colonne d’un tableau, et chaque ligne correspond à une unique observation. AInsi, le tableau resum_large2 n’est pas au format long :\n\nresum_large2\n\n# A tibble: 2 × 4\n  sex    Adelie Chinstrap Gentoo\n  &lt;fct&gt;   &lt;int&gt;     &lt;int&gt;  &lt;int&gt;\n1 female     73        34     58\n2 male       73        34     61\n\n\nEn effet, 3 de ses colonnes contiennent des données d’abondances qui pourraient (ou devraient) se trouver dans une unique colonne Abondance, et le titre de ces 3 colonnes devrait être les catégories d’une autre variable Espece. Pour transformer un tableau large en tableau long (qui contient donc toujours plus de lignes, et souvent moins de colonnes), on utilise pivot_longer(). Cette fonction possède 3 arguments :\n\ncols : quelles sont les colonnes que l’on souhaite regrouper\nnames_to : comment s’appellera la variable qui contiendra les anciens noms de colonnes du tableau large\nvalues_to : comment s’appellera la variable qui contiendra les données contenues dans les cellules du tableau large\n\nVoilà un exemple :\n\nresum_long &lt;- resum_large2 %&gt;% \n  pivot_longer(cols = c(Adelie, Chinstrap, Gentoo),\n               names_to = \"Espece\",\n               values_to = \"Abondance\")\n\nresum_long\n\n# A tibble: 6 × 3\n  sex    Espece    Abondance\n  &lt;fct&gt;  &lt;chr&gt;         &lt;int&gt;\n1 female Adelie           73\n2 female Chinstrap        34\n3 female Gentoo           58\n4 male   Adelie           73\n5 male   Chinstrap        34\n6 male   Gentoo           61\n\n\nLes 3 colonnes qui contenaient les abondance des 3 espèces de manchots ont été regroupées en 2 nouvelles colonnes dont les noms ont été précisés grâce à names_to et values_to.\nIl est très fréquent d’avoir à passer d’un format large à un format long ou inversement. Il est donc important que vous appreniez à vous familiariser avec ces 2 fonctions.\n\n\n\n\n\n\nles tableaux rangés\n\n\n\nLa plupart des fonctions du tidyverse supposent que les tableaux soient rangés (une colonne par variable, une ligne par observation) et qu’ils aient donc un format long. À l’inverse, pour présenter des tableaux dans un rapport ou pour certaines méthodes particulières, les données peuvent être présentées au format large. Les fonctions pivot_wider() et pivot_longer() sont complémentaires et permettent de passer d’un format à l’autre."
  },
  {
    "objectID": "06-EDA.html#créer-des-résumés-avec-la-fonction-reframe",
    "href": "06-EDA.html#créer-des-résumés-avec-la-fonction-reframe",
    "title": "6  Exploration statistique des données",
    "section": "6.4 Créer des résumés avec la fonction reframe()",
    "text": "6.4 Créer des résumés avec la fonction reframe()\nComme nous venons de le voir, les calculs que nous pouvons faire grâce à la fonction summarise() impliquent des fonctions statistiques qui ne renvoient qu’une valeur à la fois lorsqu’on leur fournit une série de valeurs. Par exemple, si on dispose d’un vecteur numérique (les entiers compris entre 1 et 100 pour l’exemple) :\n\n1:100\n\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100\n\n\nla fonction mean() ne renvoie qu’une valeur, la moyenne des 100 valeurs contenues dans le vecteur :\n\nmean(1:100)\n\n[1] 50.5\n\n\nDe même pour les fonctions sd(), ou median(), ou toutes les autres fonctions listées à la fin de la Section 6.2.4 :\n\nsd(1:100)\n\n[1] 29.01149\n\nmedian(1:100)\n\n[1] 50.5\n\n\nIl existe toutefois des fonctions qui renvoient plus d’une valeur à la fois. Par exemple, la fonction quantile(), renvoie par défaut 5 éléments :\n\nla valeur minimale contenue dans le vecteur (ou quantile 0%) : c’est la valeur la plus faible contenue dans la série de données\nle premier quartile du vecteur (Q1 ou quantile 25%) : c’est la valeur coupant l’échantillon en deux telle que 25% des observations du vecteur y sont inférieures\nla médiane du vecteur (Q2 ou quantile 50%) : c’est la valeur coupant l’échantillon en deux telle que 50% des observations du vecteur sont inférieures à cette valeur et 50% y sont supérieures\nle troisième quartile du vecteur (Q3 ou quantile 75%) : c’est la valeur coupant l’échantillon en deux telle que 75% des observations du vecteur y sont inférieures\nla valeur maximale contenue dans le vecteur (ou quantile 100%) : c’est la valeur la plus élevée contenue dans la série de données.\n\nPar exemple, toujours avec le vecteur des entiers contenus entre 1 et 100 :\n\nquantile(1:100)\n\n    0%    25%    50%    75%   100% \n  1.00  25.75  50.50  75.25 100.00 \n\n\nL’objet obtenu est un vecteur dont chaque élément porte un nom. Pour transformer cet objet en tibble, on utilise la fonction enframe() :\n\nenframe(quantile(1:100))\n\n# A tibble: 5 × 2\n  name  value\n  &lt;chr&gt; &lt;dbl&gt;\n1 0%      1  \n2 25%    25.8\n3 50%    50.5\n4 75%    75.2\n5 100%  100  \n\n\nIl peut être très utile de calculer ces différentes valeurs pour plusieurs variables à la fois, ou pour plusieurs sous-groupes d’un jeu de données. Le problème est que nous ne pouvons pas utiliser summarise() car la fonction quantile() ne renvoie pas qu’une unique valeur. par exemple, pour calculer les quantiles des longueurs de becs pour chaque espèce de manchots, on pourrait être tenté de taper ceci :\n\npenguins %&gt;% \n  summarise(Indices = quantile(bill_length_mm, na.rm = TRUE), \n            .by = species)\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n# A tibble: 15 × 2\n   species   Indices\n   &lt;fct&gt;       &lt;dbl&gt;\n 1 Adelie       32.1\n 2 Adelie       36.8\n 3 Adelie       38.8\n 4 Adelie       40.8\n 5 Adelie       46  \n 6 Gentoo       40.9\n 7 Gentoo       45.3\n 8 Gentoo       47.3\n 9 Gentoo       49.6\n10 Gentoo       59.6\n11 Chinstrap    40.9\n12 Chinstrap    46.3\n13 Chinstrap    49.6\n14 Chinstrap    51.1\n15 Chinstrap    58  \n\n\nC’est dans ces situations que la fonction reframe() est utile. Elle joue le même rôle que summarise(), mais dans les situation où les fonctions statistiques renvoient plus d’une valeur à la fois :\n\npenguins %&gt;% \n  reframe(Indices = quantile(bill_length_mm, na.rm = TRUE), \n          .by = species)\n\n# A tibble: 15 × 2\n   species   Indices\n   &lt;fct&gt;       &lt;dbl&gt;\n 1 Adelie       32.1\n 2 Adelie       36.8\n 3 Adelie       38.8\n 4 Adelie       40.8\n 5 Adelie       46  \n 6 Gentoo       40.9\n 7 Gentoo       45.3\n 8 Gentoo       47.3\n 9 Gentoo       49.6\n10 Gentoo       59.6\n11 Chinstrap    40.9\n12 Chinstrap    46.3\n13 Chinstrap    49.6\n14 Chinstrap    51.1\n15 Chinstrap    58  \n\n\nAu contraire de summarise(), reframe() ne renvoie pas de message d’avertissement dans cette situation. Dans cet exemple, on ne sait malheureusement pas à quoi correspondent les chiffres renvoyés puisque l’information des quartiles a disparu (quelles valeurs correspondent aux médianes ou aux premiers quartiles par exemple). Pour y remédier, on doit transformer le vecteur renvoyé par quantile() en tibble. Nous avons déjà vu comment le faire grâce à la fonction enframe(). Par ailleurs, puisque la fonction va maintenant renvoyer un tableau, on n’a pas besoin de lui fournir de nom de colonnes (je retire donc Indices = de mon code) :\n\npenguins %&gt;% \n  reframe(enframe(quantile(bill_length_mm, na.rm = TRUE)), \n          .by = species)\n\n# A tibble: 15 × 3\n   species   name  value\n   &lt;fct&gt;     &lt;chr&gt; &lt;dbl&gt;\n 1 Adelie    0%     32.1\n 2 Adelie    25%    36.8\n 3 Adelie    50%    38.8\n 4 Adelie    75%    40.8\n 5 Adelie    100%   46  \n 6 Gentoo    0%     40.9\n 7 Gentoo    25%    45.3\n 8 Gentoo    50%    47.3\n 9 Gentoo    75%    49.6\n10 Gentoo    100%   59.6\n11 Chinstrap 0%     40.9\n12 Chinstrap 25%    46.3\n13 Chinstrap 50%    49.6\n14 Chinstrap 75%    51.1\n15 Chinstrap 100%   58  \n\n\nEnfin, comme précédemment, il est possible de modifier la forme de ce tableau (avec pivot_wider()) pour le lire plus facilement et éventuellement l’intégrer dans un rapport ou compte-rendu :\n\npenguins %&gt;%\n  reframe(enframe(quantile(bill_length_mm, na.rm = TRUE)), \n          .by = species) %&gt;% \n  pivot_wider(names_from = species,\n              values_from = value)\n\n# A tibble: 5 × 4\n  name  Adelie Gentoo Chinstrap\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n1 0%      32.1   40.9      40.9\n2 25%     36.8   45.3      46.3\n3 50%     38.8   47.3      49.6\n4 75%     40.8   49.6      51.1\n5 100%    46     59.6      58  \n\n\nCes statistiques nous permettent de constater que les manchots de l’espèce Adélie semblent avoir des becs plus courts que les 2 autres espèces (les 5 quantiles le confirment). Les manchots Gentoo et Chinstrap ont en revanche des becs de longueur à peu près similaires, ben que ceux des Chinstrap soient peut-être très légèrement plus longs (Q1, médiane et Q3 supérieurs à ceux des Gentoo). On peut vérifier tout ça graphiquement avec des boîtes à moustaches :\n\npenguins %&gt;% \n  ggplot(aes(x = species, y = bill_length_mm)) +\n  geom_boxplot() +\n  labs(x = \"Espèce\", y = \"Longueur du bec (mm)\") +\n  theme_bw()\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nOu avec un graphique de densité :\n\npenguins %&gt;% \n  ggplot(aes(x = bill_length_mm, fill = species)) +\n  geom_density(alpha = 0.5, show.legend = FALSE) +\n  geom_rug() +\n  labs(x = \"Longueur du bec (mm)\", y = \"Densité\") +\n  facet_wrap(~species, ncol = 1) +\n  scale_fill_brewer(palette = \"Accent\") +\n  theme_bw()\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nÀ ce stade, vous devriez être capables de créer (et d’interpréter !) ce type de graphiques. Si ce n’est pas le cas, consultez d’urgence le chapitre 3 du livre en ligne de Biométrie du semestre 3.\n\n\n\n\n\n\nÀ retenir\n\n\n\n\nla fonction summarise() s’utilise avec des fonctions statistiques qui ne renvoient qu’une valeur (par exemple mean(), median(), sd(), var()…)\nla fonction reframe() s’utilise avec des fonctions statistiques qui renvoient plusieurs valeurs (par exemple quantile(), range()…)"
  },
  {
    "objectID": "06-EDA.html#créer-des-résumés-de-données-avec-des-fonctions-spécifiques",
    "href": "06-EDA.html#créer-des-résumés-de-données-avec-des-fonctions-spécifiques",
    "title": "6  Exploration statistique des données",
    "section": "6.5 Créer des résumés de données avec des fonctions spécifiques",
    "text": "6.5 Créer des résumés de données avec des fonctions spécifiques\nLes fonctions summarise() et reframe(), avec leur argument .by() (ou la fonction group_by()) permettent donc de calculer n’importe quel indice de statistique descriptive sur un tableau de données entier ou sur des modalités ou combinaisons de modalités de facteurs. Il existe par ailleurs de nombreuses fonctions, disponibles de base dans R ou dans certains packages spécifiques, qui permettent de fournir des résumés plus ou moins automatiques de tout ou partie des variables d’un jeu de données. Nous allons en décrire 2 ici, mais il en existe beaucoup d’autres : à vous d’explorer les possibilités et d’utiliser les fonctions qui vous paraissent les plus pertinentes, les plus simples à utiliser, les plus visuelles ou les plus complètes.\n\n6.5.1 La fonction summary()\nLa fonction summary() (à ne pas confondre avec summarise()) permet d’obtenir des résumés de données pour tous types d’objets dans R. Selon la classe des objets que l’on transmets à summary(), la nature des résultats obtenus changera. Nous verrons ainsi au semestre 6 que cette fonction peut être utilisée pour examiner les résultats de modèles de régressions linéaires ou d’analyses de variances. Pour l’instant, nous nous intéressons à 3 situations :\n\nce que renvoie la fonction quand on lui fournit un vecteur\nce que renvoie la fonction quand on lui fournit un facteur\nce que renvoie la fonction quand on lui fournit un tableau\n\n\n6.5.1.1 Variable continue : vecteur numérique\nCommençons par fournir un vecteur numérique à la fonction summary(). Nous allons pour cela extraire les données de masses corporelles des manchots du tableau penguins :\n\npenguins$body_mass_g\n\n  [1] 3750 3800 3250   NA 3450 3650 3625 4675 3475 4250 3300 3700 3200 3800 4400\n [16] 3700 3450 4500 3325 4200 3400 3600 3800 3950 3800 3800 3550 3200 3150 3950\n [31] 3250 3900 3300 3900 3325 4150 3950 3550 3300 4650 3150 3900 3100 4400 3000\n [46] 4600 3425 2975 3450 4150 3500 4300 3450 4050 2900 3700 3550 3800 2850 3750\n [61] 3150 4400 3600 4050 2850 3950 3350 4100 3050 4450 3600 3900 3550 4150 3700\n [76] 4250 3700 3900 3550 4000 3200 4700 3800 4200 3350 3550 3800 3500 3950 3600\n [91] 3550 4300 3400 4450 3300 4300 3700 4350 2900 4100 3725 4725 3075 4250 2925\n[106] 3550 3750 3900 3175 4775 3825 4600 3200 4275 3900 4075 2900 3775 3350 3325\n[121] 3150 3500 3450 3875 3050 4000 3275 4300 3050 4000 3325 3500 3500 4475 3425\n[136] 3900 3175 3975 3400 4250 3400 3475 3050 3725 3000 3650 4250 3475 3450 3750\n[151] 3700 4000 4500 5700 4450 5700 5400 4550 4800 5200 4400 5150 4650 5550 4650\n[166] 5850 4200 5850 4150 6300 4800 5350 5700 5000 4400 5050 5000 5100 4100 5650\n[181] 4600 5550 5250 4700 5050 6050 5150 5400 4950 5250 4350 5350 3950 5700 4300\n[196] 4750 5550 4900 4200 5400 5100 5300 4850 5300 4400 5000 4900 5050 4300 5000\n[211] 4450 5550 4200 5300 4400 5650 4700 5700 4650 5800 4700 5550 4750 5000 5100\n[226] 5200 4700 5800 4600 6000 4750 5950 4625 5450 4725 5350 4750 5600 4600 5300\n[241] 4875 5550 4950 5400 4750 5650 4850 5200 4925 4875 4625 5250 4850 5600 4975\n[256] 5500 4725 5500 4700 5500 4575 5500 5000 5950 4650 5500 4375 5850 4875 6000\n[271] 4925   NA 4850 5750 5200 5400 3500 3900 3650 3525 3725 3950 3250 3750 4150\n[286] 3700 3800 3775 3700 4050 3575 4050 3300 3700 3450 4400 3600 3400 2900 3800\n[301] 3300 4150 3400 3800 3700 4550 3200 4300 3350 4100 3600 3900 3850 4800 2700\n[316] 4500 3950 3650 3550 3500 3675 4450 3400 4300 3250 3675 3325 3950 3600 4050\n[331] 3350 3450 3250 4050 3800 3525 3950 3650 3650 4000 3400 3775 4100 3775\n\n\nNous avons donc 344 valeurs de masses en grammes qui correspondent aux 344 manchots du jeu de données. La fonction summary() renvoie le résumé suivant lorsqu’on lui fournit ces valeurs :\n\nsummary(penguins$body_mass_g)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   2700    3550    4050    4202    4750    6300       2 \n\n\nNous obtenons ici 7 valeurs, qui correspondent respectivement à :\n\nla valeur minimale observée dans le vecteur. Ici, le manchot le plus léger de l’échantillon pèse donc 2700 grammes.\nla valeur du premier quartile du vecteur. Le premier quartile est la valeur qui coupe l’échantillon en 2 groupes : 25% des observations du vecteur sont inférieures au premier quartile, et 75% des observations du vecteur sont supérieures au premier quartile. Ici, 25% des manchots de l’échantillon (soit 86 individus) ont une masse inférieure à 3550 grammes, et 75% des individus de l’échantillon (soit 258 individus) ont une masse supérieure à 3550 grammes.\nla valeur de médiane du vecteur. La médiane est la valeur qui coupe l’échantillon en 2 groupes : 50% des observations du vecteur sont inférieures à la médiane, et 50% des observations du vecteur sont supérieures à la médiane. Ici, 50% des manchots de l’échantillon (soit 172 individus) ont une masse inférieure à 4050 grammes, et 50% des individus de l’échantillon (soit 172 individus) ont une masse supérieure à 4050 grammes.\nla moyenne du vecteur. Ici, les manchots des 3 espèces du jeu de données ont en moyenne une masse 4202 grammes.\nla valeur du troisième quartile du vecteur. Le troisième quartile est la valeur qui coupe l’échantillon en 2 groupes : 75% des observations du vecteur sont inférieures au troisième quartile, et 25% des observations du vecteur sont supérieures au troisième quartile. Ici, 75% des manchots de l’échantillon (soit 258 individus) ont une masse inférieure à 4700 grammes, et 25% des individus de l’échantillon (soit 86 individus) ont une masse supérieure à 4750 grammes.\nla valeur maximale observée dans le vecteur. Ici, le manchot le plus lourd de l’échantillon pèse donc 6300 grammes.\nle nombre de données manquantes. Ici, 2 manchots n’ont pas été pesés et présentent donc la mention NA (comme Not Available) pour la variable body_mass_g.\n\nCette fonction fournit donc 2 indices de plus que la fonction quantile() (la moyenne et le nombre de valeurs manquantes) :\n\nquantile(penguins$body_mass_g, na.rm = TRUE)\n\n  0%  25%  50%  75% 100% \n2700 3550 4050 4750 6300 \n\n\nMais contrairement à ce que nous avons vu plus haut, la fonction summary() ne possède pas d’argument .by() et il n’est pas possible de l’utiliser avec la fonction group_by(). Par conséquent, il n’est pas possible de se servir de cette fonction pour avoir des valeurs pour chaque modalités d’un facteur (pour chaque espèce par exemple).\nLes différents indices statistiques fournis nous renseignent à la fois sur la position de la distribution et sur la dispersion des données.\n\nLa position correspond à la tendance centrale et indique quelles sont les valeurs qui caractérisent le plus grand nombre d’individus. La moyenne et la médiane sont les deux indices de position les plus fréquemment utilisés. Lorsqu’une variable a une distribution parfaitement symétrique, la moyenne et la médiane sont strictement égales. Mais lorsqu’une distribution est asymétrique, la moyenne et la médiane diffèrent. En particulier, la moyenne est beaucoup plus sensible aux valeurs extrêmes que la médiane. Cela signifie que quand une distribution est très asymétrique, la médiane est souvent une meilleure indication des valeurs les plus fréquemment observées.\n\n\n\n\n\n\nFigure 6.3: Distribution des masses corporelles des manchots\n\n\n\n\nL’histogramme de la Figure 6.3 montre la distribution de la taille des manchots (toutes espèces confondues). Cette distribution présente une asymétrie à droite. Cela signifie que la distribution n’est pas symétrique et que la “queue de distribution” est plus longue à droite qu’à gauche. La plupart des individus ont une masse comprise entre 3500 et 3700 grammes, au niveau du pic principal du graphique. La médiane, en orange et qui vaut 4050 grammes est plus proche du pic que la moyenne, en rouge, qui vaut 4202 grammes. Ici, la différence entre moyenne et médiane n’est pas énorme, mais elle peut le devenir si la distribution est vraiment très asymétrique, par exemple, si quelques individus seulement avaient une masse supérieure à 7000 grammes, la moyenne serait tirée vers la droite du graphique alors que la médiane ne serait presque pas affectée. la moyenne représenterait alors encore moins fidèlement la tendance centrale.\nSi l’on revient à la fonction summary(), observer des valeurs proches pour la moyenne et la médiane nous indique donc le degré de symétrie de la distribution.\n\nLa dispersion des données nous renseigne sur la dispersion des points autour des indices de position. Les quartiles et les valeurs minimales et maximales renvoyées par la fonction summary() nous renseignent sur l’étalement des points. Les valeurs situées entre le premier et le troisième quartile correspondent aux 50% des valeurs de l’échantillon les plus centrales. Plus l’étendue entre ces quartiles (notée IQR pour “intervalle interquartile”) sera grande, plus la dispersion sera importante. D’ailleurs, lorsque la dispersion est très importante, les moyennes et médianes ne renseignent que très moyennement sur le tendance centrale. Les indices de position sont surtout pertinents lorsque la dispersion des points autour de cette tendance centrale n’est pas trop large. Par exemple, si la distribution des données ressemblait à ceci (Figure 6.4), la moyenne et la médiane seraient fort peu utiles car très éloignées de la plupart des observations :\n\n\n\n\n\n\nFigure 6.4: Distribution des masses corporelles (données fictives)\n\n\n\n\nOn comprend donc l’importance de considérer les indices de dispersion en plus des indices de position pour caractériser et comprendre une série de données numériques. L’intervalle interquartile est toujours utile pour connaître l’étendue des données qui correspond aux 50% des observations les plus centrales. Les autres indices de dispersion très fréquemment utilisés, mais qui ne sont pas proposés par défaut par la fonction summary(), sont la variance et l’écart-type. Il est possible de calculer tous les indices renvoyés par la fonction summary() et ceux qui nous manquent grâce à la fonction summarise() :\n\npenguins %&gt;% \n  summarise(min = min(body_mass_g, na.rm = TRUE),\n            Q1 = quantile(body_mass_g, 0.25, na.rm = TRUE),\n            med = median(body_mass_g, na.rm = TRUE),\n            moy = mean(body_mass_g, na.rm = TRUE),\n            Q3 = quantile(body_mass_g, 0.75, na.rm = TRUE),\n            max = max(body_mass_g, na.rm = TRUE),\n            var = var(body_mass_g, na.rm = TRUE),\n            et = sd(body_mass_g, na.rm = TRUE))\n\n# A tibble: 1 × 8\n    min    Q1   med   moy    Q3   max     var    et\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1  2700  3550  4050 4202.  4750  6300 643131.  802.\n\n\nVous notez que le code est beaucoup plus long, et qu’utiliser summary() peut donc faire gagner beaucoup de temps, même si cette fonction ne nous fournit ni la variance ni l’écart-type. Mais comme souvent dans R, il est possible de calculer à la main toutes ces valeurs si besoin. Comme indiqué plus haut, les fonctions suivantes peuvent être utilisées :\n\nmean() permet de calculer la moyenne.\nmedian() permet de calculer la médiane.\nmin() et max() permettent de calculer les valeurs minimales et maximales respectivement.\nquantile() permet de calculer les quartiles. Vous notez que contrairement aux exemples de la partie précédente, on utilise ici la fonction quantile() en précisant une valeur supplémentaire pour n’obtenir qu’une valeur à la fois : 0.25 pour le premier quartile, et 0.75 pour le troisième.\nsd() permet de calculer l’écart-type.\nvar() permet de calculer la variance.\n\nPour toutes ces fonctions l’argument na.rm = TRUE permet d’obtenir les résultats même si certaines valeurs sont manquantes. Enfin, la fonction IQR() permet de calculer l’intervalle inter-quartiles :\n\nIQR(penguins$body_mass_g, na.rm = TRUE)\n\n[1] 1200\n\n\nIci, les 50% des valeurs les plus centrales de l’échantillon sont situées dans un intervalle de 1200 grammes autour de la médiane.\n\n\n6.5.1.2 Variable quantitative : facteur\nSi l’on fournit une variable catégorielle ou facteur à summary(), le résultat obtenu sera naturellement différent : calculer des moyennes, médianes ou quartiles n’aurait en effet pas de sens lorsque la variable fournie ne contient que des catégories :\n\nsummary(penguins$species)\n\n   Adelie Chinstrap    Gentoo \n      152        68       124 \n\n\nPour les facteurs, summary() compte simplement le nombre d’observations pour chaque modalité. Ici, la variable species est un facteur qui compte 3 modalités. La fonction summary() nous indique donc le nombre d’individus pour chaque modalité : notre jeu de données se compose de 152 individus de l’espèce Adélie, 68 individus de l’espèce Chinstrap, et 124 individus de l’espèce Gentoo.\nComme pour les vecteurs numériques, si le facteur présente des données manquantes, la fonction summary() compte également leur nombre :\n\nsummary(penguins$sex)\n\nfemale   male   NA's \n   165    168     11 \n\n\nPour les facteurs, la fonction summary() est donc tout à fait équivalente à la fonction count() :\n\npenguins %&gt;% \n  count(species)\n\n# A tibble: 3 × 2\n  species       n\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\nL’avantage de la fonction count() est qu’il est possible d’utiliser plusieurs facteurs pour compter le nombre d’observations de toutes les combinaisons de modalités (par exemple, combien d’individus de chaque sexe pour chaque espèce), ce qui n’est pas possible avec la fonction summary().\n\n\n6.5.1.3 Les tableaux : data.frame ou tibble\nL’avantage de la fonction summary() par rapport à la fonction count() apparaît lorsque l’on souhaite obtenir des informations sur toutes les variables d’un tableau à la fois :\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\n\nIci, on obtient un résumé pour chaque colonne du tableau. Les colonnes numériques sont traitées comme les vecteurs numériques (on obtient alors les minimas et maximas, les quartiles, les moyennes et médianes) et les colonnes contenant des variables catégorielles sont traitées comme des facteurs (et on obtient alors le nombre d’observations pour chaque modalité).\nOn constate au passage que la variable year est considérée ici comme une variable numérique, alors qu’elle devrait plutôt être considérée comme un facteur, ce qui nous permettrait de savoir combien d’individus ont été échantillonnés chaque année :\n\npenguins %&gt;% \n  mutate(year = factor(year)) %&gt;% \n  summary()\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex        year    \n Min.   :172.0     Min.   :2700   female:165   2007:110  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   2008:114  \n Median :197.0     Median :4050   NA's  : 11   2009:120  \n Mean   :200.9     Mean   :4202                          \n 3rd Qu.:213.0     3rd Qu.:4750                          \n Max.   :231.0     Max.   :6300                          \n NA's   :2         NA's   :2                             \n\n\nAu final, la fonction summary() est très utile dans certaines situations, notamment pour avoir rapidement accès à des statistiques descriptives simples sur toutes les colonnes d’un tableau. Elle reste cependant limitée car d’une part, elle ne fournit pas les variances ou les écarts-types pour les variables numériques, et il est impossible d’avoir des résumés plus fins, pour chaque modalité d’un facteur par exemple. Ici, il serait en effet intéressant d’avoir des informations synthétiques concernant les mesures biométriques des manchots, espèce par espèce, plutôt que toutes espèces confondues. C’est là que la fonction skim() intervient.\n\n\n\n6.5.2 La fonction skim()\nLa fonction skim() fait partie du package skimr. Avant de pouvoir l’utiliser, pensez donc à l’installer et à le charger en mémoire si ce n’est pas déjà fait. Comme pour la fonction summary(), on peut utiliser la fonction skim() sur plusieurs types d’objets. Nous nous contenterons d’examiner ici le cas le plus fréquent : celui des tableaux, groupés avec group_by() ou non.\n\n6.5.2.1 Tableau non groupé\nCommençons par examiner le résultat avec le tableau penguins non groupé :\n\nskim(penguins)\n\n\nData summary\n\n\nName\npenguins\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nspecies\n0\n1.00\nFALSE\n3\nAde: 152, Gen: 124, Chi: 68\n\n\nisland\n0\n1.00\nFALSE\n3\nBis: 168, Dre: 124, Tor: 52\n\n\nsex\n11\n0.97\nFALSE\n2\nmal: 168, fem: 165\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nbill_length_mm\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\n▃▇▇▆▁\n\n\nbill_depth_mm\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\n▅▅▇▇▂\n\n\nflipper_length_mm\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\n▂▇▃▅▂\n\n\nbody_mass_g\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\n▃▇▆▃▂\n\n\nyear\n0\n1.00\n2008.03\n0.82\n2007.0\n2007.00\n2008.00\n2009.0\n2009.0\n▇▁▇▁▇\n\n\n\n\n\nLes résultats obtenus grâce à cette fonction sont nombreux. La première section nous donne des informations sur le tableau :\n\nson nom, son nombre de lignes et de colonnes\nla nature des variables qu’il contient (ici 3 facteurs et 5 variables numériques)\nla présence de variables utilisées pour faire des regroupements (il n’y en a pas encore à ce stade)\n\nEnsuite, un bloc apporte des information sur chaque facteur présent dans le tableau :\n\nle nom de la variable catégorielle (skim_variable)\nle nombre de données manquantes (n_missing) et le taux de “données complètes” (complete_rate)\ndes informations sur le nombre de modalités (n_unique)\nle nombre d’observations pour les modalités les plus représentées (top_counts)\n\nEn un coup d’œil, on sait donc que 3 espèces sont présentes (et on connait leurs effectifs), on sait que les manchots ont été échantillonnées sur 3 îles, et on sait que le sexe de 11 individu (sur 344) est inconnu. Pour le reste, il y a presque autant de femelles que de mâles.\nLe dernier bloc renseigne sur les variables numériques. Pour chaque d’elle, on a :\n\nle nom de la variable numérique (skim_variable)\nle nombre de données manquantes (n_missing) et le taux de “données complètes” (complete_rate)\nla moyenne (mean) et l’écart-type (sd), ce qui est une nouveauté par rapport à la fonction summary()\nles valeurs minimales (p0), de premier quartile (p25), de second quartile (p50, c’est la médiane !), de troisième quartile (p75) et la valeur maximale (p100)\nun histogramme très simple qui donne un premier aperçu grossier de la forme de la distribution\n\nLà encore, en un coup d’œil, on dispose donc de toutes les informations pertinentes pour juger de la distribution, de la position et de la dispersion de chaque variable numérique du jeu de données.\n\n\n6.5.2.2 Tableau groupé\nLa fonction skim(), déjà très pratique, le devient encore plus lorsque l’on choisit de lui fournir seulement certaines variables, et qu’on fait certains regroupements. Par exemple, on peut sélectionner les variables relatives aux dimensions du bec (bill_length_mm et bill_depth_mm) avec la fonction select() que nous connaissons déjà, et demander un résumé des données pour chaque espèce grâce à la fonction group_by() que nous connaissons également :\n\npenguins %&gt;%                     # Avec le tableau penguins...\n  select(species, \n         bill_length_mm,\n         bill_depth_mm) %&gt;%      # Je sélectionne les variables d'intérêt...\n  group_by(species) %&gt;%          # Je regroupe par espèce...\n  skim()                         # Et je produis un résumé des données\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n344\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nspecies\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nspecies\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nbill_length_mm\nAdelie\n1\n0.99\n38.79\n2.66\n32.1\n36.75\n38.80\n40.75\n46.0\n▁▆▇▆▁\n\n\nbill_length_mm\nChinstrap\n0\n1.00\n48.83\n3.34\n40.9\n46.35\n49.55\n51.08\n58.0\n▂▇▇▅▁\n\n\nbill_length_mm\nGentoo\n1\n0.99\n47.50\n3.08\n40.9\n45.30\n47.30\n49.55\n59.6\n▃▇▆▁▁\n\n\nbill_depth_mm\nAdelie\n1\n0.99\n18.35\n1.22\n15.5\n17.50\n18.40\n19.00\n21.5\n▂▆▇▃▁\n\n\nbill_depth_mm\nChinstrap\n0\n1.00\n18.42\n1.14\n16.4\n17.50\n18.45\n19.40\n20.8\n▅▇▇▆▂\n\n\nbill_depth_mm\nGentoo\n1\n0.99\n14.98\n0.98\n13.1\n14.20\n15.00\n15.70\n17.3\n▅▇▇▆▂\n\n\n\n\n\nOn constate ici que pour chaque variable numérique sélectionnée, des statistiques descriptives détaillées nous sont fournies pour chacune des 3 espèces. Ce premier examen semble montrer que :\n\nL’espèce Adélie est celle qui possède le bec le plus court (ses valeurs de moyennes, médianes et quartiles sont plus faibles que celles des 2 autres espèces).\nL’espèce Gentoo est celle qui possède le bec le plus fin, ou le moins épais (ses valeurs de moyennes, médianes et quartiles sont plus faibles que celles des 2 autres espèces)\nIl ne semble pas y avoir de fortes différences d’écarts-types (donc des dispersions des points autour des moyennes) entre les 3 espèces : pour chacune des 2 variables numériques, des valeurs d’écarts-types comparables sont en effet observées pour les 3 espèces\nLa distribution des 2 variables numériques semble approximativement suivre une distribution symétrique pour les 3 espèces, avec une forme de courbe en cloche. Les distributions devraient donc suivre à peu une distribution normale\n\n\n\n\n\n\n\nNote\n\n\n\nVous comprenez j’espère l’importance d’examiner ce genre de résumé des données avant de vous lancer dans des tests statistiques. Ils sont un complément indispensable aux explorations graphiques que vous devez également prendre l’habitude de réaliser pour mieux appréhender et comprendre la nature de vos données. Puisque chaque jeu de données est unique, vous devrez vous adapter à la situation et aux questions scientifiques qui vous sont posées (ou que vous vous posez !) : les choix qui seront pertinents pour une situation ne le seront pas nécessairement pour une autre. Mais dans tous les cas, pour savoir où vous allez et pour ne pas faire de bêtise au moment des tests statistiques et de leur interprétation, vous devrez toujours explorer vos données, avec des graphiques exploratoires et des statistiques descriptives(.\n\n\n\n\n\n6.5.3 Exercice\nEn utilisant les fonctions de résumé abordées jusqu’ici et le tableau weather, répondez aux questions suivante :\n\nDans quel aéroport de New York les précipitations moyennes ont-elle été les plus fortes en 2013 ?\nDans quel aéroport de New York la vitesse du vent moyenne était-elle la plus forte en 2013 ? Quelle est cette vitesse ?\nDans quel aéroport de New York les rafales de vent étaient-elles les plus variables en 2013 ? Quel indice statistique vous donne cette information et quelle est sa valeur ?\nLes précipitation dans les 3 aéroports de New-York ont-elles une distribution symétrique ?\nQuelle est la température médiane observée en 2013 tous aéroports confondus ?\nTous aéroports confondus, quel est le mois de l’année où la température a été la plus variable en 2013 ? Quelles étaient les températures minimales et maximales observées ce mois-là ?\n\n\n\n\n\nHorst, Allison, Alison Hill, et Kristen Gorman. 2022. palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nWaring, Elin, Michael Quinn, Amelia McNamara, Eduardo Arino de la Rubia, Hao Zhu, et Shannon Ellis. 2022. skimr: Compact and Flexible Summaries of Data. https://CRAN.R-project.org/package=skimr.\n\n\nWickham, Hadley. 2021. nycflights13: Flights that Departed NYC in 2013. https://github.com/hadley/nycflights13.\n\n\n———. 2023. tidyverse: Easily Install and Load the Tidyverse. https://CRAN.R-project.org/package=tidyverse.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, et Dewey Dunnington. 2023. ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, et Davis Vaughan. 2023. dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, et Jennifer Bryan. 2023. readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWickham, Hadley, Davis Vaughan, et Maximilian Girlich. 2023. tidyr: Tidy Messy Data. https://CRAN.R-project.org/package=tidyr."
  },
  {
    "objectID": "01-R-basics.html#préambule",
    "href": "01-R-basics.html#préambule",
    "title": "1  R et RStudio : les bases",
    "section": "1.1 Préambule",
    "text": "1.1 Préambule\nAvant de commencer à explorer des données dans R, il y a plusieurs concepts clés qu’il faut comprendre en premier lieu :\n\nQue sont R et RStudio ?\nComment s’y prend-on pour coder dans R ?\nQue sont les packages ?\n\nMême si vous pensez être déjà à l’aise avec ces concepts, lisez attentivement ce chapitre et faites les exercices demandés. Cela vous rafraîchira probablement la mémoire, et il n’est pas impossible que vous appreniez une chose ou deux au passage. Une bonne maîtrise des éléments présentés dans ce chapitre est indispensable pour aborder sereinement les chapitres suivants, à commencer par le Chapitre 2, qui présente un jeu de données que nous explorerons en détail un peu plus tard. Lisez donc attentivement ce chapitre et faites bien tous les exercices demandés.\nCe chapitre est en grande partie basé sur les 3 ressources suivantes que je vous encourage à consulter si vous souhaitez obtenir plus de détails :\n\nL’ouvrage intitulé ModernDive, de Chester Ismay et Albert Y. Kim. Une bonne partie de ce livre est très largement inspirée de cet ouvrage. C’est en anglais, mais c’est un très bon texte d’introduction aux statistiques sous R et RStudio.\nL’ouvrage intitulé Getting used to R, RStudio, and R Markdown de Chester Ismay, comprend des podcasts (en anglais toujours) que vous pouvez suivre en apprenant.\nLes tutoriels en ligne de DataCamp. DataCamp est une plateforme de e-learning accessible depuis n’importe quel navigateur internet et dont la priorité est l’enseignement des “data sciences”. Leurs tutoriels vous aideront à apprendre certains des concepts de développés dans ce livre.\n\n\n\n\n\n\n\nImportant\n\n\n\nAvant d’aller plus loin, rendez-vous sur le site de DataCamp, créez-vous un compte gratuit, et reprenez la lecture de ce livre."
  },
  {
    "objectID": "01-R-basics.html#que-sont-r-et-rstudio",
    "href": "01-R-basics.html#que-sont-r-et-rstudio",
    "title": "1  R et RStudio : les bases",
    "section": "1.2 Que sont R et RStudio ?",
    "text": "1.2 Que sont R et RStudio ?\nPour l’ensemble de ces TP, j’attends de vous que vous utilisiez R via RStudio. Les utilisateurs novices confondent souvent les deux. Pour tenter une analogie simple :\n\nR est le moteur d’une voiture\nRStudio est l’habitacle, le tableau de bord, les pédales…\n\nSi vous n’avez pas de moteur, vous n’irez nulle part. En revanche, un moteur sans tableau de bord est difficile à manœuvrer. Il est en effet beaucoup plus simple de faire avancer une voiture depuis l’habitacle, plutôt qu’en actionnant à la main les câbles et leviers du moteur.\nEn l’occurrence, R est un langage de programmation capable de produire des graphiques et de réaliser des analyses statistiques, des plus simples aux plus complexes. RStudio est un “emballage” qui rend l’utilisation de R plus aisée. RStudio est ce qu’on appelle un IDE ou “Integrated Development Environment”. On peut utiliser R sans RStudio, mais c’est nettement plus compliqué, nettement moins pratique.\n\n1.2.1 Installation\n\n\n\n\n\n\nAvertissement\n\n\n\nSi vous travaillez exclusivement sur les ordinateurs de l’Université, vous pouvez passer cette section. En revanche, si vous souhaitez utiliser R et RStudio sur votre ordinateur personnel, alors lisez attentivement la suite !\n\n\nAvant tout, vous devez télécharger et installer R, puis RStudio, dans cet ordre :\n\nTéléchargez et installez R\n\n\nVous devez installer ce logiciel en premier.\nCliquez sur le lien de téléchargement qui correspond à votre système d’exploitation, puis, sur “base”, si vous êtes sous Windows, sur “R-4.3.1-x86_64.pkg” si vous êtes sous Mac avec processeur Intel, ou sur R-4.3.1-arm64.pkg si vous êtes sous Mac avec processeur M1 ou M2 (sous Mac, cliquez sur le Menu , puis sur “À propos de ce Mac” et regardez à la rubrique “Processeur”), et suivez les instructions.\n\n\nTéléchargez et installez RStudio\n\n\nCliquez sur “RStudio Desktop”, puis sur “Download RStudio Desktop”.\nChoisissez la version gratuite et cliquez sur le lien de téléchargement qui correspond à votre système d’exploitation.\n\n\n\n1.2.2 Utiliser R depuis RStudio\nPuisqu’il est beaucoup plus facile d’utiliser Rstudio pour interagir avec R, nous utiliserons exclusivement l’interface de RStudio. Après les installations réalisées à la Section 1.2.1, vous disposez de 2 nouveaux logiciels sur votre ordinateur. RStudio ne peut fonctionner sans R, mais nous travaillerons exclusivement dans RStudio :\n\nR, ne pas ouvrir ceci :   \nRStudio, ouvrir cela : \n\nÀ l’université, vous trouverez RStudio dans le menu Windows, à condition d’être connecté à la machine virtuelle bio. Quand vous ouvrez RStudio pour la première fois, vous devriez obtenir une fenêtre qui ressemble à ceci :\n\nPrenez le temps d’explorer cette interface, cliquez sur les différents onglets, ouvrez les menus, allez faire un tour dans les préférences du logiciel pour découvrir les différents panneaux de l’application, en particulier la Console dans laquelle nous exécuterons très bientôt du code R."
  },
  {
    "objectID": "01-R-basics.html#sec-code",
    "href": "01-R-basics.html#sec-code",
    "title": "1  R et RStudio : les bases",
    "section": "1.3 Comment exécuter du code R ?",
    "text": "1.3 Comment exécuter du code R ?\nContrairement à d’autres logiciels comme Excel, STATA ou SAS qui fournissent des interfaces où tout se fait en cliquant avec sa souris, R est un langage interprété, ce qui signifie que vous devez taper des commandes, écrites en code R. C’est-à-dire que vous devez programmer en R (j’utilise les termes “coder” et “programmer” de manière interchangeable dans ce livre).\nIl n’est pas nécessaire d’être un programmeur pour utiliser R, néanmoins, il est nécessaire de programmer ! Il existe en effet un ensemble de concepts de programmation de base que les utilisateurs de R doivent comprendre et maîtriser. Et progresser en programmation vous permettra d’automatiser de plus en plus de choses, et donc, à terme, de gagner beaucoup de temps. Par conséquent, bien que ce livre ne soit pas un livre sur la programmation, vous en apprendrez juste assez en programmation pour explorer et analyser efficacement des données.\n\n1.3.1 La console\nLa façon la plus simple d’interagir avec RStudio (mais pas du tout la meilleure !) consiste à taper directement des commandes que R pourra comprendre dans la Console.\nCliquez dans la console (après le symbole &gt;) et tapez ceci, sans oublier de valider en tapant sur la touche Entrée :\n\n3 + 8\n\n[1] 11\n\n\nFélicitations, vous venez de taper votre première instruction R : vous savez maintenant faire des additions !\nDans la version en ligne de ce livre (en html), à chaque fois que du code R sera fourni, il apparaîtra dans un cadre grisé avec une ligne bleue à gauche, comme ci-dessus. Vous pourrez toujours taper dans RStudio, les commandes qui figurent dans ces blocs de code, afin d’obtenir vous même les résultats souhaités. Dans ce livre, lorsque les commandes R produisent des résultats, ils sont affichés juste en dessous des blocs de code. Enfin, en passant la souris sur les blocs de code, vous verrez apparaître, à droite, une icône de presse-papier qui vous permettra de copier-coller les commandes du livre dans la console de RStudio ou, très bientôt, dans vos scripts.\n\n\n\n\n\n\nLes risques du “copier-coller” \n\n\n\nAttention : il est fortement conseillé de réserver les copier-coller aux blocs de commandes de (très) grande taille, ou en cas d’erreur de syntaxe inexplicable. L’expérience a en effet montré qu’on apprend beaucoup mieux en tapant soi-même les commandes. Ça n’est que comme cela que l’on peut prendre conscience de toutes les subtilités du langage (par exemple, faut-il mettre une virgule ou un point, une parenthèse ou un crochet, le symbole moins ou un tilde, etc.). Je vous conseille donc de taper vous-même les commandes autant que possible.\n\n\n\n\n1.3.2 Les scripts\nTaper du code directement dans la console est probablement la pire façon de travailler dans RStudio. Cela est parfois utile pour faire un rapide calcul, ou pour vérifier qu’une commande fonctionne correctement. Mais la plupart du temps, vous devriez taper vos commandes dans un script.\n\n\n\n\n\n\nDéfinition importante !\n\n\n\nUn script est un fichier au format “texte brut” (cela signifie qu’il n’y a pas de mise en forme et que ce fichier peut-être ouvert par n’importe quel éditeur de texte, y compris les plus simples comme le bloc notes de Windows), dans lequel vous pouvez taper :\n\ndes instructions qui seront comprises par R comme si vous les tapiez directement dans la console\ndes lignes de commentaires, qui doivent obligatoirement commencer par le symbole #.\n\n\n\nLes avantages de travailler dans un script sont nombreux :\n\nVous pouvez sauvegarder votre script à tout moment (vous devriez prendre l’habitude de le sauvegarder très régulièrement). Vous gardez ainsi la trace de toutes les commandes que vous avez tapées.\nVous pouvez aisément partager votre script pour collaborer avec vos collègues de promo et enseignants.\nVous pouvez documenter votre démarche et les différentes étapes de vos analyses. Vous devez ajouter autant de commentaires que possible. Cela permettra à vos collaborateurs de comprendre ce que vous avez fait. Et dans 6 mois, cela vous permettra de comprendre ce que vous avez fait. Si votre démarche vous paraît cohérente aujourd’hui, il n’est en effet pas garanti que vous vous souviendrez de chaque détail quand vous vous re-plongerez dans vos analyses dans quelques temps. Donc aidez-vous vous même en commentant vos scripts dès maintenant.\nUn script bien structuré, bien indenté (avec les bons retours à la ligne, des sauts de lignes, des espaces, bref, de l’air) et clair permet de rendre vos analyses répétables. Si vous passez 15 heures à analyser un tableau de données précis, il vous suffira de quelques secondes pour analyser un nouveau jeu de données similaire : vous n’aurez que quelques lignes à modifier dans votre script original pour l’appliquer à de nouvelles données.\n\nVous pouvez créer un script en cliquant dans le menu “File &gt; New File &gt; R Script”. Un nouveau panneau s’ouvre dans l’application. Pensez à sauvegarder immédiatement votre nouveau script en cliquant dans le menu “File &gt; Save” ou “File &gt; Save as…”. Il faut pour cela lui donner un nom et choisir un emplacement sur votre disque dur.\n\n\n\n\n\n\nOù sauvegarder vos scripts ? \n\n\n\nJe vous encourage vivement à créer, sur votre disque dur, un nouveau dossier spécifique, que vous nommerez par exemple Data_Analysis. Il est important que le nom de ce dossier ne contienne pas de caractères spéciaux (e.g. accents, cédilles, apostrophes, espaces, etc.). Ce dossier devrait être facilement accessible : vous y enregistrerez tous vos scripts, vos jeux de données, vos graphiques, etc.\nSi vous travaillez sur les ordinateurs de l’université, créez obligatoirement votre dossier sur le disque W:\\. Il s’agit de votre espace personnel sur le réseau de l’université. Cela vous garantit que vous retrouverez votre script la prochaine fois, même si vous utilisez un ordinateur différent.\n\n\nÀ partir de maintenant, vous ne devriez plus taper de commande directement dans la console. Tapez systématiquement vos commandes dans un script et sauvegardez-le régulièrement.\nPour exécuter les commandes du script dans la console, il suffit de placer le curseur sur la ligne contenant la commande et de presser les touches ctrl + enter (ou command + enter sous macOS). Si un message d’erreur s’affiche dans la console, c’est que votre instruction était erronée. Modifiez la directement dans votre script et pressez à nouveau les touches ctrl + enter (ou command + enter sous macOS) pour tenter à nouveau votre chance. Idéalement, votre script ne devrait contenir que des commandes qui fonctionnent et des commentaires expliquant à quoi servent ces commandes.\nVoici un exemple de script que je ne vous demande pas de reproduire. Lisez simplement attentivement son contenu :\n\n# Penser à installer le package ggplot2 si besoin\n# install.packages(\"ggplot2\")\n\n# Chargement du package\nlibrary(ggplot2)\n\n# Mise en mémoire des données de qualité de l'air à New-York de mai à\n# septembre 1973\ndata(airquality)\n\n# Affichage des premières lignes du tableau de données\nhead(airquality)\n\n# Quelle est la structure de ce tableau ?\nstr(airquality)\n\n# Réalisation d'un graphique présentant la relation entre la concentration\n# en ozone atmosphérique en ppb et la température en degrés Fahrenheit\nggplot(data = airquality, mapping = aes(x = Temp, y = Ozone)) +\n  geom_point() +\n  geom_smooth(method = \"loess\")\n\n# On constate une augmentation importante de la concentration d'ozone \n# pour des températures supérieures à 75ºF\n\nMême si vous ne comprenez pas encore les commandes qui figurent dans ce script (ça viendra !), voici ce que vous devez en retenir :\n\nLe script contient plus de lignes de commentaires que de commandes R.\nChaque étape de l’analyse est décrite en détail.\nLes 2 dernières lignes du script décrivent les résultats obtenus (ici, un graphique).\nSeules des commandes pertinentes et qui fonctionnent ont été conservées dans ce script.\nChaque ligne de commentaire commence par #. Il est ainsi possible de conserver certaines commandes R dans le script, “pour mémoire”, sans pour autant qu’elle ne soient exécutées. C’est le cas pour la ligne # install.packages(\"ggplot2\").\n\nSi j’exécute ce script dans la console de RStudio (en sélectionnant toutes les lignes et en pressant les touches ctrl + enter ou command + enter sous macOS), voilà ce qui est produit :\n\n\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1\n2    36     118  8.0   72     5   2\n3    12     149 12.6   74     5   3\n4    18     313 11.5   62     5   4\n5    NA      NA 14.3   56     5   5\n6    28      NA 14.9   66     5   6\n\n\n'data.frame':   153 obs. of  6 variables:\n $ Ozone  : int  41 36 12 18 NA 28 23 19 8 NA ...\n $ Solar.R: int  190 118 149 313 NA NA 299 99 19 194 ...\n $ Wind   : num  7.4 8 12.6 11.5 14.3 14.9 8.6 13.8 20.1 8.6 ...\n $ Temp   : int  67 72 74 62 56 66 65 59 61 69 ...\n $ Month  : int  5 5 5 5 5 5 5 5 5 5 ...\n $ Day    : int  1 2 3 4 5 6 7 8 9 10 ...\n\n\n\n\n\n\n\n1.3.3 Les projets, ou Rprojects\nPour travailler le plus efficacement possible avec RStudio, vous devriez créer, à l’intérieur de votre dossier de travail, un nouveau fichier très particulier, qui s’appelle, dans le jargon de RStudio, un Rproject.\nPour le créer, cliquez simplement dans le Menu “File &gt; New Project…”. Cette boîte de dialogue devrait apparaître :\n\n\n\n\n\nChoisissez “Existing Directory”, puis, dans la boîte de dialogue suivante :\n\n\n\n\n\ncliquez sur “Browse…”, naviguez jusqu’au dossier que vous avez créé plus tôt sur votre disque dur et qui contient votre script, puis cliquez sur “Create Project”. La fenêtre de RStudio se ferme, puis une nouvelle fenêtre vierge apparaît. En apparence, rien n’a changé ou presque. Pourtant :\n\nen haut à droite de la fenêtre de RStudio, le logiciel indique maintenant que vous êtes bel et bien à l’intérieur d’un Rproject. Au lieu de Project: (None), on lit maintenant le nom du Rproject (chez moi, Data_Analysis)\ndans le quart inférieur droit de l’interface, l’onglet “Files” ne présente plus le même aspect. Avant de créer le Rproject, cet onglet présentait le chemin vers le dossier utilisé par défaut par le logiciel, ainsi que son contenu. Il s’agissait d’un dossier système auquel il vaut mieux ne pas toucher pour éviter les problèmes. Après la création du Rproject, l’onglet “Files” indique le contenu du dossier contenant le projet. Autrement dit, c’est ici que vous trouverez vos scripts, tableaux de données dans différents formats, figures sauvegardées, etc. Dans cet onglet, vous pouvez donc cliquer sur le nom de votre script pour l’ouvrir à nouveau, le modifier, l’exécuter…\n\n\n\n\n\n\n\nSans Rproject\n\n\n\n\n\n\n\nAvec RProject\n\n\n\n\n\n\nun nouveau fichier portant l’extension .Rproj a été créé dans votre dossier de travail. La prochaine fois que vous voudrez travailler dans RStudio, il vous suffira de double-cliquer sur ce fichier dans l’explorateur de fichier de Windows ou le Finder de MacOS, pour que RStudio s’ouvre, et que vous retrouviez tous vos fichiers et scripts de la fois précédente\n\n\n\n\n\n\nPour vérifier que tout s’est bien passé jusqu’ici, tapez la commande suivante dans votre script puis envoyez-la dans la console en pressant les touches ctrl + entrée (ou command + entrée sous MacOS).\n\ngetwd()\n\nRStudio doit vous afficher, dans la console, le chemin jusqu’à votre répertoire de travail ou “Working Directory” en anglais (getwd() est l’abréviation de “GET Working Directory”). Si tout s’est bien passé, ce chemin doit être celui du dossier qui contient votre script et le fichier .Rproj que vous venez de créer. Si ce n’est pas le cas, reprenez calmement toutes les étapes décrites depuis le début de la Section 1.3.2. Si ça ne fonctionne toujours pas, contactez-moi sur Slack.\n\n\n\n\n\n\nPour résumer… \n\n\n\nLes Rprojects sont un moyen très pratique de travailler efficacement dans RStudio car ils permettent de gérer facilement la question du répertoire de travail. Lorsque vous envisagez de travailler sur un nouveau sujet/projet/jeu de données/compte-rendu de TP…, les étapes à suivre, pour vous mettre dans une configuration idéale qui vous évitera bien des problèmes par la suite, sont donc les suivantes :\n\nSur votre ordinateur, créez un nouveau dossier avec un nom simple, et à un endroit facile d’accès (pas de caractères spéciaux dans le chemin du dossier si possible)\nDémarrez RStudio\nDans le logiciel, cliquez dans le menu “File &gt; New Project…”\nChoisissez “Existing Directory”, puis naviguez jusqu’au dossier que vous venez de créer\nCliquez sur “Create Project”\nCréer un nouveau script (menu “File &gt; New File &gt; R script”)\nDonnez un nom à votre script (menu “File &gt; Save As…”) pour le sauvegarder. Par défaut, RStudio vous propose d’enregistrer votre script dans le dossier de votre Rproject, ce qui est parfait.\nTapez getwd() dans votre script et exécutez cette commande en l’envoyant dans la console.\n\nSi le chemin qui s’affiche est celui du dossier contenant votre Rproject et votre script, félicitation, vous êtes prêt·e à travailler. Avec un peu d’habitude, ces étapes ne prennent qu’une à deux minutes.\n\n\n\n\n1.3.4 Concepts de base en programmation et terminologie\nAprès ces considérations techniques sur l’utilisation et les réglages de RStudio, nous entrons maintenant dans le vif du sujet avec la découverte des premiers éléments de syntaxe du langage R.\n\n1.3.4.1 Objets, types, vecteurs, facteurs et tableaux de données\nPour vous présenter les concepts de base et la terminologie de la programmation dont nous aurons besoin, vous allez suivre des tutoriels en ligne sur le site de DataCamp. Pour cette première prise en main, tout va maintenant se passer dans votre navigateur internet, et vous pouvez donc mettre de côté RStudio pour l’instant. Vous allez voir que l’interface de DataCamp ressemble à une version simplifiée de l’éditeur de script et de la console de RStudio : vous n’aurez pas à vous soucier des réglages, de Rprojects ou de sauvegarder quoi que ce soit. Si vous avez correctement créé votre compte gratuit DataCamp comme indiqué au tout début de la Chapitre 1, votre progression sera sauvegardée automatiquement. Il vous suffit de cliquer sur les liens direct ci-dessous pour démarrer les tutoriels en ligne.\nAvant de démarrer, quelques précisions :\n\npour chaque tutoriel que je vous demande de suivre, j’indique ci-dessous une liste des concepts de programmation qui sont couverts. N’hésitez pas à vous y référer (et à y revenir) tout au long du semestre si vous avez oublié certaines choses\nce tutoriel DataCamp contient 6 chapitres. Seuls les chapitres 1, 2, 4, et 5 doivent être suivis. Nous ne travaillerons pas sur les matrices ni sur les listes\nà la fin de chaque chapitre du tutoriel, revenez à ce livre en ligne pour cliquer sur le lien direct ver le chapitre suivant. Procéder ainsi vous évitera de suivre des chapitres inutiles du tutoriel, et cela vous permettra également d’éviter les demandes d’inscriptions payantes à DataCamp\n\nIl est important de noter que, bien que ces tutoriels sont d’excellentes introductions, une lecture seule, même attentive, est insuffisante pour un apprentissage en profondeur et une rétention à long terme. Il faut pour cela pratiquer et répéter. Outre les exercices demandés dans DataCamp, que vous devez effectuer directement dans votre navigateur, je vous encourage à prendre des notes, à multiplier les essais, directement dans la console de RStudio, ou, de préférence, dans un script que vous annoterez, pour vous assurer que vous avez bien compris chaque partie.\nAllez maintenant découvrir le cours d’introduction à R sur DataCamp, et cliquez sur les liens des chapitres ci-dessous. Au fur et à mesure de votre travail, notez les termes importants et ce à quoi ils font référence.\n\nChapitre 1 : introduction\n\nLa console : l’endroit où vous tapez des commandes\nLes objets : où les valeurs sont stockées, comment assigner des valeurs à des objets\nLes types de données : entiers, doubles/numériques, caractères et logiques\n\nChapitre 2 : vecteurs\n\nLes vecteurs : des collections de valeurs du même type\n\nChapitre 4 : les facteurs\n\nDes données catégorielles (et non pas numériques) représentées dans R sous forme de factors\n\nChapitre 5 : les jeux de données ou data.frame\n\nLes data.frames sont similaires aux feuilles de calcul rectangulaires que l’on peut produire dans un tableur. Dans R, ce sont des objets rectangulaires (des tableaux !) contenant des jeux de données : les lignes correspondent aux observations et les colonnes aux variables décrivant les observations. La plupart du temps, c’est le format de données que nous utiliserons. Plus de détails dans le Chapitre 2\n\n\nAvant de passer à la suite, il nous reste 2 grandes notions à découvrir dans le domaine du code et de la syntaxe afin de pouvoir travailler efficacement dans R : les opérateurs de comparaison d’une part, et les fonctions d’autre part. Pour les découvrir et expérimenter, et puisque vous avez terminé les tutoriels DataCamp, reprenez maintenant RStudio et travaillez dans votre script.\n\n\n1.3.4.2 Opérateurs de comparaison\nComme leur nom l’indique, ils permettent de comparer des valeurs ou des objets. Les principaux opérateurs de comparaison sont :\n\n== : égal à\n!= : différent de\n&gt; : supérieur à\n&lt; : inférieur à\n&gt;= : supérieur ou égal à\n&lt;= : inférieur ou égal à\n\nAinsi, on peut tester si 3 est égal à 5 :\n\n3 == 5\n\n[1] FALSE\n\n\nLa réponse est bien entendu FALSE. Est-ce que 3 est inférieur à 5 ?\n\n3 &lt; 5\n\n[1] TRUE\n\n\nLa réponse est maintenant TRUE. Lorsque l’on utilise un opérateur de comparaison, la réponse est toujours soit vrai (TRUE), soit faux (FALSE).\nIl est aussi possible de comparer des chaînes de charactères :\n\n\"Bonjour\" == \"Au revoir\"\n\n[1] FALSE\n\n\"Bonjour\" &gt;= \"Au revoir\"\n\n[1] TRUE\n\n\nManifestement, “Bonjour” est supérieur ou égal à “Au revoir”. En fait, R utilise l’ordre alphabétique pour comparer les chaînes de caractères. Puisque dans l’alphabet, le “B” de “Bonjour” arrive après le “A” de “Au revoir”, pour R, “Bonjour” est supérieur à “Au revoir”.\nIl est également possible d’utiliser ces opérateurs pour comparer un chiffre et un vecteur :\n\ntailles_pop1 &lt;- c(112, 28, 86, 14, 154, 73, 63, 48)\ntailles_pop1 &gt; 80\n\n[1]  TRUE FALSE  TRUE FALSE  TRUE FALSE FALSE FALSE\n\n\nIci, l’opérateur nous permet d’identifier quels éléments du vecteur taille_pop1 sont supérieurs à 80. Il s’agit des éléments placés en première, troisième et cinquième positions.\nIl est aussi possible de comparer 2 vecteurs qui contiennent le même nombre d’éléments :\n\ntailles_pop2 &lt;- c(114, 27, 38, 91, 54, 83, 33, 68)\ntailles_pop1 &gt; tailles_pop2\n\n[1] FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE FALSE\n\n\nLes comparaisons sont ici faites élément par élément. Ainsi, les observations 2, 3, 5 et 7 du vecteur tailles_pop1 sont supérieures aux observations 2, 3, 5 et 7 du vecteur tailles_pop2 respectivement.\nCes vecteurs de vrais/faux sont très utiles car ils peuvent permettre de compter le nombre d’éléments répondant à une certains condition :\n\nsum(tailles_pop1 &gt; tailles_pop2)\n\n[1] 4\n\n\nLorsque l’on effectue une opération arithmétique (comme le calcul d’une somme ou d’une moyenne) sur un vecteur de vrais/faux, les TRUE sont remplacés par 1 et les FALSE par 0. La somme nous indique donc le nombre de vrais dans un vecteur de vrais/faux, et la moyenne nous indique la proportion de vrais :\n\nmean(tailles_pop1 &gt; tailles_pop2)\n\n[1] 0.5\n\n\nNote : Attention, si les vecteurs comparés n’ont pas la même taille, un message d’avertissement est affiché :\n\ntailles_pop3 &lt;- c(43, 56, 92)\ntailles_pop1\n\n[1] 112  28  86  14 154  73  63  48\n\ntailles_pop3\n\n[1] 43 56 92\n\ntailles_pop3 &gt; tailles_pop1\n\nWarning in tailles_pop3 &gt; tailles_pop1: la taille d'un objet plus long n'est\npas multiple de la taille d'un objet plus court\n\n\n[1] FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE\n\n\nIci, R renvoie un résultat, accompagné d’un message d’avertissement qui nous indique que tout ne s’est probablement pas déroulé comme on le pensait. Dans un cas comme celui là, R va en effet recycler l’objet le plus court, ici tailles_pop3 pour qu’une comparaison puisse être faite avec chaque élément de l’objet le plus long (ici, tailles_pop1). Ainsi, 43 est comparé à 112, 56 est comparé à 28 et 92 est comparé à 86. Puisque tailles_pop3 ne contient plus d’éléments, ils sont recyclés, dans le même ordre : 43 est comparé à 14, 56 est comparé à 154, et ainsi de suite jusqu’à ce que tous les éléments de tailles_pop1 aient été passés en revue.\nCe type de recyclage est très risqué car il est difficile de savoir ce qui a été comparé avec quoi. En travaillant avec des tableaux plutôt qu’avec des vecteurs, le problème est généralement évité puisque toutes les colonnes d’un data.frame contiennent le même nombre d’éléments.\n\n\n\n\n\n\nErreur ou avertissement ?  ou  ?\n\n\n\nIl ne faut pas confondre message d’erreur et message d’avertissement :\n\nUn message d’erreur commence généralement par Error ou Erreur et indique que R n’a pas compris ce que vous lui demandiez. Il n’a donc pas été en mesure de faire quoi que ce soit et votre commande n’a donc pas été exécutée. Vous devez absolument revenir à votre code et corriger la commande fautive car il y a fort à parier que si vous ne le faites pas, les commandes suivantes renverrons à leur tour un message d’erreur. Il est donc important de toujours revenir à la première erreur d’un script et de la corriger avant de passer à la suite.\nUn message d’avertissement commence généralement par Warning et vous indique que quelque chose d’inhabituel, ou de “non-optimal” a été réalisé. Un résultat a été produit, mais peut-être n’est-il pas conforme à ce que vous attendiez. La prudence est donc requise.\n\nDans les deux cas, un message explique de façon plus ou moins claire ce qui a posé problème. Progresser dans la maîtrise du logiciel et du langage signifie en grande partie progresser dans la compréhension de la signification de ces messages parfois obscures. Pour progresser, il faut donc commencer par lire attentivement ces messages, et tenter de comprendre ce qu’ils veulent dire.\n\n\nDernière chose concernant les opérateurs de comparaison : la question des données manquantes. Dans R les données manquantes sont symbolisées par cette notation : NA, abréviation de “Not Available”. Le symbole NaN (comme “Not a Number”) est parfois aussi observé lorsque des opérations ont conduit à des indéterminations. Mais c’est plus rare et la plupart du temps, les NaNs peuvent être traités comme les NAs. L’un des problèmes des données manquantes est qu’il est nécessaire de prendre des précautions pour réaliser des comparaisons les impliquant :\n\n3 == NA\n\n[1] NA\n\n\nOn s’attend logiquement à ce que 3 ne soit pas considéré comme égal à NA, et donc, on s’attend à obtenir FALSE. Pourtant, le résultat est NA. La comparaison d’un élément quelconque à une donnée manquante fournit toujours une donnée manquante : la comparaison ne peut pas se faire, R n’a donc rien à retourner. C’est également le cas aussi lorsque l’on compare deux valeurs manquantes :\n\nNA == NA\n\n[1] NA\n\n\nC’est en fait assez logique. Imaginons que j’ignore l’âge de Pierre et l’âge de Marie. Il n’y a aucune raison pour que leur âge soit le même, mais il est tout à fait possible qu’il le soit. C’est impossible à déterminer :\n\nage_Pierre &lt;- NA\nage_Marie &lt;- NA\nage_Pierre == age_Marie\n\n[1] NA\n\n\nMais alors comment faire pour savoir si une valeur est manquante puisqu’on ne peut pas utiliser les opérateurs de comparaison ? On utilise la fonction is.na() :\n\nis.na(age_Pierre)\n\n[1] TRUE\n\nis.na(tailles_pop3)\n\n[1] FALSE FALSE FALSE\n\n\nD’une façon générale, le point d’exclamation permet de signifier à R que nous souhaitons obtenir le contraire d’une expression :\n\n!is.na(age_Pierre)\n\n[1] FALSE\n\n!is.na(tailles_pop3)\n\n[1] TRUE TRUE TRUE\n\n\nCette fonction nous sera très utile plus tard pour éliminer toutes les lignes d’un tableau contenant des valeurs manquantes.\n\n\n1.3.4.3 L’utilisation des fonctions\nDans R, les fonctions sont des objets particuliers qui permettent d’effectuer des tâches très variées. Du calcul d’une moyenne à la création d’un graphique, en passant par la réalisation d’analyses statistiques complexes ou simplement l’affichage du chemin du répertoire de travail, tout, dans R, repose sur l’utilisation de fonctions. Vous en avez déjà vu un certain nombre :\n\n\n\n\n\n\n\nFonction\nPour quoi faire ?\n\n\n\n\nc()\nCréer des vecteurs\n\n\nclass()\nAfficher ou modifier la classe d’un objet\n\n\nfactor()\nCréer des facteurs\n\n\ngetwd()\nAfficher le chemin du répertoire de travail\n\n\nhead()\nAfficher les premiers éléments d’un objet\n\n\nis.na()\nTester si un objet contient des valeurs manquantes\n\n\nmean()\nCalculer une moyenne\n\n\nnames()\nAfficher ou modifier le nom des éléments d’un vecteur\n\n\norder()\nOrdonner les éléments d’un objet\n\n\nsubset()\nExtraire une partie des éléments d’un objet\n\n\nsum()\nCalculer une somme\n\n\ntail()\nAfficher les derniers éléments d’un objet\n\n\n\nCette liste va très rapidement s’allonger au fil des séances. Je vous conseille donc vivement de tenir à jour une liste des fonctions décrites, avec une explication de leur fonctionnement et éventuellement un exemple de syntaxe.\nCertaines fonctions ont besoin d’arguments (par exemple, la fonction factor()), d’autres peuvent s’en passer (par exemple, la fonction getwd()). Pour apprendre comment utiliser une fonction particulière, pour découvrir quels sont ses arguments possibles, quel est leur rôle et leur intérêt, la meilleure solution est de consulter l’aide de cette fonction. Il suffit pour cela de taper un ? suivi du nom de la fonction :\n\n?factor()\n\nToutes les fonctions et jeux de données disponibles dans R disposent d’un fichier d’aide similaire. Cela peut faire un peu peur au premier abord (tout est en anglais !), mais ces fichiers d’aide ont l’avantage d’être très complets, de fournir des exemples d’utilisation, et ils sont tous construits sur le même modèle. Vous avez donc tout intérêt à vous familiariser avec eux. Vous devriez d’ailleurs prendre l’habitude de consulter l’aide de chaque fonction qui vous pose un problème. Par exemple, le logarithme (en base 10) de 100 devrait faire 2, car 100 est égal à 10^2. Pourtant :\n\nlog(100)\n\n[1] 4.60517\n\n\nQue se passe-t’il ? Pour le savoir, il faut consulter l’aide de la fonction log :\n\n?log()\n\nCe fichier d’aide nous apprend que par défaut, la syntaxe de la fonction log() est la suivante :\n\nlog(x, base = exp(1))\n\nPar défaut, la base du logarithme est fixée à exp(1). Nous avons donc calculé un logarithme népérien (en base e). Cette fonction prend donc 2 arguments :\n\nx ne possède pas de valeur par défaut : il nous faut obligatoirement fournir quelque chose (la rubrique “Argument” du fichier d’aide nous indique que x doit être un vecteur numérique ou complexe) afin que la fonction puisse calculer un logarithme\nbase possède un argument par défaut. Si nous ne spécifions pas nous même la valeur de base, elle sera fixée à sa valeur par défaut, c’est à dire exp(1).\n\nPour calculer le logarithme de 100 en base 10, il faut donc taper, au choix, l’une de ces 3 expressions :\n\nlog(x = 100, base = 10)\n\n[1] 2\n\nlog(100, base = 10)\n\n[1] 2\n\nlog(100, 10)\n\n[1] 2\n\n\nLe nom des arguments d’une fonction peut être omis tant que ses arguments sont indiqués dans l’ordre attendu par la fonction (cet ordre est celui qui est précisé à la rubrique “Usage” du fichier d’aide de la fonction). Il est possible de modifier l’ordre des arguments d’une fonction, mais il faut alors être parfaitement explicite et utiliser les noms des arguments tels que définis dans le fichier d’aide.\nAinsi, pour calculer le logarithme de 100 en base 10, on ne peut pas taper :\n\nlog(10, 100)\n\n[1] 0.5\n\n\ncar cela revient à calculer le logarithme de 10 en base 100. On peut en revanche taper :\n\nlog(base = 10, x = 100)\n\n[1] 2"
  },
  {
    "objectID": "01-R-basics.html#sec-packages",
    "href": "01-R-basics.html#sec-packages",
    "title": "1  R et RStudio : les bases",
    "section": "1.4 Les packages additionels",
    "text": "1.4 Les packages additionels\nUne source de confusion importante pour les nouveaux utilisateurs de R est la notion de package. Les packages étendent les fonctionnalités de R en fournissant des fonctions, des données et de la documentation supplémentaires et peuvent être téléchargés gratuitement sur Internet. Ils sont écrits par une communauté mondiale d’utilisateurs de R. Par exemple, parmi les plus de 18000 packages disponibles à l’heure actuelle, nous utiliseront fréquemment :\n\nLe package ggplot2 pour la visualisation des données dans le Chapitre 3\nLe package dplyr pour manipuler des tableaux de données dans le Chapitre 5\n\nUne bonne analogie pour les packages R : ils sont comme les apps que vous téléchargez sur un téléphone portable. R est comme un nouveau téléphone mobile. Il est capable de faire certaines choses lorsque vous l’utilisez pour la première fois, mais il ne sait pas tout faire. Les packages sont comme les apps que vous pouvez télécharger dans l’App Store et Google Play. Pour utiliser un package, comme pour utiliser Instagram, vous devez :\n\nLe télécharger et l’installer. Vous ne le faites qu’une fois grâce à la commande install.packages()\nLe charger (en d’autres termes, l’ouvrir) en utilisant la commande library() à chaque nouvelle session de travail\n\nDonc, tout comme vous ne pouvez commencer à partager des photos avec vos amis sur Instagram que si vous installez d’abord l’application et que vous l’ouvrez, vous ne pouvez accéder aux données et fonctions d’un package R que si vous installez d’abord le package et le chargez avec la fonction library(). Passons en revue ces 2 étapes.\n\n1.4.1 Installation d’un package\nIl y a deux façons d’installer un package. Par example, pour installer le package ggplot2 :\n\nLe plus simple : Dans le quart inférieur droit de l’interface de Rstudio :\n\nCliquez sur l’onglet “Packages”\nCliquez sur “Install”\nTapez le nom du package dans le champ “Packages (separate multiple with space or comma):” Pour notre exemple, tapez ggplot2\nCliquez sur “Install”\n\nMétode alternative : Dans la console, tapez install.packages(\"ggplot2\") (vous devez inclure les guillemets).\n\nEn procédant de l’une ou l’autre façon, installez également les packages suivants : tidyverse et palmerpenguins. Le tidyverse est un “méta-package”, qui permet en fait d’installer de nombreux packages en une seule commande, dont ggplot2, tidyr, dplyr, magrittr et bien d’autres. Le package palmerpenguins contient un jeu de données dont nous nous servirons copieusement dans les chapitres suivants.\n\n\n\n\n\n\nNote : install.packages()\n\n\n\nUn package doit être installé une fois seulement sur un ordinateur, sauf si une version plus récente est disponible et que vous souhaitez mettre à jour ce package. Il n’est donc pas nécessaire de laisser ces commandes dans votre script. Sinon, vous risquez de ré-installer les packages à chaque nouvelle session de travail, ce qui est inutile et consomme inutilement de la bande passante, des ressources numériques, et donc, du carbone…  \n\n\n\n\n1.4.2 Charger un package en mémoire\nAprès avoir installé un package, vous pouvez le charger en utilisant la fonction library(). Par exemple, pour charger ggplot2 et dplyr tapez ceci dans la console :\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\nPuisque ces packages font partie du tidyverse, on aurait pu les charger tous les deux (et d’autres) en une seule étape en tapant :\n\nlibrary(tidyverse)\n\nQuand vous exécutez une commande, si vous voyez un message d’erreur commençant par :\nError: could not find function...\nc’est probablement parce que vous tentez d’utiliser une fonction qui fait partie d’un package que vous n’avez pas chargé. Pour corriger l’erreur, il suffit donc de charger le package approprié avec la commande library().\n\n\n\n\n\n\nNote : library()\n\n\n\nVous devrez charger à nouveau chaque package que vous souhaitez utiliser à chaque fois que vous ouvrirez une nouvelle session de travail dans RStudio (à chaque nouveau démarrage du logiciel, donc). C’est une erreur fréquente pour les débutants. Pour l’éviter, pensez bien à intégrer, tout en haut de votre script, les commandes library() nécessaires pour chaque package que vous comptez utiliser."
  },
  {
    "objectID": "01-R-basics.html#sec-exo-1",
    "href": "01-R-basics.html#sec-exo-1",
    "title": "1  R et RStudio : les bases",
    "section": "1.5 Exercice",
    "text": "1.5 Exercice\nDans votre dossier de travail, créez un nouveau script que vous nommerez ExoDiamonds.R. Vous prendrez soin d’ajouter autant de commentaires que nécessaire dans votre script afin de le structurer correctement.\n\nTéléchargez (si besoin) et chargez le package ggplot2\nChargez le jeu de données diamonds grâce à la commande data(diamonds)\nDéterminez le nombre de lignes et de colonnes de ce tableau nommé diamonds\nCréez un nouveau tableau que vous nommerez diamants_chers qui contiendra uniquement les informations des diamants dont le prix est supérieur ou égal à $15000.\nCombien de diamants coûtent $15000 ou plus ?\nCela représente quelle proportion du jeu de données de départ ?\nTriez ce tableau par ordre de prix décroissants et affichez les informations des 20 diamants les plus chers."
  },
  {
    "objectID": "02-Dataset.html#préambule",
    "href": "02-Dataset.html#préambule",
    "title": "2  Explorez votre premier jeu de données",
    "section": "2.1 Préambule",
    "text": "2.1 Préambule\nMettons en pratique tout ce que nous avons appris pour commencer à explorer un jeu de données réel. Les données nous parviennent sous différents formats, des images au texte en passant par des tableaux de chiffres. Tout au long de ce document, nous nous concentrerons sur les ensembles de données qui peuvent être stockés dans une feuille de calcul, car il s’agit de la manière la plus courante de collecter des données dans de nombreux domaines. N’oubliez pas ce que nous avons appris dans la Section 1.3.4.1 : ces ensembles de données de type “tableurs” sont appelés data.frame dans R, et nous nous concentrerons sur l’utilisation de ces objets tout au long de ce livre. S’il est évidemment possible d’importer dans R des données stockées dans des fichiers Excel ou des fichiers textes, nous allons dans un premier temps faire plus simple : nous travaillerons avec des données déjà disponibles dans un packages que nous avons installé dans la Section 1.4.\nAinsi, commençons par charger les packages nécessaires pour ce chapitre (cela suppose que vous les ayez déjà installés ; relisez la Section 1.4 pour plus d’informations sur l’installation et le chargement des packages R si vous ne l’avez pas déjà fait). Au début de chaque chapitre, nous aurons systématiquement besoin de charger quelques packages. Donc n’oubliez pas de les installer au préalable si besoin.\n\n# Pensez à installer ces packages avant de les charger si besoin \nlibrary(dplyr)\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "02-Dataset.html#le-package-palmerpenguins",
    "href": "02-Dataset.html#le-package-palmerpenguins",
    "title": "2  Explorez votre premier jeu de données",
    "section": "2.2 Le package palmerpenguins",
    "text": "2.2 Le package palmerpenguins\nCe package (Horst, Hill, et Gorman 2022) contient un jeu de données collectées par Kristen Gorman (membre du ``Long Term Ecological Research Network’’) et la station de Palmer en Antarctique (Gorman, Williams, et Fraser 2014). Les données contiennent des informations au sujet de 330 individus appartenant à 3 espèces de manchots (voir Figure 2.1) étudiés sur 3 îles de l’archipel de Palmer, an Antarctique. Ces espèces ont fait l’objet de nombreuses études comparatives, notamment afin de déterminer comment elles utilisent le milieu pour acquérir des ressources. Puisque ces 3 espèces sont proches sur le plan phylogénétique et qu’elles occupent le même habitat, la question de la compétition inter-spécifique, pour l’espace et les ressources, se pose tout naturellement.\n\n\n\nFigure 2.1: Les 3 espèces de manchots de l’archipel de Palmer. Illustration : Allison Horst"
  },
  {
    "objectID": "02-Dataset.html#le-data-frame-penguins",
    "href": "02-Dataset.html#le-data-frame-penguins",
    "title": "2  Explorez votre premier jeu de données",
    "section": "2.3 Le data frame penguins",
    "text": "2.3 Le data frame penguins\nNous allons commencer par explorer le jeu de données penguins qui est inclus avec le package palmerpenguins afin de nous faire une idée de sa structure. Dans votre script, tapez la commande suivante et exécutez la dans la console (selon les réglages de RStudio et la largeur de votre console, l’affichage peut varier légèrement) :\n\npenguins\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nEssayons de décrypter cet affichage :\n\nA tibble: 344 x 8 : un tibble est un data.frame amélioré. Il a toutes les caractéristiques d’un data.frame, (tapez class(penguins) pour vous en convaincre), mais en plus, il a quelques propriétés intéressantes sur lesquelles nous reviendrons plus tard. Ce tibble possède donc :\n\n344 lignes\n8 colonnes, qui correspondent aux variables. Dans un tibble, les observations sont toujours en lignes et les variables en colonnes\n\nspecies, island, bill_length_mm, bill_depth_mm, flipper_length_mm… sont les noms des colonnes, c’est à dire les variables de ce jeu de données\nNous avons ensuite les 10 premières lignes du tableau\n... with 334 more rows, and abbreviated variable names..., nous indique que 334 lignes ne logent pas à l’écran et que le nom de certains variables a été abrégé afin de permettre un affichage plus clair. Ces données font toutefois partie intégrante du tableau penguins\nles noms complets de toutes les variables abrégées sont également indiqués\n\nCette façon d’afficher les tableaux est spécifique des tibbles. Vous noterez que le type de chaque variable est indiqué entre &lt;...&gt;, juste sous les noms de colonnes. Voici certains des types de données que vous pourrez rencontrer :\n\n&lt;int&gt; : nombres entiers (“integers”)\n&lt;dbl&gt; : nombres réels (“doubles”)\n&lt;chr&gt; : caractères (“characters”)\n&lt;fct&gt; : facteurs (“factors”)\n&lt;ord&gt; : facteurs ordonnés (“ordinals”)\n&lt;lgl&gt; : logiques (colonne de vrais/faux : “logical”)\n&lt;date&gt; : dates\n&lt;time&gt; : heures\n&lt;dttm&gt; : combinaison de date et d’heure (“date time”)\n\nCette façon d’afficher le contenu d’un tableau permet d’y voir (beaucoup) plus clair que l’affichage classique d’un data.frame. Malheureusement, ce n’est pas toujours suffisant. Voyons quelles sont les autres méthodes permettant d’explorer un data.frame."
  },
  {
    "objectID": "02-Dataset.html#explorer-un-data.frame",
    "href": "02-Dataset.html#explorer-un-data.frame",
    "title": "2  Explorez votre premier jeu de données",
    "section": "2.4 Explorer un data.frame",
    "text": "2.4 Explorer un data.frame\nParmi les nombreuses façons d’avoir une idée des données contenues dans un data.frame tel que penguins, on présente ici 3 fonctions qui prennent le nom du data.frame en guise d’argument, et un opérateur :\n\nla fonction View() intégrée à RStudio. C’est celle que vous utiliserez le plus souvent. Attention, elle s’écrit avec un “V” majuscule\nla fonction glimpse() chargée avec le package dplyr. Elle est très similaire à la fonction str() découverte dans les tutoriels de DataCamp\nl’opérateur $ permet d’accéder à une unique variable d’un data.frame\nla fonction skim() du package skimr permet d’obtenir un résumé complet mais très synthétique et visuel des variables d’un data.frame\n\n\n2.4.1 View()\nTapez View(penguins) dans votre script et exécutez la commande. Un nouvel onglet contenant ce qui ressemble à un tableur doit s’ouvrir.\n\n\n\n\n\n\nQuizz : à quoi correspondent chacune des lignes de ce tableau ?\n\n\n\n\naux données d’une espèce\naux données d’une île\naux données d’un individu\naux données d’une population (plusieurs manchots à la fois)\n\n\n\nIci, vous pouvez donc explorer la totalité du tableau, passer chaque variable en revue, et même appliquer des filtres pour ne visualiser qu’une partie des données. Par exemple, essayez de déterminer combien d’individus sont issus de l’île “Biscoe”.\nCe tableau n’est pas facile à manipuler. Il est impossible de corriger des valeurs, et lorsque l’on applique des filtres, il est impossible de récupérer uniquement les données filtrées. Nous verrons plus tard comment les obtenir en tapant des commandes simples dans un script. La seule utilité de ce tableau est donc l’exploration visuelle des données.\n\n\n2.4.2 glimpse()\nLa seconde façon d’explorer les données contenues dans un tableau est d’utiliser la fonction glimpse() après avoir chargé le package dplyr :\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\nIci, les premières observations sont présentées en lignes pour chaque variable du jeu de données. Là encore, le type de chaque variable est précisé. Essayez d’identifier 3 variables catégorielles. À quoi correspondent-elles ? En quoi sont-elles différentes des variables numériques ?\n\n\n2.4.3 L’opérateur $\nL’opérateur $ permet d’accéder à une unique variable grâce à son nom. Par exemple on peut accéder à toutes les données concernant les noms d’espèces (variable species du tableau penguins) en tapant :\n\npenguins$species\n\n  [1] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n  [8] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [15] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [22] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [29] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [36] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [43] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [50] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [57] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [64] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [71] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [78] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [85] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [92] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [99] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[106] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[113] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[120] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[127] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[134] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[141] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[148] Adelie    Adelie    Adelie    Adelie    Adelie    Gentoo    Gentoo   \n[155] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[162] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[169] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[176] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[183] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[190] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[197] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[204] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[211] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[218] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[225] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[232] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[239] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[246] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[253] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[260] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[267] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[274] Gentoo    Gentoo    Gentoo    Chinstrap Chinstrap Chinstrap Chinstrap\n[281] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[288] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[295] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[302] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[309] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[316] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[323] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[330] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[337] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[344] Chinstrap\nLevels: Adelie Chinstrap Gentoo\n\n\nCela nous permet de récupérer les données sous la forme d’un vecteur ou, comme ici, d’un facteur. Attention toutefois, le tableau penguins contient beaucoup de lignes. Récupérer une variable grâce à cet opérateur peut rapidement saturer la console. Nous serons amenés à manipuler des tableaux contenant plusieurs dizaines ou centaines de milliers de lignes. C’est le cas du tableau diamonds du package ggplot2 que vous avez découvert dans les exercice de la Section 1.5.\nSi, par exemple, vous souhaitez extraire les données relatives à la clarté des diamants (colonne clarity) du tableau diamonds, vous pouvez taper ceci :\n\nlibrary(ggplot2)\ndiamonds$clarity\n\nLe résultat est pour le moins indigeste ! Lorsqu’un tableau contient de nombreuses lignes, c’est rarement une bonne idée de transformer l’une de ses colonnes en vecteur. Dans la mesure du possible, les données d’un tableau doivent rester dans le tableau.\n\n\n2.4.4 skim()\nPour utiliser la fonction skim(), vous devez au préalable installer le package skimr :\n\ninstall.packages(\"skimr\")\n\nCe package est un peu “expérimental” et il se peut que l’installation pose problème. Si un message d’erreur apparaît lors de l’installation, procédez comme suit :\n\nQuittez RStudio (sans oublier de sauvegarder votre travail au préalable)\nRelancez RStudio et dans la console, tapez ceci :\n\n\ninstall.packages(\"rlang\")\n\n\nTentez d’installer skimr à nouveau.\nExécutez à nouveau tout votre script afin de retrouver votre travail dans l’état où il était avant de quitter RStudio.\n\nSi l’installation de skimr s’est bien passée, vous pouvez maintenant taper ceci :\nlibrary(skimr)\nskim(penguins)\n\n\nData summary\n\n\nName\npenguins\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nspecies\n0\n1.00\nFALSE\n3\nAde: 152, Gen: 124, Chi: 68\n\n\nisland\n0\n1.00\nFALSE\n3\nBis: 168, Dre: 124, Tor: 52\n\n\nsex\n11\n0.97\nFALSE\n2\nmal: 168, fem: 165\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nbill_length_mm\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\n▃▇▇▆▁\n\n\nbill_depth_mm\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\n▅▅▇▇▂\n\n\nflipper_length_mm\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\n▂▇▃▅▂\n\n\nbody_mass_g\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\n▃▇▆▃▂\n\n\nyear\n0\n1.00\n2008.03\n0.82\n2007.0\n2007.00\n2008.00\n2009.0\n2009.0\n▇▁▇▁▇\n\n\n\n\nNous aurons l’occasion de revenir en détail sur la signification de tous ces indices au semestre prochain. À ce stade, retenez que cette fonction skim() permet d’accéder à un résumé très détaillé de chaque variable d’un jeu de données. Par exemple, on apprend ici que la masse corporelle moyenne des manchots de l’ensemble du jeu de données vaut 4201.75 grammes (ligne body_mass_g, colonne mean), avec un écart-type de 0.82 grammes (colonne sd), et que la masse de 2 individus est manquante (colonne n_missing). Cette fonction nous sera donc très utile au semestre prochain lorsque nous aborderons la question des statistiques descriptives.\n\n\n2.4.5 Les fichiers d’aide\nUne fonctionnalité particulièrement utile de R est son système d’aide. On peut obtenir de l’aide au sujet de n’importe quelle fonction et de n’importe quel jeu de données en tapant un “?” immédiatement suivi du nom de la fonction ou de l’objet.\nPar exemple, examinez l’aide du jeu de données penguins :\n\n?penguins\n\nVous devriez absolument prendre l’habitude d’examiner les fichiers d’aide des fonctions ou jeux de données pour lesquels vous avez des questions. Ces fichiers sont très complets, et même s’il peuvent paraître impressionnants au premier abord, ils sont tous structurés sur le même modèle et vous aideront à comprendre comment utiliser les fonctions, quels sont les arguments possibles, à quoi ils servent et comment les utiliser.\nPrenez le temps d’examiner le fichier d’aide du jeu de données penguins. Avant de passer à la suite, assurez-vous d’avoir compris à quoi correspondent chacune des 8 variables de ce tableau."
  },
  {
    "objectID": "02-Dataset.html#sec-exo-2",
    "href": "02-Dataset.html#sec-exo-2",
    "title": "2  Explorez votre premier jeu de données",
    "section": "2.5 Exercices",
    "text": "2.5 Exercices\nConsultez l’aide du jeu de données diamonds du package ggplot2.\n\nQuel est le code de la couleur la plus prisée ?\nQuel est le code de la moins bonne clarté ?\nÀ quoi correspond la variable z ?\nEn quoi la variable depth est-elle différente de la variable z ?\n\nInstallez le package nycflights13 et consultez son aide en tapant help(package=\"nycflights13\").\n\nConsultez l’aide des 5 jeux de données de ce package.\nÀ quoi correspond la variable visib ?\nDans quel tableau se trouve-t-elle ?\nCombien de lignes possède ce tableau ?\n\n\n\n\n\nGorman, Kristen B., Tony D. Williams, et William R Fraser. 2014. « Ecological Sexual Dimorphism and Environmental Variability within a Community of Antarctic Penguins (Genus Pygoscelis) ». PLOS ONE 9 (mars): 1‑14. https://doi.org/10.1371/journal.pone.0090081.\n\n\nHorst, Allison, Alison Hill, et Kristen Gorman. 2022. palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins."
  },
  {
    "objectID": "03-Visualization.html#préambule",
    "href": "03-Visualization.html#préambule",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.1 Préambule",
    "text": "3.1 Préambule\nDans le Chapitre 1 et le Chapitre 2, vous avez découvert les concepts essentiels qu’il est important de maîtriser avant de commencer à explorer en détail des données dans R. Les éléments de syntaxe abordés dans la Section 1.3 sont nombreux et vous n’avez probablement pas tout retenu. C’est pourquoi je vous conseille de garder les tutoriels de DataCamp à portée de main afin de pouvoir refaire les parties que vous maîtrisez le moins. Ce n’est qu’en répétant plusieurs fois ces tutoriels que les choses seront vraiment comprises et que vous les retiendrez. Ainsi, si des éléments de code présentés ci-dessous vous semblent obscurs, revenez en arrière : toutes les réponses à vos questions se trouvent probablement dans les chapitres précédents.\nAprès la découverte des bases du langage R, nous abordons maintenant les parties de ce livre qui concernent la “science des données” (ou “Data Science” pour nos amis anglo-saxons). Nous allons voir dans ce chapitre qu’outre les fonctions View() et glimpse(), l’exploration visuelle via la représentation graphique des données est un moyen indispensable et très puissant pour comprendre ce qui se passe dans un jeu de données.\n\n\n\n\n\n\nImportant\n\n\n\nLa visualisation de vos données est un préalable indispensable à toute analyse statistique.\n\n\nLa visualisation des données est en outre un excellent point de départ quand on découvre la programmation sous R, car ses bénéfices sont clairs et immédiats : vous pouvez créer des graphiques élégants et informatifs qui vous aident à comprendre les données. Dans ce chapitre, vous allez donc plonger dans l’art de la visualisation des données, en apprenant la structure de base des graphiques réalisés avec ggplot2 qui permettent de transformer des données numériques et catégorielles en graphiques.\nToutefois, la visualisation seule ne suffit généralement pas. Il est en effet souvent nécessaire de transformer les données pour produire des représentations plus parlantes. Ainsi, dans le Chapitre 5, vous découvrirez les fonctions clés qui vous permettront de sélectionner des variables importantes, de filtrer des observations, de créer de nouvelles variables, ou d’en modifier la forme.\nCe n’est qu’en combinant les transformations de données et représentations graphiques d’une part, avec votre curiosité et votre esprit critique d’autre part, que vous serez véritablement en mesure de réaliser une analyse exploratoire de vos données à la fois utile et pertinente. C’est la seule façon d’identifier des questions intéressantes sur vos données, afin de tenter d’y répondre par les analyses statistiques et la modélisation qui seront abordées lors des prochains semestres."
  },
  {
    "objectID": "03-Visualization.html#prérequis",
    "href": "03-Visualization.html#prérequis",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.2 Prérequis",
    "text": "3.2 Prérequis\nDans ce chapitre, nous aurons besoin des packages suivants :\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(nycflights13)\nlibrary(gapminder)\nlibrary(scales)\n\nSi ce n’est pas déjà fait, pensez à les installer avant de les charger en mémoire.\nAu niveau le plus élémentaire, les graphiques permettent de comprendre comment les variables se comparent en termes de tendance centrale (à quel endroit les valeurs ont tendance à être localisées, regroupées) et leur dispersion (comment les données varient autour du centre). La chose la plus importante à savoir sur les graphiques est qu’ils doivent être créés pour que votre public (le professeur qui vous évalue, le collègue avec qui vous collaborez, votre futur employeur, etc.) comprenne bien les résultats et les informations que vous souhaitez transmettre. Il s’agit d’un exercice d’équilibriste : d’une part, vous voulez mettre en évidence autant de relations significatives et de résultats intéressants que possible, mais de l’autre, vous ne voulez pas trop en inclure, afin d’éviter de rendre votre graphique illisible ou de submerger votre public. Tout comme n’importe quel paragraphe de document écrit, un graphique doit permettre de communiquer un message (une idée forte, un résultat marquant, une hypothèse nouvelle, etc).\nComme nous le verrons, les graphiques nous aident également à repérer les tendances extrêmes et les valeurs aberrantes dans nos données. Nous verrons aussi qu’une façon de faire, assez classique, consiste à comparer la distribution d’une variable quantitative pour les différents niveaux d’une variable catégorielle.\n\n\n\n\n\n\nObjectifs\n\n\n\nDans ce chapitre, vous apprendrez à :\n\nfaire différents types de graphiques exploratoires avec le package ggplot2   \nchoisir le ou les graphiques appropriés selon la nature des variables dont vous disposez ou que vous souhaitez mettre en relation\nmettre vos graphiques en forme pour les intégrer dans vos rapports ou compte-rendus de TP"
  },
  {
    "objectID": "03-Visualization.html#sec-gggraph",
    "href": "03-Visualization.html#sec-gggraph",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.3 La grammaire des graphiques",
    "text": "3.3 La grammaire des graphiques\nLes lettres gg du package ggplot2 sont l’abréviation de “grammar of graphics” : la grammaire des graphiques. De la même manière que nous construisons des phrases en respectant des règles grammaticales précises (usage des noms, des verbes, des sujets et adjectifs…), la grammaire des graphiques établit un certain nombre de règles permettant de construire des graphiques : elle précise les composants d’un graphique en suivant le cadre théorique défini par Wilkinson (2005).\n\n3.3.1 Éléments de la grammaire\nEn bref, la grammaire des graphiques nous dit que :\n\nUn graphique est l’association (mapping) de données/variables (data) à des attributs esthétiques (aesthetics) d’objets géométriques (geometric objects).\n\nPour clarifier, on peut disséquer un graphique en 3 éléments essentiels :\n\ndata : le jeu de données contenant les variables que l’on va associer à des objets géométriques. Pour ggplot2 les données doivent obligatoirement être stockées dans un data.frame ou un tibble\ngeom : les objets géométriques en question. Cela fait référence aux types d’objets que l’on peut observer sur le graphique (des points, des lignes, des barres, etc.)\naes : les attributs esthétiques des objets géométriques présents sur le graphique. Par exemple, la position sur les axes x et y, la couleur, la taille, la transparence, la forme, etc. Chacun de ces attributs esthétiques peut-être associé à une variable de notre jeu de données.\n\nExaminons un exemple pour bien comprendre.\n\n\n3.3.2 Gapminder\nEn février 2006, un statisticien du nom de Hans Rosling a donné un TED Talk intitulé “The best stats you’we ever seen”. Au cours de cette conférence, Hans Rosling présente des données sur l’économie mondiale, la santé et le développement des pays du monde. Les données sont disponibles sur ce site et dans le package gapminder.\nPour l’année 2007, le jeu de données contient des informations pour 142 pays. Examinons les premières lignes de ce jeu de données :\n\n\n\nLes 6 premières lignes du jeu de données gapminder pour l’année 2007.\n\n\nCountry\nContinent\nLife Expectancy\nPopulation\nGDP per Capita\n\n\n\n\nAfghanistan\nAsia\n43.828\n31889923\n974.5803\n\n\nAlbania\nEurope\n76.423\n3600523\n5937.0295\n\n\nAlgeria\nAfrica\n72.301\n33333216\n6223.3675\n\n\nAngola\nAfrica\n42.731\n12420476\n4797.2313\n\n\nArgentina\nAmericas\n75.320\n40301927\n12779.3796\n\n\nAustralia\nOceania\n81.235\n20434176\n34435.3674\n\n\n\n\n\nPour chaque ligne, les variables suivantes sont décrites :\n\nCountry : le pays\nContinent : le continent\nLife Expectancy : espérance de vie à la naissance\nPopulation : nombre de personnes vivant dans le pays\nGDP per Capita : produit intérieur brut (PIB) par habitant en dollars américains. GDP est l’abréviation de “Growth Domestic Product”. C’est un indicateur de l’activité économique d’un pays, parfois utilisé comme une approximation du revenu moyen par habitant.\n\nExaminons maintenant la Figure 3.1 qui représente ces variables pour chacun des 142 pays de ce jeu de données (notez l’utilisation de la notation scientifique dans la légende, et de l’échelle logarithmique de l’axe des abscisses).\n\n\n\n\n\nFigure 3.1: Espérance de vie en fonction du PIB par habitant en 2007.\n\n\n\n\nSi on décrypte ce graphique du point de vue de la grammaire des graphiques, on voit que :\n\nla variable GDP per Capita est associée à l’aesthetic x de la position des points\nla variable Life Expectancy est associée à l’aesthetic y de la position des points\nla variable Population est associée à l’aesthetic size (taille) des points\nla variable Continent est associée à l’aesthetic color (couleur) des points\n\nIci, l’objet géométrique (ou geom) qui représente les données est le point. Les données (ou data) sont contenues dans le tableau gapminder et chacune de ces variables est associée (mapping) aux caractéristiques esthétiques des points.\n\n\n3.3.3 Autres éléments de la grammaire des graphiques\nOutre les éléments indispensables évoqués ici (data, mapping, aes, et geom), il existe d’autres aspects de la grammaire des graphiques qui permettent de contrôler l’aspect des graphiques. Ils ne sont pas toujours indispensables. Nous en verrons néanmoins quelque-uns particulièrement utiles :\n\nfacet : c’est un moyen très pratique de scinder le jeu de données en plusieurs sous-groupes et de produire automatiquement un graphique pour chacun d’entre eux.\nposition : permet notamment de modifier la position des barres d’un barplot.\nlabs : permet de définir les titres, sous-titres et légendes des axes d’un graphique\ntheme : permet de modifier l’apect général des graphiques en appliquant des thèmes prédéfinis ou en modifiant certains aspects de thèmes existants\n\n\n\n3.3.4 Le package ggplot2\nComme indiqué plus haut, le package ggplot2 (Wickham et al. 2023) permet de réaliser des graphiques dans R en respectant les principes de la grammaire des graphiques. Vous avez probablement remarqué que depuis le début de la section Section 3.3, beaucoup de termes sont écrits dans la police réservée au code informatique. C’est parce que les éléments de la grammaire des graphiques sont tous précisés dans la fonction ggplot() qui demande, au grand minimum, que les éléments suivants soient spécifiés :\n\nle nom du data.frame contenant les variables qui seront utilisées pour le graphique. Ce nom correspond à l’argument data de la fonction ggplot().\nl’association des variables à des attributs esthétiques. Cela se fait grâce à l’argument mapping et la fonction aes()\n\nAprès avoir spécifié ces éléments, on ajoute des couches supplémentaires au graphique grâce au signe +. La couche la plus essentielle à ajouter à un graphique, est une couche contenant un élément géométrique, ou geom (par exemple des points, des lignes ou des barres). D’autres couches peuvent s’ajouter pour spécifier des titres, des facets ou des modifications des axes et des thèmes du graphique.\nDans le cadre de ce cours, nous verrons un grand nombre de types de gra[hiques distincts, y compris les 5 types de graphiques les plus courants :\n\nles nuages de points\nles graphiques en lignes\nles histogrammes\nles diagrammes bâtons\nles boîtes à moustaches\n\n\n\n3.3.5 Votre premier graphique\nReprenons maintenant le jeu de données penguins :\n\npenguins\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nComme évoqué plus haut, il s’agit d’un tibble. Plusieurs de ses variables concernent la biométrie des manchots, en particulier de son bec (voir Figure 3.2).\n\n\n\nFigure 3.2: Morphométrie du bec des manchots. Illustration de Allison Horst\n\n\nSupposons qu’on cherche à déterminer si la longueur du bec des manchots est proportionnelle à leur masse. Pour produire un graphique permettant de le déterminer, nous avons besoin des éléments suivants :\n\ndata : le tableau penguins\nun objet géométrique, ici, des points (geom_point()) puisque nous disposons de 2 variables numériques (plus de détails à ce sujet plus bas)\nl’association de certaines variables du jeu de données (ici, body_mass_g et bill_length_mm) à certaines caractéristiques esthétiques du graphiques (ici, la position sur les axes des x et des y), grâce à l’argument mapping et la fonction aes().\n\nConcrètement, voilà le code qu’il faut taper dans votre script :\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = bill_length_mm))\n\n\n\n\nCette première ligne de code permet de faire plusieurs choses :\n\non indique à R qu’on souhaite faire un graphique (avec la fonction ggplot())\non indique à R que les données sont contenues dans l’objet penguins avec data = penguins\non associe (avec mapping = la variable body_mass_g à l’axe des x et la variable bill_length_mm à l’axe des y. On fait cela grâce à aes(x = body_mass_g, y = bill_length_mm)\n\nCette commande génère la première couche du graphique. Il n’y a pas encore de données car nous n’avons pas indiqué quel type d’objet géométrique nous souhaitons afficher, mais la fenêtre graphique est bel et bien créée, les axes apparaissent, ils sont légendés et leur échelle est adaptée aux variables du tableau penguins que nous avons sélectionnées. Pour terminer le graphique, il nous faut donc ajouter une seconde couche, celle de l’objet géométrique :\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = bill_length_mm)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nRelation entre masse corporelle et longueur du bec chez les manchots de l’archipel de Palmer\n\n\n\n\nAu moment de produire ce graphique, R nous indique que 2 lignes du tableau penguins ne figurent pas sur ce graphique car elles possèdent des données manquantes (NA), pour l’une et/ou l’autre des variables que nous avons sélectionnées. La fonction geom-point() est donc incapable de les placer sur le graphique.\nVous avez donc ici un premier exemple de graphique très simple. Il est loin d’être parfait (à minima, le titre des axes devrait être modifié), mais il a le mérite de vous présenter la syntaxe que vous devrez utiliser pour produire presque tous les graphiques qui vous seront utiles avec ggplot2. En outre, on peut percevoir qu’il semble exister une relation positive (mais imparfaite) entre longueur des becs et masse des individus. Il faut toutefois être prudent car nous avons ici utilisé toutes les données disponibles (donc les données des 3 espèces à la fois), ce qui est loin d’être pertinent.\n\n\n\n\n\n\nEn résumé\n\n\n\n\nAu sein de la fonction ggplot(), on spécifie 2 composants de la grammaire des graphiques :\n\nle nom du tableau contenant les données grâce à l’argument data = penguins\nl’association (mapping) des variables du tableau de données à des caractéristiques esthétiques (aes()) en précisant aes(x = body_mass_g, y = bill_length_mm) :\n\nla variable body_mass_g est associée à l’esthétique de position x\nla variable bill_length_mm est associée à l’esthétique de position y\n\n\nOn ajoute une couche au graphique ggplot() grâce au symbole +. La couche en question précise le troisième élément indispensable de la grammaire des graphiques : l’objet geométrique. Ici, les objets sont des points. On le spécifie grâce à la fonction geom_point().\n\n\n\nQuelques remarques concernant les couches :\n\nNotez que le signe + est placé à la fin de la ligne. Vous recevrez un message d’erreur si vous le placez au début.\nQuand vous ajoutez une couche à un graphique, je vous encourage vivement à presser la touche enter de votre clavier juste après le symbole +. Ainsi, le code correspondant à chaque couche sera sur une ligne distincte, ce qui augmente considérablement la lisibilité de votre code.\nComme indiqué dans la Section 1.3.4.3, tant que les arguments d’une fonction sont spécifiés dans l’ordre, on peut se passer d’écrire leur nom. Ainsi, les deux blocs de commande suivants produisent exactement le même résultat :\n\n\n# Le nom des arguments est précisé\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = bill_length_mm)) +\n  geom_point()\n\n# Le nom des arguments est omis\nggplot(penguins, aes(x = body_mass_g, y = bill_length_mm)) +\n  geom_point()\n\n\n\n3.3.6 Exercices\n\nDonnez une raison pratique expliquant pourquoi les variables body_mass_g et bill_length_mm ont une relation positive\nQuelles variables (pas nécessairement dans le tableau penguins) pourraient avoir une corrélation négative (relation négative) avec body_mass_g ? Pourquoi ? Rappelez-vous que nous étudions ici des variables numériques.\nCitez les éléments de ce graphique/de ces données qui vous sautent le plus aux yeux ?\nCréez un nouveau nuage de points en utilisant d’autres variables du jeu de données penguins"
  },
  {
    "objectID": "03-Visualization.html#quel-graphique-dans-quelle-situation",
    "href": "03-Visualization.html#quel-graphique-dans-quelle-situation",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.4 Quel graphique dans quelle situation ?",
    "text": "3.4 Quel graphique dans quelle situation ?\nIl n’est pas possible de faire n’importe quel type de graphique dans n’importe quelle situation. Selon le nombre de variables dont on dispose ou que l’on souhaite examiner, et selon la nature de ces variables (numériques et/ou catégorielles), le choix des types de graphiques possibles sera limité. Par exemple, les diagrammes bâtons sont réservés aux variables catégorielles, alors que les histogrammes sont possibles uniquement avec les variables numériques continues. Néanmoins, dans certaines situations, plusieurs choix de graphiques seront possibles, et vous aurez donc une certaine liberté. Vos choix seront alors guidés par les objectifs que vous souhaiterez atteindre grâce aux graphiques, ainsi que par vos préférences.\n\n\n\n\n\n\nObjectifs\n\n\n\nDans la suite de ce chapitre, nous traiterons donc des situations les plus courantes : quel(s) type(s) de graphique(s) produire lorsque l’on dispose d’une, deux ou trois variables ? Quel(s) type(s) de graphique(s) produire lorsque les variables sont toutes numériques, toutes catégorielles, ou lorsqu’on dispose de variables des deux types ?\nPour chaque situation, un ou des exemples seront fournis à partir des données du tableau penguins. Cela sera aussi l’occasion de présenter quelques-unes des nombreuses subtilités liées à l’utilisation du package ggplot2."
  },
  {
    "objectID": "03-Visualization.html#une-seule-variable-numérique",
    "href": "03-Visualization.html#une-seule-variable-numérique",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.5 Une seule variable numérique",
    "text": "3.5 Une seule variable numérique\nLorsque l’on souhaite examiner une unique variable numérique, deux types de représentations graphiques sont en général possibles :\n\nles histogrammes : la variable d’intérêt est placée sur l’axe des x du graphique. Les valeurs utilisées sur l’axe des y est calculée automatiquement par le logiciel.\nles nuages de points : la variable d’intérêt est placée sur l’axe des y. L’axe des x porte soit un simple numéro d’indice pour chaque observation, soit une unique valeur sans importance, la même pour toutes les observations.\n\nLes syntaxes et options pour ces 2 types de graphiques sont présentées ci-dessous.\n\n3.5.1 Les histogrammes\n\n3.5.1.1 Syntaxe élémentaire\nImaginons que l’on s’intéresse à la variable body_mass_g du jeu de données penguins.\nLa syntaxe permettant de produire un histogramme, sous sa forme la plus simple, est la suivante :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nDeux messages nous sont adressés par le logiciel :\n\nWarning: Removed 2 rows containing non-finite values (stat_bin). Ce message indique, comme pour le premier nuage de points, que 2 individus du tableau penguins ont une masse corporelle inconnue (NA). Ces 2 individus (donc les deux lignes correspondantes), ont été ignorés pour produire ce graphique\n'stat_bin()' using 'bins = 30'. Pick better value with 'binwidth'. Ce message indique que R a choisi pour nous les limites des classes utilisées pour faire l’histogramme. Sur un histogramme, la variable d’intérêt (toujours numérique et continue), qui apparaît sur l’axe des abscisses, est en effet “découpée” en plusieurs classes, en général de même taille, afin de permettre une représentation de la distribution des valeurs. Ici, R indique qu’il a créé 30 catégories pour nous, et que nous pouvons faire un choix différent grâce à l’argument binwidth. Nous y reviendrons un peu plus loin.\n\nSur ce graphique, l’axe des abscisses porte donc la variable continue “découpée” en classes de mêmes largeur, et l’axe des ordonnées renseigne sur le nombre (count ou fréquence absolue) d’individus observés dans chaque classe. Les zones du graphique où les barres sont les plus hautes indiquent donc les caractéristiques des individus observés le plus fréquemment. À l’inverse, les barres les plus courtes correspondent à des valeurs de masse rarement observées. Au final, ce type de graphique permet de visualiser la distribution des données pour une variable numérique continue.\nIci, on constate qu’une majorité d’individus semble avoir des masses proches de 3500 grammes. Une autre portion non négligeable des individus (mais moins importante) semble avoir une masse légèrement supérieure à 4500 grammes. Enfin, les masses supérieures à 6000 grammes sont très rares. L’histogramme nous permet également de visualiser l’étendue des données : les manchots étudiés ici ont des masses qui s’étalent d’un peu plus de 2500 grammes à un peu moins de 6500 grammes.\n\n\n3.5.1.2 Couleur\nPour rendre ce graphique plus facilement lisible, on peut en modifier la couleur :\n\nla couleur de remplissage des barres peut-être spécifiée grâce à l’argument fill =\nla couleur de contour des barres peut-être spécifiée grâce à l’argument color =\n\nUne liste des couleurs disponibles dans R peut être affichée dans la console en tapant :\n\ncolors()\n\nVous pouvez voir à quelle couleur correspond chacun de ces noms dans ce document pdf.\nMettons à jour notre histogramme en ajoutant un peu de couleur :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nLes 30 classes de masses sont maintenant plus facilement visibles et distingables.\n\n\n3.5.1.3 À l’intérieur ou à l’extérieur de aes() ?\nLes couleurs de remplissage et de contour des barres d’un histogramme font partie des caractéristiques esthétiques du graphique. Pourtant, elles ne sont pas précisées à l’intérieur de la fonction aes(). La raison est simple mais importante :\n\n\n\n\n\n\nImportant\n\n\n\nOn place à l’intérieur de aes() uniquement les caractéristiques esthétiques du graphique que l’on souhaite associer à des variables du jeu de données.\n\n\nIci, les couleurs que l’on indique sont des constantes : toutes les barres ont les mêmes couleur de remplissage et de contour. On n’associe pas une variable du jeu de données à ces caractéristiques esthétiques. On place donc fill = et color = à l’extérieur de aes(). Si on se trompe, voilà ce qui se produit :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(aes(fill = \"steelblue\", color = \"black\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nLes couleurs qui apparaissent ne correspondent pas à ce qui est demandé, et une légende ne correspondant à rien apparaît à droite du graphique. La syntaxe utilisée ici suppose en effet que \"steelblue\" et \"black\" seraient des variables du jeu de données penguins. Puisqu’elles n’existent pas, R essaie de se débrouiller pour interpréter comme il peut ce qu’on lui demande, et finit par produire ce graphique incohérent. La couleur utilisée est la première couleur de la palette par défaut de ggplot2.\nPour élaborer des graphiques plus avancés, il faudra donc toujours vous poser la question suivante : la caractéristique esthétique que je souhaite modifier doit-elle être associée à une valeur constante que je fixe pour toutes les barres ou tous les points d’un graphique, et alors, je l’indique en dehors de aes(), ou est-elle au contraire associée à une variable du jeu de données, et alors, je l’indique à l’intérieur de aes().\nIl est bien sûr possible d’avoir un mélange des deux. Par exemple, le code suivant permet d’associer la couleur de remplissage au sexe des individus étudiés (variable sex du jeu de données penguins), et de spécifier une valeur constante pour la couleur de contour des barres (ici, le noir) :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(aes(fill = sex), color = \"black\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nOn constate que toutes les barres ont un contour noir, mais que plusieurs couleurs de remplissage apparaissent maintenant, selon le sexe des individus, dans chaque classe de masse. Une légende adaptée est aussi créée automatiquement à droite du graphique. On apprend ainsi que les individus les plus lourds sont tous des mâles. On constate également que le sexe de certains individus est inconnu.\nAu final, nous ne sommes déjà plus dans la situation où on examine une unique variable numérique. Nous avons en effet ici un graphique nous permettant de mettre en relation une variable numérique (la masse des individus en grammes) et une variable catégorielle (le sexe des individus). Nous reviendrons plus tard sur ce type de graphiques.\n\n\n3.5.1.4 La largeur des classes\nComme évoqué plus haut, par défaut, R choisit arbitrairement de découper la variable numérique utilisée en 30 classes de même largeur afin de produire l’histogramme. Ça n’est que rarement un bon choix, et malheureusement, il n’y a pas de règle permettant de définir à coup sûr le bon nombre de classes pour visualiser au mieux la distribution d’une variable numérique. Il faut en effet presque toujours procéder par essais-erreurs successifs. Il est possible d’ajuster les caractéristiques (nombre et/ou largeur) des classes de l’histogramme de l’une des 3 façons suivantes :\n\nEn ajustant le nombre de classes avec bins.\nEn précisant la largeur des classes avec binwidth.\nEn fournissant manuellement les limites des classes avec breaks.\n\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\",\n                 bins = 10)\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nIci, diminuer le nombre de classes à 10 a pour effet de trop lisser la distribution des données. On ne visualise plus les variations subtiles de la distribution. À l’inverse, trop augmenter le nombre de classes n’est pas pertinent non plus :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\",\n                 bins = 100)\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nIci, passer à 100 classes de taille génère un histogramme plein de trous, avec des classes très étroites, dont certaines sont très représentées, et immédiatement suivies ou précédées par des classes très peu représentées. Cela n’a pas de logique, et c’est presque toujours le signe qu’il faut réduire le nombre de classes.\nAu final, pour ces données, un nombre de classes compris entre 20 et 30 semble un bon choix :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\",\n                 bins = 25)\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nC’est un bon choix, entre trop peu d’information, et trop de bruit visuel. Évidemment, ce nombre sera différent pour chaque jeu de données. On constate ici à peu près 3 pics (autour de 3500 grammes, un peu au-dessus de 4500 grammes, et autour de 5500 grammes) qui reflètent bien la distribution de ces données.\nOn peut également modifier la largeur des classes (et non plus leur nombre) avec binwidth :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\",\n                 binwidth = 200)\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nIci, chaque catégorie recouvre 200 grammes. Avec l’argument bins, on indique à R combien on souhaite obtenir de classes, et il détermine automatiquement leur largeur. Avec binwidth, on indique la largeur des classes souhaitées, et R détermine automatiquement le nombre de classes nécessaires pour couvrir la totalité des données.\nEnfin, il est possible de déterminer manuellement les limites des classes souhaitées avec l’argument breaks :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\",\n                 breaks = c(2500, 2750, 3000, 3500, 4000, 4500, 5000, 6000, 7000))\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nVous constatez ici que les choix effectués ne sont pas très pertinents : toutes les classes n’ont pas la même largeur. Cela rend l’interprétation difficile. Il est donc vivement conseillé, pour spécifier breaks, de créer des suites régulières, comme avec la fonction seq() (consultez son fichier d’aide et les exemples) :\n\nlimites &lt;- seq(from = 2500, to = 6500, by = 250)\nlimites\n\n [1] 2500 2750 3000 3250 3500 3750 4000 4250 4500 4750 5000 5250 5500 5750 6000\n[16] 6250 6500\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\",\n                 breaks = limites)\n\n\n\n\nUn exemple d’utilisation de l’argument breaks\n\n\n\n\nIl est important que toute la gamme des valeurs de body_mass_g soit bien couverte par les limites des classes que nous avons définies, sinon, certaines valeurs sont omises et l’histogramme est donc incomplet/incorrect. Une façon de s’en assurer est d’afficher le résumé des données pour la colonne body_mass_g du jeu de données penguins :\n\nsummary(penguins$body_mass_g)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   2700    3550    4050    4202    4750    6300       2 \n\n\nOn voit ici que les masses varient de 2700 à 6300 grammes. Les classes que nous avons définies couvrent une plage de masses plus large (de 2500 à 6500). Toutes les données sont donc bien intégrées à l’histogramme.\n\n\n3.5.1.5 geom_rug et geom_density\nLa fonction geom_histogram() n’est pas la seule qui permette de visualiser la distribution des données. Il est en effet possible d’utiliser d’autres objets géométriques, en plus ou à la place de geom_histogram() pour ajouter de l’information sur le graphique, ou pour visualiser différemment la distribution des mêmes données.\nLa fonction geom_rug() permet d’ajouter les données réelles sous forme de segments, sous un histogramme. Cela prend souvent l’aspect d’une sorte de tapis, d’où le nom de la fonction (“rug” signifie “tapis” en anglais). Pour ajouter une couche supplémentaire au graphique, on ajoute simplement un + à la fin de la dernière ligne, et sur la ligne suivante, on ajoute un objet géométrique supplémentaire :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\",\n                 bins = 25) +\n  geom_rug()\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nLes tirets qui sont maintenant visibles en-dessous de l’histogramme correspondent aux 342 valeurs de masses réellement observées dans le jeu de données. Puisque certaines tailles ont été observées plusieurs fois, faire des tirets semi-transparents nous permettra de mieux visualiser quelles tailles ont été observées fréquemment ou rarement. On peut régler la transparence des éléments d’un graphique avec l’argument alpha =, qui prend des valeurs comprises entre 0 (transparence totale) et 1 (opacité totale) :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\",\n                 bins = 25) +\n  geom_rug(alpha = 0.3)\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nLes tirets sont maintenant d’autant plus foncés que les tailles ont été observées un grand nombre de fois. On retrouve bien ici la distribution décrite plus haut, avec 3 principaux groupes de valeurs. Cela révèle certainement en partie la complexité des données : ces tailles correspondent en effet aux mesures effectuées chez 3 espèces distinctes qui peuvent avoir des caractéristiques différentes, sans compter que le sexe des individus, qui n’apparaît pas ici, entre aussi probablement en jeu. Nous y reviendrons plus tard.\nLa fonction geom_density() permet de s’affranchir de la question du nombre ou de la largeur des classes de taille :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_density(fill = \"steelblue\", color = \"black\", alpha = 0.7, bw = 300)\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nOn obtient une sorte d’histogramme lissé qui fait bien apparaître les 3 tailles les plus fréquentes (au niveau des 3 “bosses” du graphique). Inutile ici de spécifier un nombre de classes de taille, ou leur largeur : le lissage est ici automatique. On peut modifier l’importance du lissage avec l’argument bw, mais la valeur choisie par défaut par R est généralement tout à fait satisfaisante. Vous pouvez essayer avec une valeur de lissage de 30, puis de 500 pour vous rendre compte de l’effet de ce paramètre.\nNotez également que si l’histogramme présentait des valeurs d’abondance sur l’axe des y (des nombres d’individus), le graphique de densité présente, comme son nom l’indique, l’information de densité des observations. Cela signifie que la surface totale sous la courbe (en bleu) vaut 1. Cela peut s’avérer utile pour comparer plusieurs distributions pour lesquelles on disposes de tailles d’échantillons très différentes.\nEnfin, on peut créer un graphique qui présentera à la fois l’histogramme (avec geom_histogram()), les données individuelles (avec geom_rug()) et la courbe de densité (avec geom_density()). Mais pour que tout s’affiche correctement, il faut indiquer à geom_histogram que l’axe des y doit porter les densités et non les abondances. On fait cela en précisant y = after_stat(density), cela indique à R que la variable density ne figure pas dans le tableau penguins, mais qu’elle est calculée par la fonction geom_histogram() :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(aes(y = after_stat(density)),\n                 fill = \"steelblue\", color = \"black\",\n                 bins = 25, alpha = 0.7) +\n  geom_rug(alpha = 0.3) +\n  geom_density(color = \"purple\", linewidth = 2)\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nNotez l’utilisation des arguments alpha, color et size, pour modifier l’aspect de différents éléments du graphique. Assurez-vous d’avoir compris comment on les utilise, et faites vos propres expériences.\n\n\n3.5.1.6 Un mot sur la position de la fonction aes()\nSur le dernier exemple, vous constatez que la fonction aes() apparaît une fois à l’intérieur de la fonction ggplot(), et une autre fois à l’intérieur de geom_histogram(). Pourquoi ne pas avoir tapé, plus simplement :\n\nggplot(penguins, aes(x = body_mass_g, y = after_stat(density))) +\n  geom_histogram(fill = \"steelblue\", color = \"black\",\n                 bins = 25, alpha = 0.7) +\n  geom_rug(alpha = 0.3) +\n  geom_density(color = \"purple\", linewidth = 2)\n\nL’explication est relativement simple, mais importante :\n\n\n\n\n\n\nImportant\n\n\n\nCe qui est spécifié dans la fonction ggplot() s’applique à toutes les couches du graphiques (donc ici, aux 3 couches geom_histogram(), geom_rug() et geom_density()).\nCe qui est spécifié dans une fonction geom_...() ne s’applique qu’à cette couche géométrique particulière.\n\n\nAinsi, ajouter y = after_stat(density) à l’intérieur de ggplot() renvoie donc un message d’erreur, car seule la fonction geom_histogram() calcule la variable density, seule la fonction geom_histogram() sait quoi faire de cette variable. Dans notre exemple, il est en revanche logique d’ajouter aes(x = body_mass_g) dans la fonction ggplot(), car nos trois couches géométriques ont besoin de cet argument, et pour les 3 couches géométriques, on associe bien cette variable body_mass_g à l’axe des x. Toutefois, rien ne nous empêche d’écrire ceci à la place :\n\nggplot(data = penguins) +\n  geom_histogram(aes(x = body_mass_g, y = after_stat(density)),\n                 fill = \"steelblue\", color = \"black\",\n                 bins = 25, alpha = 0.7) +\n  geom_rug(aes(x = body_mass_g),\n           alpha = 0.3) +\n  geom_density(aes(x = body_mass_g),\n               color = \"purple\", linewidth = 2)\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nC’est plus long, mais c’est tout à fait correct et ça produit exactement le même résultat qu’auparavant.\n\n\n\n3.5.2 Les nuages de points et stripcharts\nPour ces deux types de graphiques, la variable numérique sera portée par l’axe des y, et toutes les valeurs seront visibles, de façon non agrégée (contrairement aux histogrammes où les valeurs individuelles sont rassemblées à l’intérieur de classes). La différence entre les deux types de graphiques tient à la nature des informations qui figureront sur l’axe des x :\n\nPour les nuages de points, l’axe des x portera simplement l’information du numéro d’observation pour chaque individu. L’individu placé sur la première ligne du tableau de données portera l’indice 1. L’individu placé sur la deuxième ligne du tableau de données portera l’indice 2, et ainsi de suite jusqu’à l’individu placé sur la dernière ligne du tableau (il portera ici l’indice 344 puisque le tableau compte 344 lignes)\nPour un stripchart, l’axe des x portera une unique valeur, la même pour tous les individus\n\nDans les deux cas, l’axe des x ne nous sera pas vraiment utile. Il nous servira simplement à afficher des points sur un graphique, mais puisque nous ne disposons que d’une unique variable, c’est bien l’axe des y qui nous intéressera en priorité. Pour faire un nuage de points, on utilise geom_point(), et pour un stripchart geom_jitter(). Commençons par examiner le nuage de points pour la variable body-mass-g :\n\nggplot(penguins, aes(x = seq_along(body_mass_g), y = body_mass_g)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nC’est la fonction seq_along(), que l’on associe à l’axe des x, qui permet de faire apparaître les numéros de lignes du tableau penguins. On constate ici que 3 groupes de points sont présents :\n\nPour les lignes 1 à 150 (environ), un premier groupe de points présente des masses comprises entre 3000 et 4800 grammes environ.\nPour les lignes 151 à 275 (environ), un second groupes de points présente des masses comprises entre 4000 et plus de 6000 grammes.\nPour les lignes 276 à 344 (environ), un troisième groupe de points présente des valeurs similaires à celles du premier groupe.\n\nEn examinant le tableau penguins de plus près, on se rend compte que les 3 espèces de manchots sont présentées dans l’ordre. Ainsi, ces 3 groupes correspondent à 3 espèces différentes. Pour le visualiser, il suffit d’associer la variable species à la couleur des points. Puisqu’on cherche à associer une variable du tableau de données à une caractéristique esthétique d’un objet géométrique, on renseigne color = species à l’intérieur de aes() :\n\nggplot(penguins, aes(x = seq_along(body_mass_g), y = body_mass_g)) +\n  geom_point(aes(color = species))\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nFigure 3.3: Nuage de points des masses corporelles des 3 espèces de manchots\n\n\n\n\nAttention, nous ne sommes déjà plus dans la situation d’une unique variable numérique : nous avons ici visualisé 2 variables : une numérique (portée par l’axe des y) et une catégorielle (l’espèce représentée par la couleur des points). Ici, on constate que les espèces Adélie et Chinstrap semblent avoir approximativement la même gamme de masses, alors que les Gentoo semblent nettement plus lourds.\nComme pour les histogrammes, on peut utiliser des caractéristiques esthétiques variées pour modifier l’apparence des points :\n\nalpha : la transparence. Choisir une valeur comprise entre 0 (invisible) et 1 (totalement opaque)\nsize : la taille des points\ncolor : la couleur des points (ou de leur contour pour les symboles qui permettent de spécifier une couleur de remplissage et une couleur de contour)\nfill : la couleur de remplissage des points (pour les symboles qui permettent de spécifier une couleur de remplissage et une couleur de contour)\nshape : pour modifier les symboles utilisés. Les symboles possibles sont codés ainsi :\n\n\n\n\nFigure 3.4: Liste des symboles et codes correspondants pour les graphiques faisant apparaître des points. Pour les symboles 21 à 25, il sera possible de spécifier une couleur de remplissage fill et une couleur de contour color. Pour tous les autres symboles, les changements de couleurs se feront avec l’argument color.\n\n\nChacune de ces caractéristiques esthétiques peut être associée à une variable d’un tableau (il faut alors le spécifier à l’intérieur de aes()), ou à une valeur unique, constante et identique pour tous les points du graphique (il faut alors le spécifier à l’extérieur de aes()). Par exemple :\n\nggplot(penguins, aes(x = seq_along(body_mass_g), y = body_mass_g)) +\n  geom_point(shape = 23, fill = \"steelblue\", color = \"black\", \n             size = 3, alpha = 0.5)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nL’ajout de la transparence permet de régler le problème des points qui se superposent (un phénomène nommé “overplotting”).\nExaminons à présent un exemple de stripchart :\n\nggplot(penguins, aes(x = \"\", y = body_mass_g)) +\n  geom_jitter()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nEn indiquant x = \"\", nous créons une unique catégorie pour l’axe des abscisses, qui sera utilisée pour placer les valeurs de tous les individus. Les valeurs de body_mass_g sont lues sur l’axe des y, comme pour un nuage de point classique. Si les points apparaissent dispersés, c’est en raison de 2 arguments spécifiques de la fonction geom_jitter() :\n\nwidth = permet de spécifier l’étendue horizontale du bruit aléatoire qui sera utilisé pour placer les points\nheight = permet de spécifier l’étendue verticale du bruit aléatoire qui sera utilisé pour placer les points\n\nSi nous ne renseignons pas nous même ces deux arguments, ils sont fixés automatiquement par le logiciel, ce qui n’est pas souhaitable, notamment pour le bruit vertical. Pour mieux comprendre, voyons ce qui se passe dans 3 situations :\n\nggplot(penguins, aes(x = \"\", y = body_mass_g)) +\n  geom_jitter(width = 0, height = 0)\n\nggplot(penguins, aes(x = \"\", y = body_mass_g)) +\n  geom_jitter(width = 0.1, height = 0)\n\nggplot(penguins, aes(x = \"\", y = body_mass_g)) +\n  geom_jitter(width = 0.1, height = 2000)\n\n\n\n\n\n\n\n(a) Pas de dispersion horizontale, pas de dispersion verticale\n\n\n\n\n\n\n\n(b) Faible dispersion horizontale, pas de dispersion verticale\n\n\n\n\n\n\n\n(c) Faible dispersion horizontale, forte dispersion verticale\n\n\n\n\nFigure 3.5: Trois exemples de stripchart\n\n\n\n\nLe premier exemple (Figure 3.5 (a)) ne présente aucune dispersion, ni horizontale (width = 0), ni verticale (height = 0). Les points apparaissent donc tous alignés, ils ont en effet tous la même valeur sur l’axe des abscisses. Leur position sur l’axe des y reflète la masse réellement observée pour chaque individu. Cette façon de représenter les données n’est pas très utile car la superposition des points vient empêcher la visualisation correcte de la distribution : ici, il est impossible de dire quelles sont les masses les plus fréquemment observées ou les plus rarement observées.\nLe second exemple (Figure 3.5 (b)) présente une dispersion horizontale modérée (width = 0.1) et pas de dispersion verticale (height = 0). Ici, tous les points ne sont plus alignés sur une seule droite. Puisque nous avons fixé width = 0.1, la position horizontale des points est choisie aléatoirement par R : il ajoute un léger bruit horizontal aléatoire, soit positif, soit négatif, avant de placer les points le long de l’axe des abscisses. Plus la valeur de width sera élevée, plus l’étendue du bruit horizontal sera importante. Sur l’axe des y en revanche, aucun bruit n’a été ajouté (height = 0). La position des points le long de cet axe reflète donc parfaitement la masse de chaque individu telle qu’enregistrées dans le tableau penguins et c’est bien ce que nous voulons. D’ailleurs, on constate que l’axe des ordonnées est strictement identique (même étendue, même graduations…) pour les 2 premiers sous-graphiques. C’est ce type de représentation que nous recherchons. En effet, l’absence de bruit vertical nous permet de visualiser correctement (donc sans distorsion) la variable numérique choisie (ici body_mass_g), et le bruit horizontal nous permet d’étaler légèrement les points de part et d’autres d’un axe vertical virtuel, ce qui a pour effet de réduire l’overplotting, et ce qui nous permet donc de visualiser les zones où les points sont plus nombreux/denses et les zones où les observations sont plus rares. Ici, on observe une majorité de points entre 3000 et 4000 grammes, une densité de points intermédiaire entre 4000 et 5000 grammes, et des points moins nombreux (donc moins d’individus) pour les masses supérieures à 5000 grammes.\nLe troisième exemple (Figure 3.5 (c)) présente une dispersion horizontale modérée (width = 0.1) et une importante dispersion verticale (height = 2000). Cela signifie que la position des points sur l’axe des y ne reflète plus les vraies valeurs de masses enregistrées dans le tableau penguins, mais des valeurs de masses auxquelles un bruit aléatoire a été ajouté ou retiré. C’est ce qui explique que l’axe des ordonnées ne présente pas la même échelle que pour les 2 autres graphiques. Ce n’est évidemment pas souhaitable, car si nous voulons bel et bien ajouter un bruit horizontal pour éviter la superposition des points, il est essentiel de ne pas modifier la position verticale des points qui nous renseigne sur la variable d’intérêt. Ici, la Figure 3.5 (c) présente un axe des y différent des 2 autres sous-figures, et la position verticale des points a été tellement altérée qu’on ne peut plus distinguer la sur-abondance de données entre 3000 et 4000 grammes, ni la sous-représentation des observations au-dessus de 5000 grammes. Il sera donc important à l’avenir de toujours fixer height = 0 pour faire un stripchart correct.\n\n\n\n\n\n\n\nImportant\n\n\n\nSur un stripchart :\n\nla position verticale des points ne doit jamais être modifiée. On fixera donc toujours height = 0\nla position horizontale des points doit être modifiée afin d’éviter l’overplotting et de visualiser les zones de fortes et faibles densités de points. On choisira donc en général des valeurs de width comprises entre 0.1 et 0.4\n\n\n\nEnfin, puisqu’un stripchart permet d’afficher des points sur un graphiques, les arguments permettant de modifier l’aspect des points sont les mêmes que pour les nuages de points. Par exemple :\n\nggplot(penguins, aes(x = \"\", y = body_mass_g)) +\n  geom_jitter(aes(color = species, shape = species),\n              size = 3, alpha = 0.6, \n              width = 0.1, height = 0)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nFigure 3.6: Un exemple de stripchart\n\n\n\n\nSur cette figure, comme pour le nuage de points réalisé plus haut, j’ai associé la variable species à la couleur des points (donc à l’intérieur de aes()). J’ai également associé cette variable à la forme des points shape = species à l’intérieur de aes(). C’est ce qui explique que chacune des 3 espèces apparaît sous la forme de symboles de formes et de couleurs différents. Pour limiter l’overplotting, j’ai spécifié un bruit horizontal, et j’ai fixé le bruit vertical à zéro. Enfin j’ai augmenté la taille des symboles (avec size = 3, en dehors de aes() car 3 est une constante qui s’appliquera à tous les points du graphique de la même manière) et leur transparence (avec alpha = 0.6, toujours en dehors de aes() pour la même raison). On constate ici encore que les masses corporelles des manchots Adélie et Chinstrap sont très similaires, et inférieures à celles de l’espèce Gentoo.\n\n\n3.5.3 Exercices\n\nÀ quoi sert l’argument stroke pour les nuages de points et les stripcharts ?\nCréez de nouveaux graphiques (histogramme et diagramme de densité) avec la variable contenant l’information de la longueur des nageoires des manchots flipper_length_mm. Décrivez les graphiques obtenus. Vos observations sont-elles cohérentes avec ce que nous savons maintenant des masses individuelles ?\nVisualisez ces données avec un nuage de points ou un stripchart. Retrouvez-vous les mêmes informations de distribution ?"
  },
  {
    "objectID": "03-Visualization.html#une-seule-variable-catégorielle",
    "href": "03-Visualization.html#une-seule-variable-catégorielle",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.6 Une seule variable catégorielle",
    "text": "3.6 Une seule variable catégorielle\n\n3.6.1 Les diagrammes bâtons\nComme nous l’avons vu plus haut, les histogrammes permettent de visualiser la distribution d’une variable numérique continue. Souvent, on souhaite visualiser la distribution d’une variable catégorielle. C’est une tâche relativement aisée puisqu’elle consiste simplement à compter combien d’éléments tombent dans chacune des catégories (ou modalités) de la variable catégorielle. Le meilleur moyen de visualiser de telles données de comptage (aka fréquences) est de réaliser un diagramme bâtons, autrement appelé barplot ou barchart.\nUne difficulté, toutefois, concerne la façon dont les données sont présentées : est-ce que la variable d’intérêt est “pré-comptée” ou non ? Par exemple, le code ci-dessous crée 2 data.frame qui représentent la même collection de fruits : 3 pommes, 2 oranges et 4 bananes :\n\npanier &lt;- tibble(\n  fruit = c(\"pomme\", \"pomme\", \"banane\", \"pomme\", \"orange\", \"banane\", \"orange\", \"banane\", \"banane\")\n)\n\npanier_counted &lt;- tibble(\n  fruit = c(\"pomme\", \"orange\", \"banane\"),\n  nombre = c(3, 2, 4)\n)\n\nLe tableau panier contient des données qui n’ont pas encore été comptées. Le tableau contient donc une unique variable nommée fruit :\n\npanier\n\n# A tibble: 9 × 1\n  fruit \n  &lt;chr&gt; \n1 pomme \n2 pomme \n3 banane\n4 pomme \n5 orange\n6 banane\n7 orange\n8 banane\n9 banane\n\n\nÀ l’inverse, le tableau panier_counted contient des données qui ont déjà été comptées. Le tableau contient donc 2 variables dans 2 colonnes distinctes : une colonne fruit et une colonne nombre, mais seulement 3 lignes puisque seulement 3 modalités (les catégories de la variable catégorielle) sont présentes pour la variable fruit :\n\npanier_counted\n\n# A tibble: 3 × 2\n  fruit  nombre\n  &lt;chr&gt;   &lt;dbl&gt;\n1 pomme       3\n2 orange      2\n3 banane      4\n\n\nLes deux tableaux panier et panier_counted représentent exactement les mêmes données, mais sous deux formats différents. Du fait de ces deux formats possibles, deux objets géométriques distincts devront être utilisés pour représenter les données. Le graphique obtenu sera le même, mais à chaque format de tableau son geom_...().\n\n3.6.1.1 geom_bar() et geom_col()\nPour visualiser les données non pré-comptées, on utilise geom_bar() :\n\nggplot(panier, aes(x = fruit)) +\n  geom_bar()\n\n\n\n\nFigure 3.7: Barplot pour des données non pré-comptées.\n\n\n\n\nPour visualiser les données déjà pré-comptées, on utilise geom_col() :\n\nggplot(panier_counted, aes(x = fruit, y = nombre)) +\n  geom_col()\n\n\n\n\nFigure 3.8: Barplot pour des données pré-comptées.\n\n\n\n\nNotez que les figures Figure 3.7 et Figure 3.8 sont absolument identiques (à l’exception du titre de l’axe des ordonnées), mais qu’elles ont été créées à partir de 2 tableaux de données différents. En particulier, notez que :\n\nLe code qui génère la figure Figure 3.7 utilise le jeu de données panier, et n’associe pas de variable à l’axe des ordonnées : dans la fonction aes(), seule la variable associée à x est précisée. C’est la fonction geom_bar() qui calcule automatiquement les abondances (ou fréquences) pour chaque catégorie de la variable fruit. La variable count est ainsi générée automatiquement et associée à y.\nLe code qui génère la figure Figure 3.8 utilise le jeu de données panier_counted. Ici, c’est bien l’utilisateur qui associe la variable nombre à l’axe des y à l’intérieur de la fonction aes(). La fonction geom_col() a besoin de 2 variables (une variable catégorielle pour l’axe des x et une numérique pour l’axe des y) pour fonctionner.\n\nAutrement dit, lorsque vous souhaiterez créer un diagramme bâtons, il faudra donc au préalable vérifier de quel type de données vous disposez pour choisir l’objet géométrique approprié :\n\n\n\n\n\n\nDiagrammes bâtons\n\n\n\n\nSi la variable catégorielle n’est pas pré-comptée dans le tableau de données  geom_bar(). La variable catégorielle est associée à l’esthétique x du graphique. On ne renseigne pas y.\nSi la variable catégorielle est pré-comptée dans le tableau de données  geom_col(). La variable catégorielle est associée à l’esthétique x du graphique. On associe explicitement les comptages à l’esthétique y du graphique.\n\n\n\nEnfin, notez que l’ordre des modalité (ou catégories) qui apparaissent sur l’axe des abscisses est l’ordre alphabétique : la modalité banane apparaît à gauche, puis la modalité orange et enfin la modalité pomme. Bien souvent, cet ordre alphabétique n’est pas pertinent. Nous verrons plus loin comment faire pour trier les catégories par ordre croissant ou décroissant. C’est en effet une possibilité intéressante qui est impossible pour les histogrammes (car l’axe des x porte une variable numérique continue qu’il est impossible de “mélanger”), mais souvent vivement recommandée pour les diagrammes bâtons.\n\n\n3.6.1.2 Un exemple concret\nRevenons aux manchots. Imaginons que nous souhaitions connaître le nombre d’individus étudiés pour chaque espèce. Dans le jeu de données penguins, la variable species indique à quelle espèce appartiennent chacun des 344 individus étudiés. Une façon simple de représenter ces données est donc la suivante :\n\nggplot(penguins, aes(x = species)) +\n  geom_bar()\n\n\n\n\nFigure 3.9: Effectifs pour les 3 espèces de manchots étudiées\n\n\n\n\nIci, geom_bar() a compté le nombre d’occurrences de chaque espèce dans le tableau penguins et a automatiquement associé ce nombre à l’axe des ordonnées.\nLà encore, les modalités sont triées par ordre alphabétique sur l’axe des abscisses. Il est généralement plus utile de trier les catégories par ordre décroissant. Nous pouvons faire cela facilement grâce à la fonction fct_infreq() du package forcats, qui permet de modifier l’ordre des modalités d’une variable catégorielle (ou facteur). Si vous avez installé le tidyverse, le package forcast doit être disponible sur votre ordinateur. N’oubliez pas de le charger si besoin :\n\nlibrary(forcats)\nggplot(penguins, aes(x = fct_infreq(species))) +\n  geom_bar()\n\n\n\n\nFigure 3.10: Effectifs pour les 3 espèces de manchots étudiées, triés en ordre décroissant\n\n\n\n\nOrdonner les catégories par ordre décroissant est souvent indispensable afin de faciliter la lecture du graphique et les comparaisons entre catégories.\nSi nous souhaitons connaître le nombre précis d’individus de chaque espèce, il nous faut faire appel à plusieurs fonctions du package dplyr que nous détaillerons dans le chapitre Chapitre 5. Ci-dessous, nous créons un nouveau tableau species_table contenant le nombre d’individus de chaque espèce et les espèces sont ordonnées par abondance décroissante :\n\nspecies_table &lt;- penguins %&gt;%   # On prend le tableau penguins, puis...\n  count(species) %&gt;%            # On compte les effectifs de chaque espèce, puis...\n  arrange(desc(n))              # On trie par effectif décroissants ...\nspecies_table                   # Enfin, on affiche la nouvelle table\n\n# A tibble: 3 × 2\n  species       n\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Gentoo      124\n3 Chinstrap    68\n\n\nIci, la table a été triée par effectifs décroissants. Mais attention, les niveaux du facteur species n’ont pas été modifiés :\n\nfactor(species_table$species)\n\n[1] Adelie    Gentoo    Chinstrap\nLevels: Adelie Chinstrap Gentoo\n\n\nLe premier niveau est toujours Adélie, puis Chinstrap, en enfin Gentoo, et non pas l’ordre du tableau nouvellement créé (Adelie, puis Gentoo, puis Chinstrap) car les niveaux sont toujours triés par ordre alphabétique. La conséquence est que si nous devions faire un diagramme bâtons avec ces données, la fonction geom_col() ne permettrait pas d’ordonner les catégories correctement :\n\nggplot(species_table, aes(x = species, y = n)) +\n  geom_col()\n\n\n\n\nSi nous souhaitons trier ces catégories par effectif décroissant, la fonction fct_infreq() ne nous est ici d’aucune utilité. En effet, le tableau species_table contient une seule ligne pour chaque espèce, donc une fréquence de 1 pour chaque espèce. Le critère de la fréquence d’occurrence des modalités dans le tableau de données ne peut donc pas être utilisé. Pour parvenir à nos fins avec ce tableau déjà précompté, il faut cette fois utiliser la fonction fct_reorder() pour ordonner correctement les catégories. Cette fonction prends 3 arguments :\n\nLa variable catégorielle dont on souhaite réordonner les niveaux (ici, la variable species du tableau species_table).\nUne variable numérique qui permet d’ordonner les catégories (ici, la variable n du même tableau).\nL’argument optionnel .desc qui permet de préciser si le tri doit être fait en ordre croissant (c’est le cas par défaut) ou décroissant.\n\n\nggplot(species_table, \n       aes(x = fct_reorder(species, n, .desc = TRUE), y = n)) +\n  geom_col()\n\n\n\n\nVous voyez donc que selon le type de données dont vous disposez (soit un tableau comme penguins, avec toutes les observations, soit un tableau beaucoup plus compact comme species_table), la démarche permettant de produire un diagramme bâtons, dans lequel les catégories seront triées, sera différente.\nUne dernière précision : inverser l’ordre des variables sur les axes du graphiques permet de faire un diagramme bâtons horizontal. C’est parfois très utile lorsque les modalités de la variable catégorielle sont nombreuses et/ou que leur nom est long. Faire apparaître les modalités sur l’axe des y au lieu de l’axe des x peut rendre leur lecture plus aisée :\n\nggplot(penguins, aes(y = fct_infreq(species))) +\n  geom_bar(fill = \"steelblue\", color = \"black\", alpha = 0.7)\n\n\n\nggplot(species_table, \n       aes(y = fct_reorder(species, n, .desc = TRUE), x = n)) +\n  geom_col(fill = \"firebrick\", color = \"black\", alpha = 0.7)\n\n\n\n\n\n\n3.6.1.3 Exercices\n\nQuelle est la différence entre un histogramme et un diagramme bâtons ?\nPourquoi les histogrammes sont-ils inadaptés pour visualiser des données catégorielles ?\nPourquoi ne peut-on pas trier un histogramme par ordre croissant ?\nQuelle île de l’archipel Palmer a fourni le plus grand nombre de manchots pour cette étude ?\n\n\n\n\n3.6.2 Éviter à tout prix les diagrammes circulaires\nÀ mon grand désarroi, l’un des graphiques classiquement utilisé pour représenter la distribution d’une variable catégorielle est le diagramme circulaire (ou diagramme camembert, piechart en anglais). C’est presque toujours la plus mauvaise visualisation possible pour représenter les effectifs ou pourcentages associés aux modalités d’une variable catégorielle. Je vous demande de l’éviter à tout prix. Notre cerveau n’est en effet pas correctement équipé pour comparer des angles et des surfaces. Ainsi, par exemple, nous avons naturellement tendance à surestimer les angles supérieurs à 90º, et à sous-estimer les angles inférieurs à 90º. En d’autres termes, il est difficile pour les humains de comparer des grandeurs sur des diagrammes circulaires.\nÀ titre d’exemple, examinez ce diagramme, qui reprend les mêmes chiffres que précédemment, et tentez de répondre aux questions suivantes :\n\n\n\n\n\nFigure 3.11: Répartition des effectifs par espèce et par sexe\n\n\n\n\n\nQuelle est la catégorie la plus représentée ?\nDe combien de fois la part des Gentoo mâles est-elle supérieure à celle des Chinstrap femelles ? (1,5 fois, 2 fois, 2.5 fois ?…)\nQuelle est la quatrième catégorie la plus représentée ?\n\nIl est difficile (voir impossible) de répondre précisément à ces questions avec le diagramme circulaire de la Figure 3.11, alors qu’il est très simple d’obtenir des réponses précises avec un diagramme bâtons tel que présenté à la Figure 3.12 ci-dessous (vérifiez-le !) :\n\n\n\n\n\nFigure 3.12: Répartition des effectifs par espèce et par sexe"
  },
  {
    "objectID": "03-Visualization.html#deux-variables-numériques",
    "href": "03-Visualization.html#deux-variables-numériques",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.7 Deux variables numériques",
    "text": "3.7 Deux variables numériques\nLa représentation graphique la plus adaptée à la visualisation des relations entre deux variables numériques est aussi l’une des plus simples : il s’agit des nuages de points que nous avons déjà évoqués. Ici dépendant, puisque nous disposons de 2 variables numériques, nous allons en associer une à l’axe des x et l’autre à l’axe des y. Si l’on pressent que l’une des deux variables pourrait “expliquer” la seconde, ou être en partie responsable de ses variations, on l’appelle variable explicative et on la placera alors sur l’axe des x. L’autre variable, celle que l’on suppose influencée par la première est appelée variable expliquée, et sera associée à l’axe des y.\nLes nuages de points de 2 variables numériques permettent donc de visualiser les relations (supposées ou réelles) entre deux variables.\n\n3.7.1 Nuage de points\n\n3.7.1.1 Syntaxe élémentaire\nPrenons un exemple : nous souhaitons examiner les relations qui existent entre la masse corporelle des individus et la longueur de leur nageoire. Une relation allométrique simple suppose en effet que plus un individu est grand et lourd, plus ses membres seront développés. La nature de la relation allométrique peut toutefois être radicalement différente selon les espèces. Pour l’instant, nous ne nous intéressons pas aux éventuelles différences entre espèces et nous examinerons donc l’ensemble des données, toutes espèces confondues.\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nIci, j’associe body_mass_g à l’axe des x car je suppose que c’est la variable explicative. Il est en effet plus logique de considérer que la masse corporelle influence la longueur des nageoires plutôt que le contraire. La variable expliquée, ici flipper_length_mm est associée à l’axe des y.\nLa syntaxe est donc très simple, et le graphique obtenu permet de constater que plus les individus sont lourds, plus leurs nageoires sont longues.\n\n\n3.7.1.2 Droite de tendance\nSi l’on souhaite visualiser (modéliser !) cette association entre les deux variables, on peut ajouter sur ce graphique une courbe de tendance ou une droite de régression avec l’objet géométrique geom_smooth() :\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nL’argument method = \"lm\" indique que nous souhaitons ajouter une droite de régression (lm est l’abréviation de “linear model”). L’intervalle grisé autour de la droite représente l’incertitude associée à la régression et indique que la “vraie” droite de régression, dans la population générale (et pas seulement dans notre échantillon de 344 individus) est probablement située dans cette zone grisée. Nous aurons l’occasion de revenir en détail sur la notion de régression linéaire et d’incertitude associée plus loin dans ce livre.\n\n\n3.7.1.3 Autres caractéristiques esthétiques\nComme pour tous les graphiques faisant apparaître des points, il est possible de modifier les caractéristiques esthétiques habituelles, soit en les associant à des variables du jeu de données (et en l’indiquant à l’intérieur de aes()), soit en les fixant à des valeurs constantes qui s’appliqueront à tous les points (et en l’indiquant alors en dehors de aes()). L’exemple ci-dessous illustre ces possibilités :\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm, fill = species)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  geom_smooth(aes(color = species), method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nL’argument se = FALSE de la fonction geom_smooth() permet de ne pas afficher l’intervalle d’incertitude de la régression linéaire. Ici, j’ai associé la couleur de remplissage des points et la couleur des droites de régression aux espèces (donc à l’intérieur de aes(), soit dans ggplot() soit dans geom_smooth()), et j’ai fixé pour tous les points, le choix du type de symbole (shape = 21, voir Figure 3.4), la couleur de contour (color = \"black\") et la transparence alpha = 0.6.\nLà encore, il ne s’agit plus strictement d’un graphique représentant les relations entre 2 variables numériques, mais bien entre 3 variables : deux variables numériques (body_mass_g et flipper_length_mm) et une variable catégorielle ou facteur (species). Il est finalement très simple d’ajouter d’autres variables sur un graphique bivarié tel qu’un nuage de points.\n\n\n\n3.7.2 Les graphiques en lignes\nLes graphiques en lignes, ou “linegraphs” sont généralement utilisés lorsque l’axe des x porte une information temporelle, et l’axe des y une autre variable numérique. Le temps est une variable naturellement ordonnée : les jours, semaines, mois, années, se suivent naturellement. Les graphiques en lignes devraient être évités lorsqu’il n’y a pas une organisation séquentielle évidente de la variable portée par l’axe des x. Ainsi, lorsque l’une des 2 variables dont on dispose est une variable numérique temporelle (des dates, des heures, etc.), on la place sur l’axe des x et la seconde variable, dont on étudiera les fluctuations au cours du temps, sur l’axe des y. On peut alors relier les valeurs grâce à l’objet géométrique geom_line() afin de créer une série temporelle. Pour illustrer cela, examinons un autre jeu de données qui contient une variable temporelle :\n\neconomics\n\n# A tibble: 574 × 6\n   date         pce    pop psavert uempmed unemploy\n   &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1 1967-07-01  507. 198712    12.6     4.5     2944\n 2 1967-08-01  510. 198911    12.6     4.7     2945\n 3 1967-09-01  516. 199113    11.9     4.6     2958\n 4 1967-10-01  512. 199311    12.9     4.9     3143\n 5 1967-11-01  517. 199498    12.8     4.7     3066\n 6 1967-12-01  525. 199657    11.8     4.8     3018\n 7 1968-01-01  531. 199808    11.7     5.1     2878\n 8 1968-02-01  534. 199920    12.3     4.5     3001\n 9 1968-03-01  544. 200056    11.7     4.1     2877\n10 1968-04-01  544  200208    12.3     4.6     2709\n# ℹ 564 more rows\n\n\nLe jeu de données economics est fourni avec le package ggplot2. Puisque vous avez chargé ce package (ou le tidyverse qui contient ce package), vous devriez pouvoir accéder à ce tableau sans difficulté. Nous nous intéresserons ici à la variable date que nous placerons sur l’axe des x et à la variable uempmed qui est la durée de chômage médiane dans la population américaine, en nombre de semaines, que nous placerons sur l’axe des y. Examinons donc comment la durée médiane du du chômage a évolué au fil du temps :\n\nggplot(economics, aes(x = date, y = uempmed)) +\n  geom_line()\n\n\n\n\nNotez que puisque la variable date du tableau economics est comprise par R comme étant du type “variable temporelle” (le type indiqué dans le tableau, juste sous le nom de variable, est &lt;date&gt;), l’axe des abscisses du graphique, qui est associé à cette variable, est correctement mis en forme : seules les années apparaissent.\nLes graphiques en lignes permettent de visualiser des progressions/évolutions lorsqu’il existe une temporalité entre les données. Sur l’exemple, traité plus haut, du lien entre masse et longueur des nageoire des manchots, relier les points n’aurait absolument aucun sens puisque toutes les observations sont indépendantes : elles correspondent à des individus différents. Soyez donc prudents lorsque vous reliez les points dur un graphique. Cela n’est possible que lorsque les données le permettent. Vous devez donc toujours vous poser la question de la pertinence de vos choix de représentations.\nComme pour les autres types de graphiques, il est possible de modifier les caractéristiques esthétiques des lignes sur un graphique, en particulier :\n\ncolor : la couleur des lignes\nsize : l’épaisseur des lignes\nlinetype : le type de ligne (continue, pointillée, tirets, etc. Essayez plusieurs valeurs entières pour comparer les types de lignes)\n\n\nggplot(economics, aes(x = date, y = uempmed)) +\n  geom_line(color = \"orange\", linetype = 2)\n\n\n\n\nL’argument linetype est également utilisable par l’objet géométrique geom_smooth() :\n\nggplot(economics, aes(x = date, y = uempmed)) +\n  geom_line() +\n  geom_smooth(se = FALSE, linetype = 4, color = \"red\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nGlobalement, la durée médiane de chômage aux USA varie de façon cyclique. La durée des cycles varie selon les période entre 5 et 10 ans environ. Depuis les années 2000, la durée de chômage a augmenté de façon très importante, pour passer de 5 à 6 semaines en 2001, à plus de 25 semaines en 2011.\n\n\n3.7.3 Les cartes\nLes latitudes et longitudes sont un autre type de variable numériques très particulières qui permettent notamment de produire des cartes. Il s’agit ici d’un domaine extrêmement vaste qui dépasse largement le cadre de ce livre. Retenez simplement qu’il est possible de produire des cartes très informatives avec ggplot2, et quelques autres packages spécialisés :\n En règle général, les cartes portent un grand nombre de variables, numériques et/ou catégorielles. Mais tout commence toujours par 2 variables numériques, les latitudes et longitude des structures/informations que l’on souhaite représenter (traits de côte, profiles bathymétriques, lieux d’observations diverses, …)."
  },
  {
    "objectID": "03-Visualization.html#deux-variables-catégorielles",
    "href": "03-Visualization.html#deux-variables-catégorielles",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.8 Deux variables catégorielles",
    "text": "3.8 Deux variables catégorielles\nLorsque l’on souhaite examiner les relations entre deux variables catégorielles (ou facteurs), on a en général le choix entre les types de représentations graphiques suivants :\n\nles diagrammes bâtons empilés\nles diagrammes bâtons juxtaposés\nles diagrammes bâtons “facettés”\nles graphiques en mosaïque (ou mosaic plots)\n\nPour toutes ces méthodes, des données qui n’ont pas été comptées au préalable sont requises. Il est en effet beaucoup plus simple de travailler avec le tidyverse (donc avec ggplot2) lorsque chaque ligne d’un tableau correspond à une observation plutôt qu’à une somme d’observation. C’est le concept de tableau rangé, central dans le traitement de données ainsi que pour l’utilisation de tous les packages du tidyverse, et qui stipule qu’un tableau de données devrait contenir une unique ligne pour chaque observation, et une unique colonne pour chaque variable. Nous aurons l’occasion (notamment en L3) de voir des tableaux qui ne respectent pas ces règles et que nous devrons donc ré-organiser pour permettre leur analyse et les représentations graphiques.\nNous allons passer ces différentes possibilités en revue pour examiner les liens entre 2 variables catégorielles du jeu de données penguins : species et sex. La première renseigne sur l’espèce à laquelle un individu étudié appartient. La seconde renseigne sur le sexe de chaque individu. L’étude du sex-ratio est en effet souvent essentielle pour comprendre l’écologie des espèces. Les sexe-ratios sont-ils équilibrés ou non. Et s’ils ne sont pas équilibrés, sont-ils en faveur des mâles ou des femelles ?\n\n3.8.1 Diagrammes bâtons empilés\nLa façon la plus simple (mais rarement la meilleure) de procéder pour visualiser 2 facteurs conjointement est de créer un diagramme bâtons empilés :\n\nggplot(penguins, aes(x = species, fill = sex)) +\n  geom_bar()\n\n\n\n\nIci, les espèces sont associées à l’axe des x (x = species) et la couleur de remplissage des barres est associée au sexe des individus (fill = sex), à l’intérieur de la fonction aes(). Comme toujours, on peut modifier certaines caractéristiques esthétiques (couleur de contour des barres, transparence, etc.) et ré-ordonner les espèces sur l’axe des abscisses :\n\nggplot(penguins, aes(x = fct_infreq(species), fill = sex)) +\n  geom_bar(alpha = 0.6, color = \"black\")\n\n\n\n\nCe type de visualisation est utile pour se rendre compte des ordres de grandeur. On voit ici clairement que l’espèce Adélie est la plus représentée dans cette étude, suivie par l’espèce Gentoo, et enfin l’espèce Chinstrap. Pour chacune de ces 3 espèces, le sex-ratio a l’air très équilibré. Toutefois, des différences subtiles de proportions entre mâles et femelles selon les espèces pourraient être masqués par les effectifs inégaux entre espèces. Il peut donc être préférable, pour comparer des proportions, de normaliser les effectifs de toutes les espèces pour ramener chaque barre du graphique à la même hauteur :\n\nggplot(penguins, aes(x = fct_infreq(species), fill = sex)) +\n  geom_bar(alpha = 0.6, color = \"black\", position = \"fill\")\n\n\n\n\nL’argument position = \"fill\" de la fonction geom_bar() permet de transformer en proportions les abondances de chaque modalités de la variable portée par l’axe des x. L’axe des ordonnées varie maintenant entre 0 et 1 (0% et 100%), ce qui rend les comparaisons plus aisées. Ici, le fait que le sexe de quelques individus n’ait pas pu être déterminé vient gêner la lecture du graphique. On peut supprimer ces valeurs grâce à la fonction filter() du packages dplyr. Nous verrons dans le #sec-wrangling la signification du code suivant. Pour l’instant retenez simplement qu’il permet d’éliminer les individus dont le sexe est inconnu :\n\npenguins %&gt;% \n  filter(!is.na(sex)) %&gt;% \n  ggplot(aes(x = fct_infreq(species), fill = sex)) +\n  geom_bar(alpha = 0.6, color = \"black\", position = \"fill\")\n\n\n\n\nOn peut maintenant constater très facilement que le sex-ratio est parfaitement équilibré pour les espèces Adélie et Chinstrap, et qu’il est très légèrement en faveur des mâles pour l’espèce Gentoo.\n\n\n3.8.2 Diagrammes bâtons juxtaposés\nLa syntaxe permettant de produire un diagramme bâtons juxtaposé est très similaire à celle décrite ci-dessus :\n\nggplot(penguins, aes(x = fct_infreq(species), fill = sex)) +\n  geom_bar(alpha = 0.6, color = \"black\", position = \"dodge\")\n\n\n\n\nLa seule chose qui a changé est la valeur prise par l’argument position, que l’on fixe ici à dodge. L’avantage de cette représentation est qu’elle permet à la fois de visualiser les effectifs de chaque catégorie et sous-catégorie (espèce et sexe), ainsi que de comparer les proportions au sein de chaque espèce. Un inconvénient et que lorsque les catégories n’ont pas toutes le même nombre de sous-catégories, les barres ont des largeurs différentes. Ici, l’espèce Chinstrap, qui n’a que 2 sous catégories (female et male) présente des barres plus larges que les deux autres espèces qui présentent chacune 3 sous-catégories (female, male et NA). Pour y remédier, on peut :\n\nsoit retirer les données manquantes, comme précédemment :\n\n\npenguins %&gt;% \n  filter(!is.na(sex)) %&gt;% \n  ggplot(aes(x = fct_infreq(species), fill = sex)) +\n  geom_bar(alpha = 0.6, color = \"black\", position = \"dodge\")\n\n\n\n\n\nsoit imposer que toutes les sous-catégories apparaissent pour chaque catégorie :\n\n\nggplot(penguins, aes(x = fct_infreq(species), fill = sex)) +\n  geom_bar(alpha = 0.6, color = \"black\",\n           position = position_dodge(preserve = \"single\") )\n\n\n\n\nIci, l’argument position prend une valeur plus complexe puisque nous faisons appel à une fonction nommée position_dodge(). C’est l’argument preserve = \"single\" qui permet de s’assurer que toutes les sous-catégories sont bien représentées au sein de chaque catégorie, et donc, que toutes les barres ont bien la même largueur.\nLe choix d’une méthode ou de l’autre dépend de ce que l’on souhaite montrer : il n’y a pas une façon de faire meilleure ou moins bonne que l’autre. Tout dépend de l’objectif poursuivi par l’auteur du graphique.\n\n\n3.8.3 Diagrammes bâtons “facettés”\nDans le jargon de ggplot2, les facets sont simplement des sous-graphiques. Typiquement, une variable catégorielle peut être utilisée pour représenter un sous-graphique pour chaque modalité de cette variable. Ici, on peut par exemple produire un diagramme bâton pour chaque espèce, et l’axe des x de chaque graphique portera la variable sex :\n\nggplot(penguins, aes(x = sex)) +\n  geom_bar() +\n  facet_wrap(~species)\n\n\n\n\nC’est la fonction facet_wrap() qui permet de produire plusieurs sous graphiques. Examinons quelques-une de ces particularités :\n\nsa syntaxe fait appel à la notion de “formule”, utilisée pour certaines fonctions spécifiques dans le langage R. Nous en verrons des exemples en L3 pour illustrer certains tests statistiques. Le tilde ~ se lit “en fonction de”. Ici ~species signifie “crée des facets en fonction des espèces”, autrement dit, produit un sous-graphique par modalité de la variable species.\npar défaut, les axes de tous les sous graphiques sont strictement identiques, en abscisse comme en ordonnée. On peut modifier ce comportement grâce à l’un des arguments suivants : scales = \"free_x\" (pour que les axes des abscisses soient indépendants entre les sous-graphiques), scales = \"free_y\" (pour que les axes des ordonnées soient indépendants entre les sous-graphiques) ou scales = \"free\" (pour quelles deux axes soient indépendants entre les sous-graphiques)\nl’argument ncol = permet de spécifier le nombre de colonnes souhaité pour l’organisation des sous-graphiques\n\nVoici un exemple de ces syntaxes :\n\nggplot(penguins, aes(x = sex)) +\n  geom_bar() +\n  facet_wrap(~species, scales = \"free_y\", ncol = 2)\n\n\n\n\nLes 3 sous-graphiques sont maintenant disposés dans 2 colonnes, et si l’axe des x est toujours le même pour chaque sous-graphique, les axes des y sont différents pour les 3 sous-graphiques.\nPour égayer un peu ce graphique, ajoutons une couleur de remplissage pour les barres, selon l’espèce :\n\nggplot(penguins, aes(x = sex, fill = species)) +\n  geom_bar(color = \"black\", alpha = 0.7) +\n  facet_wrap(~species, scales = \"free_y\", ncol = 2)\n\n\n\n\nLa légende qui est automatiquement créée à droite est inutile puisque les sous-graphiques indiquent déjà le nom des espèces. Pour retirer une légende inutile, on peut utiliser l’argument show.legend = FALSE de la plupart des objets géométriques :\n\nggplot(penguins, aes(x = sex, fill = species)) +\n  geom_bar(color = \"black\", alpha = 0.7, show.legend = FALSE) +\n  facet_wrap(~species, scales = \"free_y\", ncol = 2)\n\n\n\n\n\n\n3.8.4 Mosaïc plots\nLes graphiques en mosaïque sont une alternative aux diagrammes bâtons en tous genre. Ils permettent de visualiser à la fois les effectifs et de comparer les proportions. La difficulté de ce genre de graphique est qu’il n’existe pas d’objet géométrique permettant de les représenter simplement dans le package ggplot2. Le package ggmosaic de Jeppson, Hofmann, et Cook (2021) est toutefois entièrement dédié à ce type de graphique. Installez ce package puis chargez-le en mémoire :\n\ninstall.packages(\"ggmosaic\")\nlibrary(ggmosaic)\n\nOn peut maintenant accéder à un nouvel objet géométrique, geom_mosaic(), dont l’utilisation est un peu différente de celle que nous avons vu jusqu’ici :\n\nggplot(penguins) +\n  geom_mosaic(aes(x = product(species), fill = sex))\n\n\n\n\nIl faut obligatoirement :\n\nspécifier aes() à l’intérieur de geom_mosaic() et non à l’intérieur de ggplot()\nutiliser la fonction product() (qui fait elle aussi partie du package ggmosaic) pour indiquer quelle variable catégorielle on souhaite associer à l’axe des x\nComme pour les diagrammes bâtons, la couleur de remplissage est associée à la seconde variable catégorielle de façon tout à fait classique\n\nComme pour les diagrammes en bâtons empilés pour lesquels on spécifie position = \"fill\", toutes les barres d’un graphique en mosaïque ont la même hauteur, ce qui permet de visualiser les proportions de chaque sexe pour chaque espèce, mais pas les effectifs. C’est ici la largueur des barres qui est proportionnelle aux effectifs de chaque espèce. Si on n’accède par directement aux valeurs absolues, on peut néanmoins effectuer des comparaisons d’ordres de grandeur. L’espèce Adélie est ainsi la plus représentée dans nos données, suivie de l’espèce Gentoo puis de l’espèce Chinstrap.\nAu final, le choix d’un graphique doit vous permettre de mettre en évidence les relations qui vous paraissent importantes de la façon la plus visuelle et évidente possible pour une personne ne connaissant pas vos données. Votre choix dépendra donc des données disponibles et de votre objectif (p. ex. comparaisons de proportions ou de valeurs absolues, nombreuses modalités ou seulement quelques unes, etc.)."
  },
  {
    "objectID": "03-Visualization.html#une-variable-de-chaque-type",
    "href": "03-Visualization.html#une-variable-de-chaque-type",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.9 Une variable de chaque type",
    "text": "3.9 Une variable de chaque type\nLes représentations graphiques réalisables et pertinentes lorsque l’on dispose d’une variable numérique et d’un facteur sont souvent des adaptations des graphiques précédents. Globalement, trois choix s’offrent à nous :\n\nles histogrammes facettés\nles stripcharts\nles boîtes à moustaches, que nous détaillerons au semestre 4. Nous donnerons ici un simple exemple sans expliquer la signification de tous les éléments de ces graphiques\n\nPour illustrer ces différentes possibilités, intéressons nous maintenant à la relation qui existe entre l’épaisseur du bec des manchots (bill_depth_mm, variable numérique) et l’espèce (species, variable catogorielle ou facteur)\n\n3.9.1 Histogrammes “facettés”\nLa syntaxe est ici tout à fait classique. Pour réaliser un histogramme, on place la variable numérique sur l’axe des abscisses. La variable catégorielle nous servira à créer les sous graphiques, ici, un par espèce. Afin de faciliter les comparaisons, nous placerons les sous-graphiques les uns sous les autres en spécifiant ncol = 1. Enfin, l’aspect général sera amélioré en modifiant quelques caractéristiques esthétiques :\n\nggplot(penguins, aes(x = bill_depth_mm)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\", \n                 alpha = 0.6, bins = 20) +\n  facet_wrap(~species, ncol = 1)\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nOn peut aussi choisir d’utiliser une couleur pour chaque espèce (mais on n’affichera pas la légende puisque les espèces sont déjà séparées dans les sous graphiques). En outre, puisque les effectifs des Chinstrap sont bien plus faibles que pour les deux autres espèces, on a intérêt à “libérer” l’axe des y afin que l’histogramme des Chinstrap soit plus facilement lisible (il apparaît pour l’instant très “écrasé” comparé aux autres).\n\nggplot(penguins, aes(x = bill_depth_mm, fill = species)) +\n  geom_histogram(show.legend = FALSE, color = \"black\", \n                 alpha = 0.6, bins = 20) +\n  facet_wrap(~species, ncol = 1, scales = \"free_y\")\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nLes Gentoo, qui ont pourtant des masses corporelles supérieures à celle des deux autres espèces (voir Figure 3.3 de la Section 3.5.2), ont visiblement des becs moins épais (entre 12 et 17 mm) que les deux autres espèces (entre 16 et 22 mm).\n\n\n\n\n\n\nImportant\n\n\n\nC’est la position des données le long de l’axe des x qui nous permet de faire des comparaisons pertinentes. Il est donc essentiel de présenter les différents histogrammes les uns sous les autres, en conservant la même échelle pour les abscisses de tous les sous-graphiques.\n\n\nIci, on peut donc discuter de la distribution de la variable numérique pour chaque modalité de la variable catégorielle (i.e. quelle distribution de l’épaisseur des becs pour chaque espèce), mais on peut en plus faire des comparaisons entre modalités (entre les espèces). Cela est beaucoup plus pertinent que de s’intéresser à la distribution de l’épaisseur des becs toutes espèces confondues.\n\n\n3.9.2 Les stripcharts\nNous avons déjà abordé ce type de graphique dans la Section 3.5.2. Contrairement à la situation où nous n’avions qu’une variable numérique et où nous devions fixer x = \"\" pour que toutes les observations se placent au même niveau de l’axe des abscisses (voir Figure 3.6), nous allons ici associer la variable catégorielle à l’axe des x. La variable numérique sera quant-à-elle toujours associée à l’axe des ordonnées :\n\nggplot(penguins, aes(x = species, y = bill_depth_mm)) +\n  geom_jitter(width = 0.20, height = 0)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nFigure 3.13: Un exemple de stripchart\n\n\n\n\nNotez que la position des points sur l’axe des y doit parfaitement correspondre aux valeurs contenues dans le jeu de données pour la variable numérique d’intérêt. Cela signifie que l’argument height doit obligatoirement être fixé à 0.\nComme pour les diagrammes bâtons, il est possible de produire des stripcharts horizontaux. Les modifications à apporter sont alors les suivantes :\n\nla variable numérique est associée à l’axe des x\nla variable catégorielle est associée à l’axe des y\nla dispersion horizontale width doit obligatoirement être fixée à 0\nla dispersion verticale height doit être comprise entre 0.1 et 0.4 pour étaler les points de chaque modalité et ainsi éviter l’overplotting\n\n\nggplot(penguins, aes(x = bill_depth_mm, y = species)) +\n  geom_jitter(width = 0, height = 0.20, alpha = 0.6)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n3.9.3 Les boîtes à moustaches ou boxplots\nVoilà à quoi ressemble un graphique de ce type pour les données qui nous intéressent (épaisseur des becs selon l’espèce) :\n\nggplot(penguins, aes(x = species, y = bill_depth_mm)) +\n  geom_boxplot()\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nDans la forme, ça ressemble un à un stripchart (comparez par exemple avec la syntaxe et les résultats obtenus à la Figure 3.13). Néanmoins, ici, au lieu de visualiser tous les points du jeu de données, seules quelques valeurs caractéristiques sont utilisées pour construire le boîte à moustache de chaque espèce. Les différents éléments d’un boxplot, sont les suivants :\n\nLa limite inférieure de la boîte correspond au premier quartile : 25% des données de l’échantillon sont situées au-dessous de cette valeur.\nLa limite supérieure de la boîte correspond au troisième quartile : 25% des données de l’échantillon sont situées au-dessus de cette valeur.\nLe segment épais à l’intérieur de la boîte correspond au second quartile : c’est la médiane de l’échantillon. 50% des données de l’échantillon sont situées au-dessus de cette valeur, et 50% au-dessous.\nLa hauteur de la boîte correspond à ce que l’on appelle l’étendue inter-quartile ou Inter Quartile Range (IQR) en anglais. On trouve dans cette boîte 50% des observations de l’échantillon. C’est une mesure de la dispersion des 50% des données les plus centrales. Une boîte plus allongée indique donc une plus grande dispersion.\nLes moustaches correspondent à des valeurs qui sont en dessous du premier quartile (pour la moustache du bas) et au-dessus du troisième quartile (pour la moustache du haut). La règle utilisée dans R est que ces moustaches s’étendent jusqu’aux valeurs minimales et maximales de l’échantillon, mais elles ne peuvent en aucun cas s’étendre au-delà de 1,5 fois la hauteur de la boîte (1,5 fois l’IQR) vers le haut et le bas. Si des points apparaissent au-delà des moustaches (vers le haut ou le bas), ces points sont appelés “outliers”. On peut en observer un pour l’espèce Adélie. Ce sont des points qui s’éloignent du centre de la distribution de façon importante puisqu’ils sont au-delà de 1,5 fois l’IQR de part et d’autre du premier ou du troisième quartile. Il peut s’agir d’anomalies de mesures, d’anomalies de saisie des données, ou tout simplement, d’enregistrements tout à fait valides mais atypiques ou extrêmes. J’attire votre attention sur le fait que la définition de ces outliers est relativement arbitraire. Nous pourrions faire le choix d’étendre les moustaches jusqu’à 1,8 fois l’IQR (ou 2, ou 2,5). Nous observerions alors beaucoup moins d’outliers. D’une façons générale, la longueur des moustaches renseigne sur la variabilité des données en dehors de la zone centrale. Plus elles sont longues, plus la variabilité est importante. Et dans tous les cas, l’examen attentif des outliers est utile car il nous permet d’en apprendre plus sur le comportement extrême de certaines observations.\n\nLorsque les boîtes ont une forme à peu près symétrique de part et d’autre de la médiane (c’est le cas pour notre exemple), cela signifie qu’un histogramme des mêmes données serait symétrique également (on peut le vérifier avec les histogrammes de la Section 3.9.1).\n\n3.9.3.1 L’intervalle de confiance à 95% de la médiane\nOn peut également ajouter une encoche autour de la valeur de médiane en ajoutant l’argument notch = TRUE à la fonction geom_boxplot() :\n\nggplot(penguins, aes(x = species, y = bill_depth_mm)) +\n  geom_boxplot(notch = TRUE)\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nL’encoche qui apparaît sur chaque boîte à moustache correspond à l’étendue de l’intervalle de confiance à 95% de la médiane. Pour chaque échantillon, nous espérons que la médiane calculée soit le reflet fidèle de la vraie valeur de médiane de la population générale. Mais il sera toujours impossible d’en avoir la certitude absolue. Le mieux que l’on puisse faire, c’est quantifier l’incertitude associée à l’estimation de la médiane à partir des données d’un échantillon. L’intervalle de confiance nous indique qu’il y a de bonnes chances que la vraie valeur de médiane de la population générale (qui restera à jamais inconnue) se trouve dans cet intervalle.\nNous reviendrons sur cette notion importante plus tard dans le cursus, car ce type de graphique nous permettra d’anticiper sur les résultats des tests statistiques de comparaison de moyennes.\nAu final, nous avons 3 moyens d’obtenir des informations de distribution :\n\nobserver l’ensemble des données brutes grâce à un nuage de points ou stripchart\nregrouper en partie les données brutes dans les classes d’un histogramme. On ne visualise plus l’ensemble des données individuelles, mais un résumé de ces données puisqu’on ne dispose plus que d’une unique valeur pour chaque classe de l’histogramme. L’histogramme peut donc résumer des centaines voire des milliers de points sous la forme d’un petit nombre de classes (entre 10 et 40 en général)\nregrouper très fortement les données brutes sous la forme d’une boîte à moustache. Les boîtes à moustaches permettent de résumer l’information de centaines ou milliers de points sous la forme d’un résumé statistique composé de 5 valeurs (minimum et maximum, médiane, premier et troisième quartiles), ou 7 si l’on ajoute les encoches des intervalles de confiance à 95% des médianes. On observe alors moins facilement les nuances subtiles de distribution qu’avec un histogramme ou les données brutes, mais l’avantage est qu’on peut comparer facilement les grandes tendances d’un grand nombre de séries de données (parfois plusieurs dizaines) en plaçant des boîtes à moustaches côte à côte.\n\nLa Figure 3.14 illustre ces 3 possibilités de visualisation de la distribution d’une variable numérique (ici, la distribution des masses corporelles des manchots Adélie) :\n\n\n\n\n\nFigure 3.14: Trois façons de visualiser la distribution des masses des manchots Adélie"
  },
  {
    "objectID": "03-Visualization.html#trois-variables-et-plus",
    "href": "03-Visualization.html#trois-variables-et-plus",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.10 Trois variables (et plus !)",
    "text": "3.10 Trois variables (et plus !)\nLorsque l’on dispose de 3 variables, les situations possibles commencent à être nombreuses :\n\ntrois variables numériques\ndeux variables numériques et un facteur\nune variable numérique et deux facteurs\ntrois facteurs\n\nPour chacune de ces situations, on peut en générale reprendre les types de graphiques proposés dans les 3 sections précédentes consacrées aux situations où l’on dispose de 2 variables (), et :\n\nsoit ajouter une variable sous forme de code couleur (avec color ou fill à l’intérieur de aes())\nsoit ajouter une variable sous forme de facets (avec facet_wrap() ou avec facet_grid())\n\nLes possibilités sont très nombreuses et il ne sera pas possible d’être exhaustif ici. Je fournis néanmoins quelques exemples ci-dessous afin que vous compreniez bien la logique. Ensuite, ça sera à vous d’expérimenter selon les données dont vous disposez, les questions scientifiques que vous vous posez, et les relations que vous souhaitez explorer/visualiser.\n\n3.10.1 Trois variables numériques\nDans cette situation, on fait en général un nuage de points qui porte une variable numérique sur chaque axe, et on associe la troisième variable numérique soit à la couleur des points, soit à leur taille (soit aux deux à la fois). Par exemple, pour examiner les relations entre longueur du bec, épaisseur du bec, et masse corporelle, on peut procéder ainsi :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     size = body_mass_g)) +\n  geom_point(shape = 21, fill = \"steelblue\", color = \"black\", alpha = 0.6)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nC’est ce qu’on appelle un “bubble plot”. Ici on constate que les individus qui ont les becs les plus courts, sont aussi ceux qui ont un bec épais (groupe de points en haut à gauche). Ces individus sont parmi les plus légers (symboles de petite taille). À l’inverse, les individus ayant les becs les plus longs ont aussi des becs peu épais (groupes de points situés en bas à droite). Ces individus sont parmi les plus lourds du jeu de données (symboles de grandes taille).\nUne autre façon de visualiser ces mêmes données consiste à associer la masse des individus à la couleur de remplissage des symboles :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6, size = 2)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nCette fois, les individus les plus légers apparaissent en bleu très sombre, et les individus les plus lourds en bleu très clair. Ce choix de couleur nous est imposé, mais nous verrons plus loin comment le modifier pour rendre ce type de graphique plus facile à lire. Lorsque nous associons une variable numérique continue à la couleur des points, la légende qui est générée automatiquement pour nous par R sera toujours un gradient de couleurs. Si vous revenez en arrière au niveau des graphiques en mosaïques (Section 3.8.4), ou au niveau des diagrammes bâtons juxtaposés (Section 3.8.2), vous verrez que lorsque la couleur est associée à une variable catégorielle (ou facteur), la légende présente des couleurs distinctes, une pour chaque modalité du facteur considéré. Là encore, R choisit les couleurs pour nous. Mais là encore, nous verrons comment imposer des couleurs différentes si les choix par défaut ne nous conviennent pas.\nEnfin, il est évidemment possible de jouer à la fois sur la couleur et sur la taille des symboles :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nIci, l’information de masse est donc associée à 2 caractéristiques esthétiques distinctes : la couleur de remplissage des points et leur taille. Cela rend la lecture plus facile dans certaines situations.\nAu final, nous avons donc associé 3 variables numériques à 4 caractéristiques esthétiques du graphique :\n\nbill_length_mm est associée à x\nbill_depth_mm est associée à y\nbody_mass_g est associé à fill\nbody_mass_g est associé à size\n\nRien ne nous empêche d’ajouter des variables et des caractéristiques esthétiques. C’est ce que nous allons voir tout de suite.\n\n\n3.10.2 Cinq variables !\nPour commencer, essayez de reproduire le graphique suivant :\n\n\nWarning: Removed 11 rows containing missing values (`geom_point()`).\n\n\n\n\n\nIci, 5 variables du jeu de données (3 numériques et 2 facteurs) sont associées à 5 caractéristiques esthétiques du graphique. Le graphique est donc très riche, on peut voir par exemple :\n\nque les 3 espèces ont des morphologies de bec assez distinctes : les Gentoo ont des becs longs et fins, les Chinstrap ont des becs longs et épais, et les Adélie ont des becs courts et épais.\nqu’un dimorphisme sexuel est présent au niveau du bec : pour chaque espèce, les mâles ont des becs plus longs et épais que les femelles\nqu’un dimorphisme sexuel est présent au niveau des masses : pour chaque espèce, les mâles sont plus lourds que les femelles\n\nAu final, beaucoup d’informations sont présentées sur ce graphique et c’est presque trop. Même en améliorant l’aspect général du graphique pour le rendre plus lisible (voir ci-dessous), il vaut parfois mieux se limiter à 2 ou 3 variables et faire plusieurs graphiques, plutôt que de tout mettre sur le même. Une bonne solution consiste souvent à mettre 2 ou 3 variables sur un graphique, mais à faire plusieurs sous-graphiques pour chaque modalité d’une 4ème et/ou d’une 5ème variable catégorielle.\n\n\n\n\n\nEn particulier, sur ce graphique, il est presque impossible de déterminer la masse des individus mâles. La légende indique en effet des tailles de cercles qui correspondent à des masses spécifiques. Mais nous n’avons aucune indication pour la taille des triangles. Il vaudrait donc mieux procéder ainsi :\n\n\n\n\n\nFigure 3.15: Relation entre la morphologie du bec, la masse et le sexe chez trois espèces de manchots de l’archipel Palmer\n\n\n\n\nEn associant le sexe des individus à la couleur de remplissage plutôt qu’à la forme des points, et en faisant un sous-graphique par espèce, on élimine la difficulté de lecture liée à la taille des symboles triangulaires. L’information concernant la masse des individus est donc plus facile à visualiser. Le dimorphisme sexuel de taille des becs, présent pour chaque espèce, apparaît beaucoup plus clairement qu’avant (les mâles ont des becs plus longs et épais que les femelles). Mais les différences inter-spécifiques de morphologie des becs sont moins visibles qu’avant, notamment pour les différences de longueur des becs selon les espèces. On ne peut malheureusement pas gagner sur les tableaux à la fois. C’est la raison pour laquelle les choix de graphiques que vous ferez devront refléter les questions auxquelles vous vous intéressez, et les messages que vous souhaitez faire passer.\n\n\n3.10.3 Deux variables numériques et un facteur\nL’exemple qui suit est fondamental pour bien comprendre l’importance d’explorer en détail tous les aspects d’un jeu de données pour éviter de dire de grosses bêtises.\nImaginez que dans le jeu de données penguins, on souhaite étudier la relation qui existe entre l’épaisseur du bec des individus et la longueur des nageoires. Ces deux variables étant numériques, il semble logique de commencer par faire un nuage de points :\n\nggplot(penguins, aes(x = bill_depth_mm, y = flipper_length_mm)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nNous avons vu plus haut que pour visualiser le relations qui existent entre deux variables numériques, il est possible d’ajouter une courbe ou une droite de tendance avec la fonction geom_smooth() :\n\nggplot(penguins, aes(x = bill_depth_mm, y = flipper_length_mm)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nSi l’on s’en tient à ça, la relation semble claire : plus le bec des individus est épais, plus leurs nageoires sont courtes, et inversement. En outre, nous avons visiblement deux groupes d’individus qui présentent des caractéristiques distinctes : certains ont des becs fins et des nageoires très longues, quand d’autres ont des becs épais et des nageoires courtes. Et quasiment aucun individu ne présente de caractéristiques intermédiaires (becs d’épaisseur moyenne épais et nageoires moyennes).\nEn réalité, cette vision des choses est totalement trompeuse ! N’oubliez pas que nous avons 3 espèces distinctes dans ce jeu de données, et que ces espèces peuvent présenter des caractéristiques morphologiques très variées. Examiner la relation becs-nageoires tel que nous l’avons fait, sans considérer les espèces, n’a strictement aucun sens ! Pour s’en convaincre, il suffit d’associer la couleur (des points et des lignes) à l’espèce :\n\nggplot(penguins, aes(x = bill_depth_mm, y = flipper_length_mm,\n                     color = species)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nLe résultat obtenu ici est à l’opposé de nos conclusions précédentes : la relation entre les deux variables numérique est en fait positive ! Au sein de chaque espèce, les individus possédant les becs les plus épais sont aussi ceux qui possèdent les nageoires les plus longues !\nEn statistiques ce phénomène (observer une relation inverse lorsque plusieurs groupes sont combinés) s’appelle le paradoxe de Simpson, et je vous encourage à consulter la page wikipédia qui y est consacrée.\nIci, si la relation entre nos deux variables numériques s’inverse lorsque l’on examine cette relation à l’échelle de chaque modalité de la variable catégorielle. Une façon encore plus nette de mettre la relation positive en évidence est la suivante :\n\nggplot(penguins, aes(x = bill_depth_mm, y = flipper_length_mm,\n                     color = species)) +\n  geom_point(show.legend = FALSE) +\n  geom_smooth(method = \"lm\", show.legend = FALSE) +\n  facet_wrap(~species, scales = \"free\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nMême sans connaître en détail le principe et les limites de la régression linéaire, vous comprenez j’espère à quel point l’exploration rigoureuse d’un jeu de données est importante. Par exemple, nous avons vu que plus tôt que, pour chaque espèce, les mâles sont plus lourds que les femelles. Est-ce que des différences morphologiques entre les sexes pourraient expliquer la relation que nous observons ici entre épaisseur du bec et longueur des nageoires ? Est-il possible qu’un second effet Simpson se cache dans ces données ? Si on distingue les deux sexes au sein de chaque espèce, la relation existe-t-elle toujours ? Et si oui, est-elle toujours positive ou s’inverse-t-elle à nouveau ? Pour le savoir, on peut utiliser une autre fonction permettant de produire des sous-graphiques, la fonction facte_grid(), qui permet de faire un sous graphique pour chaque combinaison de modalités de 2 variables catégorielles :\n\npenguins %&gt;% \n  filter(!is.na(sex)) %&gt;%    # Elimine les individus dont le sexe est inconnu\n  ggplot(aes(x = bill_depth_mm, y = flipper_length_mm,\n                     color = species, shape = sex)) +\n  geom_point(show.legend = FALSE) +\n  geom_smooth(method = \"lm\", show.legend = FALSE) +\n  facet_grid(sex ~ species, scales = \"free\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nLa syntaxe sex ~ species indique que l’on souhaite un sous-graphique pour chaque combinaison des modalités des facteurs sex et species. Les graphiques correspondant aux différents sexes apparaîtront sur des lignes distinctes, et les espèces sur des colonnes distinctes. On constate ici que si la relation semble toujours positive et assez nette pour les mâles des 3 espèces, la situation est moins tranchée pour les femelles, en particulier pour les espèces Adélie et Chinstrap.\nNous avons vu dans ce chapitre quelques exemples et des règles à suivre strictement (notamment, quels types de graphiques pour quelles types de variables). Mais les possibilités sont infinies, et je vous encourage donc à poursuivre l’exploration. Toutes les combinaisons des éléments que nous avons décrits sont possibles. Entre les facets, qui permettent de faire des sous graphiques pour chaque modalités (ou combinaisons de modalités) d’une ou deux variables catégorielles, les caractéristiques esthétiques auxquelles ont peut associer un nombre conséquent de variables numériques et/ou catégorielles, et les nombreux objets géométriques existants (nous n’avons fait qu’utiliser les plus courants, mais il en existe beaucoup d’autres), les possibilités sont infinies. À vous de faire preuve de curiosité et d’explorer d’autres types de visualisation. L’avantage de ggplot2 est que tous les graphiques se construisent sur le même modèle :\n\n\n\n\n\n\nImportant\n\n\n\n\nggplot(TABLEAU, aes(x = VAR1, y = VAR2, fill = VAR3, ...)) +\n  geom_XXX() +\n  geom_YYY() +\n  facet_ZZZ()\n\n\n\nQuand on a bien compris ce principe, on peut quasiment tout faire, les réponses aux questions qu’on se pose se trouvant presque toujours dans les fichiers d’aide des fonctions."
  },
  {
    "objectID": "03-Visualization.html#peaufiner-lapparence",
    "href": "03-Visualization.html#peaufiner-lapparence",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.11 Peaufiner l’apparence",
    "text": "3.11 Peaufiner l’apparence\nJusqu’ici, les morceaux de code que nous avons vus permettent de produire une large gamme de graphiques exploratoires. Mais il y a une différence de taille entre des graphiques que l’on fait pour soi, afin de comprendre et explorer des données, et des graphiques que l’on fait pour communiquer à autrui des informations ou le fruit de nos découvertes.\nLes graphiques que l’on souhaite intégrer à un compte-rendu ou un rapport doivent :\n\navoir des labels corrects pour les axes (penser à toujours indiquer l’unité des variables portées par les axes)\navoir des labels corrects pour les légendes situées à droite de la plupart des graphiques (voir les nombreux exemples décrits plus haut)\navoir éventuellement un titre. Il ne sera pas toujours utile de l’intégrer à la figure car la plupart du temps, les titres sont ajoutés manuellement dans le traitement de texte que vous utilisez\nutiliser des couleurs agréables et faciles à distinguer (y compris pour les personnes atteintes de daltonisme)\nutiliser des échelles adaptées (ordres de grandeur, échelles logarithmiques, etc.)\nsi possible avoir tous le même thème (mêmes choix de couleurs, de contours, de polices de caractères, etc.)\n\nDonc, lorsqu’on obtient un graphique exploratoire parlant et que l’on souhaite l’intégrer à un rapport ou un compte-rendu, 3 étapes sont nécessaires à sa mise en forme :\n\nmodifier les légendes avec la fonction labs()\nmodifier les échelles avec les nombreuses fonctions scale_XXX_YYY()\nmodifier le thème général avec les fonctions theme_XX()\n\n\n3.11.1 Les légendes ou labels\nLe point de départ le plus évident est d’ajouter des labels de qualité. La fonction labs() du package ggplot2 permet d’ajouter plusieurs types de labels sur vos graphiques :\n\nUn titre (title =) : il doit résumer les résultats les plus importants.\nUn sous-titre (subtitle =) : il permet de donner quelques détails supplémentaires.\nUne légende (caption =) : souvent utilisée pour présenter la source des données du graphique.\nUn titre pour chaque axe (x = et y =) : permet de préciser les variables portées par les axes et leurs unités.\nUn titre pour les échelles de couleurs, de forme, de taille, etc.\n\nReprenons par exemple le graphique permettant de visualiser la relation entre épaisseur et longueur du bec selon la masse des individus :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nNous préciser les légendes en ajoutant la fonction labs() sur une nouvelle couche du graphique :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nPour annoter correctement les légendes situées à droite, il convient d’avoir bien compris ce qui, dans notre code, a permis à R de générer automatiquement ces légendes. Le gradient de couleur a été créé parce que nous avons tapé fill = body_mass_g. Et l’échelle de taille des symboles a été créée parce que nous avons tapé size = body_mass_g. Dans la fonction labs(), nous devons donc préciser fill = \"...\" et size = \"...\" pour modifier le titre de ces 2 légendes :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Masse (g)\",\n       size = \"Masse (g)\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nFigure 3.16: Une figure correctement légendée\n\n\n\n\nÀ partir de maintenant, vous devriez systématiquement légender les axes de vos graphiques et annoter vos légendes correctement, en n’oubliant pas de préciser les unités lorsque c’est pertinent, pour tous les graphiques que vous intégrez dans vos rapports, compte-rendus, mémoires, présentation, etc.\n\n\n3.11.2 Les échelles\nTous les détails des graphiques que vous produisez peuvent être édités. C’est notamment le cas des échelles. Qu’il s’agisse de modifier l’étendue des axes, la densité du quadrillage, la position des tirets sur les axes, le nom des catégories figurant sur les axes ou dans les légendes ou encore les couleurs utilisées pour différentes catégories d’objets géométriques, tout est possible dans ggplot2.\nNous n’avons pas le temps ici d’aborder toutes ces questions en détail. Je vous encourage donc à consulter l’ouvrage en ligne intitulé R for data science, et en particulier son chapitre dédié aux échelles, si vous avez besoin d’apporter des modifications à vos graphiques et que vous ne trouvez pas comment faire dans cet ouvrage.\n\n3.11.2.1 La gestion des couleurs\nNous allons néanmoins examiner quelques possibilités, à commencer par la façon de procéder pour modifier les couleurs choisies par défaut par ggplot2. Reprenons la figure Figure 3.16, et changeons le gradient de couleur proposé par défaut par R. Il est possible de modifier ces couleurs de plusieurs façons :\n\nsoit en utilisant d’autres palettes de couleurs prédéfinies\nsoit en choisissant manuellement les couleurs\n\nToutes les fonctions permettant d’altérer les légendes commencent par scale_. Vient ensuite le nom de l’esthétique que l’on souhaite modifier (ici fill_) et enfin, le nom d’une fonction à appliquer. Les possibilités sont nombreuses et vous pouvez en avoir un aperçu en tapant le début du nom de la fonction et en parcourant la liste proposée par RStudio sous le curseur. Il faut toutefois distinguer 2 types d’échelles de couleurs : les échelles continues (c’est notre cas ici) et les échelles discrètes (quand l’esthétique de couleur est associée à une variable catégorielle, nous en verrons un exemple plus loin).\nPar exemple, il est possible d’utiliser la palette viridis. Selon ses auteurs :\n\n“Use [this palette] to make plots that are pretty, better represent your data, easier to read by those with colorblindness, and print well in gray scale.\n\nPour utiliser cette palette, il suffit d’ajouter une couche à notre graphique :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Masse (g)\",\n       size = \"Masse (g)\") +\n  scale_fill_viridis_c()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nLa palette viridis est proposée pour les échelles continues (d’où le _c à la fin du nom de fonction), ou pour les échelles discrètes (scale_fill_viridis_d). Des fonctions équivalentes existent pour les couleurs de contour (scale_color_viridis_c et scale_color_viridis_d). Allez lire le fichier d’aide de cette fonction pour en apprendre plus sur son fonctionnement et ses nombreuses options.\nIci, les individus les plus lourds apparaissent en jaune, et les plus légers en bleu sombre. Si on souhaite faire le contraire, c’est possible :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Masse (g)\",\n       size = \"Masse (g)\") +\n  scale_fill_viridis_c(direction = -1)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nD’autres palettes de couleurs sont également accessibles grâce à l’argument option = de ces fonctions :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Masse (g)\",\n       size = \"Masse (g)\") +\n  scale_fill_viridis_c(option = \"A\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nVoici toutes les possibilités :\n\n\n\n\n\nDernière chose concernant viridis : la fonction scale_fill_viridis_b() discrétise la variable continue pour en faire une échelle discontinue. Il est en effet parfois plus facile de repérer une couleur parmi une palette de 4 ou 5 couleurs distinctes, plutôt qu’au sein d’un gradient. Voilà à quoi cela ressemble :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Masse (g)\",\n       size = \"Masse (g)\") +\n  scale_fill_viridis_b(option = \"E\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nOutre les fonctions d’échelles proposant les palettes viridis, les fonctions se terminant par _gradient(), _gradient2() et _gradientn() permettent de spécifier manuellement les couleurs à intégrer dans un dégradé. Avec la fonction scale_fill_gradient() on indique simplement les couleurs du début de de la fin du gradient :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Masse (g)\",\n       size = \"Masse (g)\") +\n  scale_fill_gradient(low = \"gold\", high = \"firebrick3\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nN’importe quelle nom de couleur valide, ou n’importe que code couleur hexadécimal fonctionne (voir par exemple ce site pour trouver les codes hexadécimaux dont vous avez besoin) :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Masse (g)\",\n       size = \"Masse (g)\") +\n  scale_fill_gradient(low = \"#A0F87D\", high = \"#151197\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nAvec la fonction scale_fill_gradient2(), nous avons plus de contrôle : on indique une couleur de départ, une couleur d’arrivée, mais aussi, une couleur intermédiaire, et la valeur numérique à laquelle cette couleur doit apparaître :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Masse (g)\",\n       size = \"Masse (g)\") +\n  scale_fill_gradient2(low = \"deeppink\", high = \"gold\", mid = \"darkslateblue\",\n                       midpoint = 4500)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nJe vous laisse explorer l’aide de cette fonction ainsi que celle de scale_fill_gradientn() pour savoir comment en utiliser toutes les possibilités.\nLorsqu’une variable catégorielle est associée à la couleur, il est évidemment possible aussi d’effectuer les choix de palettes. Voyons en exemple en associant la couleur de remplissage des points à l’espèce plutôt qu’à la masse :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = species, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Espèce\",\n       size = \"Masse (g)\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nLa version discrète de viridis peut maintenant être appliquée. Les mêmes options que pour la version continue sont disponibles :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = species, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Espèce\",\n       size = \"Masse (g)\") +\n  scale_fill_viridis_d(option = \"B\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nLes possibilités sont nombreuses, notamment grâce aux fonctions scale_fill_brewer() (pour les couleurs de remplissages associées à une variable catégorielle) et scale_color_brewer() (pour les couleurs de contour associées à une variable catégorielle). L’utilisation est simple, un précise simplement quelle palette on souhaite utiliser parmi la liste des palettes disponibles :\n\nCertaines palettes sont séquentielles (lorsque les catégories se suivent logiquement, pour les variables catégorielles ordinales en particulier), d’autres contiennent des couleurs indépendantes :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = species, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Espèce\",\n       size = \"Masse (g)\") +\n  scale_fill_brewer(palette = \"Accent\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nEnfin, il est possible de spécifier manuellement la liste des couleurs que l’on souhaite utiliser avec la fonction scale_fill_manual(). il faut bien entendu indiquer autant de couleurs que de modalités pour notre variable catégorielle (ici 3 espèces dont 3 couleurs) :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = species, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Espèce\",\n       size = \"Masse (g)\") +\n  scale_fill_manual(values = c(\"deepskyblue\", \"darkorchid3\", \"lightsalmon\"))\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nDernière chose concernant les couleurs : un choix de fonction scale_XXX_XXX() inapproprié est une cause d’erreur très fréquente ! Par exemple, pour la première figure de la partie consacrée au paradoxe de Simpson (Section 3.10.3), la couleur des points et des lignes n’est pas spécifiée avec fill mais avec color. C’est donc bien une fonction qui commence par scale_color_ qu’il faut utiliser :\n\nggplot(penguins, aes(x = bill_depth_mm, y = flipper_length_mm,\n                     color = species)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(x = \"Épaisseur du bec (mm)\", y = \"Longueur des nageoires (mm)\",\n       color = \"Espèce\") +\n  scale_color_brewer(palette = \"Set2\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nComme pour les fonctions geom_XXX(), les fonctions scale_color_XXX() et scale_fill_XXX() sont très nombreuses. Je vous encourage donc à explorer les fichiers d’aide et à faire des essais.\n\n\n3.11.2.2 Les autres échelles\nLes deux autres échelles que vous pourrez être couramment appelés à modifier sont les échelles des axes des x et des y. Les fonctions qui permettent de la faire sont construites comme ces des échelles de couleurs : scale_x_XXX() et scale_y_XXX(). La dernière partie du nom de la fonction sera, la plupart du temps, soit discrete si une variable catégorielle est associée à l’axe, soit continuous si une variable numérique y est associée.\nReprenons l’exemple du stripchart suivant :\n\nggplot(penguins, aes(x = species, y = bill_depth_mm)) +\n  geom_jitter(width = 0.20, height = 0)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nOn commence par légender les axes avec labs() :\n\nggplot(penguins, aes(x = species, y = bill_depth_mm)) +\n  geom_jitter(width = 0.20, height = 0) +\n  labs(x = \"Espèce\", y = \"Épaisseur du bec (mm)\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nSi on souhaite renommer l’espèce Adelie en Adélie (avec un accent sur le “e” donc), il faut modifier l’échelle de l’axe des x, qui porte une variable catégorielle :\n\nggplot(penguins, aes(x = species, y = bill_depth_mm)) +\n  geom_jitter(width = 0.20, height = 0) +\n  labs(x = \"Espèce\", y = \"Épaisseur du bec (mm)\") +\n  scale_x_discrete(label = c(\"Adélie\", \"Chinstrap\", \"Gentoo\"))\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nPour l’axe des y, qui porte une variable continue, on peut avoir besoin de faire apparaître des graduations tous les 2 millimètres (au lieu de tous les 2,5 millimètres) :\n\nggplot(penguins, aes(x = species, y = bill_depth_mm)) +\n  geom_jitter(width = 0.20, height = 0) +\n  labs(x = \"Espèce\", y = \"Épaisseur du bec (mm)\") +\n  scale_x_discrete(label = c(\"Adélie\", \"Chinstrap\", \"Gentoo\")) +\n  scale_y_continuous(breaks = seq(from = 12, to = 22, by = 2))\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nIl est également très fréquent de souhaiter étendre les axes au-delà des seules valeurs observées, pour faire apparaître le 0 par exemple. C’est tellement fréquent qu’une fonction de raccourci très facile à utiliser nous permet d’éviter le recours à une fonction scale_XXX_XXX(). Même si dans ce cas précis, ça n’est pas très pertinent, voilà un exemple :\n\nggplot(penguins, aes(x = species, y = bill_depth_mm)) +\n  geom_jitter(width = 0.20, height = 0) +\n  labs(x = \"Espèce\", y = \"Épaisseur du bec (mm)\") +\n  scale_x_discrete(label = c(\"Adélie\", \"Chinstrap\", \"Gentoo\")) +\n  expand_limits(y = 0)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nEnfin, il arrive que les valeurs prises par une variable numérique recouvrent plusieurs ordres de grandeurs (avec par exemple des valeurs de l’ordre des dizaines, des centaines et des milliers). Utiliser une échelle logarithmique permet, dans cette situation, de mieux visualiser la variabilité des données, notamment parmi les valeurs les plus faibles. Les fonctions scale_x_log10() et scale_y_log10() permettent d’effectuer ce changement d’échelle tout en conservant des valeurs normales sur les axes.\nOutre ces changements d’échelles pour les axes et les couleurs, il est possible de modifier manuellement toutes les échelles générées automatiquement par les fonction geom_XXX() (par exemple, l’échelle des tailles, ou les types de symboles utilisés pour distinguer plusieurs catégories de points). Il “suffit” pour cela de trouver la bonne fonction (par exemple scale_size_continuous(), scale_shape_manual(), … Il est evidemment impossible de faire le tour de toutes ces fonctions. Mais sachez qu’elles existent et consultez leurs fichiers d’aide le jour où vous en avez besoin.\n\n\n\n3.11.3 Les thèmes\nL’apparence de tout ce qui ne concerne pas directement les données d’un graphique est sous le contrôle d’un thème. Les thèmes contrôlent l’apparence générale du graphique : quelles polices et tailles de caractères sont utilisées, quel sera l’arrière plan du graphique, faut-il intégrer un quadrillage sous le graphique, et si oui, quelles doivent être ses caractéristiques ?\nIl est possible de spécifier chaque élément manuellement. Nous nous contenterons ici de passer en revue quelques thèmes prédéfinis qui devraient couvrir la plupart de vos besoins.\nReprenons par exemple le code suivant :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = species, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Espèce\",\n       size = \"Masse (g)\") +\n  scale_fill_viridis_d(option = \"B\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nLe thème utilisé par défaut est theme_gray(). Il est notamment responsable de l’arrière plan gris et du quadrillage blanc. Pour changer de thème, il suffit d’ajouter une couche au graphique en donnant le nom du nouveau thème :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = species, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Espèce\",\n       size = \"Masse (g)\") +\n  scale_fill_viridis_d(option = \"B\") +\n  theme_bw()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nLe fond gris a disparu, et le quadrillage a changé de couleur. Les thèmes complets proposés par ggplot2 que vous pouvez utiliser sont les suivants :\n\ntheme_bw() : fond blanc et quadrillage.\ntheme_classic() : thème classique, avec des axes mais pas de quadrillage.\ntheme_dark() : fond sombre pour augmenter le contraste.\ntheme_gray() : thème par défaut : fond gris et quadrillage blanc.\ntheme_light() : axes et quadrillages discrets.\ntheme_linedraw() : uniquement des lignes noires.\ntheme_minimal() : pas d’arrière plan, pas d’axes, quadrillage discret.\ntheme_void() : thème vide, seuls les objets géométriques restent visibles.\n\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = species, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Espèce\",\n       size = \"Masse (g)\") +\n  scale_fill_viridis_d(option = \"B\") +\n  theme_minimal()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nTous les thèmes possèdent la même liste d’argument. L’un d’entre eux est l’argument base_family, qui permet de spécifier une police de caractères différente de celle utilisée par défaut. Évidemment, vous ne pourrez utiliser que des polices qui sont disponibles sur l’ordinateur que vous utilisez. Un bon tutoriel expliquant comment indiquer à R les polices qui sont disponibles sur votre ordinateur est disponible ici. N’hésitez pas à revenir vers moi pour toute question à ce sujet.\nDans l’exemple ci-dessous, j’utilise la police “Gill Sans”. Si cette police n’est pas disponible sur votre ordinateur, ce code produira une erreur (ou R prendra simplement la police par défaut. Si c’est le cas, remplacez-la par une police de votre ordinateur. Attention, son nom exact doit être utilisé. Cela signifie bien sûr le respect des espaces, majuscules, etc.\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = species, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Espèce\",\n       size = \"Masse (g)\") +\n  scale_fill_viridis_d(option = \"B\") +\n  theme_minimal(base_family = \"Gill Sans\")\n\n\nIl est également possible de spécifier la taille de police qui devrait être utilisée par défaut. On spécifie la taille de base avec l’argument base_size =, et toutes les autres tailles de polices seront mises à jour pour refléter le changement. Ainsi, les différences de tailles entre titre, sous-titres, légendes des axes, etc, seront maintenues :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = species, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec des manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Espèce\",\n       size = \"Masse (g)\") +\n  scale_fill_viridis_d(option = \"B\") +\n  theme_minimal(base_family = \"Gill Sans\", base_size = 14)\n\n\nLe choix d’un thème et d’une police adaptés doivent vous permettre de faire des graphiques originaux et clairs. Rappelez-vous toujours que vos choix en matière de graphiques doivent avoir pour objectif principal de rendre les tendances plus faciles à décrypter pour un lecteur non familier de vos données. C’est un outil de communication au même titre que n’importe quel paragraphe d’un rapport ou compte-rendu. Et comme pour un paragraphe, la première version d’un graphique est rarement la bonne.\nVous devriez donc maintenant être bien armés pour produire 95% des graphiques dont vous aurez besoin tout au long de votre cursus universitaire. Toutefois, un point important a pour l’instant été omis : l’ajout de barres d’erreurs sur vos graphiques. Nous verrons comment faire cela au prochain semestre, après avoir appris à manipuler efficacement des tableaux de données avec les packages tidyr et dplyr.\nQuoi qu’il en soit, il est maintenant attendu de vous que vous utilisez R et ce que vous avez appris de ggplot2 pour produire tous les graphiques que vous serez amenés à intégrer à vos comptes-rendus de TP et à vos rapports."
  },
  {
    "objectID": "03-Visualization.html#exercices",
    "href": "03-Visualization.html#exercices",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.12 Exercices",
    "text": "3.12 Exercices\n\nAvec le jeu de données diamonds, du packages ggplot2, tapez les commandes suivantes pour créer un nouveau tableau diams contenant moins de lignes (3000 au lieu de près de 54000) :\n\n\nlibrary(dplyr)\nset.seed(4532) # Afin que tout le monde récupère les mêmes lignes\ndiams &lt;- diamonds %&gt;%\n  sample_n(3000)\n\n\nAvec ce nouveau tableau diams, tapez le code permettant de créer le graphique ci-dessous. Indice : affichez le tableau diams dans la console afin de voir quelles sont les variables disponibles.\n\n\n\n\n\n\nPrix de 3000 diamants en fonction de leur taille en carats et de leur clarté.\n\n\n\n\n\nSelon vous, à quoi sont dues les bandes verticales que l’on observe sur ce graphique ?\nInstallez et chargez en mémoire le package nycflights13\nExaminez le tableau flights de ce package, et lisez son fichier d’aide pour comprendre à quoi correspondent ces données\nCréer un nouveau jeu de données en exécutant ces commandes :\n\n\nset.seed(1234)\nsmall_flights &lt;- flights %&gt;%\n  filter(!is.na(arr_delay),\n         distance &lt; 3000)  %&gt;%\n  sample_n(1000)\n\n\nCe nouveau jeu de données de petite taille (1000 lignes) est nommé small_flights. Il contient les mêmes variables que le tableau flights mais ne contient qu’une petite fraction de ses lignes. Les lignes retenues ont été choisies au hasard. Vous pouvez visualiser son contenu en tapant son nom dans la console ou en utilisant la fonction View().\n\nEn vous appuyant sur les fonctions et les principes de la grammaire des graphiques que vous avez découverts dans ce chapitre, et en vous servant de ce nouveau jeu de données, tapez les commandes qui permettent de produire le graphique ci-dessous :\n\n\n\n\n\nQuelques indices :\n\nLes couleurs utilisées sont celles de la palette Set1 du package RColorBrewer.\nLes variables utilisées sont origin, air_time et distance.\nLa transparence des symboles est fixée à 0.8.\n\n\nToujours avec ce jeu de données small-flights, tapez les commandes permettant de produire le graphique ci-dessous :\n\n\n\n\n\n\nQuelques indices :\n\nLes couleurs utilisées sont celles de la palettes Accent du package RColorBrewer.\nLes variables utilisées sont month, carrier et origin.\nLa variable month est codée sous forme numérique dans le tableau de données. Il faudra la transformer en facteur avec la fonction factor(month) au moment de l’associer à un axe du graphique.\n\n\n\n\n\n\nJeppson, Haley, Heike Hofmann, et Di Cook. 2021. ggmosaic: Mosaic Plots in the ggplot2 Framework. https://github.com/haleyjeppson/ggmosaic.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, et Dewey Dunnington. 2023. ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWilkinson, Leland. 2005. The grammar of graphics. 2nd éd. New-York: Springer-Verlag. https://www.springer.com/us/book/9780387245447."
  },
  {
    "objectID": "04-Tidy-Data.html#préambule",
    "href": "04-Tidy-Data.html#préambule",
    "title": "4  (Ar)ranger des données avec tidyr",
    "section": "4.1 Préambule",
    "text": "4.1 Préambule\nDans la Section 1.3.4.1, nous avons introduit le concept de tableaux de données ou data.frame dans R. Il s’agit d’une représentation rectangulaire des données, à la manière d’un tableur, dans laquelle les lignes correspondent aux observations et les colonnes correspondent à des variables décrivant chaque observation.\nDans ce chapitre, nous allons aller plus loin en présentant le concept de tidy data, ou “données nettes/rangées/soignées/ordonnées”. Vous verrez que l’idée d’avoir des données stockées dans un format “net” va plus loin que la simple définition usuelle que le terme “rangé” peut avoir lorsque les données sont simplement bien organisées dans un tableur. Nous définirons le terme “tidy data” de manière plus rigoureuse, en établissant un ensemble de règles permettant de stocker les données correctement afin de rendre plus aisées les analyses statistiques et les représentations graphiques.\nJusqu’à maintenant, vous avez utilisé des données qui étaient déjà dans ce format (c’est le cas des données contenues dans penguins, ou dans diamonds par exemple). Pourtant, la plupart du temps, les données que vous manipulerez dans R seront importées depuis un tableur dans lequel vous ou vos collaborateurs en aurez fait la saisie. S’assurer que les données importées manuellement dans R sont correctement “nettoyées” et mises en forme de “tidy data” est indispensable pour éviter les problèmes lors de la réalisation de graphiques (voir Chapitre 3) comme lors de la manipulation des données pour en tirer de l’information statistique pertinente (ce que nous verrons au Chapitre 5)."
  },
  {
    "objectID": "04-Tidy-Data.html#sec-prerek",
    "href": "04-Tidy-Data.html#sec-prerek",
    "title": "4  (Ar)ranger des données avec tidyr",
    "section": "4.2 Pré-requis",
    "text": "4.2 Pré-requis\nDans ce chapitre, nous aurons besoin des packages suivants :\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(readxl)  # la dernière lettre est un \"L\" minuscule, pas le chiffre 1...\n\nComme d’habitude, si vous recevez des messages d’erreur, c’est probablement parce que le package que vous essayez de charger en mémoire n’a pas été installé au préalable. Consultez la Section 1.4 si vous ne savez plus comment procéder.\nOutre ces packages classiques, nous aurons aussi besoin du package EDAWR qui n’est pas disponible sur les serveurs habituels de R. Pour l’installer, on procède de la façon suivante :\n\nInstallez et chargez en mémoire le package remotes :\n\n\ninstall.packages(\"remotes\")\nlibrary(remotes)\n\n\nInstallez le package EDAWR grâce à la fonction install_github() du package remotes qui va chercher le package sur le site https://github.com :\n\n\ninstall_github(\"rstudio/EDAWR\")\n\nAttention, sur les ordinateurs de l’université cette procédure ne fonctionne pas toujours. Si vous rencontrez des difficultés, suivez les instructions décrites à la fin de cette Section 4.2.\n\nChargez le package EDAWR de la façon habituelle :\n\n\nlibrary(EDAWR)\n\nLe package EDAWR contient plusieurs jeux de données dont nous allons nous servir pour illustrer les questions liées au format des tableaux de données. Pour en avoir la liste, vous pouvez taper :\n\ndata(package = \"EDAWR\")\n\nEn cas de problème pour installer le package EDAWR sur les ordinateurs de l’université.\nVous pouvez télécharger manuellement les 4 jeux de données dont nous aurons besoin grâce à ces 4 liens :\n\ncases\npopulation\nrates\nstorms\n\nUne fois téléchargés, les données contenues dans ces 4 fichiers peuvent être importées dans RStudio en cliquant sur File &gt; Open File..., puis en sélectionnant un à un chacun des fichiers. Pour chaque fichier un nouvel objet doit apparaître dans votre environnement de travail (onglet Environnement, dans le panneau en haut à droite de RStudio). L’inconvénient de cette méthode est que les fichiers d’aide de ces jeux de données ne seront pas disponibles dans RStudio. Vous pouvez toutefois en consulter une version brute (non mise en forme) en cliquant ici."
  },
  {
    "objectID": "04-Tidy-Data.html#cest-quoi-des-tidy-data",
    "href": "04-Tidy-Data.html#cest-quoi-des-tidy-data",
    "title": "4  (Ar)ranger des données avec tidyr",
    "section": "4.3 C’est quoi des “tidy data” ?",
    "text": "4.3 C’est quoi des “tidy data” ?\nLes “tidy data” (nous les appellerons “données rangées” dans la suite de ce livre), sont des données qui respectent un format standardisé. En particulier :\n\nChaque variable est dans une colonne unique.\nChaque colonne contient une unique variable.\nChaque ligne correspond à une observation pour chaque variable.\nLes cellules du tableau représentent les valeurs de chaque observation pour chaque variable.\n\n\n\n\n\n\nFigure 4.1: La définition des ‘données rangées’, d’après http://r4ds.had.co.nz/tidy-data.html.\n\n\n\n\nMalheureusement, les données peuvent être présentées sous de nombreux formats qui ne respectent pas ces règles de base. La modification des tableaux est donc souvent un préambule nécessaire à toute analyse statistique ou représentation graphique.\nPar exemple, examinez le tableau cases du package EDAWR, qui présente le nombre de cas de tuberculose dans 3 pays en 2011, 2012 et 2013.\n\ncases\n\n  country  2011  2012  2013\n1      FR  7000  6900  7000\n2      DE  5800  6000  6200\n3      US 15000 14000 13000\n\n\nDans ce tableau, essayez d’identifier quelles sont les variables en présence. Indice, vous devriez en trouver 3.\nEssayez d’identifier également où se trouvent ces variables.\nPour ma part, je compte les 3 variables suivantes :\n\ncountry : qui indique les pays dans lesquels les cas de tuberculose ont été dénombrés. Cette variable occupe la première colonne du tableau.\nLa seconde variable est l’année, qui peut prendre les valeurs 2011, 2012 ou 2013. Cette variable occupe la ligne des titres des 3 colonnes de droite du tableau.\nEt enfin, la troisième variable est le nombre de cas de tuberculose observés dans chaque pays et chaque année. Cette troisième variable occupe 3 lignes et 3 colonnes du tableau.\n\nAutrement dit, les variables peuvent être visualisées de la façon suivante :\n\n\n\n\n\nFigure 4.2: Position des variables dans le tableau cases du package EDAWR.\n\n\n\n\nDonc même si nous disposons ici d’un tableau rectangulaire classique, nous sommes bien loin du format des données rangées.\n\n4.3.1 La fonction pivot_longer()\nAfin de transformer les données non rangées du tableau cases en données rangées, nous allons utiliser la fonction pivot_longer() du package tidyr. Avant d’aller plus loin, essayez d’imaginer à quoi le tableau rangé devrait ressembler.\nLa fonction pivot_longer() prend 4 arguments :\n\ndata : le nom du tableau de données que l’on souhaite “ranger”.\ncols : La liste des colonnes du tableau initial que l’on souhaite rassembler en 2 nouvelles variables. Ici, les colonnes 2, 3 et 4 (on pourra les noter 2:4 ou, en utilisant leur nom, \"2011\":\"2013\").\nnames_to : le nom d’une nouvelle variable qui contiendra les en-têtes des colonnes qui constituent la seconde variable. Ici, nous nommerons cette seconde variable year car elle devra contenir les années 2011, 2012 et 2013.\nvalues_to : le nom d’une nouvelle variable qui contiendra les informations correspondant à la troisième variable identifiée plus haut. Nous appellerons cette variables n_cases car elle contiendra les nombres de cas de tuberculose (7000, 5800, 15000, etc).\n\n\npivot_longer(data = cases, \n             cols = `2011`:`2013`, \n             names_to = \"year\", \n             values_to = \"n_cases\")\n\n# A tibble: 9 × 3\n  country year  n_cases\n  &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n1 FR      2011     7000\n2 FR      2012     6900\n3 FR      2013     7000\n4 DE      2011     5800\n5 DE      2012     6000\n6 DE      2013     6200\n7 US      2011    15000\n8 US      2012    14000\n9 US      2013    13000\n\n\nNous avons bien transformé le tableau de départ en un “tableau rangé” : chacune de nos 3 variables se trouve dans une unique colone, et chaque ligne correspond à une observation pour chacune de ces 3 variables. Comme d’habitude, si nous souhaitons pouvoir utiliser ce nouveau tableau, il faut lui donner un nom :\n\ncases_tidy &lt;- pivot_longer(data = cases, \n                           cols = `2011`:`2013`, \n                           names_to = \"year\", \n                           values_to = \"n_cases\")\n\nIl nous est maintenant plus facile de manipuler ces données pour en tirer de l’information, grâce à des analyses statistiques ou des représentations graphiques :\n\nggplot(cases_tidy, aes(x = country, y = n_cases, fill = year)) +\n  geom_col(position = \"dodge\", color = \"black\") +\n  scale_fill_brewer(palette = \"Accent\") +\n  theme_minimal() +\n  labs(x = \"Pays\",\n       y = \"Nombre de cas\",\n       fill = \"Année\",\n       title = \"Évolution du nombre de cas de tuberculose entre 2011 et 2013\",\n       subtitle = \"DE : Allemagne, FR : France, US : États-Unis\")\n\n\n\n\nFigure 4.3: Évolution du nombre de cas de tuberculose dans 3 pays, de 2011 à 2013.\n\n\n\n\nOn constate ici qu’entre 2011 et 2013, le nombre de cas de tuberculose a légèrement augmenté en Allemagne, est resté stable en France, et a diminué aux États-Unis.\nNotez ici que la variable year de notre nouveau tableau est considérée comme une variable de type “chaîne de caractères” et non comme une variable numérique. On peut le voir en affichant notre tableau en tapant son nom, ou en utilisant la fonction str() déjà décrite plus tôt :\n\nstr(cases_tidy)\n\ntibble [9 × 3] (S3: tbl_df/tbl/data.frame)\n $ country: chr [1:9] \"FR\" \"FR\" \"FR\" \"DE\" ...\n $ year   : chr [1:9] \"2011\" \"2012\" \"2013\" \"2011\" ...\n $ n_cases: num [1:9] 7000 6900 7000 5800 6000 6200 15000 14000 13000\n\n\nC’est le comportement par défaut de la fonction pivot_longer() : les anciens titres de colonnes sont convertis en chaînes de caractères. Si ce comportement n’est pas souhaitable, il y a 2 alternatives possibles :\n\nutiliser les arguments names_transform et/ou values_transform de la fonction pivot_longer(). Cela permet de spécifier comment transformer les variables nouvellement créées au moment de leur création.\nutiliser les fonctions mutate() et as.numeric() ou as.integer() après avoir modifié le tableau de départ avec pivot_longer(). Cette façon de faire sera décrite dans la Section 5.6.\n\n\n# On commence par afficher `cases`\ncases \n\n  country  2011  2012  2013\n1      FR  7000  6900  7000\n2      DE  5800  6000  6200\n3      US 15000 14000 13000\n\n# On utilise ensuite pivot_longer() avec l'argument \n# names_transform pour transformer year en variable entière\npivot_longer(data = cases, \n             cols = `2011`:`2013`, \n             names_to = \"year\", \n             values_to = \"n_cases\",\n             names_transform = list(year = as.integer))\n\n# A tibble: 9 × 3\n  country  year n_cases\n  &lt;chr&gt;   &lt;int&gt;   &lt;dbl&gt;\n1 FR       2011    7000\n2 FR       2012    6900\n3 FR       2013    7000\n4 DE       2011    5800\n5 DE       2012    6000\n6 DE       2013    6200\n7 US       2011   15000\n8 US       2012   14000\n9 US       2013   13000\n\n\nOn voit ici que la variable year est maintenant une colonne numérique (&lt;int&gt; : nombres entiers), et non plus une variable de type “character”. En utilisant as.numeric() au lieu de as.integer(), on aurait transformé la variable year en &lt;dbl&gt; (nombre réel au lieu de nombre entier), ce qui ici, reviendrait exactement au même.\nDe la même façon, on peut avoir besoin de présenter la colonne year sous la forme d’un facteur :\n\npivot_longer(data = cases, \n             cols = `2011`:`2013`, \n             names_to = \"year\", \n             values_to = \"n_cases\",\n             names_transform = list(year = as.factor))\n\n# A tibble: 9 × 3\n  country year  n_cases\n  &lt;chr&gt;   &lt;fct&gt;   &lt;dbl&gt;\n1 FR      2011     7000\n2 FR      2012     6900\n3 FR      2013     7000\n4 DE      2011     5800\n5 DE      2012     6000\n6 DE      2013     6200\n7 US      2011    15000\n8 US      2012    14000\n9 US      2013    13000\n\n\n\n\n4.3.2 La fonction pivot_wider()\nLa fonction pivot_wider() permet de réaliser l’opération inverse de pivot_longer(). Elle “disperse” une unique colonne catégorielle en plusieurs colonnes, le tableau obtenu est donc plus large (“wider”) que le tableau de départ.\nReprenons par exemple notre tableau cases_tidy :\n\ncases_tidy\n\n# A tibble: 9 × 3\n  country year  n_cases\n  &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n1 FR      2011     7000\n2 FR      2012     6900\n3 FR      2013     7000\n4 DE      2011     5800\n5 DE      2012     6000\n6 DE      2013     6200\n7 US      2011    15000\n8 US      2012    14000\n9 US      2013    13000\n\n\nLa fonction pivot_wider() prend 3 arguments :\n\nLe nom du tableau contenant les données (ici, cases_tidy).\nnames_from : le nom de la variable contenant les catégories qui devront être transformées en colonnes (ici, year).\nvalues_from : le nom de la variable contenant les valeurs qui devront remplir les nouvelles colonnes (ici, n_cases).\n\n\npivot_wider(data = cases_tidy, \n            names_from = year, \n            values_from = n_cases)\n\n# A tibble: 3 × 4\n  country `2011` `2012` `2013`\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 FR        7000   6900   7000\n2 DE        5800   6000   6200\n3 US       15000  14000  13000\n\n\nCette fonction sera donc rarement utilisée puisqu’elle ne permet pas d’obtenir des “tableaux rangés”. Toutefois, elle pourra vous être utile dans 2 situations :\n\npour mettre en forme des données appariées afin de réaliser certains tests statistiques et graphiques spécifiques (plus de détails à ce sujet dans le ?sec-moy2)\npour présenter des résultats sous forme synthétique. Prenons un exemple avec le jeu de données penguins. Imaginons que vous deviez créer un tableau resum présentant les effectifs de mâles et de femelles des 3 espèces de manchots. Une possibilité serait de taper ceci :\n\n\nresum &lt;- penguins |&gt; \n  group_by(species, sex) |&gt; \n  count()\nresum\n\n# A tibble: 8 × 3\n# Groups:   species, sex [8]\n  species   sex        n\n  &lt;fct&gt;     &lt;fct&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    &lt;NA&gt;       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    &lt;NA&gt;       5\n\n\nLes commandes permettant de produire ce tableau seront expliquées dans le Chapitre 5. On peut cependant constater ici que ce tableau contient 8 lignes et 3 colonnes. Il s’agit bien d’un “tableau rangé” parfaitement adapté pour faire des statistiques et des visualisations graphiques, mais son format n’est pas terrible si notre objectif est de le faire figurer dans un rapport. La solution : utiliser pivot_wider() :\n\nresum_large &lt;- pivot_wider(resum, \n            names_from = sex, \n            values_from = n)\n\nresum_large\n\n# A tibble: 3 × 4\n# Groups:   species [3]\n  species   female  male  `NA`\n  &lt;fct&gt;      &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 Adelie        73    73     6\n2 Chinstrap     34    34    NA\n3 Gentoo        58    61     5\n\n\nCe nouveau tableau contient maintenant 3 lignes (une par espèce), et 4 colonnes : une pour la variable species, et 3 pour la variable sex, soit une colonne pour les femelles, une colonne pour les mâles, et une pour les individus dont le sexe est inconnu (`NA`). On parle de tableau au format large (par opposition au “tableau rangé”, dit “format long”). Cela rend la présentation dans un rapport plus aisée.\nNotez également que pour l’espèce Chinstrap, tous les individus ont été sexés correctement. Le tableau au format large devrait donc indiquer 0 au lieu de NA dans la indique quatrième colonne de la deuxième ligne. En effet, NA signifie “Not Available”, autrement dit : données manquantes. Ici, il ne s’agit pas du tout d’une données manquantes : cela signifie simplement qu’aucun individu de l’espèce Chinstrap ne possède un sexe inconnu. Nous pouvons donc indiquer à R quelle valeur utiliser pour les catégories qui ne sont pas représentées dans le tableau de départ grâce à l’argument values_fill :\n\npivot_wider(resum, \n            names_from = sex, \n            values_from = n, \n            values_fill = 0)\n\n# A tibble: 3 × 4\n# Groups:   species [3]\n  species   female  male  `NA`\n  &lt;fct&gt;      &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 Adelie        73    73     6\n2 Chinstrap     34    34     0\n3 Gentoo        58    61     5\n\n\nD’autres arguments existent. Je vous encourage vivement à consulter l’aide des fonctions pivot_longer() et pivot_wider() et à faire des essais.\n\n\n4.3.3 Les fonctions separate() et unite()\nCes fonctions sont complémentaires : tout comme pivot_longer() et pivot_wider(), elles effectuent 2 opérations opposées. Reprenons le jeu de données cases_tidy :\n\ncases_tidy\n\n# A tibble: 9 × 3\n  country year  n_cases\n  &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n1 FR      2011     7000\n2 FR      2012     6900\n3 FR      2013     7000\n4 DE      2011     5800\n5 DE      2012     6000\n6 DE      2013     6200\n7 US      2011    15000\n8 US      2012    14000\n9 US      2013    13000\n\n\nImaginons que nous ayons besoin de séparer les données de la colonne year en 2 variables : le siècle d’une part, et l’année d’autre part. La fonction separate() permet de faire exactement cela :\n\nseparate(cases_tidy, year, into = c(\"century\", \"year\"), sep = 2)\n\n# A tibble: 9 × 4\n  country century year  n_cases\n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n1 FR      20      11       7000\n2 FR      20      12       6900\n3 FR      20      13       7000\n4 DE      20      11       5800\n5 DE      20      12       6000\n6 DE      20      13       6200\n7 US      20      11      15000\n8 US      20      12      14000\n9 US      20      13      13000\n\n\n\nLe premier argument est le nom du tableau de données.\nLe second argument est la variable que l’on souhaite scinder en plusieurs morceaux.\ninto est un vecteur qui contient le nom des nouvelles colonnes à créer\nsep peut prendre plusieurs formes. Lorsqu’on utilise un nombre, ce nombre correspond à la position de la coupure dans la variable d’origine. Ici, la variable d’origine a été coupée après le second caractère. Il est aussi possible d’utiliser des nombres négatifs : R compte alors à partir de la droite au lieu de compter à partir de la gauche. Enfin, il est aussi possible d’utiliser un symbole. Par exemple, certaines variables contiennent des tirets - ou des slashs \\. Utiliser ces caractères en guise de séparateur permet de couper les variables à ce niveau là. Nous en verrons un exemple plus tard.\n\nNotez ici que les 2 nouvelles variables sont de type &lt;chr&gt;. Si nous souhaitons que ces variables soient considérées comme numériques, nous devons ajouter un argument lorsque nous utilisons separate() :\n\ncases_split &lt;- separate(cases_tidy, \n                        year, \n                        into = c(\"century\", \"year\"), \n                        sep = 2, \n                        convert = TRUE)\ncases_split\n\n# A tibble: 9 × 4\n  country century  year n_cases\n  &lt;chr&gt;     &lt;int&gt; &lt;int&gt;   &lt;dbl&gt;\n1 FR           20    11    7000\n2 FR           20    12    6900\n3 FR           20    13    7000\n4 DE           20    11    5800\n5 DE           20    12    6000\n6 DE           20    13    6200\n7 US           20    11   15000\n8 US           20    12   14000\n9 US           20    13   13000\n\n\nNotre nouvel objet cases_split contient maintenant 2 nouvelles colonnes de nombres entiers, l’une contenant le siècle, l’autre contenant l’année.\nLa fonction unite() fait exactement le contraire : elle fusionne 2 colonnes existantes en accolant leurs contenus (et en ajoutant un séparateur) :\n\nunite(cases_split, new, century, year)\n\n# A tibble: 9 × 3\n  country new   n_cases\n  &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n1 FR      20_11    7000\n2 FR      20_12    6900\n3 FR      20_13    7000\n4 DE      20_11    5800\n5 DE      20_12    6000\n6 DE      20_13    6200\n7 US      20_11   15000\n8 US      20_12   14000\n9 US      20_13   13000\n\n\nLa colonne new a été créée par la fusion des colonnes century et year du tableau cases_split. Si l’on souhaite supprimer le tiret, il nous faut le spécifier explicitement :\n\nunite(cases_split, new, century, year, sep = \"\")\n\n# A tibble: 9 × 3\n  country new   n_cases\n  &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n1 FR      2011     7000\n2 FR      2012     6900\n3 FR      2013     7000\n4 DE      2011     5800\n5 DE      2012     6000\n6 DE      2013     6200\n7 US      2011    15000\n8 US      2012    14000\n9 US      2013    13000\n\n\n\n\n4.3.4 Exercices\nExaminez les tableaux rates, storms et population du package EDAWR.\n\nCes tableaux sont-ils des “tableaux rangés” (tidy data) ?\nSi oui, quelles sont les variables représentées ?\nSi non, transformez-les en “tableaux rangés”."
  },
  {
    "objectID": "04-Tidy-Data.html#importer-des-données-depuis-un-tableur",
    "href": "04-Tidy-Data.html#importer-des-données-depuis-un-tableur",
    "title": "4  (Ar)ranger des données avec tidyr",
    "section": "4.4 Importer des données depuis un tableur",
    "text": "4.4 Importer des données depuis un tableur\n\n4.4.1 Les règles de base\nJusqu’à maintenant, nous avons travaillé exclusivement avec des jeux de données déjà disponibles dans R. La plupart du temps, les données sur lesquelles vous devrez travailler devront au préalable être importées dans R ou RStudio, à partir de fichiers issus de tableurs. De tels fichiers se présentent généralement sous l’un des 2 formats suivants :\n\nFichiers au format .csv : il s’agit d’un format de fichier dit “texte brut”, c’est à dire qu’il peut être ouvert avec n’importe quel éditeur de texte, y compris le bloc notes de Windows. L’extension .csv est l’abréviation de Comma Separated Values, autrement dit, dans ce type de fichiers, les colonnes sont séparées par des virgules. Cela peut poser problème en France puisque le symbole des décimales est souvent aussi la virgule (et non le point comme dans les pays anglo-saxons). Le séparateur de colonnes utilisé en France dans les fichiers .csv est alors souvent le point-virgule. Il est possible de créer des fichiers .csv à partir de n’importe quel tableur en choisissant Fichier &gt; Exporter... ou Fichier &gt; Enregistrer sous... puis en sélectionnant le format approprié (les dénominations sont variables selon les logiciels : format texte brut, format csv, plain text, etc…).\nFichiers au format tableur : .xls ou .xlsx pour Excel, .calc pour Open Office.\n\nDans les 2 cas, pour que R puisse importer les données contenues dans ces fichiers, un certain nombre de règles doivent être respectées :\n\nLa première chose à laquelle il faut veiller est la présentation des données. Les variables doivent être en colonnes et les observations en lignes. Dans l’idéal, les données doivent donc être “rangées”.\nLes cases vides qui correspondent à des données manquantes doivent contenir les lettres NA en majuscule. Il est important de bien faire la distinction entre les vrais zéros (i.e. les grandeurs mesurées pour lesquelles un zéro a été obtenu), et les valeurs manquantes, c’est à dire pour lesquelles aucune valeur n’a pu être obtenue (e.g. variable non mesurée pour un individu donné ou à une station donnée).\nIl est généralement conseillé d’utiliser la première ligne du tableau pour stocker le nom des variables.\nPour les noms de fichiers, de colonnes ou dans le contenu des colonnes, il vaut mieux éviter les caractères spéciaux tels que #, $, %, ^, &, *, (, ), {, }, [, ], \\, /, les accents, cédilles, guillemets ou apostrophes… Cela pourrait causer des erreurs dans R. Si votre fichier en contient, faites une recherche (via le menu Edition &gt; Rechercher et remplacer...) pour remplacer chaque instance par un caractère qui ne posera pas de problème.\nÉvitez les espaces dans vos noms de variables, d’observations ou de catégories et remplacez-les par des points ou, de préférence, des tirets bas _.\nSi des noms de lignes sont présents dans votre tableau, chaque ligne doit avoir un nom unique (il ne faut pas que plusieurs lignes portent le même nom).\nDes noms courts pour les variables sont généralement plus faciles à manipuler par la suite.\nLa première valeur de votre tableau devrait toujours se trouver dans la cellule A1 du tableur. Autrement dit, il ne devrait jamais y avoir de lignes incomplètes ou de lignes de commentaires au-dessus des données, ou de colonne vide à gauche de votre tableau. D’ailleurs, il ne devrait jamais y avoir de commentaires à droite ou en dessous de vos données non plus.\n\n\n\n\n\n\n\nDifférence de philosophie\n\n\n\nQuand on travaille dans un tableur, on double clique sur le nom du fichier pour l’ouvrir dans le logiciel approprié (Excel par exemple), puis on en modifie ensuite le contenu en ajoutant ou supprimant des cellules, en modifiant des données déjà existantes ou en créant des graphiques par exemple. Les modifications sont en général sauvegardées au fur et à mesure, manuellement ou automatiquement. Au final, le fichier de départ a été modifié : son contenu n’est plus le même après votre séance de travail et il est virtuellement impossible de garder la trace de toutes les opérations qui ont été effectuées lors de la séance de travail.\nLorsqu’on importe des données issues d’un tableur dans R ou RStudio, la philosophie est totalement différente : les données sont copiées dans la mémoire vive de l’ordinateur au moment de l’importation, et on ne travaille donc pas directement dans le fichier de données. On travaille dans RStudio pour mettre en forme les données, ajouter ou modifier des variables, faire des graphiques et des tests statistiques, en tapant des commandes dans un script. À aucun moment le fichier tableur de départ n’est modifié, à aucun moment son contenu n’est altéré. Tout le travail que l’on effectue sur les données importées n’existe que :\n\ndans la mémoire vive de l’ordinateur,\net sous la forme de commandes tapées dans un script.\n\nPour sauvegarder notre travail, on enregistre notre script. À la prochaine session de travail, nous n’aurons plus qu’à ré-ouvrir notre script dans RStudio, puis à ré-envoyer dans la console la totalité des commandes qu’il contient. Ainsi, les données du fichier tableur seront ré-importées puis toutes les analyses seront exécutées à nouveau et on pourra reprendre le travail là où on l’avait laissé. Cela présente le très gros avantage de ne jamais modifier les données brutes contenues dans le fichier de départ. En outre, un script ne contient en général que quelques centaines de lignes de code au format texte brut. Cela en fait des fichiers très peu volumineux qu’il est facile de dupliquer, modifier, échanger, etc. Ils contiennent la trace de toutes les modifications et opérations que nous faisons subir aux données, ce qui en fait un outil indispensable pour la reproductibilité des analyses.\n\n\n\n\n4.4.2 Fichiers au format tableur (.xls ou .xlsx)\nÀ titre d’exemple, téléchargez le fichier dauphin.xls et placez-le dans votre répertoire de travail. Ce jeu de données contient des résultats de dosages de différents métaux lourds (cadmium, cuivre et mercure) dans différents organes (foie et rein) de plusieurs dauphins communs Delphinus delphis. Les informations de taille, d’âge et de statut reproducteur sont également précisées. Ouvrez ce fichier dans un tableur. Vous constaterez que son format ne permet pas de l’importer tel quel dans R :\n\nIl contient des lignes vides inutiles au-dessus des données.\nIl contient des commentaires inutiles au-dessus des données.\nLes titres de colonnes sont complexes et contiennent des caractères spéciaux.\nDans le tableau, les données manquantes sont représentées soit par des “*”, soit par des cellules vides.\n\nImporter un tel jeu de données dans R par les méthodes classiques (c’est-à-dire sans utiliser RStudio et uniquement grâce aux fonctions de base de R) demanderait donc un gros travail de mise en forme préalable. Heureusement, RStudio et le package readxl facilitent grandement le processus.\nDans RStudio, localisez l’onglet Files situé dans le panneau en bas à droite de l’interface du logiciel. Dans ce panneau, naviguez jusqu’à votre répertoire de travail, qui doit maintenant contenir le fichier daupin.xls que vous avez téléchargé. Cliquez sur son nom, puis, dans le menu qui s’affiche, choisissez Import Dataset... :\n\n\n\n\n\nFigure 4.4: L’option Import Dataset... dans la fenêtre Files de RStudio.\n\n\n\n\nLa nouvelle fenêtre qui s’ouvre est celle de l’assistant d’importation (Figure 4.5).\n\n\n\n\n\nFigure 4.5: L’assistant d’importation de RStudio.\n\n\n\n\nCette fenêtre contient plusieurs zones importantes :\n\nFile/URL (en haut) : lien vers le fichier contenant les données, sur votre ordinateur ou en ligne.\nData Preview : zone principale affichant les 50 premières lignes du fichier que l’on souhaite importer.\nImport Options (en bas à gauche) : zone dans laquelle des options permettant d’importer les données correctement peuvent être spécifiées.\nCode Preview (en bas à droite) : les lignes de codes que vous pourrez copier-coller dans votre script une fois les réglages corrects effectués.\n\nIci, nous constatons que les données ne sont pas au bon format. La première chose que nous pouvons faire est d’indiquer à R que nous souhaitons ignorer les 9 premières lignes du fichier. Ensuite, nous précisons à RStudio que l’étoile “*” a été utilisée pour indiquer des données manquantes (Figure 4.6) :\n\n\n\n\n\nFigure 4.6: Les bons réglages pour ce fichier.\n\n\n\n\nNotez qu’à chaque fois que vous modifiez une valeur dans la zone Import Options, 2 choses se produisent simultanément :\n\nLa zone Data Preview est mise à jour. Cela permet de s’assurer que les changements effectués ont bien les effets escomptés.\nLa zone Code Preview est mise à jour. Cela permet de copier-coller dans un script les commandes permettant d’importer correctement les données. Ici, voilà le code que nous devons ajouter à notre script :\n\n\ndauphin &lt;- read_excel(\"data/dauphin.xls\", na = \"*\", skip = 9)\n\nLa commande library(readxl) est inutile puisque nous l’avons déjà saisie au début de ce chapitre. Nous disposons maintenant d’un nouvel objet nommé dauphin. Il est stocké sous la forme d’un tibble :\n\ndauphin\n\n# A tibble: 93 × 9\n   `N°`      Sexe  `Statut reproducteur` `Taille en cm` `Age en années`\n   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;                          &lt;dbl&gt;           &lt;dbl&gt;\n 1 Numéro 1  f     imm                              315               3\n 2 Numéro 2  f     imm                              357               4\n 3 Numéro 3  f     pnl                              439              34\n 4 Numéro 4  f     imm                              316               4\n 5 Numéro 5  f     l                                435              26\n 6 Numéro 6  f     pnl                              388               6\n 7 Numéro 7  f     mat                              410              NA\n 8 Numéro 8  m     imm                              355              NA\n 9 Numéro 9  m     imm                              222              NA\n10 Numéro 10 m     imm                              412               9\n# ℹ 83 more rows\n# ℹ 4 more variables: `Cd (mg.kg-1)` &lt;dbl&gt;, `Cu (mg.kg-1)` &lt;dbl&gt;,\n#   `Hg (mg.kg-1)` &lt;dbl&gt;, Organe &lt;chr&gt;\n\n\nNotez toutefois que les noms de colonnes complexes sont toujours présents. Avec de tels noms, les variables ne seront pas faciles à manipuler et les risques d’erreurs de frappes seront nombreux. Nous avons tout intérêt à les modifier à l’aide de la fonction names() :\n\nnames(dauphin) &lt;- c(\"ID\", \"Sexe\", \"Statut\", \"Taille\",\n                    \"Age\", \"Cd\", \"Cu\", \"Hg\", \"Organe\")\ndauphin\n\n# A tibble: 93 × 9\n   ID        Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n 1 Numéro 1  f     imm       315     3  29.6   3.24 NA    rein  \n 2 Numéro 2  f     imm       357     4  55.1   4.42 NA    rein  \n 3 Numéro 3  f     pnl       439    34 129.    5.01  9.02 rein  \n 4 Numéro 4  f     imm       316     4  71.2   4.33 NA    rein  \n 5 Numéro 5  f     l         435    26 192     5.15 NA    rein  \n 6 Numéro 6  f     pnl       388     6  NA     4.12  4.53 rein  \n 7 Numéro 7  f     mat       410    NA  76     5.1  33.9  foie  \n 8 Numéro 8  m     imm       355    NA  74.4   4.72 13.3  foie  \n 9 Numéro 9  m     imm       222    NA   0.09  9.5   2.89 foie  \n10 Numéro 10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nEnfin, vous pouvez également noter que certaines variables devraient être modifiées :\n\nLes variables Sexe, Statut (qui contient l’information de statut reproducteur des dauphins) et Organe (qui indique dans quel organe les métaux ont été dosés) sont de type &lt;chr&gt;. L’idéal serait de disposer de facteurs puisqu’ils s’agit de variables catégorielles.\nLa variable ID est totalement inutile puisqu’elle est parfaitement redondante avec le numéro de ligne. Nous pourrions donc la supprimer.\nCertaines catégories (ou niveaux) de la variable Statut devraient être ordonnées puisqu’elles reflètent une progression logique : imm (immature), mat (mature), pnl (pregnant not lactating), pl (pregnant lactating), l (lactating), repos (repos somatique).\n\nNous verrons dans le Chapitre 5 comment effectuer simplement ces différentes opérations.\n\n\n4.4.3 Fichiers au format texte brut (.csv)\nNous allons utiliser les mêmes données que précédemment, mais cette fois-ci, elles sont contenues dans un fichier au format .csv. Téléchargez le fichier dauphin.csv (pour cela, faites un clic droit sur le lien et choisissez Enregistrez la cible du lien sous... ou une mention équivalente), placez-le dans votre répertoire de travail, et ouvrez-le avec le bloc notes Windows ou tout autre éditeur de texte brut disponible sur votre ordinateur. Attention : Microsoft Word n’est pas un éditeur de texte brut. Un fichier au format .doc ou .docx est illisible dans un éditeur de texte brut car outre le texte, ces formats de documents contiennent toutes les informations concernant la mise en forme du texte (polices de caractères, tailles, couleurs et autres attributs, présence de figures, de tableaux dans le document, etc.).\nÀ l’inverse, les fichiers au format .txt, .csv, .tsv et même .R (vos scripts !) sont des fichiers au format texte brut. Vous pouvez d’ailleurs essayer d’ouvrir dauphin.csv depuis RStudio, en allant dans la fenêtre Files puis en cliquant sur le nom du fichier et en choisissant View File. RStudio ouvre un nouvel onglet à côté de votre script vous permettant d’inspecter le contenu de ce fichier. Par rapport au fichier Excel, vous pouvez noter un certain nombre de différences :\n\nLes colonnes sont séparées par des tabulations (il aurait pu s’agir de virgules, de points-virgules, d’un caractère spécial ou de simples espaces).\nLes nombres décimaux utilisent la virgule (et non le point comme dans les pays anglo-saxons).\nLes noms de colonnes ont déjà été corrigés/simplifiés par rapport au tableau d’origine.\nLes valeurs manquantes sont toutes codées par des NAs.\n\nUn travail d’édition du fichier .xls de départ a donc été réalisé en amont de l’enregistrement au format .csv.\nAttention, à ce stade, vous avez ouvert un fichier au format texte brut dans RStudio, mais les données contenues dans ce fichier n’ont pas été importées dans R pour autant. Pour les importer, on procède comme pour les fichiers au format tableur (voir Section 4.4.2 ci-dessus).\nOn commence par cliquer sur dauphin.csv dans l’onglet Files de RStudio. On sélectionne ensuite Import Dataset... :\n\n\n\n\n\nFigure 4.7: Importer un fichier .csv depuis l’onglet Files de RStudio.\n\n\n\n\nLa fenêtre qui s’ouvre est en tous points identique à celle obtenue pour l’importation de fichiers tableurs (Figure 4.8).\n\n\n\n\n\nFigure 4.8: Importer un fichier .csv depuis l’onglet Files de RStudio.\n\n\n\n\nNous voyons ici que par défaut, RStudio considère qu’une unique colonne est présente. En effet, les fichiers .csv utilisent généralement la virgule pour séparer les colonnes. Ce n’est pas le cas ici. Il nous faut donc sélectionner, dans le champ Delimiter, l’option Tab (tabulation) et non Comma (virgule).\nÀ ce stade, chaque variable est maintenant reconnue comme telle, chaque variable occupe donc une colonne distincte. Mais les colonnes Cd, Cu et Hg ne contiennent pas les bonnes valeurs (vous pouvez le vérifier en consultant l’onglet dauphin.csv que vous avez ouvert un peu plus tôt à côté de votre script). La cause est simple : R s’attend à ce que les nombres décimaux utilisent le point en guise de symbole des décimales. Or, notre fichier .csv utilise la virgule. C’est une convention qui dépend du pays dans lequel vous vous trouvez, et de la langue de votre système d’exploitation (en langage technique, on parle de Locale). Le fichier dauphin.csv ayant été créé sur un ordinateur français, la virgule a été utilisée en guise de symbole des décimales. Pour l’indiquer à R, cliquez sur Locale &gt; Configure..., changez le . en , dans le champ Decimal Mark et validez en cliquant sur Configure.\n\n\n\n\n\nFigure 4.9: Changement du symbole utilisé pour les décimales.\n\n\n\n\nLes données sont maintenant au bon format, prêtes à être importées dans RStudio. Afin de ne pas écraser l’objet dauphin que nous avons créé à partir du fichier tableur un peu plus tôt, nous stockerons ces nouvelles données dans un objet nommé dauphin2. Pour cela, ajoutez un 2 au nom dauphin dans le champ Name en bas à gauche :\n\n\n\n\n\nFigure 4.10: Les données, dans un format correct permettant l’importation.\n\n\n\n\nNous n’avons plus qu’à copier-coller dans notre script le code généré automatiquement en bas à droite de la fenêtre. Comme précédemment, la ligne library(readr) est inutile : ce fait package fait partie du tidyverse et nous l’avons donc déjà chargé en début de chapitre.\n\ndauphin2 &lt;- read_delim(\"data/dauphin.csv\", \n                       \"\\t\", escape_double = FALSE, \n                       locale = locale(decimal_mark = \",\"), \n                       trim_ws = TRUE)\n\nRows: 93 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (3): Sexe, Statut, Organe\ndbl (6): Id, Taille, Age, Cd, Cu, Hg\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNotez que :\n\nC’est le package readr et non plus readxl qui est utilisé.\nLa fonction read_delim() a remplacé la fonction read_excel(). Il existe beaucoup d’autres fonctions selon le format de vos données (par exemple read_csv() et read_csv2()). Il est inutile de toutes les connaître dans la mesure où généralement, RStudio vous propose automatiquement la plus appropriée.\nR indique de quelle façon les colonnes ont été “parsées”, autrement dit, R indique quelles fonctions ont été utilisées pour reconnaître le type des données présentes dans chaque colonne.\n\nToutes les fonctions permettant d’importer des données n’ont pas nécessairement le même comportement. Ainsi, si l’on compare les objets importés depuis le fichier tableur (dauphin) et depuis le fichier texte brut (dauphin2), le type de certaines variables peut être différent :\n\ndauphin\n\n# A tibble: 93 × 9\n   ID        Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n 1 Numéro 1  f     imm       315     3  29.6   3.24 NA    rein  \n 2 Numéro 2  f     imm       357     4  55.1   4.42 NA    rein  \n 3 Numéro 3  f     pnl       439    34 129.    5.01  9.02 rein  \n 4 Numéro 4  f     imm       316     4  71.2   4.33 NA    rein  \n 5 Numéro 5  f     l         435    26 192     5.15 NA    rein  \n 6 Numéro 6  f     pnl       388     6  NA     4.12  4.53 rein  \n 7 Numéro 7  f     mat       410    NA  76     5.1  33.9  foie  \n 8 Numéro 8  m     imm       355    NA  74.4   4.72 13.3  foie  \n 9 Numéro 9  m     imm       222    NA   0.09  9.5   2.89 foie  \n10 Numéro 10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\ndauphin2\n\n# A tibble: 93 × 9\n      Id Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n 1     1 f     imm       315     3  29.6   3.24 NA    rein  \n 2     2 f     imm       357     4  55.1   4.42 NA    rein  \n 3     3 f     pnl       439    34 129.    5.01  9.02 rein  \n 4     4 f     imm       316     4  71.2   4.33 NA    rein  \n 5     5 f     l         435    26 192     5.15 NA    rein  \n 6     6 f     pnl       388     6  NA     4.12  4.53 rein  \n 7     7 f     mat       410    NA  76     5.1  33.9  foie  \n 8     8 m     imm       355    NA  74.4   4.72 13.3  foie  \n 9     9 m     imm       222    NA   0.09  9.5   2.89 foie  \n10    10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nEn particulier selon la version des packages que vous utilisez et les réglages spécifiques de vos systèmes d’exploitation, les variables Taille et Age sont parfois considérées comme réelles dans dauphin (&lt;dbl&gt;) mais comme entières dans dauphin2 (&lt;int&gt;, ce n’est pas le cas ici). Afin d’éviter les confusions dans la suite du document, nous allons supprimer dauphin2 en tapant :\n\nrm(dauphin2)\n\nTaper dauphin2 dans la console devrait maintenant produire une erreur :\n\ndauphin2\n\nError in eval(expr, envir, enclos): objet 'dauphin2' introuvable\n\n\n\n\n4.4.4 En cas de problème…\nIl arrive parfois que l’importation de fichiers textes bruts par la méthode décrite ci-dessus échoue en raison d’un bug du package readr qui gère mal la présence de caractères spéciaux (accents, cédilles, etc) dans le chemin des fichiers que l’on tente d’importer. À l’heure où j’écris ces lignes, ce bug déjà ancien est toujours présent sur certains systèmes. Il est donc utile de connaître une méthode alternative pour importer de tels fichiers dans R. Cette méthode repose sur “la mère de toutes les fonctions d’importation” : read.table().\nLa fonction read.table() est à la base de la plupart des fonctions d’importation décrites dans ce chapitre. Il est donc important d’en connaître la syntaxe et les arguments les plus courants. Cette fonction requiert en général les arguments suivants :\n\nLe chemin du fichier texte contenant les données à importer. Si le fichier se trouve dans votre répertoire de travail, il suffit de donner son nom. S’il est dans un sous-dossier de votre répertoire de travail, il faut donner le nom complet : \"sous_dossier/nom_du_fichier.csv\".\nsep : la spécification du symbole utilisé en guise de séparateur de colonnes dans le fichier texte. Cela peut-être la virgule (sep = \",\"), le point virgule (sep = \";\") ou encore la tabulation (sep = \"\\t\") selon les fichiers importés.\ndec : la spécification du symbole utilisé en guise de symbole pour les décimales. Il n’est pas nécessaire de spécifier cet argument lorsque le symbole dans le fichier source est le point. Mais si c’est une virgule (comme c’est souvent le cas dans les pays francophones), il faut alors préciser dec = \",\".\nheader : la première ligne du fichier source contient-elle des noms de variables. Si oui, il faut indiquer header = TRUE.\n\nAinsi, par exemple, pour le fichier dauphin.csv que j’ai placé dans un sous-dossier de mon répertoire de travail nommé data, on peut taper ceci :\n\ndauph &lt;- read.table(\"data/dauphin.csv\",\n                    sep = \"\\t\",\n                    dec = \",\",\n                    header = TRUE)\ndauph\n\n   Id Sexe Statut Taille Age     Cd    Cu     Hg Organe\n1   1    f    imm    315   3  29.60  3.24     NA   rein\n2   2    f    imm    357   4  55.10  4.42     NA   rein\n3   3    f    pnl    439  34 129.30  5.01   9.02   rein\n4   4    f    imm    316   4  71.20  4.33     NA   rein\n5   5    f      l    435  26 192.00  5.15     NA   rein\n6   6    f    pnl    388   6     NA  4.12   4.53   rein\n7   7    f    mat    410  NA  76.00  5.10  33.90   foie\n8   8    m    imm    355  NA  74.40  4.72  13.30   foie\n9   9    m    imm    222  NA   0.09  9.50   2.89   foie\n10 10    m    imm    412   9  85.60  5.42     NA   rein\n11 11    m    imm    310   4  39.80  3.62     NA   rein\n12 12    f    pnl    452  28 193.90  6.34   8.70   rein\n13 13    m    imm    299   3  25.80  5.10   7.40   foie\n14 14    f     pl    432  14  77.30  8.75 128.80   foie\n15 15    m    imm    392   4  36.70  5.10  13.70   foie\n16 16    f    pnl    445  22  88.40  8.40 141.90   foie\n17 17    f    imm    348  NA  49.80  6.30  32.40   foie\n18 18    m    imm    210  NA   0.05  5.50   3.09   foie\n19 19    f     pl    430  NA  57.90  7.00  14.10   foie\n20 20    m    imm    264  NA   4.40  3.40   1.25   foie\n21 21    f    pnl    433  23 155.90  8.51     NA   rein\n22 22    f    imm    447  27  43.40  3.56     NA   rein\n23 23    m    mat    548  21  57.90  3.21     NA   rein\n24 24    m    imm    308   2  29.70  3.93     NA   rein\n25 25    f    pnl    435  21  55.40  4.35     NA   rein\n26 26    f      l    465  14 146.80  5.78     NA   rein\n27 27    m    imm    334   1   1.55  3.35     NA   rein\n28 28    f      l    434  22  55.00  3.53     NA   rein\n29 29    f    pnl    387   6  90.10  4.17     NA   rein\n30 30    f  repos    444  40 107.30  5.01     NA   rein\n31 31    m    mat    581  18 164.30  5.69     NA   rein\n32 32    f    imm    359  11     NA  3.97     NA   rein\n33 33    f    imm    245  NA   0.07  5.80   1.30   foie\n34 34    m    imm    346   4  34.40  2.65  21.60   foie\n35 35    f    imm    370  NA  36.40  3.80  15.70   foie\n36 36    f      l    432  27  80.10  3.96     NA   rein\n37 37    m    imm    279   2   7.84  3.63     NA   rein\n38 38    f    imm    316   3  34.20  3.21     NA   rein\n39 39    m    imm    315   2  16.50  3.35     NA   rein\n40 40    f    pnl    363   8  56.20  4.00     NA   rein\n41 41    f    pnl    457  14 123.30  5.86   4.23   rein\n42 42    m    imm    472   9 109.60  4.50     NA   rein\n43 43    f     pl    442  16 193.10  5.25   6.38   rein\n44 44    m    imm    422  10  75.10  6.90  53.15   foie\n45 45    f    imm    193   1     NA  5.70     NA   rein\n46 46    m    imm    324   4  31.60  4.50   7.90   foie\n47 47    f    pnl    478  36  82.20  6.70 243.60   foie\n48 48    f    pnl    451  NA 584.70  5.26     NA   rein\n49 49    m    imm    245  NA   0.07  6.00   5.70   foie\n50 50    f    pnl    405  NA  70.00  6.90  28.70   foie\n51 51    m    imm    433  NA  55.20  7.50  52.50   foie\n52 52    m    imm    326  NA  19.90  3.70  11.00   foie\n53 53    f    pnl    440  22  84.00  9.10 207.40   foie\n54 54    f    pnl    431  NA  90.30  4.64     NA   rein\n55 55    f     pl    428  12 108.30  4.47   3.93   rein\n56 56    f    imm    308  NA  50.80  5.00  27.00   foie\n57 57    f    pnl    422  14  70.40  7.30  62.90   foie\n58 58    f     pl    426  12  94.40  8.00  85.00   foie\n59 59    f    imm    216  NA   0.01  4.20   3.53   foie\n60 60    f    imm    314  NA  37.10  4.40  15.20   foie\n61 61    f    pnl    394   9  78.50  6.20  55.20   foie\n62 62    m    imm    400   5  89.10  4.83     NA   rein\n63 63    f    pnl    416  NA  67.80  7.50  95.90   foie\n64 64    f    imm    275   2   2.30  3.00   1.20   foie\n65 65    m    imm    382  10  89.10  4.62     NA   rein\n66 66    f    imm    320   6     NA  4.65     NA   rein\n67 67    f     pl    418  12  89.10  4.26   5.44   rein\n68 68    f    pnl    423  12  71.90  7.20  72.50   foie\n69 69    f      l    407  11  64.40  5.10  39.00   foie\n70 70    f     pl    459  22  76.20 10.70 178.20   foie\n71 71    m    imm    215  NA   0.04  4.40   2.74   foie\n72 72    m    imm    354   5  31.80  5.40 172.10   foie\n73 73    m    imm    237  NA   0.07  7.10   1.29   foie\n74 74    m    mat    513  18  44.30  5.80  49.80   foie\n75 75    f     pl    431  15  80.80  9.40 145.20   foie\n76 76    m    mat    519  15  71.30  4.41     NA   rein\n77 77    f    pnl    386   8 918.80  7.38     NA   rein\n78 78    f    imm    378   5 129.20  6.38     NA   rein\n79 79    f    imm    342   4  89.40  4.68     NA   rein\n80 80    m    mat    582  21 127.10  5.76     NA   rein\n81 81    f      l    453  24  59.40  7.90 141.90   foie\n82 82    f    imm    242   1   7.20  4.30   3.48   foie\n83 83    f    imm    292   3  33.20  3.60     NA   rein\n84 84    m    mat    545  25  89.30  2.67     NA   rein\n85 85    f    imm    185  NA   0.01  5.50   2.58   foie\n86 86    m    imm    340  NA  42.00  4.20   9.90   foie\n87 87    m    imm    232   5   0.08  6.40   1.10   foie\n88 88    m    mat    560  24  35.70  5.70  69.70   foie\n89 89    m    imm    308  NA  38.20  4.40  11.50   foie\n90 90    m    imm    227  NA   3.40  3.70   3.08   foie\n91 91    f     pl    460  19  98.90  3.63     NA   rein\n92 92    f      l    436  35  94.00  4.01     NA   rein\n93 93    m    mat    582  27  82.20  3.39     NA   rein\n\n\nPuisque la fonction read.table() importe les données sous la forme d’un data.frame, il est nécessaire de transformer le tableau obtenu en tibble grâce à la fonction as_tibble() afin de bénéficier de tous les avantages de ce format d’objet.\n\ndauph &lt;- as_tibble(dauph)\ndauph\n\n# A tibble: 93 × 9\n      Id Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;   &lt;int&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n 1     1 f     imm       315     3  29.6   3.24 NA    rein  \n 2     2 f     imm       357     4  55.1   4.42 NA    rein  \n 3     3 f     pnl       439    34 129.    5.01  9.02 rein  \n 4     4 f     imm       316     4  71.2   4.33 NA    rein  \n 5     5 f     l         435    26 192     5.15 NA    rein  \n 6     6 f     pnl       388     6  NA     4.12  4.53 rein  \n 7     7 f     mat       410    NA  76     5.1  33.9  foie  \n 8     8 m     imm       355    NA  74.4   4.72 13.3  foie  \n 9     9 m     imm       222    NA   0.09  9.5   2.89 foie  \n10    10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\n\n\n4.4.5 Exercices\n\nL’objet dauphin est-il “tidy” (autrement dit, s’agit-il de “données rangées”) ? Justifiez.\nProduisez le graphique ci-dessous :\n\n\n\n\n\n\nFigure 4.11: Figure à reproduire.\n\n\n\n\nIndice : les droites de régression avec les intervalles de confiance sont ajoutés grâce à la fonction geom_smooth(method = \"lm\").\n\nImportez dans R le jeu de données whoTB.csv. Ce jeu de données contient les cas de tuberculose (TB) rapportés par l’Organisation Mondiale de la Santé (OMS, ou WHO en anglais : World Health Organization). Les cas sont répertoriés par année, pays, âge, sexe, type de tuberculose et méthode de diagnostique. Selon vous, ce jeu de données est-il “rangé” ? Pourquoi ?\nSi ce jeu de données n’est pas rangé, rangez-le en utilisant les fonctions du packages tidyr que nous avons découvertes dans ce chapitre : pivot_longer(), pivot_wider(), separate() et unite(). Vous n’aurez pas nécessairement besoin d’utiliser ces 4 fonctions, et à l’inverse, certaines devront peut-être être utilisées plusieurs fois.\n\nPour vous aider, l’OMS donne la signification des codes utilisés en guise de noms pour la plupart des colonnes. Ainsi :\n\nnew indique des nouveaux cas, old des anciens (ici, seuls des nouveaux cas sont rapportés).\nLe type de cas est précisé ensuite :\n\nsp signifie “Smear Positive” (tuberculose pulmonaire à frottis positif).\nsn signifie “Smear Negative” (tuberculose pulmonaire à frottis négatif).\nrel signifie “relapse” (rechute).\nep signifie “Extra Pulmonary” (tuberculose extra-pulmonaire).\n\nLe sexe est codé par m (male) ou f (female).\nEnfin, les chiffres correspondent à des tranches d’âges : 014 signifie “de 0 à 14 ans”, “1524” signifie “de 15 à 24 ans”, etc.\n\nDans ces colonnes aux noms composés, les nombres de cas de tuberculose sont rapportés."
  },
  {
    "objectID": "05-DataWrangling.html#pré-requis",
    "href": "05-DataWrangling.html#pré-requis",
    "title": "5  Manipuler des tableaux avec dplyr",
    "section": "5.1 Pré-requis",
    "text": "5.1 Pré-requis\nNous abordons ici une étape essentielle de toute analyse de données : la manipulation de tableaux, la sélection de lignes, de colonnes, la création de nouvelles variables, etc. Bien souvent, les données brutes que nous importons dans R ne sont pas utiles en l’état. Il nous faut parfois sélectionner seulement certaines lignes pour travailler sur une petite partie du jeu de données. Il nous faut parfois modifier des variables existantes (pour modifier les unités par exemple) ou en créer de nouvelles à partir des variables existantes. Nous avons aussi très souvent besoin de constituer des groupes et d’obtenir des statistiques descriptives pour chaque groupe (moyenne, écart-type, erreur type, etc). Nous verrons dans ce chapitre comment faire tout cela grâce au package dplyr qui fournit un cadre cohérent et des fonctions simples permettant d’effectuer tous les tripatouillages de données dont nous pourrons avoir besoin.\nDans ce chapitre, nous aurons besoin des packages suivants :\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(nycflights13)"
  },
  {
    "objectID": "05-DataWrangling.html#le-pipe",
    "href": "05-DataWrangling.html#le-pipe",
    "title": "5  Manipuler des tableaux avec dplyr",
    "section": "5.2 Le pipe |>",
    "text": "5.2 Le pipe |&gt;\nAvant d’entrer dans le vif du sujet, je souhaite introduire ici la notion de “pipe” (prononcer à l’anglo-saxonne). Le pipe est un opérateur que nous avons déjà vu apparaître à plusieurs reprises dans les chapitres précédents sans expliquer son fonctionnement.\n\n\n\n\n\n\nFigure 5.1: Pour que ces raccourcis fonctionnent, assurez-vous que l’option Use native pipe operator est bien cochée dans les préférences de RStudio.\n\n\n\nLe pipe, noté |&gt;, peut être obtenu en pressant les touches ctrl + shift + M de votre clavier (ou command + shift + M sous macOS). Il peut aussi être noté de la façon suivante : |&gt;. Historiquement, c’est d’ailleurs ce symbole qui était systématiquement utilisé et qui apparaissait en pressant les raccourcis claviers décrits plus haut (voir (figpiperef?) ci-contre). Ce pipe est apparu dans le package magrittr qui fait partie du tidyverse. Cet opérateur s’est avéré tellement utile et a permis de rendre les scripts tellement plus faciles à lire, que depuis la version 4.1.0 de R, un pipe “natif” (|&gt;, disponible par défaut, sans avoir besoin de charger le moindre package) a été rendu disponible.\nIl permet d’enchaîner logiquement des actions les unes à la suite des autres. Globalement, le pipe prend l’objet situé à sa gauche, et le transmet à la fonction situé à sa droite. En d’autres termes, les 2 expressions suivantes sont strictement équivalentes :\n\n# Ici, \"f\" est une fonction quelconque, \n# \"x\" et \"y\" sont 2 objets dont la fonction a besoin.\n\n# Il s'agit d'un exemple fictif : ne tapez pas ceci dans votre script !\nf(x, y)\nx |&gt; f(y)\n\nTravailler avec le pipe est très intéressant car toutes les fonctions de dplyr que nous allons décrire ensuite sont construites autour de la même syntaxe : on leur fournit un data.frame (ou encore mieux, un tibble), elles effectuent une opération et renvoient un nouveau data.frame (ou un nouveau tibble). Il est ainsi possible de créer des groupes de commandes cohérentes qui permettent, grâce à l’enchaînement d’étapes simples, d’aboutir à des résultats complexes.\nDe la même façon que le + permet d’ajouter une couche supplémentaire à un graphique ggplot2, le pipe |&gt; permet d’ajouter une opération supplémentaire dans un groupe de commandes.\nPour reprendre un exemple de la Section 3.8.1 sur les diagrammes bâtons empilés, nous avions utilisé ce code :\n\npenguins |&gt; \n  filter(!is.na(sex)) |&gt; \n  ggplot(aes(x = fct_infreq(species), fill = sex)) +\n  geom_bar(alpha = 0.6, color = \"black\", position = \"fill\")\n\n\n\n\nLigne par ligne, voilà la signification de ce code :\n\n“Prend le tableau penguins, puis…”\n“transmets-le à la fonction filter() pour éliminer les lignes pour lequel le sexe est inconnu, puis…”\n“transmets le résultat à la fonction ggplot() pour en faire un graphique”\n\nOn aurait pu faire la même chose ainsi :\n\npenguins_clean &lt;- filter(penguins, !is.na(sex))\nggplot(penguins_clean, aes(x = fct_infreq(species), fill = sex)) +\n    geom_bar(alpha = 0.6, color = \"black\", position = \"fill\")\n\n\n\n\nC’est strictement équivalent. La deuxième méthode à l’inconvénient de nous obliger à créer un objet intermédiaire (que j’ai ici nommé penguins_clean). Lorsque l’on a de nombreuses fonctions à enchaîner, il faut donc créer de nombreux objets intermédiaires dont nous n’avons besoin qu’une seule fois, ce qui peut être source de nombreuses erreurs.\nUne troisième façon de procéder est la suivante :\n\nggplot(filter(penguins, !is.na(sex)), \n       aes(x = fct_infreq(species), fill = sex)) +\n    geom_bar(alpha = 0.6, color = \"black\", position = \"fill\")\n\n\n\n\nCette fois, on ne crée plus d’objet intermédiaire, mais on intègre directement la fonction filter() à l’intérieur de la fonction ggplot(). Le code devient un peu moins lisible, et quand ça n’est pas deux fonctions mais 4, 5 ou plus que nous devons enchaîner, procéder ainsi est la garantie que des erreurs seront commises et qu’elles seront très difficiles à corriger.\nOn préfère donc toujours utiliser le pipe qui a le mérite de placer chaque fonction sur une nouvelle ligne, et de permettre une lecture plus simple du code, ligne par ligne, étape par étape, et non de façon imbriquée, de l’intérieur d’une commande vers l’extérieur :\n\npenguins |&gt; \n  filter(!is.na(sex)) |&gt; \n  ggplot(aes(x = fct_infreq(species), fill = sex)) +\n  geom_bar(alpha = 0.6, color = \"black\", position = \"fill\")\n\nNotez bien qu’avec le pipe, le premier argument des fonctions filter() et ggplot() a disparu : le pipe a fourni automatiquement à filter() les données du tableau penguins. Il a ensuite fourni automatiquement à ggplot() les données modifiées par la fonction filter().\nComme pour le + de ggplot2, il est conseillé de placer un seul pipe par ligne, toujours à la fin, et de revenir à la ligne pour préciser l’étape suivante.\nToutes les commandes que nous utiliserons à partir de maintenant reposeront sur le pipe puisqu’il permet de rendre le code plus lisible."
  },
  {
    "objectID": "05-DataWrangling.html#les-verbes-du-tripatouillage-de-données",
    "href": "05-DataWrangling.html#les-verbes-du-tripatouillage-de-données",
    "title": "5  Manipuler des tableaux avec dplyr",
    "section": "5.3 Les verbes du tripatouillage de données",
    "text": "5.3 Les verbes du tripatouillage de données\nNous allons ici nous concentrer sur les fonctions les plus couramment utilisées pour manipuler et résumer des données. Nous aborderons ici une dizaine des principaux verbes de la manipulation des données, chacun correspondant à une fonction précise de dplyr. Chaque section de ce chapitre sera consacrée à la présentation d’un exemple utilisant un ou plusieurs de ces verbes.\nLes 6 verbes sont :\n\nfilter() : choisir des lignes dans un tableau à partir de conditions spécifiques (filtrer).\nselect() : sélectionner des colonnes d’un tableau.\nmutate() : créer de nouvelles variables en transformant et combinant des variables existantes (muter).\narrange() : trier les lignes d’un tableau selon un ou plusieurs critères (arranger).\nsummarise() et reframe() : calculer des résumés statistiques des données (résumer). Souvent utilisé en combinaison avec group_by() (grouper par), qui permet de constituer des groupes au sein des données.\nleft_join() et inner_join() : associer, fusionner 2 data.frames en faisant correspondre les éléments d’une colonne commune entre les 2 tableaux (joindre). Il y a de nombreuses façons de joindre des tableaux, et donc, de nombreuses fonctions de jointure (left_join(), right_join(), inner_join(), full_join(), outer_join(), cross_join(), nest_join()…). Nous nous contenterons d’examiner les fonctions les plus basiques et qui devraient couvrir l’essentiel de vos besoins.\n\nToutes ces fonctions, tous ces verbes, sont utilisés de la même façon : on prend un data.frame, grâce au pipe, on le transmet à l’une de ces fonctions dont on précise les arguments entre parenthèses, la fonction nous renvoie un nouveau tableau modifié. Évidemment, on peut enchaîner les actions pour modifier plusieurs fois le même tableau, c’est tout l’intérêt du pipe.\nEnfin, gardez en tête qu’il existe beaucoup plus de fonctions dans dplyr que la dizaine que nous allons détailler ici. Nous verrons parfois quelques variantes, mais globalement, maîtriser ces fonctions simples devrait vous permettre de conduire une très large gamme de manipulations de données, et ainsi vous faciliter la vie pour la production de graphiques et l’analyse statistique de vos données."
  },
  {
    "objectID": "05-DataWrangling.html#sec-filter",
    "href": "05-DataWrangling.html#sec-filter",
    "title": "5  Manipuler des tableaux avec dplyr",
    "section": "5.4 Filtrer des lignes avec filter()",
    "text": "5.4 Filtrer des lignes avec filter()\n\n5.4.1 Principe\n\n\n\n\n\nFigure 5.2: Schéma de la fonction filter() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nComme son nom l’indique, filter() permet de filtrer des lignes en spécifiant un ou des critères de tri portant sur une ou plusieurs variables. Nous pouvons ainsi créer un nouveau tableau ne contenant que les données de l’espèce Adélie :\n\npeng_adelie &lt;- penguins |&gt; \n  filter(species == \"Adelie\")\n\nLa première ligne de code nous permet :\n\nd’indiquer le nom du nouvel objet dans lequel les données modifiées seront stockées (ici, peng_adelie)\nd’indiquer de quel objet les données doivent être extraites (penguins)\nde passer cet objet à la fonction suivante avec un pipe |&gt;\n\nLe premier argument de la fonction filter() doit être le nom d’un data.frame ou d’un tibble. Ici, puisque nous utilisons le pipe, il est inutile de spécifier cet argument : c’est ce qui est placé à gauche du pipe qui est utilisé comme premier argument de la fonction filter(). Les arguments suivants constituent la ou les conditions qui doivent être respectées par les lignes du tableau de départ afin d’être intégrées au nouveau tableau de données.\n\n\n5.4.2 Exercice\nCréez un objet nommé adelie_light qui contiendra uniquement les données de l’espèce Adélie, et uniquement pour les individus pesant 3700 grammes ou moins. Indice : relisez la Section 1.3.4.2\nVérifiez que cet objet contient bien 81 lignes.\n\n\n5.4.3 Les conditions logiques\nDans la Section 1.3.4.2, nous avons présenté en détail le fonctionnement des opérateurs de comparaison dans R. Relisez cette section si vous ne savez plus de quoi il s’agit. Les opérateurs de comparaison permettent de vérifier l’égalité ou l’inégalité entre des éléments. Ils renvoient TRUE ou FALSE et seront particulièrement utiles pour filtrer des lignes dans un tableau. Voici à nouveau la liste des opérateurs de comparaison usuels :\n\n== : égal à\n!= : différent de\n&gt; : supérieur à\n&lt; : inférieur à\n&gt;= : supérieur ou égal à\n&lt;= : inférieur ou égal à\n\nÀ cette liste, nous pouvons ajouter quelques éléments utiles :\n\nis.na() : renvoie TRUE en cas de données manquantes.\n! : permet de tester le contraire d’une expression logique. Par exemple !is.na() renvoie TRUE s’il n’y a pas de données manquantes.\n%in% : permet de tester si l’élément de gauche est contenu dans la série d’éléments fournie à droite. Par exemple 2 %in% 1:5 renvoie TRUE, mais 2 %in% 5:10 renvoie FALSE.\n| : opérateur logique OU. Permet de tester qu’une condition OU une autre est remplie.\n& : opérateur logique ET. Permet de tester qu’une condition ET une autre sont remplies.\n\nVoyons comment utiliser ces opérateurs avec la fonction filter().\nDans le tableau penguins, quels sont les individus pour lesquels la masse n’a pas été mesurée ? Une bonne façon de le savoir est de regarder si, pour la variable body_mass_g, des données manquantes sont présentes :\n\npenguins |&gt; \n  filter(is.na(body_mass_g))\n\n# A tibble: 2 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen             NA            NA                NA          NA\n2 Gentoo  Biscoe                NA            NA                NA          NA\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nSeules les lignes contenant NA dans la colonne body_mass_g sont retenues. Il y a donc 2 individus dont la masse est inconnue. D’ailleurs, pour ces individu, aucune mesure biométrique n’est disponible. il s’agit d’un manchot Adélie, et d’un manchot Gentoo, tous les deux de sexe inconnu.\nDans le même ordre d’idée, y a t-il des individus dont on ne connait pas le sexe mais dont on connait les mesures biométriques (au moins la masse) ? Là encore, une façon d’obtenir cette information est de sélectionner les individus dont le sexe est manquant, mais pour lesquels la masse n’est pas manquante :\n\npenguins |&gt; \n  filter(is.na(sex),\n         !is.na(body_mass_g))\n\n# A tibble: 9 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           34.1          18.1               193        3475\n2 Adelie  Torgersen           42            20.2               190        4250\n3 Adelie  Torgersen           37.8          17.1               186        3300\n4 Adelie  Torgersen           37.8          17.3               180        3700\n5 Adelie  Dream               37.5          18.9               179        2975\n6 Gentoo  Biscoe              44.5          14.3               216        4100\n7 Gentoo  Biscoe              46.2          14.4               214        4650\n8 Gentoo  Biscoe              47.3          13.8               216        4725\n9 Gentoo  Biscoe              44.5          15.7               217        4875\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nNotez l’utilisation du ! pour la seconde condition. Nous récupérons ici les lignes pour lesquelles body_mass_g n’est pas NA et pour lesquelles sex est NA. Seules les lignes qui respectent cette double condition sont retenues. Cette syntaxe est équivalente à :\n\npenguins |&gt; \n  filter(is.na(sex) & !is.na(body_mass_g))\n\n# A tibble: 9 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           34.1          18.1               193        3475\n2 Adelie  Torgersen           42            20.2               190        4250\n3 Adelie  Torgersen           37.8          17.1               186        3300\n4 Adelie  Torgersen           37.8          17.3               180        3700\n5 Adelie  Dream               37.5          18.9               179        2975\n6 Gentoo  Biscoe              44.5          14.3               216        4100\n7 Gentoo  Biscoe              46.2          14.4               214        4650\n8 Gentoo  Biscoe              47.3          13.8               216        4725\n9 Gentoo  Biscoe              44.5          15.7               217        4875\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nDans la fonction filter(), séparer plusieurs conditions par des virgules signifie que seules les lignes qui remplissent toutes les conditions seront retenues. C’est donc l’équivalent du ET logique.\n\nEnfin, pour illustrer l’utilisation de | (le OU logique) et de %in%, imaginons que nous souhaitions extraire les informations des individus de l’espèce Adélie qui vivent soit sur l’île Biscoe, soit sur l’île Dream, et dont le bec mesure moins de 42 mm de longueur :\n\nadel_small &lt;- penguins |&gt; \n  filter(species == \"Adelie\", \n         island == \"Biscoe\" | island == \"Dream\", \n         bill_length_mm &lt; 42)\nadel_small\n\n# A tibble: 91 × 8\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Biscoe           37.8          18.3               174        3400\n 2 Adelie  Biscoe           37.7          18.7               180        3600\n 3 Adelie  Biscoe           35.9          19.2               189        3800\n 4 Adelie  Biscoe           38.2          18.1               185        3950\n 5 Adelie  Biscoe           38.8          17.2               180        3800\n 6 Adelie  Biscoe           35.3          18.9               187        3800\n 7 Adelie  Biscoe           40.6          18.6               183        3550\n 8 Adelie  Biscoe           40.5          17.9               187        3200\n 9 Adelie  Biscoe           37.9          18.6               172        3150\n10 Adelie  Biscoe           40.5          18.9               180        3950\n# ℹ 81 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nExaminez ce tableau avec View() pour vérifier que la variable island contient bien uniquement les valeurs Biscoe et Dream correspondant aux 2 îles qui nous intéressent. Nous avons extrait ici les individus des îles Biscoe et Dream, pourtant, il nous a fallu utiliser le OU logique. Car chaque individu n’est issu que d’une unique île, or nous souhaitons récupérer toutes les lignes pour lesquelles l’île est soit Biscoe, soit Dream (l’une ou l’autre). Pour chaque ligne, les deux conditions ne peuvent pas être vraies l’une et l’autre en même temps. En revanche, on retient chaque ligne qui remplit la première condition ou la seconde.\nUne autre solution pour obtenir le même tableau est de remplacer l’expression contenant | par une expression contenant %in% :\n\nadel_small2 &lt;- penguins |&gt; \n  filter(species == \"Adelie\", \n         island %in% c(\"Biscoe\", \"Dream\"), \n         bill_length_mm &lt; 42)\nadel_small2\n\n# A tibble: 91 × 8\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Biscoe           37.8          18.3               174        3400\n 2 Adelie  Biscoe           37.7          18.7               180        3600\n 3 Adelie  Biscoe           35.9          19.2               189        3800\n 4 Adelie  Biscoe           38.2          18.1               185        3950\n 5 Adelie  Biscoe           38.8          17.2               180        3800\n 6 Adelie  Biscoe           35.3          18.9               187        3800\n 7 Adelie  Biscoe           40.6          18.6               183        3550\n 8 Adelie  Biscoe           40.5          17.9               187        3200\n 9 Adelie  Biscoe           37.9          18.6               172        3150\n10 Adelie  Biscoe           40.5          18.9               180        3950\n# ℹ 81 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nIci, toutes les lignes du tableau dont la variable island est égale à un élément du vecteur c(\"Biscoe\", \"Dream\") sont retenues. L’utilisation du OU logique peut être source d’erreur. Je préfère donc utiliser %in% qui me semble plus parlant. La fonction identical() nous confirme que les deux façons de faire produisent exactement le même résultat. Libre à vous de privilégier la méthode qui vous convient le mieux :\n\nidentical(adel_small, adel_small2)\n\n[1] TRUE"
  },
  {
    "objectID": "05-DataWrangling.html#sélectionner-des-variables-avec-select",
    "href": "05-DataWrangling.html#sélectionner-des-variables-avec-select",
    "title": "5  Manipuler des tableaux avec dplyr",
    "section": "5.5 Sélectionner des variables avec select()",
    "text": "5.5 Sélectionner des variables avec select()\n\n\n\n\n\nFigure 5.3: Schéma de la fonction select() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nIl n’est pas rare de travailler avec des tableaux contenant des centaines, voir des milliers de colonnes. Dans de tels cas, il peut être utile de réduire le jeu de données aux variables qui vous intéressent. Le rôle de la fonction select() est de retenir uniquement les colonnes dont on a spécifié le nom, afin de recentrer l’analyse sur les variables utiles.\nselect() n’est pas particulièrement utile pour le jeu de données penguins puisqu’il ne contient que 8 variables. Toutefois, on peut malgré tout ces données pour comprendre le fonctionnement général de select(). Ainsi, pour sélectionner uniquement les colonnes species, sex et body_mass_g, on tape :\n\n# Sélection de variables par leur nom\npenguins |&gt;\n  select(species, sex, body_mass_g)\n\n# A tibble: 344 × 3\n   species sex    body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;        &lt;int&gt;\n 1 Adelie  male          3750\n 2 Adelie  female        3800\n 3 Adelie  female        3250\n 4 Adelie  &lt;NA&gt;            NA\n 5 Adelie  female        3450\n 6 Adelie  male          3650\n 7 Adelie  female        3625\n 8 Adelie  male          4675\n 9 Adelie  &lt;NA&gt;          3475\n10 Adelie  &lt;NA&gt;          4250\n# ℹ 334 more rows\n\n\nPour retenir des colonnes qui sont côte à côte dans le tableau de départ, on peut utiliser l’opérateur : pour les sélectionner :\n\n# Sélection de toutes les variables entre `island` et `bill_depth_mm` (inclues)\npenguins |&gt;\n  select(island:bill_depth_mm)\n\n# A tibble: 344 × 3\n   island    bill_length_mm bill_depth_mm\n   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;\n 1 Torgersen           39.1          18.7\n 2 Torgersen           39.5          17.4\n 3 Torgersen           40.3          18  \n 4 Torgersen           NA            NA  \n 5 Torgersen           36.7          19.3\n 6 Torgersen           39.3          20.6\n 7 Torgersen           38.9          17.8\n 8 Torgersen           39.2          19.6\n 9 Torgersen           34.1          18.1\n10 Torgersen           42            20.2\n# ℹ 334 more rows\n\n\nÀ l’inverse, si on veut supprimer certaines colonnes, on peut utiliser la notation - :\n\n# Sélection de toutes les variables de `penguins` à l'exception\n# de celles comprises entre `island` et `bill_depth_mm` (inclues)\npenguins |&gt;\n  select(-(island:bill_depth_mm))\n\n# A tibble: 344 × 5\n   species flipper_length_mm body_mass_g sex     year\n   &lt;fct&gt;               &lt;int&gt;       &lt;int&gt; &lt;fct&gt;  &lt;int&gt;\n 1 Adelie                181        3750 male    2007\n 2 Adelie                186        3800 female  2007\n 3 Adelie                195        3250 female  2007\n 4 Adelie                 NA          NA &lt;NA&gt;    2007\n 5 Adelie                193        3450 female  2007\n 6 Adelie                190        3650 male    2007\n 7 Adelie                181        3625 female  2007\n 8 Adelie                195        4675 male    2007\n 9 Adelie                193        3475 &lt;NA&gt;    2007\n10 Adelie                190        4250 &lt;NA&gt;    2007\n# ℹ 334 more rows\n\n\nIl y a beaucoup de fonctions permettant de sélectionner des variables dont les noms respectent certains critères. Par exemple :\n\nstarts_with(\"abc\") : renvoie toutes les variables dont les noms commencent par “abc”\nends_with(\"xyz\") : renvoie toutes les variables dont les noms se terminent par “xyz”\ncontains(\"ijk\") : renvoie toutes les variables dont les noms contiennent “ijk”\n\nIl en existe beaucoup d’autres. Vous pouvez consulter l’aide de ?select() pour en savoir plus.\nAinsi, il est par exemple possible d’extraire toutes les variables contenant le mot “mm” ainsi :\n\npenguins |&gt;\n  select(contains(\"mm\"))\n\n# A tibble: 344 × 3\n   bill_length_mm bill_depth_mm flipper_length_mm\n            &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;\n 1           39.1          18.7               181\n 2           39.5          17.4               186\n 3           40.3          18                 195\n 4           NA            NA                  NA\n 5           36.7          19.3               193\n 6           39.3          20.6               190\n 7           38.9          17.8               181\n 8           39.2          19.6               195\n 9           34.1          18.1               193\n10           42            20.2               190\n# ℹ 334 more rows\n\n\nÉvidemment, le tableau penguins n’est pas modifié par cette opération : il contient toujours les 8 variables de départ. Pour travailler avec ces tableaux de données contenant moins de variables, il faut les stocker dans un nouvel objet en leur donnant un nom :\n\nmeasures &lt;- penguins |&gt;\n  select(contains(\"mm\"))\n\nEnfin, on peut utiliser select() pour renommer des variables. Mais ce n’est que rarement utile car select() élimine toutes les variables qui n’ont pas été explicitement nommées :\n\npenguins |&gt;\n  select(species:island,\n         b_length = bill_length_mm,\n         flipper = flipper_length_mm)\n\n# A tibble: 344 × 4\n   species island    b_length flipper\n   &lt;fct&gt;   &lt;fct&gt;        &lt;dbl&gt;   &lt;int&gt;\n 1 Adelie  Torgersen     39.1     181\n 2 Adelie  Torgersen     39.5     186\n 3 Adelie  Torgersen     40.3     195\n 4 Adelie  Torgersen     NA        NA\n 5 Adelie  Torgersen     36.7     193\n 6 Adelie  Torgersen     39.3     190\n 7 Adelie  Torgersen     38.9     181\n 8 Adelie  Torgersen     39.2     195\n 9 Adelie  Torgersen     34.1     193\n10 Adelie  Torgersen     42       190\n# ℹ 334 more rows\n\n\nIl est donc généralement préférable d’utiliser rename() pour renommer certaines variables sans en éliminer aucune :\n\npenguins |&gt;\n  rename(b_length = bill_length_mm,\n         flipper = flipper_length_mm)\n\n# A tibble: 344 × 8\n   species island    b_length bill_depth_mm flipper body_mass_g sex     year\n   &lt;fct&gt;   &lt;fct&gt;        &lt;dbl&gt;         &lt;dbl&gt;   &lt;int&gt;       &lt;int&gt; &lt;fct&gt;  &lt;int&gt;\n 1 Adelie  Torgersen     39.1          18.7     181        3750 male    2007\n 2 Adelie  Torgersen     39.5          17.4     186        3800 female  2007\n 3 Adelie  Torgersen     40.3          18       195        3250 female  2007\n 4 Adelie  Torgersen     NA            NA        NA          NA &lt;NA&gt;    2007\n 5 Adelie  Torgersen     36.7          19.3     193        3450 female  2007\n 6 Adelie  Torgersen     39.3          20.6     190        3650 male    2007\n 7 Adelie  Torgersen     38.9          17.8     181        3625 female  2007\n 8 Adelie  Torgersen     39.2          19.6     195        4675 male    2007\n 9 Adelie  Torgersen     34.1          18.1     193        3475 &lt;NA&gt;    2007\n10 Adelie  Torgersen     42            20.2     190        4250 &lt;NA&gt;    2007\n# ℹ 334 more rows"
  },
  {
    "objectID": "05-DataWrangling.html#sec-mutate",
    "href": "05-DataWrangling.html#sec-mutate",
    "title": "5  Manipuler des tableaux avec dplyr",
    "section": "5.6 Créer de nouvelles variables avec mutate()",
    "text": "5.6 Créer de nouvelles variables avec mutate()\n\n5.6.1 Principe\n\n\n\n\n\nFigure 5.4: Schéma de la fonction mutate() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nLa fonction mutate() permet de créer de nouvelles variables à partir des variables existantes, ou de modifier des variables déjà présentes dans un jeu de données. Il est en effet fréquent d’avoir besoin de calculer de nouvelles variables, souvent plus informatives que les variables disponibles.\nVoyons un exemple. À partir de penguins, nous allons calculer une nouvelle variable et en modifier une autre :\n\nratio : le rapport entre la longueur du bec et son épaisseur. Cela nous donnera un indice de la compacité du bec. Des valeurs faibles de ce ratio indiqueront un bec très trapu, alors que des valeurs fortes indiqueront un bec très effilé\nmass_kg : la masse, qui est ici exprimée en grammes sera transformée en kilogrammes par une simple division par 1000\n\n\npenguins |&gt;\n  mutate(ratio = bill_length_mm / bill_depth_mm,\n         mass_kg = body_mass_g / 1000)\n\n# A tibble: 344 × 10\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 4 more variables: sex &lt;fct&gt;, year &lt;int&gt;, ratio &lt;dbl&gt;, mass_kg &lt;dbl&gt;\n\n\nSi on ne souhaite conserver que les variables nouvellement créées par mutate() et éliminer toutes les autres, on peut utiliser transmute() :\n\npenguins |&gt;\n  transmute(ratio = bill_length_mm / bill_depth_mm,\n            mass_kg = body_mass_g / 1000)\n\n# A tibble: 344 × 2\n   ratio mass_kg\n   &lt;dbl&gt;   &lt;dbl&gt;\n 1  2.09    3.75\n 2  2.27    3.8 \n 3  2.24    3.25\n 4 NA      NA   \n 5  1.90    3.45\n 6  1.91    3.65\n 7  2.19    3.62\n 8  2       4.68\n 9  1.88    3.48\n10  2.08    4.25\n# ℹ 334 more rows\n\n\nEt comme toujours, pour pouvoir réutiliser ces données, on leur donne un nom :\n\npengu_ratio &lt;-  penguins |&gt;\n  transmute(ratio = bill_length_mm / bill_depth_mm,\n            mass_kg = body_mass_g / 1000)\n\n\n\n5.6.2 Transformer des variables en facteurs\nIl n’est pas rare que les tableaux de données que nous importons contiennent des colonnes numériques ou de chaînes de caractères qui devraient en réalité être reconnues en tant que facteurs. La fonction mutate() nous permet de changer rapidement le type d’une variable afin qu’elle soit reconnue comme un facteur. Plusieurs variables du tableau dauphin, importé plus tôt, devrait être transformées en facteur :\n\ndauphin\n\n# A tibble: 93 × 9\n   ID        Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n 1 Numéro 1  f     imm       315     3  29.6   3.24 NA    rein  \n 2 Numéro 2  f     imm       357     4  55.1   4.42 NA    rein  \n 3 Numéro 3  f     pnl       439    34 129.    5.01  9.02 rein  \n 4 Numéro 4  f     imm       316     4  71.2   4.33 NA    rein  \n 5 Numéro 5  f     l         435    26 192     5.15 NA    rein  \n 6 Numéro 6  f     pnl       388     6  NA     4.12  4.53 rein  \n 7 Numéro 7  f     mat       410    NA  76     5.1  33.9  foie  \n 8 Numéro 8  m     imm       355    NA  74.4   4.72 13.3  foie  \n 9 Numéro 9  m     imm       222    NA   0.09  9.5   2.89 foie  \n10 Numéro 10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nC’est le cas des variables Sexe, Statut et Organe. Par ailleurs, la variable ID pourrait être supprimée puisqu’elle n’apporte aucune information est est parfaitement redondante avec les numéros de ligne du tableau. Voyons comment réaliser toutes ces actions :\n\ndauphin_clean &lt;- dauphin |&gt; \n  select(-ID) |&gt;                 # Suppression de la colonne ID, puis\n  mutate(Sexe = factor(Sexe),     # Transformation de Sexe en facteur\n         Organe = factor(Organe), # Transformation d'Organe en facteur\n         Statut = factor(Statut,  # Transformation de Statut en facteur\n                         levels = c(\"imm\", \"mat\", \"pnl\", \"pl\", \"l\", \"repos\")))\n\nL’objet dauphin_clean contient les résultats de nos manipulations :\n\ndauphin_clean\n\n# A tibble: 93 × 8\n   Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;fct&gt; &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; \n 1 f     imm       315     3  29.6   3.24 NA    rein  \n 2 f     imm       357     4  55.1   4.42 NA    rein  \n 3 f     pnl       439    34 129.    5.01  9.02 rein  \n 4 f     imm       316     4  71.2   4.33 NA    rein  \n 5 f     l         435    26 192     5.15 NA    rein  \n 6 f     pnl       388     6  NA     4.12  4.53 rein  \n 7 f     mat       410    NA  76     5.1  33.9  foie  \n 8 m     imm       355    NA  74.4   4.72 13.3  foie  \n 9 m     imm       222    NA   0.09  9.5   2.89 foie  \n10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nVous notez que ID a disparu et que les 3 variables modifiées sont maintenant bel et bien des facteurs. Vous avez probablement remarqué également que pour la variable Statut, la syntaxe que j’ai utilisée est légèrement différente de celle des variables Sexe et Organe. Pour en comprendre la raison, tapez ceci pour afficher le contenu de ces facteurs :\n\ndauphin_clean$Sexe\n\n [1] f f f f f f f m m m m f m f m f f m f m f f m m f f m f f f m f f m f f m f\n[39] m f f m f m f m f f m f m m f f f f f f f f f m f f m f f f f f m m m m f m\n[77] f f f m f f f m f m m m m m f f m\nLevels: f m\n\ndauphin_clean$Organe\n\n [1] rein rein rein rein rein rein foie foie foie rein rein rein foie foie foie\n[16] foie foie foie foie foie rein rein rein rein rein rein rein rein rein rein\n[31] rein rein foie foie foie rein rein rein rein rein rein rein rein foie rein\n[46] foie foie rein foie foie foie foie foie rein rein foie foie foie foie foie\n[61] foie rein foie foie rein rein rein foie foie foie foie foie foie foie foie\n[76] rein rein rein rein rein foie foie rein rein foie foie foie foie foie foie\n[91] rein rein rein\nLevels: foie rein\n\ndauphin_clean$Statut\n\n [1] imm   imm   pnl   imm   l     pnl   mat   imm   imm   imm   imm   pnl  \n[13] imm   pl    imm   pnl   imm   imm   pl    imm   pnl   imm   mat   imm  \n[25] pnl   l     imm   l     pnl   repos mat   imm   imm   imm   imm   l    \n[37] imm   imm   imm   pnl   pnl   imm   pl    imm   imm   imm   pnl   pnl  \n[49] imm   pnl   imm   imm   pnl   pnl   pl    imm   pnl   pl    imm   imm  \n[61] pnl   imm   pnl   imm   imm   imm   pl    pnl   l     pl    imm   imm  \n[73] imm   mat   pl    mat   pnl   imm   imm   mat   l     imm   imm   mat  \n[85] imm   imm   imm   mat   imm   imm   pl    l     mat  \nLevels: imm mat pnl pl l repos\n\n\nPour les 2 premiers facteurs, les niveaux des facteurs (ou modalités) sont classés par ordre alphabétique. Ainsi, pour le facteur Sexe, la catégorie f (femelle) apparaît avant m (mâles) dans la liste des niveaux (Levels: ...). Pour le facteur Organe, la modalité foie apparaît avant la modalité rein. L’ordre des modalités d’un facteur est celui qui sera utilisé par défaut pour ordonner les catégories sur les axes d’un graphique ou dans les légendes. L’ordre alphabétique convient parfaitement pour le Sexe ou l’Organe puisqu’il n’y a pas, pour ces facteurs, d’ordre dans les modalités.\n\nlevels(dauphin_clean$Sexe)\n\n[1] \"f\" \"m\"\n\nlevels(dauphin_clean$Organe)\n\n[1] \"foie\" \"rein\"\n\n\nPour le facteur Statut en revanche, l’ordre importe, car il reflète des stades qui se succèdent logiquement au cours de la vie des individus (et des femelles plus particulièrement). Sur un graphique, on souhaite donc que ces catégories apparaissent dans un ordre bien précis, différent de l’ordre alphabétique. C’est la raison pour laquelle, lorsque l’on crée un facteur avec la fonction factor(), on peut spécifier explicitement un ordre pour les catégories grâce à l’argument levels =. Il suffit ensuite de fournir un vecteur contenant le nom de chaque catégorie, dans l’ordre souhaité.\nIl existe de nombreuses façons de ré-ordonner les modalités d’un facteur le long des axes d’un graphique. Voyons un exemple avec la Figure 5.5 :\n\ndauphin_clean |&gt; \n  ggplot(aes(x = Organe, y = Cu, fill = Sexe)) +\n  geom_boxplot(notch = TRUE) +\n  scale_fill_brewer(palette = \"Accent\") +\n  theme_bw()\n\n\n\n\nFigure 5.5: Un exemple de figure avec 2 facteurs et des modalités ordonnées automatiquement par ordre alphabétique\n\n\n\n\nImaginons que je souhaite faire apparaître les concentrations en cuivre dans les reins à gauche, et les concentrations en cuivre dans le foie à droite, et que je souhaite inverser l’ordre des catégories pour les sexes (les mâles avant les femelles). Une première possibilité consiste à modifier l’ordre des catégories de façon explicite lorsque je crée les facteurs Sexe et Organe grâce à l’argument levels de la fonction factor() :\n\ndauphin_clean |&gt; \n  mutate(Sexe = factor(Sexe, levels = c(\"m\", \"f\")),\n         Organe = factor(Organe, levels = c(\"rein\", \"foie\"))) |&gt; \n  ggplot(aes(x = Organe, y = Cu, fill = Sexe)) +\n  geom_boxplot(notch = TRUE) +\n  scale_fill_brewer(palette = \"Accent\") +\n  theme_bw()\n\n\n\n\nFigure 5.6: La même figure mais avec les modalités des 2 facteurs ordonnées manuellement\n\n\n\n\nRemarquez que l’ordre des catégories a changé sur l’axe des abscisses, mais que les couleurs de remplissage ne sont plus associées aux mêmes sexes non plus.\nUne autre solution est de faire appel au package forcats (c’est un anagramme de factors) qui est automatiquement chargé en mémoire avec le tidyverse. Ce package contient de nombreuses fonctions permettant de manipuler les facteurs, et toutes commencent par fct_. Par exemple, pour inverser l’ordre des catégories d’un facteur (et donc pour arriver au même résultat que précédemment), on peut utiliser fct_rev() :\n\ndauphin_clean |&gt; \n  ggplot(aes(x = fct_rev(Organe), y = Cu, fill = fct_rev(Sexe))) +\n  geom_boxplot(notch = TRUE) +\n  scale_fill_brewer(palette = \"Accent\") +\n  theme_bw()\n\n\n\n\nFigure 5.7: La même figure mais avec les modalités des 2 facteurs inversées avec fct_rev()\n\n\n\n\nIl conviendrait ici de changer les légendes de l’axe des x et de l’échelle de couleurs avec la fonction labs() (voir Section 3.11.1).\nIl existe de nombreuses autres fonctions très utiles dans le package forcats. L’une d’entre elles est la fonction fct_recode(), qui permet de changer le nom des modalités d’un facteur. Par exemple :\n\ndauphin |&gt; \n  mutate(Sexe = fct_recode(Sexe, \n                           \"Femelle\" = \"f\",\n                           \"Mâle\" = \"m\"))\n\n# A tibble: 93 × 9\n   ID        Sexe    Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;chr&gt;     &lt;fct&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n 1 Numéro 1  Femelle imm       315     3  29.6   3.24 NA    rein  \n 2 Numéro 2  Femelle imm       357     4  55.1   4.42 NA    rein  \n 3 Numéro 3  Femelle pnl       439    34 129.    5.01  9.02 rein  \n 4 Numéro 4  Femelle imm       316     4  71.2   4.33 NA    rein  \n 5 Numéro 5  Femelle l         435    26 192     5.15 NA    rein  \n 6 Numéro 6  Femelle pnl       388     6  NA     4.12  4.53 rein  \n 7 Numéro 7  Femelle mat       410    NA  76     5.1  33.9  foie  \n 8 Numéro 8  Mâle    imm       355    NA  74.4   4.72 13.3  foie  \n 9 Numéro 9  Mâle    imm       222    NA   0.09  9.5   2.89 foie  \n10 Numéro 10 Mâle    imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nCela permet de transformer la catégorie f en Femelle et la catégorie m en Mâle, et ainsi de rendre plus clair la signification des catégories sur un graphique :\n\ndauphin |&gt; \n  mutate(Sexe = fct_recode(Sexe, \n                           \"Femelle\" = \"f\",\n                           \"Mâle\" = \"m\")) |&gt; \n  ggplot(aes(x = fct_rev(Organe), y = Cu, fill = fct_rev(Sexe))) +\n  geom_boxplot(notch = TRUE) +\n  scale_fill_brewer(palette = \"Accent\") +\n  labs(x = \"Organe\", fill = \"Sexe\", y = \"Concentration en cuivre (µg/g de poids sec)\") +\n  theme_bw()\n\n\n\n\nFigure 5.8: La même figure mais avec les modalités plus claires pour le facteur Sexe\n\n\n\n\nEnfin, il existe une autre façon de procéder lorsque toutes les variables &lt;chr&gt; d’un tableau doivent être transformées en facteur. mutate_if() permet en effet d’appliquer la même fonction à toutes les variables respectant une condition précise. Ici, toutes les colonnes possédant le type &lt;chr&gt; seront transformées en facteur. Nous pouvons donc taper ceci :\n\ndauphin |&gt; \n  mutate_if(is.character, as.factor)\n\n# A tibble: 93 × 9\n   ID        Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; \n 1 Numéro 1  f     imm       315     3  29.6   3.24 NA    rein  \n 2 Numéro 2  f     imm       357     4  55.1   4.42 NA    rein  \n 3 Numéro 3  f     pnl       439    34 129.    5.01  9.02 rein  \n 4 Numéro 4  f     imm       316     4  71.2   4.33 NA    rein  \n 5 Numéro 5  f     l         435    26 192     5.15 NA    rein  \n 6 Numéro 6  f     pnl       388     6  NA     4.12  4.53 rein  \n 7 Numéro 7  f     mat       410    NA  76     5.1  33.9  foie  \n 8 Numéro 8  m     imm       355    NA  74.4   4.72 13.3  foie  \n 9 Numéro 9  m     imm       222    NA   0.09  9.5   2.89 foie  \n10 Numéro 10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nUn inconvénient de cette fonction est qu’il est impossible de changer manuellement l’ordre des catégories d’un facteur en même temps. On est alors obligé de procéder en deux temps :\n\ndauphin_clean &lt;- dauphin |&gt; \n  select(-ID) |&gt;                            # Suppression de la colonne ID, puis\n  mutate_if(is.character, as.factor) |&gt;     # Transformation en facteur de toutes les variables &lt;chr&gt;, puis\n  mutate(Sexe = fct_recode(Sexe,            # Changement des modalités du facteur Sexe, puis\n                           \"Femelle\" = \"f\",\n                           \"Mâle\" = \"m\"),\n         Organe = fct_rev(Organe),          # Inversion des modalités du facteur Organe\n         Statut = fct_relevel(Statut,       # Ré-agencement de l'ordre des modalités du facteur Statut\n                              \"imm\", \"mat\", \"pnl\", \"l\", \"pl\", \"repos\"))\n\nDans le code ci-dessus, la fonction fct_relevel() joue le même rôle que factor(..., levels = c(...)).\nAu final, toutes les transformations que nous avons fait subir à ce jeu de données n’ont qu’un seul objectif : “ranger” ce jeu de données. Nous avons importé dauphin depuis un fichier externe, puis nous avons supprimé les variables inutiles et modifié celles qui devaient l’être. Toutes ces étapes peuvent être enchaînées grâce au pipe, de la façon suivante :\n\n# Importation et mise en forme du jeu de données `dauphin`\nlibrary(readxl)\ndauphin &lt;- read_excel(\"data/dauphin.xls\", \n                      na = \"*\", skip = 9) |&gt;   # Importer, puis\n  rename(ID = `N°`,                 # Raccourcir les noms, puis\n         Statut = `Statut reproducteur`,\n         Taille = `Taille en cm`,\n         Age = `Age en années`,\n         Cd = `Cd (mg.kg-1)`,\n         Cu = `Cu (mg.kg-1)`,\n         Hg = `Hg (mg.kg-1)`) |&gt; \n  select(-ID) |&gt;                   # Supprimer la variable `ID`, puis\n  mutate_if(is.character,           # 'Factoriser' les variables &lt;chr&gt;, puis\n            as.factor) |&gt;          \n  mutate(Sexe = fct_recode(Sexe,    # Modifier les modalités des facteurs\n                           \"Female\" = \"f\",\n                           \"Male\" = \"m\"),\n         Organe = fct_rev(Organe), \n         Statut = fct_relevel(Statut,\n                              \"imm\", \"mat\", \"pnl\", \"l\", \"pl\", \"repos\"))\n\ndauphin\n\n# A tibble: 93 × 8\n   Sexe   Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;fct&gt;  &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; \n 1 Female imm       315     3  29.6   3.24 NA    rein  \n 2 Female imm       357     4  55.1   4.42 NA    rein  \n 3 Female pnl       439    34 129.    5.01  9.02 rein  \n 4 Female imm       316     4  71.2   4.33 NA    rein  \n 5 Female l         435    26 192     5.15 NA    rein  \n 6 Female pnl       388     6  NA     4.12  4.53 rein  \n 7 Female mat       410    NA  76     5.1  33.9  foie  \n 8 Male   imm       355    NA  74.4   4.72 13.3  foie  \n 9 Male   imm       222    NA   0.09  9.5   2.89 foie  \n10 Male   imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nÉvidemment, je ne vous demande pas d’être capable de produire un code tel que celui-ci du premier coup. D’ailleurs, ça n’est jamais comme ça qu’on construit ce type de bloc d’instructions. On procède étape par étape, et quand la première étape fonctionne, alors on passe à la suivante en ajoutant un pipe. Mais on s’assure bien que chaque étape fonctionne avant de passer à la suivante.\nOutre les fonctions fct_rev(), fct_recode() et fct_relevel() abordées ici, on peut aussi noter :\n\nfct_reorder() et fct_reorder2(), pour ordonner automatiquement les niveaux d’un facteur en fonction d’une autre variable numérique (pour avoir par exemple des séries rangées par ordre de moyennes croissantes sur un graphique).\nfct_infreq(), pour ordonner automatiquement les niveaux d’un facteur par ordre de fréquence croissante, ce qui est notamment utile pour faire des diagrammes bâtons ordonnés.\nfct_collapse(), pour fusionner deux ou plusieurs niveaux d’un facteur.\n\nNous n’avons pas le temps de développer ici des exemples pour chacune de ces fonctions, mais sachez que ces fonctions existent. Vous trouverez des exemples détaillés dans le chapitre consacré aux facteurs de l’ouvrage en ligne R for Data Science. C’est en anglais, mais les exemples sont très parlants. N’hésitez pas à consulter cet ouvrage et à faire des essais de mise en application avec les jeux de données vus ici (e.g. dauphin ou squid).\n\n\n5.6.3 Exercices\n\nDans ggplot2 le jeu de données mpg contient des informations sur 234 modèles de voitures. Examinez ce jeu de données avec la fonction View() et consultez l’aide pour savoir à quoi correspondent les différentes variables. Quelle(s) variable(s) nous renseignent sur la consommation des véhicules ? À quoi correspond la variable disp ?\nLa consommation sur autoroute est donnée en miles par gallon. Créez une nouvelle variable conso qui contiendra la consommation sur autoroute exprimée en nombre de litres pour 100 kilomètres.\nFaites un graphique présentant la relation entre la cylindrée en litres et la consommation sur autoroute exprimée en nombre de litres pour 100 kilomètres. Vous exclurez de ce graphique les véhicules dont la classe est 2seater (il s’agit de voitures de sports très compactes qu’il est difficile de mesurer aux autres). Sur votre graphique, la couleur devrait représenter le type de véhicule. Vous ajouterez une droite de régression en utilisant geom_smooth(method = \"lm\"). Votre graphique devrait ressembler à ceci :\n\n\n\n\n\n\nFigure 5.9: Consommation en fonction de la cylindrée\n\n\n\n\n\nCe graphique présente-t-il correctement l’ensemble des données de ces 2 variables ? Pourquoi ? Comparez la Figure 5.9 de la question 3 ci-dessus et la Figure 5.10 présentée ci-dessous. Selon vous, quels arguments et/ou fonctions ont été modifiés pour arriver à ce nouveau graphique ? Quels sont les avantages et les inconvénients de ce graphique par rapport au précédent ?\n\n\n\n\n\n\nFigure 5.10: Consommation en fonction de la cylindrée"
  },
  {
    "objectID": "05-DataWrangling.html#sec-arrange",
    "href": "05-DataWrangling.html#sec-arrange",
    "title": "5  Manipuler des tableaux avec dplyr",
    "section": "5.7 Trier des lignes avec arrange()",
    "text": "5.7 Trier des lignes avec arrange()\n\n\n\n\n\nFigure 5.11: Schéma de la fonction arrange() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nLa fonction arrange() permet de trier des tableaux en ordonnant les éléments d’une ou plusieurs colonnes. Les tris peuvent être en ordre croissants (c’est le cas par défaut) ou décroissants (grâce à la fonction desc(), abréviation de “descending”).\narrange() fonctionne donc comme filter(), mais au lieu de sélectionner des lignes, cette fonction change leur ordre. Il faut lui fournir le nom d’un tableau et au minimum le nom d’une variable selon laquelle le tri doit être réalisé. Si plusieurs variables sont fournies, chaque variable supplémentaire permet de résoudre les égalités. Ainsi, pour ordonner le tableau penguins par ordre croissant d’épaisseur de bec (bill_depth_mm), on tape :\n\npenguins |&gt;\n  arrange(bill_depth_mm)\n\n# A tibble: 344 × 8\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Gentoo  Biscoe           42.9          13.1               215        5000\n 2 Gentoo  Biscoe           46.1          13.2               211        4500\n 3 Gentoo  Biscoe           44.9          13.3               213        5100\n 4 Gentoo  Biscoe           43.3          13.4               209        4400\n 5 Gentoo  Biscoe           46.5          13.5               210        4550\n 6 Gentoo  Biscoe           42            13.5               210        4150\n 7 Gentoo  Biscoe           44            13.6               208        4350\n 8 Gentoo  Biscoe           40.9          13.7               214        4650\n 9 Gentoo  Biscoe           45.5          13.7               214        4650\n10 Gentoo  Biscoe           42.6          13.7               213        4950\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nNotez que la variable dbill_depth_mm est maintenant triée en ordre croissant. Notez également que 2 individus ont un bec dont l’épaisseur vaut exactement 13,5 mm. Comparez le tableau précédent avec celui-ci :\n\npenguins |&gt;\n  arrange(bill_depth_mm, bill_length_mm)\n\n# A tibble: 344 × 8\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Gentoo  Biscoe           42.9          13.1               215        5000\n 2 Gentoo  Biscoe           46.1          13.2               211        4500\n 3 Gentoo  Biscoe           44.9          13.3               213        5100\n 4 Gentoo  Biscoe           43.3          13.4               209        4400\n 5 Gentoo  Biscoe           42            13.5               210        4150\n 6 Gentoo  Biscoe           46.5          13.5               210        4550\n 7 Gentoo  Biscoe           44            13.6               208        4350\n 8 Gentoo  Biscoe           40.9          13.7               214        4650\n 9 Gentoo  Biscoe           42.6          13.7               213        4950\n10 Gentoo  Biscoe           42.7          13.7               208        3950\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nLes lignes des 2 individus dont l’épaisseur du bec vaut 13,5 mm ont été inversées : la variable bill_length_mm a été utilisée pour ordonner les lignes en cas d’égalité de la variable bill_depth_mm.\nComme indiqué plus haut, il est possible de trier les données par ordre décroissant :\n\npenguins |&gt;\n  arrange(desc(bill_depth_mm))\n\n# A tibble: 344 × 8\n   species   island   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;     &lt;fct&gt;             &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie    Torgers…           46            21.5               194        4200\n 2 Adelie    Torgers…           38.6          21.2               191        3800\n 3 Adelie    Dream              42.3          21.2               191        4150\n 4 Adelie    Torgers…           34.6          21.1               198        4400\n 5 Adelie    Dream              39.2          21.1               196        4150\n 6 Adelie    Biscoe             41.3          21.1               195        4400\n 7 Chinstrap Dream              54.2          20.8               201        4300\n 8 Adelie    Torgers…           42.5          20.7               197        4500\n 9 Adelie    Biscoe             39.6          20.7               191        3900\n10 Chinstrap Dream              52            20.7               210        4800\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nCela est particulièrement utile après l’obtention de résumés groupés (obtenus avec la fonction count()) pour connaître la catégorie la plus représentée. Par exemple, si nous souhaitons connaître l’espèce et le sexe les plus fréquemment observés, on peut procéder ainsi :\n\nprendre le tableau penguins, puis,\ncompter le nombre d’observation par espèce et sexe avec la fonction count, puis,\ntrier les données par effectif décroissant.\n\n\npenguins |&gt;\n  count(species, sex) |&gt;\n  arrange(desc(n))\n\n# A tibble: 8 × 3\n  species   sex        n\n  &lt;fct&gt;     &lt;fct&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Gentoo    male      61\n4 Gentoo    female    58\n5 Chinstrap female    34\n6 Chinstrap male      34\n7 Adelie    &lt;NA&gt;       6\n8 Gentoo    &lt;NA&gt;       5\n\n\nDeux catégories sont aussi fréquemment observées l’une que l’autre : les mâles et femelles de l’espèce Adélie, pour lesquels 73 individus ont été observés."
  },
  {
    "objectID": "05-DataWrangling.html#sec-summarise",
    "href": "05-DataWrangling.html#sec-summarise",
    "title": "5  Manipuler des tableaux avec dplyr",
    "section": "5.8 Créer des résumés avec summarise()",
    "text": "5.8 Créer des résumés avec summarise()\nDans cette partie, nous allons en réalité traiter un peu plus que de la simple fonction summarise(). Nous aborderons :\n\nsummarise() : pour créer des résumés de données simples à partir des colonnes d’un tableau\ncount() : pour compter le nombre d’observations pour chaque niveau d’un facteur (ou modalité d’une variable catégorielle)\ngroup_by() : pour effectuer des opérations pour chaque niveau d’un facteur (ou modalité d’une variable catégorielle). Cette dernière fonction a été rendue presque obsolète par une mise à jour récente du package dplyr qui introduit un nouvel argument pour plusieurs fonctions, dont summarise() (mais aussi mutate(), filter() et quelques autres) : l’argument .by. Un peu comme group-by(), ce nouvel argument permet d’effectuer des opérations pour chaque niveau d’un facteur (ou modalité d’une variable catégorielle). À notre niveau, les différences entre la fonction group_by() et l’argument .by ne sont pas importantes. Nous utiliserons donc de préférence la notation la plus simple, celle de l’argument .by.\n\nLa fonction reframe() est très proche de la fonction summarise() car elle permet de créer des résumés de données plus élaborés à partir des colonnes d’un tableau. Nous verrons comment l’utiliser dans le chapitre dédié aux statistiques descriptives (?sec-statdesc).\n\n\n\n\n\n\nLien avec les statistiques descriptives\n\n\n\nCette section est importante car elle permet de faire un premier lien avec les statistiques. La plupart des fonctions décrites ici servent en effet à produire des résumés statistiques pour des variables de tous types, ou pour des modalités spécifiques de facteurs d’intérêt.\n\n\n\n5.8.1 Principe de la fonction summarise()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5.12: Schéma de la fonction summarise() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nLa Figure 6.1 ci-dessus indique comment travaille la fonction summarise() : elle prend plusieurs valeurs (potentiellement, un très grand nombre) et les réduit à une unique valeur qui les résume. La valeur qui résume les données est choisie par l’utilisateur. Il peut s’agir par exemple d’un calcul de moyenne, de quartile ou de variance, il peut s’agir de calculer une somme, ou d’extraire la valeur maximale ou minimale, ou encore, il peut tout simplement s’agir de déterminer un nombre d’observations. Mais le fonctionnement est toujours le même : la fonction summarise() ne renvoie qu’une unique valeur pour une variable donnée (ou pour chaque modalité d’une variable catégorielle).\nAinsi, pour connaître la moyenne de la longueur du bec des manchots de l’île de Palmer, il suffit d’utiliser le tableau penguins du package palmerpenguins et sa variable bill_length_mm que nous avons déjà utilisée au semestre 3 :\n\npenguins |&gt;\n  summarise(moyenne = mean(bill_length_mm))\n\n# A tibble: 1 × 1\n  moyenne\n    &lt;dbl&gt;\n1      NA\n\n\nLa fonction mean() permet de calculer une moyenne. Ici, la valeur retournée est NA car 2 individus n’ont pas été mesurés, et le tableau contient donc des valeurs manquantes :\n\npenguins |&gt;\n  filter(is.na(bill_length_mm))\n\n# A tibble: 2 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen             NA            NA                NA          NA\n2 Gentoo  Biscoe                NA            NA                NA          NA\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nPour obtenir la valeur souhaitée, il faut indiquer à R d’exclure les valeurs manquantes lors du calcul de moyenne :\n\npenguins |&gt;\n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  moyenne\n    &lt;dbl&gt;\n1    43.9\n\n\nLa longueur moyenne du bec des manchots (toutes espèces confondues) est donc de 43.9 millimètres.\nDe la même façon, on peut demander plusieurs calculs d’indices à la fois, par exemple la moyenne et l’écart-type (avec la fonction sd()) de la longueur des becs :\n\npenguins |&gt;\n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            ecart_type = sd(bill_length_mm, na.rm = TRUE))\n\n# A tibble: 1 × 2\n  moyenne ecart_type\n    &lt;dbl&gt;      &lt;dbl&gt;\n1    43.9       5.46\n\n\nIci, l’écart-type vaut 5.5 millimètres.\nLa fonction summarise() permet donc de calculer des indices statistiques variés, et permet aussi d’accéder à plusieurs variables à la fois. Par exemple. pour calculer les moyennes, médianes, minima et maxima des longueurs de nageoires et de masses corporelles, on peut procéder ainsi :\n\npenguins |&gt; \n  summarise(moy_flip = mean(flipper_length_mm, na.rm = TRUE),\n            med_flip = median(flipper_length_mm, na.rm = TRUE),\n            min_flip = min(flipper_length_mm, na.rm = TRUE),\n            max_flip = max(flipper_length_mm, na.rm = TRUE),\n            moy_mass = mean(body_mass_g, na.rm = TRUE),\n            med_mass = median(body_mass_g, na.rm = TRUE),\n            min_mass = min(body_mass_g, na.rm = TRUE),\n            max_mass = max(body_mass_g, na.rm = TRUE))\n\n# A tibble: 1 × 8\n  moy_flip med_flip min_flip max_flip moy_mass med_mass min_mass max_mass\n     &lt;dbl&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;\n1     201.      197      172      231    4202.     4050     2700     6300\n\n\nLa fonction summarise() est donc très utile pour produire des résumés informatifs des données, mais nos exemples ne sont ici pas très pertinents puisque nous avons jusqu’ici calculé des indices sans distinguer les espèces. Si les 3 espèces de manchots ont des caractéristiques très différentes, calculer des moyennes toutes espèces confondues n’a pas de sens. Voyons maintenant comment obtenir ces même indices pour chaque espèce.\n\n\n5.8.2 Intérêt de l’argument .by\nLa fonction summarise() devient particulièrement puissante lorsqu’on y ajoute l’argument .by :\n\n\n\n\n\nFigure 5.13: Fonctionnement de l’argument .by travaillant de concert avec summarise(), tiré de la ‘cheatsheet’ de dplyr et tidyr\n\n\n\n\nComme son nom l’indique, l’argument .by permet de créer des sous-groupes dans un tableau, afin que le résumé des données soit calculé pour chacun des sous-groupes plutôt que sur l’ensemble du tableau. En ce sens, son fonctionnement est analogue à celui des facets de ggplot2 qui permettent de scinder les données d’un graphique en plusieurs sous-groupes.\nPour revenir à l’exemple de la longueur du bec des manchots, imaginons que nous souhaitions calculer les moyennes et les écart-types pour chacune des trois espèces. Voilà comment procéder :\n\npenguins |&gt;\n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            ecart_type = sd(bill_length_mm, na.rm = TRUE),\n            .by = species)\n\n# A tibble: 3 × 3\n  species   moyenne ecart_type\n  &lt;fct&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 Adelie       38.8       2.66\n2 Gentoo       47.5       3.08\n3 Chinstrap    48.8       3.34\n\n\nIci, les étapes sont les suivantes :\n\nOn prend le tableau penguins, puis\nOn résume les données sous la forme de moyennes et d’écart-types\nOn demande un calcul pour chaque modalité de la variable species\n\nLà où nous avions auparavant une seule valeur de moyenne et d’écart-type pour l’ensemble des individus du tableau de données, nous avons maintenant une valeur de moyenne et d’écart-type pour chaque modalité de la variable espèce. Puisque le facteur species contient 3 modalités (Adelie, Chinstrap et Gentoo), le résumé des données contient maintenant 3 lignes.\nCette syntaxe très simple est presque équivalente à celle de la fonction group_by() :\n\npenguins |&gt;\n  group_by(species) |&gt; \n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            ecart_type = sd(bill_length_mm, na.rm = TRUE))\n\n# A tibble: 3 × 3\n  species   moyenne ecart_type\n  &lt;fct&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 Adelie       38.8       2.66\n2 Chinstrap    48.8       3.34\n3 Gentoo       47.5       3.08\n\n\nLes valeurs obtenues sont les mêmes, mais d’une part, les commandes sont fournies avec une syntaxe et dans un ordre différents :\n\nOn prend le tableau penguins, puis\nOn groupe les données par espèce, puis\nOn résume les données sous la forme de moyennes et d’écart-types\n\nEt l’objet obtenu au final n’est pas strictement identique : avec la fonction group_by(), et dans certaines situations, le tibble obtenu conserve l’information du regroupement effectué, ce qui peut être utile dans certaines situations, mais peut parfois poser problème et causer l’affichage de messages d’avertissements dans la console. Ce comportement n’est pas observé avec l’argument .by qui ne groupe les données qu’au moment du calcul des indices dans la fonction summarise() et n’en conserve pas la trace ensuite. C’est la raison pour laquelle nous privilégierons cette méthode.\nPour aller plus loin, ajoutons à ce résumé 2 variables supplémentaires : le nombre de mesures et l’erreur standard (notée \\(se\\)), qui peut être calculée de la façon suivante :\n\\[se \\approx \\frac{s}{\\sqrt{n}}\\]\navec \\(s\\), l’écart-type de l’échantillon et \\(n\\), la taille de l’échantillon (plus d’informations sur cette statistique très importante dans la Chapitre 7). Nous allons donc calculer ici ces résumés, et nous donnerons un nom au tableau créé pour pouvoir ré-utiliser ces statistiques descriptives :\n\nstats_esp &lt;- penguins |&gt;\n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            ecart_type = sd(bill_length_mm, na.rm = TRUE),\n            nb_obs = n(),\n            erreur_std = ecart_type / sqrt(nb_obs),\n            .by = species)\n\nstats_esp\n\n# A tibble: 3 × 5\n  species   moyenne ecart_type nb_obs erreur_std\n  &lt;fct&gt;       &lt;dbl&gt;      &lt;dbl&gt;  &lt;int&gt;      &lt;dbl&gt;\n1 Adelie       38.8       2.66    152      0.216\n2 Gentoo       47.5       3.08    124      0.277\n3 Chinstrap    48.8       3.34     68      0.405\n\n\nVous constatez ici que nous avons 4 statistiques descriptives pour chaque espèce. Deux choses sont importantes à retenir ici :\n\non peut obtenir le nombre d’observations dans chaque sous-groupe d’un tableau groupé en utilisant la fonction n(). Cette fonction n’a besoin d’aucun argument : elle détermine automatiquement la taille des groupes créés par .by (ou par la fonction group_by()).\non peut créer de nouvelles variables en utilisant le nom de variables créées auparavant. Ainsi, nous avons créé la variable erreur_std en utilisant deux variables créées au préalable : ecart-type et nb_obs\n\n\n\n5.8.3 Grouper par plus d’une variable\nJusqu’ici, nous avons groupé les données par espèce. Il est tout à fait possible de grouper les données par plus d’une variable, par exemple, par espèce et par sexe :\n\nstats_esp_sex &lt;- penguins |&gt;\n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            ecart_type = sd(bill_length_mm, na.rm = TRUE),\n            nb_obs = n(),\n            erreur_std = ecart_type / sqrt(nb_obs),\n            .by = c(species, sex))\n\nstats_esp_sex\n\n# A tibble: 8 × 6\n  species   sex    moyenne ecart_type nb_obs erreur_std\n  &lt;fct&gt;     &lt;fct&gt;    &lt;dbl&gt;      &lt;dbl&gt;  &lt;int&gt;      &lt;dbl&gt;\n1 Adelie    male      40.4       2.28     73      0.267\n2 Adelie    female    37.3       2.03     73      0.237\n3 Adelie    &lt;NA&gt;      37.8       2.80      6      1.14 \n4 Gentoo    female    45.6       2.05     58      0.269\n5 Gentoo    male      49.5       2.72     61      0.348\n6 Gentoo    &lt;NA&gt;      45.6       1.37      5      0.615\n7 Chinstrap female    46.6       3.11     34      0.533\n8 Chinstrap male      51.1       1.56     34      0.268\n\n\nEn plus de la variable species, la tableau stats_esp_sex contient une variable sex. Les statistiques que nous avons calculées plus tôt sont maintenant disponibles pour chaque espèce et chaque sexe. D’ailleurs, puisque le sexe de certains individus est inconnu, nous avons également des lignes pour lesquelles le sexe affiché est NA. Pour les éliminer, il suffit de retirer les lignes du tableau pour lesquelles le sexe des individus est inconnu avant de recalculer les mêmes indices :\n\nstats_esp_sex2 &lt;- penguins |&gt;\n  filter(!is.na(sex)) |&gt; \n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            ecart_type = sd(bill_length_mm, na.rm = TRUE),\n            nb_obs = n(),\n            erreur_std = ecart_type / sqrt(nb_obs),\n            .by = c(species, sex))\n\nstats_esp_sex2\n\n# A tibble: 6 × 6\n  species   sex    moyenne ecart_type nb_obs erreur_std\n  &lt;fct&gt;     &lt;fct&gt;    &lt;dbl&gt;      &lt;dbl&gt;  &lt;int&gt;      &lt;dbl&gt;\n1 Adelie    male      40.4       2.28     73      0.267\n2 Adelie    female    37.3       2.03     73      0.237\n3 Gentoo    female    45.6       2.05     58      0.269\n4 Gentoo    male      49.5       2.72     61      0.348\n5 Chinstrap female    46.6       3.11     34      0.533\n6 Chinstrap male      51.1       1.56     34      0.268\n\n\nSi vous ne comprenez pas la commande filter(!is.na(sex)), je vous encourage vivement à relire la Section 5.4.\nEnfin, lorsque nous groupons par plusieurs variables, il peut être utile de présenter les résultats sous la forme d’un tableau large (grâce à la fonction pivot_wider()) pour l’intégration dans un rapport par exemple (voir la Section 4.3.2). La fonction pivot_wider() permet de passer d’un tableau qui possède ce format :\n\npenguins |&gt;\n  filter(!is.na(sex)) |&gt; \n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            .by = c(species, sex))\n\n# A tibble: 6 × 3\n  species   sex    moyenne\n  &lt;fct&gt;     &lt;fct&gt;    &lt;dbl&gt;\n1 Adelie    male      40.4\n2 Adelie    female    37.3\n3 Gentoo    female    45.6\n4 Gentoo    male      49.5\n5 Chinstrap female    46.6\n6 Chinstrap male      51.1\n\n\nà un tableau sous ce format :\n\npenguins |&gt;\n  filter(!is.na(sex)) |&gt; \n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            .by = c(species, sex)) |&gt; \n  pivot_wider(names_from = sex,\n              values_from = moyenne)\n\n# A tibble: 3 × 3\n  species    male female\n  &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 Adelie     40.4   37.3\n2 Gentoo     49.5   45.6\n3 Chinstrap  51.1   46.6\n\n\nSous cette forme, les données ne sont plus “rangées”, c’est à dire que nous n’avons plus une observation par ligne et une variable par colonne. En effet ici, la variable sex est maintenant “étalée” dans 2 colonnes distinctes : chaque modalité du facteur de départ (female et male) est utilisée en tant que titre de nouvelles colonnes, et la variable moyenne est répartie dans deux colonnes. Ce format de tableau n’est pas idéal pour les statistiques ou les représentations graphiques, mais il est plus synthétique, et donc plus facile à inclure dans un rapport ou un compte-rendu.\n\n\n5.8.4 Un raccourci pratique pour compter des effectifs\nIl est extrêmement fréquent d’avoir à grouper des données en fonction d’une variable catégorielle puis d’avoir à compter le nombre d’observations de chaque modalité avec n() :\n\npenguins |&gt; \n  summarise(effectif = n(), \n            .by = species)\n\n# A tibble: 3 × 2\n  species   effectif\n  &lt;fct&gt;        &lt;int&gt;\n1 Adelie         152\n2 Gentoo         124\n3 Chinstrap       68\n\n\nou encore :\n\npenguins |&gt; \n  group_by(species) |&gt; \n  summarise(effectif = n())\n\n# A tibble: 3 × 2\n  species   effectif\n  &lt;fct&gt;        &lt;int&gt;\n1 Adelie         152\n2 Chinstrap       68\n3 Gentoo         124\n\n\nCes deux opérations sont tellement fréquentes (regrouper puis compter) que le package dplyr nous fournit un raccourci : la fonction count().\nLe code ci-dessus est équivalent à celui-ci :\n\npenguins |&gt; \n  count(species)\n\n# A tibble: 3 × 2\n  species       n\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\nNotez qu’avec la fonction count(), la colonne qui contient les comptages s’appelle toujours n par défaut. Comme avec .by et group_by(), il est bien sûr possible d’utiliser count() avec plusieurs variables :\n\npenguins |&gt; \n  count(species, sex)\n\n# A tibble: 8 × 3\n  species   sex        n\n  &lt;fct&gt;     &lt;fct&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    &lt;NA&gt;       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    &lt;NA&gt;       5\n\n\n\npenguins |&gt; \n  filter(!is.na(sex)) |&gt; \n  count(species, sex)\n\n# A tibble: 6 × 3\n  species   sex        n\n  &lt;fct&gt;     &lt;fct&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Chinstrap female    34\n4 Chinstrap male      34\n5 Gentoo    female    58\n6 Gentoo    male      61\n\n\nEt il est évidemment possible de présenter le résultats sous un format de tableau large :\n\npenguins |&gt; \n  filter(!is.na(sex)) |&gt; \n  count(species, sex) |&gt; \n  pivot_wider(names_from = sex,\n              values_from = n)\n\n# A tibble: 3 × 3\n  species   female  male\n  &lt;fct&gt;      &lt;int&gt; &lt;int&gt;\n1 Adelie        73    73\n2 Chinstrap     34    34\n3 Gentoo        58    61\n\n\nVous connaissez maintenant plusieurs méthodes pour calculer à la main des statistiques descriptives pour des variables entières, ou pour des sous-groupes de lignes (par espèce, par sexe, par sexe et par espèce…). Globalement, toutes les fonctions de R qui prennent une série de chiffres en guise d’argument, et qui renvoient une valeur unique, peuvent être utilisées avec la fonction summarise(). En particulier, vous pouvez utiliser les fonctions suivantes pour faire des analyses exploratoires :\n\nmean() : calcul de la moyenne\nmedian() : calcul de la médiane\nmin() : affichage de la valeur minimale\nmax() : affichage de la valeur minimale\nn_distinct() : calcul du nombre de valeurs différentes\nn() : calcul du nombre d’observations\nvar() : calcul de la variance\nsd() : calcul de l’écart-type\nIQR() : calcul de l’intervalle inter-quartiles\n\nEt la liste n’est bien sûr pas exhaustive\n\n\n5.8.5 Exercices\n\nAvec le tableau diamonds du package ggplot2, faites un tableau indiquant combien de diamants de chaque couleur on dispose. Vous devriez obtenir le tableau suivant :\n\n\n\n# A tibble: 7 × 2\n  color     n\n  &lt;ord&gt; &lt;int&gt;\n1 D      6775\n2 E      9797\n3 F      9542\n4 G     11292\n5 H      8304\n6 I      5422\n7 J      2808\n\n\n\nExaminez le tableau weather du package nycflights13 et lisez son fichier d’aide pour comprendre à quoi correspondent les données et comment elles ont été acquises.\nÀ partir du tableau weather faites un tableau indiquant les vitesses de vents minimales, maximales et moyennes, enregistrées chaque mois dans chaque aéroport de New York. Indice : les 3 aéroports de New York sont Newark, LaGuardia Airport et John F. Kennedy, notés respectivement EWR, LGA et JFK dans la variable origin. Votre tableau devrait ressembler à ceci :\n\n\n\n# A tibble: 36 × 5\n   origin month max_wind min_wind moy_wind\n   &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 EWR        1     42.6        0     9.87\n 2 EWR        2   1048.         0    12.2 \n 3 EWR        3     29.9        0    11.6 \n 4 EWR        4     25.3        0     9.63\n 5 EWR        5     33.4        0     8.49\n 6 EWR        6     34.5        0     9.55\n 7 EWR        7     20.7        0     9.15\n 8 EWR        8     21.9        0     7.62\n 9 EWR        9     23.0        0     8.03\n10 EWR       10     26.5        0     8.32\n# ℹ 26 more rows\n\n\n\nSachant que les vitesses du vent sont exprimées en miles par heure, certaines valeurs sont-elles surprenantes ? À l’aide de la fonction filter(), éliminez la ou les valeurs aberrantes. Vous devriez obtenir ce tableau :\n\n\n\n# A tibble: 36 × 5\n   origin month max_wind min_wind moy_wind\n   &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 EWR        1     42.6        0     9.87\n 2 EWR        2     31.1        0    10.7 \n 3 EWR        3     29.9        0    11.6 \n 4 EWR        4     25.3        0     9.63\n 5 EWR        5     33.4        0     8.49\n 6 EWR        6     34.5        0     9.55\n 7 EWR        7     20.7        0     9.15\n 8 EWR        8     21.9        0     7.62\n 9 EWR        9     23.0        0     8.03\n10 EWR       10     26.5        0     8.32\n# ℹ 26 more rows\n\n\n\nEn utilisant les données de vitesse de vent du tableau weather, produisez le graphique suivant :\n\n\n\n\n\n\nIndications :\n\nles vitesses de vent aberrantes ont été éliminées grâce à la fonction filter()\nla fonction geom_jitter() a été utilisée avec l’argument height = 0\nla transparence des points est fixée à 0.2\n\n\nÀ votre avis :\n\n\npourquoi les points sont-ils organisés en bandes horizontales ?\npourquoi n’y a-t-il jamais de vent entre 0 et environ 3 miles à l’heure (mph) ?\nSachant qu’en divisant des mph par 1.151 on obtient des vitesses en nœuds, que nous apprend cette commande :\n\n\nsort(unique(weather$wind_speed)) / 1.151\n\n [1]   0.000000   2.999427   3.999235   4.999044   5.998853   6.998662\n [7]   7.998471   8.998280   9.998089  10.997897  11.997706  12.997515\n[13]  13.997324  14.997133  15.996942  16.996751  17.996560  18.996368\n[19]  19.996177  20.995986  21.995795  22.995604  23.995413  24.995222\n[25]  25.995030  26.994839  27.994648  28.994457  29.994266  30.994075\n[31]  31.993884  32.993692  33.993501  34.993310  36.992928 910.825873"
  },
  {
    "objectID": "05-DataWrangling.html#associer-plusieurs-tableaux-avec-left_join-et-inner_join",
    "href": "05-DataWrangling.html#associer-plusieurs-tableaux-avec-left_join-et-inner_join",
    "title": "5  Manipuler des tableaux avec dplyr",
    "section": "5.9 Associer plusieurs tableaux avec left_join() et inner_join()",
    "text": "5.9 Associer plusieurs tableaux avec left_join() et inner_join()\n\n5.9.1 Principe\nUne autre règle que nous n’avons pas encore évoquée au sujet des “tidy data” ou “données rangées” est la suivante :\n\nChaque tableau contient des données appartenant à une unité d’observation cohérente et unique.\n\nAinsi, le package nycflights13 contient 5 tableaux distincts :\n\nhelp(package = \"nycflights13\")\n\n\nflights contient des informations concernant les vols intérieurs ayant décollé des 3 aéroports de New York en 2013 (par exemple heure prévue de décollage et d’arrivée, heure effective de décollage et d’arrivée, numéro du vol et compagnie aérienne, date et heure du vol, code des aéroports d’origine et de destination, etc.)\nairlines contient des informations au sujet des compagnies aériennes (code et nom complet de chaque compagnie aérienne)\nairports contient des informations au sujet des aéroports de New York et de tous les aéroports desservis par les vols au décollage de New York (code et nom complet de chaque aéroport, latitude, longitude et altitude de chaque aéroport, etc.)\nplanes contient des informations au sujet de chacun des avions ayant desservi Ney York en 2013 (numéro d’immatriculation, année de fabrication, type d’avion, modèle et fabricant, type de moteur, nombre de places, vitesse de croisière, etc.)\n\nÇa n’aurait pas de sens de faire figurer toutes ces informations dans le même tableau. Pourtant, lorsque l’on traite des données, on constate souvent qu’un même tableau contient des variables qui concernent des unités d’observations différentes qu’il conviendrait de scinder en plusieurs tableaux. Et à l’inverse, lorsque nous disposons de plusieurs tableaux, il est parfois nécessaire de récupérer des informations dans plusieurs d’entre eux afin, notamment de produire des tableaux de synthèse ou de rechercher des tendances inattendues.\nPour illustrer ce besoin, nous allons nous poser 2 questions en relation avec les données du package nycflights13 :\n\nQuelles sont les destinations les plus fréquemment desservies par les vols ayant décollé de New York en 2013 ?\nPeut-on dire que les retards constatés à l’arrivée des vols sont liés à l’année de fabrication des avions (et donc, dans une certaine mesure, à leur vétusté) ?\n\nRépondre à la première question est assez simple : il suffit en apparence de compter, parmi les vols du tableau flights, le nombre de vols pour chaque destinations (variable dest), puis de trier le résultat par ordre décroissant :\n\nflights |&gt;\n  count(dest) |&gt;\n  arrange(desc(n))\n\n# A tibble: 105 × 2\n   dest      n\n   &lt;chr&gt; &lt;int&gt;\n 1 ORD   17283\n 2 ATL   17215\n 3 LAX   16174\n 4 BOS   15508\n 5 MCO   14082\n 6 CLT   14064\n 7 SFO   13331\n 8 FLL   12055\n 9 MIA   11728\n10 DCA    9705\n# ℹ 95 more rows\n\n\nLe problème est ici que les aéroports de destination sont renseignés sous la forme d’un code à 3 lettres. À quel aéroport correspondent les codes ORD et ATL ? S’agit-il d’Orlando et Atlanta ? Pour le savoir, il faut aller chercher l’information qui se trouve dans le tableau airports : il contient, parmi d’autres variables, les codes et les noms de 1458 aéroports aux État-Unis. Il va donc nous falloir trouver un moyen de fusionner les informations du tableau que nous venons de créer (et auquel nous allons donner le nom popular_dest), avec les informations contenues dans le tableau airports.\n\npopular_dest &lt;- flights |&gt;\n  count(dest) |&gt;\n  arrange(desc(n))\n\nPour répondre à la deuxième question, on commence là aussi par chercher des informations dans le tableau flights au sujet des retards à l’arrivée. Pour limiter la taille des tableaux que l’on va manipuler, on va se concentrer sur les vols ayant eu plus de 15 minutes de retard à l’arrivée :\n\nlate_flights &lt;- flights |&gt; \n  filter(arr_delay &gt; 15)\n\nlate_flights\n\n# A tibble: 77,630 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      533            529         4      850            830\n 2  2013     1     1      542            540         2      923            850\n 3  2013     1     1      555            600        -5      913            854\n 4  2013     1     1      559            600        -1      941            910\n 5  2013     1     1      602            605        -3      821            805\n 6  2013     1     1      608            600         8      807            735\n 7  2013     1     1      624            630        -6      909            840\n 8  2013     1     1      628            630        -2     1016            947\n 9  2013     1     1      635            635         0     1028            940\n10  2013     1     1      656            705        -9     1007            940\n# ℹ 77,620 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nNous obtenons un tableau de 77630, mais nous n’avons aucune information sur la date de construction (et donc sur l’âge) de ces avions. Nous avons toutefois l’information de l’immatriculation de chaque avion dans la colonne tailnum. Or, le tableau planes, qui contient des informations sur les caractéristiques des avions, indique, pour chacun d’entre eux, à la fois l’immatriculation et l’année de construction. Là encore, il va donc nous falloir fusionner les informations de deux tableaux : late_flights que nous venons de créer, et planes.\n\nplanes\n\n# A tibble: 3,322 × 9\n   tailnum  year type              manufacturer model engines seats speed engine\n   &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;             &lt;chr&gt;        &lt;chr&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; \n 1 N10156   2004 Fixed wing multi… EMBRAER      EMB-…       2    55    NA Turbo…\n 2 N102UW   1998 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n 3 N103US   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n 4 N104UW   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n 5 N10575   2002 Fixed wing multi… EMBRAER      EMB-…       2    55    NA Turbo…\n 6 N105UW   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n 7 N107US   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n 8 N108UW   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n 9 N109UW   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n10 N110UW   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n# ℹ 3,312 more rows\n\n\nLe package dplyr fournit toute une gamme de fonctions permettant d’effectuer des associations de tableaux en fonction de critères spécifiés par l’utilisateur, et nous allons en utiliser deux.\n\n\n5.9.2 inner_join()\n\n\n\n\n\nFigure 5.14: Schéma de la fonction inner_join() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nLa fonction inner_join() permet de relier deux tableaux en ne conservant que les lignes qui sont présentes à la fois dans l’un et dans l’autre. Il faut identifier, dans chacun des tableaux, une colonne contenant des données en commun, qui servira de guide pour mettre les lignes correctes les unes en face des autres. Ici, pour notre première questions, nous partons de notre tableau popular_dest, qui contient les codes des aéroports dans sa colonne dest, et nous faisons une “jointure interne” avec le tableau airports qui contient lui aussi une colonne contenant les codes des aéroports : la variable faa.\n\ninner_popular &lt;- popular_dest |&gt;\n  inner_join(airports, by = join_by(dest == faa))\ninner_popular\n\n# A tibble: 101 × 9\n   dest      n name                           lat    lon   alt    tz dst   tzone\n   &lt;chr&gt; &lt;int&gt; &lt;chr&gt;                        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n 1 ORD   17283 Chicago Ohare Intl            42.0  -87.9   668    -6 A     Amer…\n 2 ATL   17215 Hartsfield Jackson Atlanta …  33.6  -84.4  1026    -5 A     Amer…\n 3 LAX   16174 Los Angeles Intl              33.9 -118.    126    -8 A     Amer…\n 4 BOS   15508 General Edward Lawrence Log…  42.4  -71.0    19    -5 A     Amer…\n 5 MCO   14082 Orlando Intl                  28.4  -81.3    96    -5 A     Amer…\n 6 CLT   14064 Charlotte Douglas Intl        35.2  -80.9   748    -5 A     Amer…\n 7 SFO   13331 San Francisco Intl            37.6 -122.     13    -8 A     Amer…\n 8 FLL   12055 Fort Lauderdale Hollywood I…  26.1  -80.2     9    -5 A     Amer…\n 9 MIA   11728 Miami Intl                    25.8  -80.3     8    -5 A     Amer…\n10 DCA    9705 Ronald Reagan Washington Na…  38.9  -77.0    15    -5 A     Amer…\n# ℹ 91 more rows\n\n\nLe nouvel objet inner_popular contient donc les données du tableau popular_dest auxquelles ont été ajoutées les colonnes correspondantes du tableau airports. C’est l’argument by = join_by() de la fonction inner_join() qui nous garantit que les bonnes lignes des deux tableaux sont mises face à face et que nous ne nous retrouvons pas avec des données totalement mélangées : pour chaque élément de la colonne dest du tableau popular_dest, l’élément correspondant de la colonne faa du tableau airports est identifié, et les variables de ces 2 lignes sont mises bout à bout dans un nouveau tableau. L’opération se répète pour tous les éléments de dest et de faa, et seules les lignes communes qui sont présente à la fois dans popular_dest et dans airports sont conservées.\nSi tout ce qui nous intéresse, c’est de connaître le nom complet des aéroports les plus populaires, on peut utiliser select() pour ne garder que les variables intéressantes :\n\ninner_popular &lt;- popular_dest |&gt;\n  inner_join(airports, by = join_by(dest == faa)) |&gt;\n  select(dest, name, n)\ninner_popular\n\n# A tibble: 101 × 3\n   dest  name                                   n\n   &lt;chr&gt; &lt;chr&gt;                              &lt;int&gt;\n 1 ORD   Chicago Ohare Intl                 17283\n 2 ATL   Hartsfield Jackson Atlanta Intl    17215\n 3 LAX   Los Angeles Intl                   16174\n 4 BOS   General Edward Lawrence Logan Intl 15508\n 5 MCO   Orlando Intl                       14082\n 6 CLT   Charlotte Douglas Intl             14064\n 7 SFO   San Francisco Intl                 13331\n 8 FLL   Fort Lauderdale Hollywood Intl     12055\n 9 MIA   Miami Intl                         11728\n10 DCA   Ronald Reagan Washington Natl       9705\n# ℹ 91 more rows\n\n\nOn peut noter plusieurs choses dans ce nouveau tableau :\n\nORD n’est pas l’aéroport d’Orlando mais l’aéroport international de Chicago Ohare. C’est donc la destination la plus fréquente au départ de New York.\nATL est bien l’aéroport d’Atlanta.\ninner_popular contient 101 lignes alors que notre tableau de départ en contenait 105.\n\n\nnrow(popular_dest)\n\n[1] 105\n\nnrow(inner_popular)\n\n[1] 101\n\n\nCertaines lignes ont donc été supprimées car le code aéroport dans popular_dest (notre tableau de départ) n’a pas été retrouvé dans la colonne faa du tableau airports. C’est le principe même de la jointure interne (voir Figure 5.14) : seules les lignes communes trouvées dans les 2 tableaux sont conservées. Pour connaitre quelles lignes ont éte éliminées, on peut utiliser anti_join() :\n\npopular_dest |&gt;\n  anti_join(airports, by = join_by(dest == faa))\n\n# A tibble: 4 × 2\n  dest      n\n  &lt;chr&gt; &lt;int&gt;\n1 SJU    5819\n2 BQN     896\n3 STT     522\n4 PSE     365\n\n\nSi l’on souhaite absolument conserver toutes les lignes du tableau de départ, il faut faire une jointure gauche, ou “left join” (voir (sec_leftjoin?) ci-dessous).\nPour notre deuxième question, on procède exactement de la même façon : on réalise une jointure de tableaux entre late-flights et planes :\n\ninner_late &lt;- late_flights |&gt; \n  inner_join(planes, by = join_by(tailnum))\n\ninner_late\n\n# A tibble: 66,434 × 27\n   year.x month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n    &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1   2013     1     1      533            529         4      850            830\n 2   2013     1     1      542            540         2      923            850\n 3   2013     1     1      555            600        -5      913            854\n 4   2013     1     1      624            630        -6      909            840\n 5   2013     1     1      628            630        -2     1016            947\n 6   2013     1     1      702            700         2     1058           1014\n 7   2013     1     1      709            700         9      852            832\n 8   2013     1     1      715            713         2      911            850\n 9   2013     1     1      732            645        47     1011            941\n10   2013     1     1      739            739         0     1104           1038\n# ℹ 66,424 more rows\n# ℹ 19 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, year.y &lt;int&gt;, type &lt;chr&gt;,\n#   manufacturer &lt;chr&gt;, model &lt;chr&gt;, engines &lt;int&gt;, seats &lt;int&gt;, speed &lt;int&gt;,\n#   engine &lt;chr&gt;\n\n\nIci, la variable qui nous permet d’associer les bonnes informations du tableau planes avec les bonnes lignes du tableau late_flights porte le même nom dans les deux tableaux : tailnum. C’est la raison pour laquelle nous spécifions simplement by = join_by(tailnum) (et non pas by = join_by(tailnum == tailnum)) dans la fonction inner_join(). Là encore, nous avons perdu des lignes en cours de route : de 77630 lignes dans le tableau late_flights, nous passons à 66434 dans le tableau inner_late après la jointure.\nPour simplifier la suite des analyses, nous pouvons sélectionner les seules variables qui nous intéressent, et calculer l’âge des avions :\n\ninner_late &lt;- late_flights |&gt; \n  inner_join(planes, by = join_by(tailnum)) |&gt; \n  select(tailnum, arr_delay, year.y) |&gt; \n  mutate(age = 2013 - year.y)\n\ninner_late\n\n# A tibble: 66,434 × 4\n   tailnum arr_delay year.y   age\n   &lt;chr&gt;       &lt;dbl&gt;  &lt;int&gt; &lt;dbl&gt;\n 1 N24211         20   1998    15\n 2 N619AA         33   1990    23\n 3 N516JB         19   2000    13\n 4 N11107         29   2002    11\n 5 N33289         29   2004     9\n 6 N779JB         44   2009     4\n 7 N26226         20   1998    15\n 8 N841UA         21   2001    12\n 9 N37456         30   2012     1\n10 N37408         26   2001    12\n# ℹ 66,424 more rows\n\n\nNotez bien que nos deux tableaux contenaient une variable nommée year, mais que l’information de ces 2 variables était différente :\n\ndans le tableau late_flights, year correspond à l’année où chaque vol a décollé de New York (donc 2013 pour tous les vols)\ndans le tableau planes, year correspond à l’année de fabrication de chaque avion.\n\nLors de la jointure, un suffixe est donc ajouté automatiquement aux deux variables year pour que ces 2 colonnes ne soient pas fusionnées et éviter les confusions : year.x (pour la colonne du premier tableau) et year.y (pour la colonne du deuxième tableau, celle qui nous intéresse.\nPour répondre à la question posée au départ, il ne reste plus qu’à visualiser les résultats sur un graphique par exemple :\n\ninner_late |&gt; \n  ggplot(aes(x = age, y = arr_delay)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth() +\n  labs(x = \"Âge des avions (en années)\", y = \"Retard à l'arrivée des vols (en minutes)\") +\n  theme_bw()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 1244 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 1244 rows containing missing values (`geom_point()`).\n\n\n\n\n\nManifestement, l’âge des avions n’a pas grand chose à voir avec l’importance des retards constatés à l’arrivée des vols. En tous cas, s’il existe une relation, elle n’est certainement pas aussi simple qu’on aurait pu le penser.\n\n\n5.9.3 left_join()\n\n\n\n\n\nFigure 5.15: Schéma de la fonction left_join() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nComme indiqué par la Figure 5.15 ci-dessus, une jointure gauche fonctionne comme inner_join(), mais elle permet de conserver toutes les lignes du tableau de gauche, et de leur faire correspondre les lignes du second tableau. Si aucune correspondance n’est trouvée dans le second tableau, des données manquantes sont ajoutées sous forme de NAs. Voyons ce que cela donne avec les mêmes exemples que précédemment :\n\nleft_popular &lt;- popular_dest |&gt;\n  left_join(airports, by = join_by(dest == faa)) |&gt;\n  select(dest, name, n)\nleft_popular\n\n# A tibble: 105 × 3\n   dest  name                                   n\n   &lt;chr&gt; &lt;chr&gt;                              &lt;int&gt;\n 1 ORD   Chicago Ohare Intl                 17283\n 2 ATL   Hartsfield Jackson Atlanta Intl    17215\n 3 LAX   Los Angeles Intl                   16174\n 4 BOS   General Edward Lawrence Logan Intl 15508\n 5 MCO   Orlando Intl                       14082\n 6 CLT   Charlotte Douglas Intl             14064\n 7 SFO   San Francisco Intl                 13331\n 8 FLL   Fort Lauderdale Hollywood Intl     12055\n 9 MIA   Miami Intl                         11728\n10 DCA   Ronald Reagan Washington Natl       9705\n# ℹ 95 more rows\n\n\nEn apparence, le tableau left_popular, créé avec left_join() semble identique au tableau inner_popular créé avec inner_join(). Pourtant, ce n’est pas le cas :\n\nidentical(inner_popular, left_popular)\n\n[1] FALSE\n\n\nEn l’occurrence, nous avons vu que inner_popular ne contenait pas autant de ligne que le tableau de départ popular_dest. Avec une jointure gauche, les lignes du tableau de départ sont toutes conservées. popular_dest et left_popular ont donc le même nombre de lignes.\n\nnrow(inner_popular)\n\n[1] 101\n\nnrow(left_popular)\n\n[1] 105\n\nnrow(popular_dest)\n\n[1] 105\n\n\nPour savoir quelles lignes de popular_dest manquent dans inner_dest (il devrait y en avoir 4), il suffit de filtrer les lignes de left_dest qui contiennent des données manquantes dans la colonne name :\n\nleft_popular |&gt;\n  filter(is.na(name))\n\n# A tibble: 4 × 3\n  dest  name      n\n  &lt;chr&gt; &lt;chr&gt; &lt;int&gt;\n1 SJU   &lt;NA&gt;   5819\n2 BQN   &lt;NA&gt;    896\n3 STT   &lt;NA&gt;    522\n4 PSE   &lt;NA&gt;    365\n\n\nOn trouve évidemment les mêmes résultats qu’avec la fonction anti_join() évoquée plus haut. Une rapide recherche sur internet vous apprendra que ces aéroports ne sont pas situés sur le sol américain. Trois d’entre eux sont situés à Puerto Rico (SJU, BQN et PSE) et le dernier (STT) est situé aux Îles Vierges.\nDe la même façon, répondre à la deuxième question avec une jointure gauche est presque identique à ce que nous avons vu avec inner_join() :\n\nlate_flights |&gt; \n  inner_join(planes, by = join_by(tailnum)) |&gt; \n  select(tailnum, arr_delay, year.y) |&gt; \n  mutate(age = 2013 - year.y) |&gt; \n  ggplot(aes(x = age, y = arr_delay)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth() +\n  labs(x = \"Âge des avions (en années)\", y = \"Retard à l'arrivée des vols (en minutes)\") +\n  theme_bw()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 1244 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 1244 rows containing missing values (`geom_point()`).\n\n\n\n\n\nAttention toutefois : le fait que left_join() et inner_join() fournisse le même résultat n’est pas systématique. Ici, c’est bien le choix de la question d’intérêt qui fait que nous pouvons choisir l’une ou l’autre de ces fonctions de façon interchangeable. Mais ça ne sera pas toujours le cas. Quand on a besoin de conserver toutes les lignes du tableau de départ (ce qui est souvent lecas), il faudra utiliser left_join().\nIl y aurait bien plus à dire sur les jointures :\n\nQuelles sont les autres possibilités de jointures (right_join(), outer_join(), full_join(), semi_join(), cross_join(), nest_join(), etc…) ?\nQue se passe-t-il si les colonnes communes des 2 tableaux contiennent des éléments dupliqués ?\nEst-il possible de joindre des tableaux en associant plus d’une colonne de chaque tableau d’origine (la réponse est oui !) ?\n\nPour avoir la réponse à toutes ces questions, je vous conseille de lire ce chapitre de cet ouvrage très complet sur “la science des données” avec R et le tidyverse : R for Data Science. Les deux fonctions inner_join() et left_join() décrites ici devraient néanmoins vous permettre de couvrir l’essentiel de vos besoins. Et il je vous encourage vivement à explorer les fichiers d’aide des fonctions de jointures car il s’agit de fonctions tr`´s puissantes et dont les possibilités sont très larges.\n\n\n5.9.4 Accoler deux tableaux\nOutre l’association de tableaux en utilisant des jointures, il est parfois utile d’accoler 2 tableaux :\n\nSoit l’un au-dessous de l’autre, quand ils ont les mêmes nombres de colonnes, et si possible, les mêmes variables aux mêmes endroits. La fonction bind_rows() permet de faire cela.\nSoit l’un à côté de l’autre quand ils ont le même nombre de lignes, et si possible les mêmes observations en lignes. La fonction bind_cols() permet de faire cela.\n\nPrenons un exemple. Imaginons que nous ayons 2 tableaux contenant les mêmes variables. Le premier, nommé colorado, contient les informations des vols ayant décollé de New York en 2013 et ayant atterri à l’aéroport de Yempa Valley au Colorado (aéroport HDN).\n\ncolorado &lt;- flights |&gt;\n  filter(dest == \"HDN\")\n\ncolorado\n\n# A tibble: 15 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     5      829            830        -1     1047           1111\n 2  2013     1    12      827            830        -3     1112           1111\n 3  2013     1    19      843            830        13     1123           1111\n 4  2013     1    26      828            830        -2     1114           1111\n 5  2013    12    21      916            830        46     1149           1117\n 6  2013    12    28      913            829        44     1128           1116\n 7  2013     2     2      858            830        28     1124           1111\n 8  2013     2     9       NA            830        NA       NA           1111\n 9  2013     2    16      834            830         4     1114           1111\n10  2013     2    23      826            830        -4     1050           1111\n11  2013     3     2      854            830        24     1104           1111\n12  2013     3     9      838            830         8     1107           1111\n13  2013     3    16      845            830        15     1154           1111\n14  2013     3    23      835            830         5     1104           1111\n15  2013     3    30      825            830        -5     1045           1111\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nLe second est nommé indiana. Il contient les informations des vols ayant décollé de New York en 2013 et ayant atterri à l’aéroport de South Bend en Indiana (aéroport SBN).\n\nindiana &lt;- flights |&gt;\n  filter(dest == \"SBN\")\n\nindiana\n\n# A tibble: 10 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013    10    18     1820           1745        35     2030           2011\n 2  2013    11     1     2012           1905        67     2221           2131\n 3  2013    11    22     2013           1905        68     2224           2131\n 4  2013    12     1     1241           1215        26     1431           1431\n 5  2013     8    30     1909           1910        -1     2117           2136\n 6  2013     9     1      833            840        -7     1030           1040\n 7  2013     9     8      847            840         7     1043           1040\n 8  2013     9    20     1948           1950        -2     2207           2216\n 9  2013     9    22      837            840        -3     1025           1040\n10  2013     9    27     2011           1950        21     2209           2216\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nPuisque les variables de ces 2 tableaux sont les mêmes, nous pouvons “empiler” ces 2 tableaux pour n’en former qu’un seul :\n\nbind_rows(colorado, indiana)\n\n# A tibble: 25 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     5      829            830        -1     1047           1111\n 2  2013     1    12      827            830        -3     1112           1111\n 3  2013     1    19      843            830        13     1123           1111\n 4  2013     1    26      828            830        -2     1114           1111\n 5  2013    12    21      916            830        46     1149           1117\n 6  2013    12    28      913            829        44     1128           1116\n 7  2013     2     2      858            830        28     1124           1111\n 8  2013     2     9       NA            830        NA       NA           1111\n 9  2013     2    16      834            830         4     1114           1111\n10  2013     2    23      826            830        -4     1050           1111\n# ℹ 15 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nVous noterez que le nombre de lignes du nouveau tableau est la somme des nombres de lignes des 2 tableaux de départ. Bien sûr, cette opération n’est utile que si les tableaux nous sont fournis séparément. Ici, il aurait été bien plus rapide d’obtenir le même résultat en tapant :\n\nflights |&gt;\n  filter(dest %in% c(\"HDN\", \"SBN\"))\n\n# A tibble: 25 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     5      829            830        -1     1047           1111\n 2  2013     1    12      827            830        -3     1112           1111\n 3  2013     1    19      843            830        13     1123           1111\n 4  2013     1    26      828            830        -2     1114           1111\n 5  2013    10    18     1820           1745        35     2030           2011\n 6  2013    11     1     2012           1905        67     2221           2131\n 7  2013    11    22     2013           1905        68     2224           2131\n 8  2013    12     1     1241           1215        26     1431           1431\n 9  2013    12    21      916            830        46     1149           1117\n10  2013    12    28      913            829        44     1128           1116\n# ℹ 15 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nLe fonctionnement de bind_cols() est le même :\n\na &lt;- tibble(x = 1:3,\n            y = c(2, 4, 6),\n            z = c(TRUE, FALSE, FALSE))\n\nb &lt;- tibble(r = 10:8,\n            s = rnorm(3))\n\na\n\n# A tibble: 3 × 3\n      x     y z    \n  &lt;int&gt; &lt;dbl&gt; &lt;lgl&gt;\n1     1     2 TRUE \n2     2     4 FALSE\n3     3     6 FALSE\n\nb\n\n# A tibble: 3 × 2\n      r     s\n  &lt;int&gt; &lt;dbl&gt;\n1    10 1.67 \n2     9 0.546\n3     8 0.106\n\nbind_cols(a,b)\n\n# A tibble: 3 × 5\n      x     y z         r     s\n  &lt;int&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;int&gt; &lt;dbl&gt;\n1     1     2 TRUE     10 1.67 \n2     2     4 FALSE     9 0.546\n3     3     6 FALSE     8 0.106\n\n\nIci, puisque a et b ont le même nombre de lignes, il est possible de les accoler. Cela n’a de sens que si les lignes des 2 tableaux correspondent aux mêmes observations."
  },
  {
    "objectID": "05-DataWrangling.html#sec-exo-13",
    "href": "05-DataWrangling.html#sec-exo-13",
    "title": "5  Manipuler des tableaux avec dplyr",
    "section": "5.10 Exercices",
    "text": "5.10 Exercices\n\nCréez un tableau delayed indiquant, pour chaque compagnie aérienne et chaque mois de l’année, le nombre de vols ayant eu un retard supérieur à 30 minutes à l’arrivée à destination. Ce tableau devrait contenir uniquement 3 colonnes :\n\n\ncarrier : la compagnie aérienne.\nmonth : le mois de l’année 2013.\nn_delayed : le nombre de vols ayant plus de 30 minutes de retard.\n\n\nCréez un tableau total indiquant le nombre total de vols affrétés (et non annulés) par chaque compagnie aérienne et chaque mois de l’année. Ce tableau devrait contenir seulement 3 colonnes :\n\n\ncarrier : la compagnie aérienne.\nmonth : le mois de l’année 2013.\nn_total : le nombre total de vols arrivés à destination.\n\n\nFusionnez ces 2 tableaux en réalisant la jointure appropriée. Le tableau final, que vous nommerez carrier_stats devrait contenir 185 lignes. Si certaines colonnes contiennent des données manquantes, remplacez-les par des 0 à l’aide des fonctions mutate() et replace_na().\nAjoutez à votre tableau carrier_stats une variable rate qui contient la proportion de vols arrivés à destination avec plus de 30 minutes de retard, pour chaque compagnie aérienne et chaque mois de l’année.\nAjoutez à votre tableau carrier_stats le nom complet des compagnies aériennes en réalisant la jointure appropriée avec le tableau airlines.\nFaites un graphique synthétique présentant ces résultats de la façon la plus claire possible\nQuelle compagnie aérienne semble se comporter très différemment des autres ? À quoi pouvez-vous attribuer ce comportement atypique ?\nPour les compagnies affrétant un grand nombre de vols chaque année (e.g. UA, B6 et EV), quelles sont les périodes où les plus fortes proportions de vols en retard sont observées ? Et les plus faibles ? Quelle(s) hypothèse(s) pouvez-vous formuler pour expliquer ces observations ?\nFaites un tableau synthétique présentant ces résultats de la façon la plus compacte et claire que possible, afin par exemple de les intégrer à un rapport."
  },
  {
    "objectID": "07-Incertitude.html#pré-requis",
    "href": "07-Incertitude.html#pré-requis",
    "title": "7  Dispersion et incertitude",
    "section": "7.1 Pré-requis",
    "text": "7.1 Pré-requis\nNous avons ici besoin des packages suivants :\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(nycflights13)\n\nPensez à les charger en mémoire si ce n’est pas déjà fait ou si vous venez de démarrer une nouvelle session de travail."
  },
  {
    "objectID": "07-Incertitude.html#la-notion-de-dispersion",
    "href": "07-Incertitude.html#la-notion-de-dispersion",
    "title": "7  Dispersion et incertitude",
    "section": "7.2 La notion de dispersion",
    "text": "7.2 La notion de dispersion\nComme expliqué plus haut, les indices de dispersion nous renseignent sur la variabilités des données autour de la valeur centrale (moyenne ou médiane) d’une population ou d’un échantillon. L’écart-type, la variance et l’intervalle interquartile sont 3 exemples d’indices de dispersion. Prenons l’exemple de l’écart-type. Un écart-type faible indique que la majorité des observations ont des valeurs proches de la moyenne. À l’inverse, un écart-type important indique que la plupart des points sont éloignés de la moyenne. L’écart-type est une caractéristique de la population que l’on étudie grâce à un échantillon, au même titre que la moyenne. En travaillant sur un échantillon, on espère accéder aux vraies grandeurs de la population. Même si ces vraies grandeurs sont à jamais inaccessibles (on ne connaîtra jamais parfaitement quelle est la vraie valeur de moyenne \\(\\mu\\) ou d’écart-type \\(\\sigma\\) de la population), on espère qu’avec un échantillonnage réalisé correctement, la moyenne de l’échantillon (\\(\\bar{x}\\) ou \\(m\\)) et l’écart-type (\\(s\\)) de l’échantillon reflètent assez fidèlement les valeurs de la population générale. C’est la notion d’estimateur, intimement liée à la notion d’inférence statistique : la moyenne de l’échantillon, que l’on connait avec précision, est un estimateur de la moyenne \\(\\mu\\) de la population qui restera à jamais inconnue. C’est la raison pour laquelle la moyenne de l’échantillon est parfois notée \\(\\hat{\\mu}\\) (en plus de \\(\\bar{x}\\) ou \\(m\\)). De même, l’écart-type \\(s\\) et la variance \\(s^2\\) d’un échantillon sont des estimateurs de l’écart-type \\(\\sigma\\) et de la variance \\(\\sigma^2\\) de la population générale. C’est la raison pour laquelle on les note parfois \\(\\hat{\\sigma}\\) et \\(\\hat{\\sigma}^2\\) respectivement. L’accent circonflexe se prononce “chapeau”. On dit donc que \\(\\hat{\\sigma}\\) (sigma chapeau, l’écart-type de l’échantillon) est un estimateur de l´écart-type de la population générale. Comme nous l’avons vu, les indices de dispersion doivent accompagner les indices de position lorsque l’on décrit des données, car présenter une valeur de moyenne, ou de médiane seule n’a pas de sens : il faut savoir à quel point les données sont proches ou éloignées de la tendance centrale pour savoir si, dans la population générale, les indicateurs de position correspondent ou non, aux valeurs portées par la majorité des individus.\nNous avons vu plus haut comment calculer des indices de position et de dispersion. Tout ceci devrait donc être clair pour vous à ce stade."
  },
  {
    "objectID": "07-Incertitude.html#la-notion-dincertitude",
    "href": "07-Incertitude.html#la-notion-dincertitude",
    "title": "7  Dispersion et incertitude",
    "section": "7.3 La notion d’incertitude",
    "text": "7.3 La notion d’incertitude\nPar ailleurs, puisqu’on ne sait jamais avec certitude si nos estimations (de moyennes ou d’écarts-types ou de tout autre paramètre) reflètent fidèlement ou non les vraies valeurs de la population, nous devons quantifier à quel point nos estimations s’écartent de celles de la population générale. C’est tout l’intérêt des statistiques et c’est ce que permettent les indices d’incertitude : on ne connaîtra jamais la vraie valeur de moyenne ou d’écart-type de la population, mais on peut quantifier à quel point nos estimations (basées sur un échantillon) sont précises ou imprécises.\nLes deux indices d’incertitude les plus connus (et les plus utilisés) sont l’intervalle de confiance à 95% (de la moyenne ou de tout autre estimateur ; les formules sont nombreuses et il n’est pas utile de les détailler ici : nous verrons comment les calculer plus bas) et l’erreur standard de la moyenne (\\(se_{\\bar{x}}\\)), dont la formule est la suivante :\n\\[se_{\\bar{x}} = \\frac{s}{\\sqrt{n}}\\] avec \\(s\\), l’écart-type de l’échantillon et \\(n\\) la taille de l’échantillon.\nComme pour la moyenne, on peut calculer l’erreur standard d’un écart-type, d’une médiane, d’une proportion, ou de tout autre estimateur calculé sur un échantillon. Cet indice d’incertitude ne nous renseigne pas sur une grandeur de la population générale qu’on chercherait à estimer, mais bien sur l’incertitude associée à une estimation que nous faisons en travaillant sur un échantillon de taille forcément limitée. Tout processus d’échantillonnage est forcément entaché d’incertitude, causée entre autre par le hasard de l’échantillonnage (ou fluctuation d’échantillonnage). Puisque nous travaillons sur des échantillons forcément imparfaits, les indices d’incertitude vont nous permettre de quantifier à quel point nos estimations s’écartent des vraies valeurs de la population. Ces “vraies valeurs”, faute de pouvoir collecter tous les individus de la population, resteront à jamais inconnues.\n\n\n\n\n\n\nAutrement dit…\n\n\n\nQuand on étudie des populations naturelles grâce à des échantillons on se trompe toujours. Les statistiques nous permettent de quantifier à quel point on se trompe grâce aux indices d’incertitude, et c’est déjà pas mal !\n\n\nEn examinant la formule de l’erreur standard de la moyenne présentée ci-dessus, on comprend intuitivement que plus la taille de l’échantillon (\\(n\\)) augmente, plus l’erreur standard (donc l’incertitude) associée à notre estimation de moyenne diminue. Autrement dit, plus les données sont abondantes dans l’échantillon, meilleure sera notre estimation de moyenne, et donc, moins le risque de raconter des bêtises sera grand.\nL’autre indice d’incertitude très fréquemment utilisé est l’intervalle de confiance à 95% (de la moyenne, de la médiane, de la variance, ou de toute autre estimateur calculé dans un échantillon). L’intervalle de confiance nous renseigne sur la gamme des valeurs les plus probables pour un paramètre de la population étudiée. Par exemple, si j’observe, dans un échantillon, une moyenne de 10, avec un intervalle de confiance calculé de [7 ; 15], cela signifie que, dans la population générale, la vraie valeur de moyenne a de bonnes chances de se trouver dans l’intervalle [7 ; 15]. Dans la population générale, toutes les valeurs comprises entre 7 et 15 sont vraisemblables pour la moyenne alors que les valeurs situées en dehors de cet intervalle sont moins probables. Une autre façon de comprendre l’intervalle de confiance est de dire que si je récupère un grand nombre d’échantillons dans la même population, en utilisant exactement le même protocole expérimental, 95% des échantillons que je vais récupérer auront une moyenne située à l’intérieur de l’intervalle de confiance à 95%, et 5% des échantillons auront une moyenne située à l’extérieur de l’intervalle de confiance à 95%. C’est une notion qui n’est pas si évidente que ça à comprendre, donc prenez bien le temps de relire cette section si besoin, et de poser des questions le cas échéant.\nConcrètement, plus l’intervalle de confiance est large, moins notre confiance est grande. Si la moyenne d’un échantillon vaut \\(\\bar{x} = 10\\), et que son intervalle de confiance à 95% vaut [9,5 ; 11], la gamme des valeurs probables pour la moyenne de la population est étroite. Autrement dit, la moyenne de l’échantillon (10), a de bonne chances d’être très proche de la vraie valeur de moyenne de la population générale (vraisemblablement comprise quelque part entre 9,5 et 11). À l’inverse, si l’intervalle de confiance à 95% de la moyenne vaut [4 ; 17], la gamme des valeurs possibles pour la vraie moyenne de la population est grande. La moyenne de l’échantillon aura donc de grandes chances d’être assez éloignée de la vraie valeur de la population.\nLa notion d’intervalle de confiance à 95% est donc très proche de celle d’erreur standard. D’ailleurs, pour de nombreux paramètres, l’intervalle de confiance est calculé à partir de l’erreur standard."
  },
  {
    "objectID": "07-Incertitude.html#sec-errstd",
    "href": "07-Incertitude.html#sec-errstd",
    "title": "7  Dispersion et incertitude",
    "section": "7.4 Calcul de l’erreur standard de la moyenne",
    "text": "7.4 Calcul de l’erreur standard de la moyenne\nContrairement aux indices de position et de dispersion, il n’existe pas de fonction intégrée à R qui permette de calculer l’erreur standard de la moyenne. Toutefois, sa formule très simple nous permet de la calculer à la main quand on en a besoin grâce à la fonction summarise().\nPar exemple, reprenons les données de température (tableau weather du package nycflights13, colonne temp) dans les 3 aéroports de New York (colonne origin). Imaginons que nous souhaitions étudier les fluctuations de températures au fil des mois de l’année 2013 :\n\nJe vais commencer par transformer les températures (fournies en degrés Fahrenheit) en degrés Celsius :\n\n\nweather %&gt;% \n  mutate(temp_celsius = (temp - 32) / 1.8)\n\n# A tibble: 26,115 × 16\n   origin  year month   day  hour  temp  dewp humid wind_dir wind_speed\n   &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1 EWR     2013     1     1     1  39.0  26.1  59.4      270      10.4 \n 2 EWR     2013     1     1     2  39.0  27.0  61.6      250       8.06\n 3 EWR     2013     1     1     3  39.0  28.0  64.4      240      11.5 \n 4 EWR     2013     1     1     4  39.9  28.0  62.2      250      12.7 \n 5 EWR     2013     1     1     5  39.0  28.0  64.4      260      12.7 \n 6 EWR     2013     1     1     6  37.9  28.0  67.2      240      11.5 \n 7 EWR     2013     1     1     7  39.0  28.0  64.4      240      15.0 \n 8 EWR     2013     1     1     8  39.9  28.0  62.2      250      10.4 \n 9 EWR     2013     1     1     9  39.9  28.0  62.2      260      15.0 \n10 EWR     2013     1     1    10  41    28.0  59.6      260      13.8 \n# ℹ 26,105 more rows\n# ℹ 6 more variables: wind_gust &lt;dbl&gt;, precip &lt;dbl&gt;, pressure &lt;dbl&gt;,\n#   visib &lt;dbl&gt;, time_hour &lt;dttm&gt;, temp_celsius &lt;dbl&gt;\n\n\n\nEnsuite, je détermine, pour chaque jour de chaque mois de l’année, et pour chaque aéroport, quelle est la température maximale atteinte, et je stocke ces valeurs dans un nouvel objet pour pouvoir le ré-utiliser :\n\n\ntemp_jour &lt;- weather %&gt;% \n  mutate(temp_celsius = (temp - 32) / 1.8) %&gt;% \n  summarise(temperature_max = max(temp_celsius, na.rm = TRUE),\n            .by = c(origin, month, day))\n\ntemp_jour\n\n# A tibble: 1,092 × 4\n   origin month   day temperature_max\n   &lt;chr&gt;  &lt;int&gt; &lt;int&gt;           &lt;dbl&gt;\n 1 EWR        1     1            5   \n 2 EWR        1     2            1.10\n 3 EWR        1     3            1.10\n 4 EWR        1     4            4.4 \n 5 EWR        1     5            6.7 \n 6 EWR        1     6            8.9 \n 7 EWR        1     7            8.3 \n 8 EWR        1     8            9.4 \n 9 EWR        1     9           10   \n10 EWR        1    10           10   \n# ℹ 1,082 more rows\n\n\n\nJe peux maintenant calculer la température moyenne mensuelle pour chaque aéroport :\n\n\ntemp_jour %&gt;% \n  summarise(moyenne = mean(temperature_max, na.rm = TRUE),\n            .by = c(origin, month))\n\n# A tibble: 36 × 3\n   origin month moyenne\n   &lt;chr&gt;  &lt;int&gt;   &lt;dbl&gt;\n 1 EWR        1    5.69\n 2 EWR        2    4.74\n 3 EWR        3    8.20\n 4 EWR        4   16.4 \n 5 EWR        5   22.2 \n 6 EWR        6   27.4 \n 7 EWR        7   31.0 \n 8 EWR        8   27.8 \n 9 EWR        9   24.6 \n10 EWR       10   20.0 \n# ℹ 26 more rows\n\n\nPour pouvoir réutiliser ce tableau, je lui donne un nom :\n\ntemp_moyennes &lt;- temp_jour %&gt;% \n  summarise(moyenne = mean(temperature_max, na.rm = TRUE),\n            .by = c(origin, month))\n\nAu final, je peux faire un graphique de l’évolution de ces températures :\n\ntemp_moyennes %&gt;% \n  ggplot(aes(x = factor(month), y = moyenne)) +\n  geom_line(aes(group = 1)) +\n  geom_point() +\n  facet_wrap(~origin, ncol = 1) +\n  labs(x = \"Mois\", \n       y = \"Moyenne des températures quotidiennes maximales (ºC)\") +\n  theme_bw()\n\n\n\n\nVous remarquerez que :\n\nj’associe factor(month), et non simplement month, à l’axe des x afin d’avoir, sur l’axe des abscisses, des chiffres cohérents allant de 1 à 12, et non des chiffres à virgule\nl’argument group = 1 doit être ajouté pour que la ligne reliant les points apparaisse. En effet, les lignes sont censées relier des points qui appartiennent à une même série temporelle. Or ici, nous avons transformé month en facteur. Préciser group = 1 permet d’indiquer à geom_line() que toutes les catégories du facteur month appartiennent au même groupe, que ce facteur peut être considéré comme une variable continue, et qu’il est donc correct de relier les points.\n\nPour les 3 aéroports, les profils de températures sont très proches. C’est tout à fait logique puisqu’ils sont situés dans un rayon de quelques kilomètres seulement. Le problème de ce graphique est que chaque point a été obtenu en calculant une moyenne. En janvier, nous avons fait la moyenne de 31 valeurs de températures quotidiennes pour chaque aéroport. En février, nous avons fait la moyenne de 28 valeurs de températures quotidiennes pour chaque aéroport. Et ainsi de suite pour tous les mois de l’année 2013. Puisque nous présentons des valeurs de moyennes, il nous faut présenter également l’incertitude associée à ces calculs de moyennes. Pour cela, nous devons calculer l’erreur standard des moyennes :\n\ntemp_jour %&gt;% \n  summarise(moyenne = mean(temperature_max, na.rm = TRUE),\n            N_obs = n(),\n            erreur_standard = sd(temperature_max, na.rm = TRUE) / sqrt(N_obs),\n            .by = c(origin, month))\n\n# A tibble: 36 × 5\n   origin month moyenne N_obs erreur_standard\n   &lt;chr&gt;  &lt;int&gt;   &lt;dbl&gt; &lt;int&gt;           &lt;dbl&gt;\n 1 EWR        1    5.69    31           1.14 \n 2 EWR        2    4.74    28           0.762\n 3 EWR        3    8.20    31           0.649\n 4 EWR        4   16.4     30           0.919\n 5 EWR        5   22.2     31           1.02 \n 6 EWR        6   27.4     30           0.769\n 7 EWR        7   31.0     31           0.700\n 8 EWR        8   27.8     31           0.385\n 9 EWR        9   24.6     30           0.716\n10 EWR       10   20.0     31           0.882\n# ℹ 26 more rows\n\n\nNotre tableau de statistiques descriptives possède maintenant 2 colonnes supplémentaires : le nombre d’observations (que j’ai nommé N_obs), et l’erreur standard associée à chaque moyenne, calculée grâce à la formule vue plus haut \\(se_{\\bar{x}} = \\frac{s}{\\sqrt{n}}\\) (la fonction sqrt() permet de calculer la racine carrée). On constate que l’erreur standard, qui s’exprime dans la même unité que la moyenne, est variable selon les mois de l’année. Ainsi, pour l’aéroport de Newark, l’incertitude semble particulièrement faible pour le mois d’août (0.385 ºC) mais presque 3 fois plus forte pour le mois de janvier (1.14 ºC).\nUne fois de plus, je donne un nom à ce tableau de données pour pouvoir le réutiliser plus tard :\n\ntemperatures_se &lt;- temp_jour %&gt;% \n  summarise(moyenne = mean(temperature_max, na.rm = TRUE),\n            N_obs = n(),\n            erreur_standard = sd(temperature_max, na.rm = TRUE) / sqrt(N_obs),\n            .by = c(origin, month))\n\nNotez que le package ggplot2 contient une fonction permettant de calculer à la fois la moyenne et erreur standard de la moyenne d’un échantillon : mean_se(). Puisque cette fonction renvoie 3 valeurs (\\(\\bar{x}\\), \\(\\bar{x} - se\\) et \\(\\bar{x} + se\\)), on utilise reframe() :\n\ntemp_jour %&gt;% \n  reframe(mean_se(temperature_max), \n          .by = c(origin, month))\n\n# A tibble: 36 × 5\n   origin month     y  ymin  ymax\n   &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 EWR        1  5.69  4.55  6.82\n 2 EWR        2  4.74  3.97  5.50\n 3 EWR        3  8.20  7.55  8.85\n 4 EWR        4 16.4  15.5  17.4 \n 5 EWR        5 22.2  21.1  23.2 \n 6 EWR        6 27.4  26.6  28.1 \n 7 EWR        7 31.0  30.3  31.7 \n 8 EWR        8 27.8  27.4  28.2 \n 9 EWR        9 24.6  23.9  25.3 \n10 EWR       10 20.0  19.1  20.9 \n# ℹ 26 more rows\n\n\nLes résultats obtenus ne sont pas exactement au même format :\n\nla colonne y contient les valeurs de moyennes (\\(\\bar{x}\\))\nla colonne ymin contient la valeur de moyenne moins une fois l’erreur standard (\\(\\bar{x} - se\\))\nla colonne ymax contient la valeur de moyenne plus une fois l’erreur standard (\\(\\bar{x} + se\\))\n\nIl ne nous restera plus qu’à ajouter des barres d’erreur sur notre graphique pour visualiser l’incertitude associée à chaque valeur de moyenne."
  },
  {
    "objectID": "07-Incertitude.html#sec-confint",
    "href": "07-Incertitude.html#sec-confint",
    "title": "7  Dispersion et incertitude",
    "section": "7.5 Calculs d’intervalles de confiance à 95%",
    "text": "7.5 Calculs d’intervalles de confiance à 95%\nComme pour les erreurs standard, il est possible de calculer des intervalles de confiance de n’importe quel estimateur calculé à partir d’un échantillon, pour déterminer la gamme des valeurs les plus probables pour les paramètres équivalents dans la population générale. Nous nous concentrerons ici sur le calcul des intervalles de confiance à 95% de la moyenne, mais nous serons amenés à examiner également l’intervalle de confiance de la médiane, puis, au cours de votre L3, l’intervalle de confiance à 95% d’une différence de moyennes.\nContrairement à l’erreur standard, il n’y a pas qu’une bonne façon de calculer l’intervalle de confiance à 95% d’une moyenne. Plusieurs formules existent et le choix de la formule dépend en partie de la distribution des données (la distribution suit-elle une loi Normale ou non) et de la taille de l’échantillon dont nous disposons (\\(n\\) est-il supérieur à 30 ou non ?). Dans la situation idéale d’une variable qui suit la distribution Normale, les bornes inférieures et supérieures de l’intervalle de confiance à 95% sont obtenues grâce à cette formule\n\\[\\bar{x} - 1.96 \\cdot \\frac{s}{\\sqrt{n}} &lt; \\mu &lt; \\bar{x} + 1.96 \\cdot \\frac{s}{\\sqrt{n}}\\] Autrement dit, la vraie moyenne \\(\\mu\\) d’une population a de bonnes chances de se trouver dans un intervalle de plus ou moins 1.96 fois l’erreur standard de la moyenne. En première approximation, l’intervalle de confiance est donc la moyenne de l’échantillon \\(\\bar{x}\\) plus ou moins 2 fois l’erreur standard (que nous avons appris à calculer à la main un peu plus tôt). On peut donc calculer à la main les bornes inférieures et supérieures de l’intervalle de confiance ainsi :\n\ntemp_jour %&gt;% \n  reframe(mean_se(temperature_max, mult = 1.96),\n          .by = c(origin, month))\n\n# A tibble: 36 × 5\n   origin month     y  ymin  ymax\n   &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 EWR        1  5.69  3.46  7.92\n 2 EWR        2  4.74  3.24  6.23\n 3 EWR        3  8.20  6.93  9.47\n 4 EWR        4 16.4  14.6  18.2 \n 5 EWR        5 22.2  20.1  24.2 \n 6 EWR        6 27.4  25.8  28.9 \n 7 EWR        7 31.0  29.6  32.3 \n 8 EWR        8 27.8  27.0  28.5 \n 9 EWR        9 24.6  23.2  26.0 \n10 EWR       10 20.0  18.3  21.7 \n# ℹ 26 more rows\n\n\nIci, grâce à l’argument mult = 1.96 de la fonction mean_se() :\n\nla colonne ymin contient maintenant les valeurs de moyennes moins 1.96 fois l’erreur standard\nla colonne ymax contient maintenant les valeurs de moyennes plus 1.96 fois l’erreur standard\n\nDans la pratique, puisque cette méthode reste approximative et dépend de la nature des données dont on dispose, on utilisera plutôt des fonctions spécifiques qui calculeront pour nous les intervalles de confiance à 95% de nos estimateurs. C’est ce que permet en particulier la fonction mean_cl_normal() du package ggplot2. Il est toutefois important de bien comprendre qu’il y a un lien étroit entre l’erreur standard (l’incertitude associées à l’estimation d’un paramètre d’une population à partir des données d’un échantillon), et l’intervalle de confiance à 95% de ce paramètre.\n\ntemp_jour %&gt;% \n  reframe(mean_cl_normal(temperature_max),\n            .by = c(origin, month))\n\n# A tibble: 36 × 5\n   origin month     y  ymin  ymax\n   &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 EWR        1  5.69  3.36  8.01\n 2 EWR        2  4.74  3.17  6.30\n 3 EWR        3  8.20  6.88  9.53\n 4 EWR        4 16.4  14.6  18.3 \n 5 EWR        5 22.2  20.1  24.2 \n 6 EWR        6 27.4  25.8  28.9 \n 7 EWR        7 31.0  29.5  32.4 \n 8 EWR        8 27.8  27.0  28.6 \n 9 EWR        9 24.6  23.1  26.0 \n10 EWR       10 20.0  18.2  21.8 \n# ℹ 26 more rows\n\n\nComme dans les tableaux précédents, 3 nouvelles colonnes ont été crées :\n\ny contient toujours la moyenne des températures mensuelles pour chaque aéroport\nymin contient maintenant les bornes inférieures de l’intervalle à 95% des moyennes\nymax contient maintenant les bornes supérieures de l’intervalle à 95% des moyennes\n\nPour que la suite soit plus claire, nous allons afficher et donner des noms à ces différents tableaux en prenant soin de renommer les colonnes pour plus de clarté.\nTout d’abord, nous disposons du tableau temperatures_se, qui contient, les moyennes des températures mensuelles de chaque aéroport de New York en 2013, et les erreurs standard de ces moyennes :\n\ntemperatures_se\n\n# A tibble: 36 × 5\n   origin month moyenne N_obs erreur_standard\n   &lt;chr&gt;  &lt;int&gt;   &lt;dbl&gt; &lt;int&gt;           &lt;dbl&gt;\n 1 EWR        1    5.69    31           1.14 \n 2 EWR        2    4.74    28           0.762\n 3 EWR        3    8.20    31           0.649\n 4 EWR        4   16.4     30           0.919\n 5 EWR        5   22.2     31           1.02 \n 6 EWR        6   27.4     30           0.769\n 7 EWR        7   31.0     31           0.700\n 8 EWR        8   27.8     31           0.385\n 9 EWR        9   24.6     30           0.716\n10 EWR       10   20.0     31           0.882\n# ℹ 26 more rows\n\n\nEnsuite, nous avons produit un tableau presque équivalent que nous allons nommer temperature_se_bornes et pour lequel nous allons modifier le nom des colonnes y, ymin et ymax :\n\ntemperature_se_bornes &lt;- temp_jour %&gt;% \n  reframe(mean_se(temperature_max),\n            .by = c(origin, month)) %&gt;% \n  rename(moyenne = y,\n         moyenne_moins_se = ymin,\n         moyenne_plus_se = ymax)\n\ntemperature_se_bornes\n\n# A tibble: 36 × 5\n   origin month moyenne moyenne_moins_se moyenne_plus_se\n   &lt;chr&gt;  &lt;int&gt;   &lt;dbl&gt;            &lt;dbl&gt;           &lt;dbl&gt;\n 1 EWR        1    5.69             4.55            6.82\n 2 EWR        2    4.74             3.97            5.50\n 3 EWR        3    8.20             7.55            8.85\n 4 EWR        4   16.4             15.5            17.4 \n 5 EWR        5   22.2             21.1            23.2 \n 6 EWR        6   27.4             26.6            28.1 \n 7 EWR        7   31.0             30.3            31.7 \n 8 EWR        8   27.8             27.4            28.2 \n 9 EWR        9   24.6             23.9            25.3 \n10 EWR       10   20.0             19.1            20.9 \n# ℹ 26 more rows\n\n\nNous avons ensuite calculé manuellement des intervalles de confiance approximatifs, avec la fonction mean_se() et son argument mult = 1.96. Là encore, nous allons stocker cet objet dans un tableau nommé temperatures_ci_approx, et nous allons modifier le nom des colonnes y, ymin, et ymax :\n\ntemperature_ci_approx &lt;- temp_jour %&gt;% \n  reframe(mean_se(temperature_max, mult = 1.96),\n          .by = c(origin, month)) %&gt;% \n  rename(moyenne = y,\n         ci_borne_inf = ymin,\n         ci_borne_sup = ymax)\n\ntemperature_ci_approx\n\n# A tibble: 36 × 5\n   origin month moyenne ci_borne_inf ci_borne_sup\n   &lt;chr&gt;  &lt;int&gt;   &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n 1 EWR        1    5.69         3.46         7.92\n 2 EWR        2    4.74         3.24         6.23\n 3 EWR        3    8.20         6.93         9.47\n 4 EWR        4   16.4         14.6         18.2 \n 5 EWR        5   22.2         20.1         24.2 \n 6 EWR        6   27.4         25.8         28.9 \n 7 EWR        7   31.0         29.6         32.3 \n 8 EWR        8   27.8         27.0         28.5 \n 9 EWR        9   24.6         23.2         26.0 \n10 EWR       10   20.0         18.3         21.7 \n# ℹ 26 more rows\n\n\nEnfin, nous avons calculé les intervalles de confiance avec une fonction spécialement dédiée à cette tâche : la fonction mean_cl_normal(). Nous allons stocker cet objet dans un tableau nommé temperatures_ci, et nous allons modifier le nom des colonnes y, ymin, et ymax :\n\ntemperature_ci &lt;- temp_jour %&gt;% \n  reframe(mean_cl_normal(temperature_max),\n          .by = c(origin, month)) %&gt;% \n  rename(moyenne = y,\n         ci_borne_inf = ymin,\n         ci_borne_sup = ymax)\n\ntemperature_ci\n\n# A tibble: 36 × 5\n   origin month moyenne ci_borne_inf ci_borne_sup\n   &lt;chr&gt;  &lt;int&gt;   &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n 1 EWR        1    5.69         3.36         8.01\n 2 EWR        2    4.74         3.17         6.30\n 3 EWR        3    8.20         6.88         9.53\n 4 EWR        4   16.4         14.6         18.3 \n 5 EWR        5   22.2         20.1         24.2 \n 6 EWR        6   27.4         25.8         28.9 \n 7 EWR        7   31.0         29.5         32.4 \n 8 EWR        8   27.8         27.0         28.6 \n 9 EWR        9   24.6         23.1         26.0 \n10 EWR       10   20.0         18.2         21.8 \n# ℹ 26 more rows\n\n\nMaintenant, si l’on compare les 2 tableaux contenant les calculs d’intervalles de confiance de la moyenne, on constate que les résultats sont très proches :\n\ntemperature_ci_approx\ntemperature_ci\n\n\n\n# A tibble: 36 × 5\n   origin month moyenne ci_borne_inf ci_borne_sup\n   &lt;chr&gt;  &lt;int&gt;   &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n 1 EWR        1    5.69         3.46         7.92\n 2 EWR        2    4.74         3.24         6.23\n 3 EWR        3    8.20         6.93         9.47\n 4 EWR        4   16.4         14.6         18.2 \n 5 EWR        5   22.2         20.1         24.2 \n 6 EWR        6   27.4         25.8         28.9 \n 7 EWR        7   31.0         29.6         32.3 \n 8 EWR        8   27.8         27.0         28.5 \n 9 EWR        9   24.6         23.2         26.0 \n10 EWR       10   20.0         18.3         21.7 \n# ℹ 26 more rows\n\n\n# A tibble: 36 × 5\n   origin month moyenne ci_borne_inf ci_borne_sup\n   &lt;chr&gt;  &lt;int&gt;   &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n 1 EWR        1    5.69         3.36         8.01\n 2 EWR        2    4.74         3.17         6.30\n 3 EWR        3    8.20         6.88         9.53\n 4 EWR        4   16.4         14.6         18.3 \n 5 EWR        5   22.2         20.1         24.2 \n 6 EWR        6   27.4         25.8         28.9 \n 7 EWR        7   31.0         29.5         32.4 \n 8 EWR        8   27.8         27.0         28.6 \n 9 EWR        9   24.6         23.1         26.0 \n10 EWR       10   20.0         18.2         21.8 \n# ℹ 26 more rows\n\n\n\n\nLes bornes inférieures et supérieures des intervalles de confiance à 95% des moyennes ne sont pas égales quand on les calcule manuellement de façon approchée et quand on les calcule de façon exacte, mais les différences sont minimes."
  },
  {
    "objectID": "08-ErrorBars.html#pré-requis",
    "href": "08-ErrorBars.html#pré-requis",
    "title": "8  Visualiser l’incertitude et la dispersion",
    "section": "8.1 Pré-requis",
    "text": "8.1 Pré-requis\nNous avons ici besoin des packages suivants :\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(nycflights13)\n\nPensez à les charger en mémoire si ce n’est pas déjà fait ou si vous venez de démarrer une nouvelle session de travail.\nIl existe plusieurs façons de représenter visuellement les positions, les dispersions et les incertitudes. Concernant les positions et les dispersions tout d’abord, nous avons déjà vu plusieurs façons de faire au semestre 3, en particulier dans les parties consacrées aux histogrammes, aux stripcharts et aux boxplots. Nous reprenons ici brièvement chacun de ces 3 types de graphique afin de les remettre en contexte avec ce que nous avons appris ici.\nDans un dernier temps, nous verrons comment visualiser l’incertitude associée à des calculs de moyennes ou de variances grâce aux barres d’erreurs ou aux encoches des boîtes à moustaches."
  },
  {
    "objectID": "08-ErrorBars.html#position-et-dispersion-les-histogrammes",
    "href": "08-ErrorBars.html#position-et-dispersion-les-histogrammes",
    "title": "8  Visualiser l’incertitude et la dispersion",
    "section": "8.2 Position et dispersion : les histogrammes",
    "text": "8.2 Position et dispersion : les histogrammes\nJe vous renvoie à la partie sur les histogrammes du livre en ligne de biométrie du semestre 3 si vous avez besoin de vous rafraîchir la mémoire. Jetez aussi un œil la partie sur les histogrammes facettés.\nLes histogrammes permettent de déterminer à la fois où se trouvent les valeurs les plus fréquemment observées (la position du pic principal correspond à la tendance centrale), et la dispersion (ou variabilité) des valeurs autour de la tendance centrale. Par exemple, la fonction facet_grid() permet de faire des histogrammes des températures pour chaque aéroport de New York et chaque mois de l’année 2013 :\n\nweather %&gt;% \n  mutate(temp_celsius = (temp - 32) / 1.8) %&gt;% \n  ggplot(aes(x = temp_celsius, fill = factor(month))) +\n  geom_histogram(bins = 20, color = \"grey20\", show.legend = FALSE) +\n  facet_grid(factor(month) ~ origin, scales = \"free_y\") +\n  labs(x = \"Températures (ºC)\", y = \"Fréquence\") +\n  theme_bw()\n\nWarning: Removed 1 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nIci, 36 histogrammes sont produits. Ils permettent de constater que :\n\nles températures évoluent à peu près de la même façon dans les 3 aéroports (les 3 colonnes de graphiques se ressemblent beaucoup).\nles températures moyennes sont plus faibles en hiver qu’en été, et qu’elles sont intermédiaires au printemps et à l’automne. C’est bien la position des pics sur l’axe des abscisses qui nous renseigne là-dessus. On sait aussi que les températures moyennes les plus fortes sont autour de 25ºC en juillet, alors que ces mêmes températures moyennes sont proches de 0ºC en janvier, février et décembre.\nla variabilité des températures est comparable pour la plupart des mois de l’année, avec une exception au mois d’août où la dispersion des valeurs semble plus limitée. Cette fois, c’est l’étalement de l’histogramme qui nous renseigne sur la dispersion."
  },
  {
    "objectID": "08-ErrorBars.html#position-et-dispersion-les-stripcharts",
    "href": "08-ErrorBars.html#position-et-dispersion-les-stripcharts",
    "title": "8  Visualiser l’incertitude et la dispersion",
    "section": "8.3 Position et dispersion : les stripcharts",
    "text": "8.3 Position et dispersion : les stripcharts\nUne autre façon de visualiser à la fois les tendances centrales et les dispersions consiste à produire un nuage de points “stripchart”. Là encore, je vous renvoie à la partie sur les stripcharts du livre en ligne de biométrie du semestre 3 si vous avez besoin de vous rafraîchir la mémoire.\n\nweather %&gt;% \n  mutate(temp_celsius = (temp - 32) / 1.8) %&gt;% \n  ggplot(aes(x = factor(month), y = temp_celsius, fill = factor(month))) +\n  geom_jitter(shape = 21, color = \"grey20\", show.legend = FALSE,\n              width = 0.15, height = 0,\n              alpha = 0.5) +\n  facet_wrap(~ origin, ncol = 1) +\n  labs(x = \"Mois\", y = \"Températures (ºC)\") +\n  theme_bw()\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n\n\n\n\n\nCette fois, nous visualisons la totalité des données disponibles, et non les données regroupées dans des classes plus ou moins arbitraires. Mais là encore, on peut facilement comparer la position de chaque série de données : pour les mois d’été, les températures sont plus élevées que pour les mois d’hiver. Et la dispersion des données est aussi facile à comparer entre les mois. Par exemple, la variabilité des températures en janvier est nettement supérieure à celle du mois de février. C’est ici l’étendue du nuage de points sur l’axe des ordonnées qui nous permet de le dire."
  },
  {
    "objectID": "08-ErrorBars.html#position-et-dispersion-les-boxplots",
    "href": "08-ErrorBars.html#position-et-dispersion-les-boxplots",
    "title": "8  Visualiser l’incertitude et la dispersion",
    "section": "8.4 Position et dispersion : les boxplots",
    "text": "8.4 Position et dispersion : les boxplots\nLa dernière façon classique de visualiser à la fois les tendances centrales et les dispersions consiste à produire un graphique boîtes à moustaches, ou “boxplot”. Là encore, je vous renvoie à la partie sur les boxplots du livre en ligne de biométrie du semestre 3 si vous avez besoin de vous rafraîchir la mémoire.\n\nweather %&gt;% \n  mutate(temp_celsius = (temp - 32) / 1.8) %&gt;% \n  ggplot(aes(x = factor(month), y = temp_celsius, fill = factor(month))) +\n  geom_boxplot(show.legend = FALSE, alpha = 0.5) +\n  facet_wrap(~ origin, ncol = 1) +\n  labs(x = \"Mois\", y = \"Températures (ºC)\") +\n  theme_bw()\n\nWarning: Removed 1 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nVous voyez que le code est très proche pour produire un stripchart ou un boxplot. Comme indiqué au semestre 3, les différents éléments de chaque boîte nous renseignent sur la position et sur la dispersion des données pour chaque mois et chaque aéroport :\n\nLa limite inférieure de la boîte correspond au premier quartile : 25% des données de l’échantillon sont situées au-dessous de cette valeur.\nLa limite supérieure de la boîte correspond au troisième quartile : 75% des données de l’échantillon sont situées au-dessous de cette valeur.\nLe segment épais à l’intérieur de la boîte correspond au second quartile : c’est la médiane de l’échantillon, qui nous renseigne sur la position de la distribution. 50% des données de l’échantillon sont situées au-dessus de cette valeur, et 50% au-dessous.\nLa hauteur de la boîte correspond à l’étendue (ou intervalle) interquartile ou Inter Quartile Range (IQR) en anglais. On trouve dans cette boîte 50% des observations de l’échantillon. C’est une mesure de la dispersion des 50% des données les plus centrales. Une boîte plus allongée indique donc une plus grande dispersion.\nLes moustaches correspondent à des valeurs qui sont en dessous du premier quartile (pour la moustache du bas) et au-dessus du troisième quartile (pour la moustache du haut). La règle utilisée dans R est que ces moustaches s’étendent jusqu’aux valeurs minimales et maximales de l’échantillon, mais elles ne peuvent en aucun cas s’étendre au-delà de 1,5 fois la hauteur de la boîte (1,5 fois l’IQR) vers le haut et le bas. Si des points apparaissent au-delà des moustaches (vers le haut ou le bas), ces points sont appelés “outliers”. On peut en observer ici pour plusieurs mois et pour les 3 aéroports (par exemple, en avril dans les 3 aéroports). Ce sont des points qui s’éloignent du centre de la distribution de façon importante puisqu’ils sont au-delà de 1,5 fois l’IQR de part et d’autre du premier ou du troisième quartile. Il peut s’agir d’anomalies de mesures, d’anomalies de saisie des données, ou tout simplement, d’enregistrements tout à fait valides mais atypiques ou extrêmes ; ll ne s’agit donc pas toujours de point aberrants. J’attire votre attention sur le fait que la définition de ces outliers est relativement arbitraire. Nous pourrions faire le choix d’étendre les moustaches jusqu’à 1,8 fois l’IQR (ou 2, ou 2,5). Nous observerions alors beaucoup moins d’outliers. D’une façons générale, la longueur des moustaches renseigne sur la variabilité des données en dehors de la zone centrale. Plus elles sont longues, plus la variabilité est importante. Très souvent, l’examen attentif des outliers est utile car il nous permet d’en apprendre plus sur le comportement extrême de certaines observations.\n\nLorsque les boîtes ont une forme à peu près symétrique de part et d’autre de la médiane (c’est le cas pour cet exemple dans la plupart des catégories), cela signifie qu’un histogramme des mêmes données serait symétrique également.\nLes stripcharts et les boxplots sont donc un bon moyen de comparer rapidement la position et la dispersion d’un grand nombre de séries de données : ici, en quelques lignes de code, nous en comparons 12 pour chacun des 3 aéroports de New York.\nLes histogrammes sont plus utiles lorsqu’il y a moins de catégories à comparer. Ils permettent en outre de mieux visualiser les distributions non symétriques, ou qui présentent plusieurs pics (distribution bi- ou poly-modales)."
  },
  {
    "objectID": "08-ErrorBars.html#visualiser-lincertitude-les-barres-derreur",
    "href": "08-ErrorBars.html#visualiser-lincertitude-les-barres-derreur",
    "title": "8  Visualiser l’incertitude et la dispersion",
    "section": "8.5 Visualiser l’incertitude : les barres d’erreur",
    "text": "8.5 Visualiser l’incertitude : les barres d’erreur\nComme évoqué plus haut, il est important de ne pas confondre dispersion et incertitude. Lorsque l’on visualise des moyennes calculées à partir des données d’un échantillon, il est important de faire apparaître des barres d’erreurs, qui correspondent en général :\n\nsoit à l’erreur standard de la moyenne\nsoit à l’intervalle de confiance à 95% de la moyenne\n\nPuisque deux choix sont possibles, il sera important de préciser systématiquement dans la légende du graphique, la nature des barres représentées. Commençons par visualiser les températures mensuelles avec les erreurs standards. Pour cela, je reprends le tableau temperatures_se créé précédemment :\n\ntemperatures_se %&gt;% \n  ggplot(aes(x = factor(month), y = moyenne)) +\n  geom_line(aes(group = 1)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = moyenne - erreur_standard,\n                    ymax = moyenne + erreur_standard),\n                width = 0.1) +\n  facet_wrap(~origin, ncol = 1) +\n  labs(x = \"Mois\", \n       y = \"Moyenne des températures quotidiennes maximales (ºC)\") +\n  theme_bw()\n\n\n\n\nFigure 8.1: Températures moyennes mensuelles observées en 2013 dans les 3 aéroports de New York. Les barres d’erreur sont les erreurs standard\n\n\n\n\nVous remarquerez que :\n\nj’associe factor(month), et non simplement month, à l’axe des x afin d’avoir, sur l’axe des abscisses, des chiffres cohérents allant de 1 à 12, et non des chiffres à virgule.\nl’argument group = 1 doit être ajouté pour que la ligne reliant les points apparaisse. En effet, les lignes sont censées relier des points qui appartiennent à une même série temporelle. Or ici, nous avons transformé month en facteur. Préciser group = 1 permet d’indiquer à geom_line() que toutes les catégories du facteur month appartiennent au même groupe, que ce facteur peut être considéré comme une variable continue, et qu’il est donc correct de relier les points.\nla fonction geom_errorbar() contient de nouvelles caractéristiques esthétiques qu’il nous faut obligatoirement renseigner : les extrémités inférieures et supérieures des barres d’erreur. Il nous faut donc associer 2 variables à ces caractéristiques esthétiques. Ici, nous utilisons moyenne - erreur_std pour la borne inférieure des barres d’erreur, et moyenne + erreur_std pour la borne supérieure. Les variables moyenne et erreur_standard faisant partie du tableau temperatures_se, geom_errorbar() les trouve sans difficulté.\nl’argument width de la fonction geom_errorbar() permet d’indiquer la longueur des segments horizontaux qui apparaissent à chaque extrémité des barres d’erreur.\n\nIci, bien que moins lisible, on peut aussi faire apparaître les trois courbes sur le même graphique, afin de mieux visualiser les similarités des fluctuations de températures entre les 3 aéroports :\n\ntemperatures_se %&gt;% \n  ggplot(aes(x = factor(month), y = moyenne, color = origin, group = origin)) +\n  geom_line() +\n  geom_point() +\n  geom_errorbar(aes(ymin = moyenne - erreur_standard,\n                    ymax = moyenne + erreur_standard),\n                width = 0.1) +\n  labs(x = \"Mois\", \n       y = \"Moyenne des températures quotidiennes maximales (ºC)\",\n       color = \"Aéroport\") +\n  theme_bw()\n\n\n\n\nFigure 8.2: Températures moyennes mensuelles observées en 2013 dans les 3 aéroports de New York. Les barres d’erreur sont les erreurs standard.\n\n\n\n\nNous pouvons arriver au même résultats en utilisant le tableau temperature_se_bornes, qui contient des variables différentes :\n\ntemperature_se_bornes %&gt;% \n  ggplot(aes(x = factor(month), y = moyenne, color = origin, group = origin)) +\n  geom_line() +\n  geom_point() +\n  geom_errorbar(aes(ymin = moyenne_moins_se,\n                    ymax = moyenne_plus_se),\n                width = 0.1) +\n  labs(x = \"Mois\", \n       y = \"Moyenne des températures quotidiennes maximales (ºC)\",\n       color = \"Aéroport\") +\n  theme_bw()\n\n\n\n\nFigure 8.3: Températures moyennes mensuelles observées en 2013 dans les 3 aéroports de New York. Les barres d’erreur sont les erreurs standard.\n\n\n\n\nDe la même façon, nous pouvons parfaitement faire apparaître, au lieu des erreurs standards, les intervalles de confiance à 95% de chaque valeur de température moyenne. Il nous suffit pour cela d’utiliser le tableau temperatures_ci qui contient les valeurs de moyennes et des bornes supérieures et inférieures de ces intervalles :\n\ntemperature_ci %&gt;% \n  ggplot(aes(x = factor(month), y = moyenne, group = 1)) +\n  geom_line() +\n  geom_point() +\n  geom_errorbar(aes(ymin = ci_borne_inf, ymax = ci_borne_sup), width = 0.1) +\n  facet_wrap(~origin, ncol = 1) +\n  labs(x = \"Mois\", \n       y = \"Moyenne des températures quotidiennes maximales (ºC)\",\n       color = \"Aéroport\") +\n  theme_bw()\n\n\n\n\nFigure 8.4: Températures moyennes mensuelles observées en 2013 dans les 3 aéroports de New York. Les barres d’erreur sont les intervalels de confiance à 95% des moyenes mensuelles.\n\n\n\n\nComme vous voyez, les barres d’erreurs sont maintenant plus longues que sur la Figure 8.1. C’est normal car rappelez-vous que les intervalles de confiance sont à peu près équivalents à 2 fois les erreurs standards. L’intérêt de représenter les intervalles de confiance est qu’ils sont directement liés aux tests statistiques que nous aborderons en L3. Globalement, quand 2 séries de données ont des intervalles de confiance qui se chevauchent largement (comme les mois de janvier et février par exemple), alors, un test d’hypothèses conclurait presque toujours à l’absence de différence significative entre les 2 groupes. À l’inverse, quand 2 séries de données ont des intervalles de confiance qui ne se chevauchent pas du tout (comme les mois de mars et d’avril par exemple), alors, un test d’hypothèses conclurait presque toujours à l’existence d’une différence significative entre les 2 groupes. Lorsque les intervalles de confiance entre 2 catégories se chevauchent faiblement ou partiellement (comme entre les mois de juin et juillet pour l’aéroport LGA), la situation est moins tranchée, et nous devrons nous en remettre aux résultats du test pour savoir si la différence observée devrait être considérée comme significative ou non."
  },
  {
    "objectID": "08-ErrorBars.html#visualiser-lincertitude-les-boîtes-à-moustaches",
    "href": "08-ErrorBars.html#visualiser-lincertitude-les-boîtes-à-moustaches",
    "title": "8  Visualiser l’incertitude et la dispersion",
    "section": "8.6 Visualiser l’incertitude : les boîtes à moustaches",
    "text": "8.6 Visualiser l’incertitude : les boîtes à moustaches\nOutre les informations de position et de dispersion, les boîtes à moustaches permettent également de visualiser l’incertitude associée aux médianes. Il suffit pour cela d’ajouter l’argument notch = TRUE dans la fonction geom_boxplot() :\n\nweather %&gt;% \n  mutate(temp_celsius = (temp - 32) / 1.8) %&gt;% \n  ggplot(aes(x = factor(month), y = temp_celsius, fill = factor(month))) +\n  geom_boxplot(show.legend = FALSE, alpha = 0.5, notch = TRUE) +\n  facet_wrap(~ origin, ncol = 1) +\n  labs(x = \"Mois\", y = \"Températures (ºC)\") +\n  theme_bw()\n\nWarning: Removed 1 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nDes encoches ont été ajoutées autour de la médiane de chaque boîte à moustache. Ces encoches sont des encoches d’incertitudes. Les limites inférieures et supérieures de ces encoches correspondent aux bornes inférieures et supérieures de l’intervalle de confiance à 95% des médianes. Comme pour les moyennes, le chevauchement ou l’absence de chevauchement entre les encoches de 2 séries de données nous renseigne sur l’issue probable des futurs tests statistiques que nous serions amenés à réaliser. Il sera donc important de bien examiner ces encoches en amont des tests statistiques pour éviter de faire/dire des bêtises…"
  },
  {
    "objectID": "08-ErrorBars.html#sec-ploterrbar",
    "href": "08-ErrorBars.html#sec-ploterrbar",
    "title": "8  Visualiser l’incertitude et la dispersion",
    "section": "8.7 Exercice",
    "text": "8.7 Exercice\n\nAvec le tableau penguins, calculez les grandeurs suivantes pour chaque espèce de manchot et chaque sexe :\n\n\nla moyenne de la longueur des nageoires\nla variance de la longueur des nageoires\nl’écart-type de la longueur des nageoires\nl’erreur standard de la longueur moyenne des nageoires\nla moyenne de la masse corporelle\nla variance de la masse corporelle\nl’écart-type de la masse corporelle\nl’erreur standard de la masse corporelle moyenne\n\nAttention : pensez à retirer les individus dont le sexe est inconnu.\n\nVérifiez avec la fonction skim() que les moyennes et écart-types calculés ci-dessus sont corrects.\nAvec ces données synthétiques faites le graphique suivant :"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Gorman, Kristen B., Tony D. Williams, and William R Fraser. 2014.\n“Ecological Sexual Dimorphism and Environmental Variability Within\na Community of Antarctic Penguins (Genus Pygoscelis).” PLOS\nONE 9 (March): 1–14. https://doi.org/10.1371/journal.pone.0090081.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022.\nPalmerpenguins: Palmer Archipelago (Antarctica) Penguin Data.\nhttps://CRAN.R-project.org/package=palmerpenguins.\n\n\nJeppson, Haley, Heike Hofmann, and Di Cook. 2021. Ggmosaic: Mosaic\nPlots in the Ggplot2 Framework. https://github.com/haleyjeppson/ggmosaic.\n\n\nWaring, Elin, Michael Quinn, Amelia McNamara, Eduardo Arino de la Rubia,\nHao Zhu, and Shannon Ellis. 2022. Skimr: Compact and Flexible\nSummaries of Data. https://CRAN.R-project.org/package=skimr.\n\n\nWickham, Hadley. 2021. Nycflights13: Flights That Departed NYC in\n2013. https://github.com/hadley/nycflights13.\n\n\n———. 2023. Tidyverse: Easily Install and Load the Tidyverse. https://CRAN.R-project.org/package=tidyverse.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen,\nKohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey\nDunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using\nthe Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis\nVaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2023. Readr: Read\nRectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWickham, Hadley, Davis Vaughan, and Maximilian Girlich. 2023. Tidyr:\nTidy Messy Data. https://CRAN.R-project.org/package=tidyr.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. 2nd ed.\nNew-York: Springer-Verlag. https://www.springer.com/us/book/9780387245447."
  }
]