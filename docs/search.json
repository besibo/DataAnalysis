[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Analyse de Données",
    "section": "",
    "text": "Introduction"
  },
  {
    "objectID": "index.html#objectifs",
    "href": "index.html#objectifs",
    "title": "Analyse de Données",
    "section": "Objectifs",
    "text": "Objectifs\nCe livre contient l’ensemble du matériel (contenus, exemples, exercices…) nécessaire à la réalisation des travaux pratiques de l’EC Stratégie d’échantillonnage et analyse de données consacrés à la prise en main de R et RStudio.\nCes travaux pratiques ont essentiellement 4 objectifs :\n\nVous faire découvrir les logiciels R et Rstudio (Chapitre 1 et Chapitre 2) dans lesquels vous allez passer beaucoup de temps tout au long de votre cursus de master. Vous avez choisi une spécialité de master qui implique de traiter des données et de communiquer des résultats d’analyses statistiques : R et RStudio devraient être les logiciels vers lesquels vous vous tournez naturellement pour faire l’un et l’autre.\nVous apprendre à faire des graphiques de qualités dans RStudio et vous faire prendre conscience de l’importance des visualisations graphiques (Chapitre 3 : attention, ce chapitre est très long, ne vous laissez pas surprendre !) :\n\n\nd’une part, pour comprendre à quoi ressemblent les données en votre possession,\nd’autre part, pour vous permettre de formuler des hypothèses pertinentes et intéressantes concernant les systèmes que vous étudiez,\net enfin, pour communiquer efficacement vos trouvailles à un public qui ne connaît pas vos données aussi bien que vous (cela inclut évidemment vos enseignants à l’issue de vos stages).\nLes données que vous serez amenés à traiter lors de vos stages, ou plus tard, lorsque vous serez en poste, ont souvent été acquises à grands frais, et au prix d’efforts importants. Il est donc de votre responsabilité d’en tirer le maximum. Et ça commence toujours (ou presque), par la réalisation de visualisations graphiques parlantes.\n\n\nVous apprendre à manipuler efficacement des tableaux de données de grande taille (Chapitre 4 et Chapitre 5). Cela signifie que vous devriez être en mesure de sélectionner des variables (colonnes) d’un tableau, d’en créer de nouvelles en modifiant et/ou combinant des variables existantes, de filtrer des lignes spécifiques, d’effectuer des tris de données, de transformer des tableaux larges en tableaux longs (et réciproquement), d’effectuer des jointures entre plusieurs tableaux, etc.\nVous apprendre comment calculer des statistiques descriptives simples, sur plusieurs types de variables, et comment mettre en œuvre, dans RStudio, les procédures statistiques décrites en cours, afin de vous mettre dans les meilleures conditions possibles pour aborder d’une part les comptes-rendus de TP et rapports de stage que vous aurez à produire dans ce cursus de master et d’autre part les statistiques plus avancées que vous découvrirez lors des semestres 2 et 3. Vos enseignants attendent de vous la plus grande rigueur lorsque vous analysez et présentez des résultats d’analyses statistiques. Ces TP ont pour objectifs de vous fournir les bases nécessaires pour satisfaire ce niveau d’exigence.\n\nÀ l’issue de ces TP et TEA, vous devriez donc être suffisamment à l’aise avec le logiciel RStudio pour y importer des données issues de tableurs, les manipuler pour les mettre dans un format permettant les représentations graphiques et les analyses statistiques, pour produire des graphiques pertinents, adaptés aux données dont vous disposez, et d’une qualité vous permettant de les intégrer sans honte à vos compte-rendus de TP et rapports de stages, et de réaliser les tests et analyses statistiques les plus adaptés aux questions auxquelles vous tenterez de répondre.\nLes données que vous serez amenés à traiter lors de vos stages, ou plus tard, lorsque vous serez en poste, ont souvent été acquises à grands frais, et au prix d’efforts importants. Il est donc de votre responsabilité d’en tirer le maximum. Et ça commence toujours (ou presque), par la manipulation de données dans RStudio et la réalisation de visualisations graphiques parlantes. Se lancer dans les tests statistiques sans avoir une idée claire de la structure des données dont on dispose est toujours une erreur. C’est pourquoi les chapitres consacrés aux statistiques n’arrivent que dans la seconde partie de ce livre en ligne. En règle générale, face à une question scientifique précise, lorsque l’on traite des données, environ 80% du temps est consacré à la mise en forme et l’exploration (statistique et graphique) des données. La réalisation des tests et leur interprétation ne prend que rarement plus de 20% du temps. Cela souligne l’importance des 5 premiers chapitres de ce livre en ligne : plus vous serez à l’aise avec les notions et concepts décrits dans ces chapitres, plus vous serez efficaces et plus vous gagnerez du temps par la suite.\n\n\n\n\n\n\nImportant\n\n\n\nÀ partir de maintenant, tous les compte-rendus de TP que vous aurez à produire dans le cadre du master Gestion de l’Environnement et Écologie Littorale devront respecter les bonnes pratiques décrites dans ce document. En particulier, les collègues de l’équipe pédagogique attendent que les graphiques que vous intégrerez à vos compte-rendus de TP soient systématiquement produits dans RStudio. C’est la raison pour laquelle cet enseignement arrive si tôt dans votre cursus."
  },
  {
    "objectID": "index.html#organisation",
    "href": "index.html#organisation",
    "title": "Analyse de Données",
    "section": "Organisation",
    "text": "Organisation\nAu total, la partie analyse de données de l’EC “Stratégie d’échantillonnage et analyse de données” contient :\n\n15 heures de cours magistraux\n9 heures de travaux pratiques (pour chaque groupe)\n16 heures de TEA\n\n\nLes cours magistraux\nLes cours magistraux sont globalement découpés en 2 blocs à peu près indépendants :\n\nun bloc de 10 heures consacrées aux notions statistiques élémentaires, aux statistiques descriptives et aux statistiques inférentielles. Nous couvrirons notamment les notions d’incertitude et d’inférence, les tests d’hypothèses, la comparaison de proportions, l’ajustement de données observées à des distributions théoriques, l’analyse de tables de contingences, les comparaisons de moyennes, les régressions linéaires, les ANOVA et ANCOVA…\nun bloc de 5 heures consacrées aux statistiques multivariées telles que l’Analyse en Composantes Principales (ACP) et l’Analyse Factorielle des Correspondances (AFC).\n\nMon objectif n’est pas de survoler l’ensemble du matériel dans ce faible volume horaire : s’il n’est pas suffisant, nous ajouterons quelques séances afin de traiter correctement l’ensemble du matériel. Je suis convaincu que tout le monde est capable de comprendre les grands principes des statistiques, et de réaliser des analyses dans un logiciel tel que R, y compris les plus réfractaires aux mathématiques et à l’informatique. Mais il est nécessaire de démystifier cette discipline essentielle, et si certains ont besoin de plus de temps que d’autres, nous prendrons ce temps. Les TP et TEA, décrits plus bas, sont justement organisés pour permettre à chacun d’avancer à son rythme. Mais ne vous y trompez pas, cela vous demandera beaucoup de travail pendant ces 3 semaines.\nTous les aspects vus en cours seront en effet développés lors des séances de TP et de TEA. Vous aurez, pour chaque partie, des exercices à préparer et nous les corrigerons ensemble lors des séances de TP et/ou de TEA. ils doivent d’une part vous préparer aux évaluations (voir plus bas) mais surtout, vous permettre d’acquérir des compétences en analyse de données, compétences qui seront attendues de vous lorsque vous sortirez diplômé·e de ce master.\n\n\nLes Travaux pratiques\nLe contenu des séances de travaux pratiques sera découpé en 3 parties (inégales) :\n\nPrise en main des logiciels R et RStudio\nIllustration du cours sur les statistiques descriptives et inférentielles, mise en pratique et réalisation d’exercices\nIllustration du cours sur les statistiques multivariées, mise en pratique et réalisation d’exercices\n\nPour chaque séance de TP, vous travaillerez soit à distance, soit en salle banalisée, sur vos ordinateurs personnels. La première séance aura lieu en présentiel et sera consacrée à l’installation des logiciels ainsi qu’à la présentation de l’organisation des séances.\nLes séances de travaux pratiques ne seront pas toutes obligatoires : seules quelques séances en présentiel (les dates vous seront présentées ultérieurement) le seront, probablement pas plus d’une ou deux par semaine.\n\n\n\n\n\n\nImportant\n\n\n\nL’essentiel du contenu de cet enseignement peut être abordé en autonomie, à distance, grâce à ce livre en ligne, aux ressources mises à disposition sur Moodle et à votre ordinateur personnel. Cela signifie que la présence physique lors de ces séances de TP n’est pas obligatoire.\n\n\nPour toutes les autres séances, le fonctionnement sera celui d’une permanence non obligatoire : seuls celles et ceux qui en éprouvent le besoin sont tenus de se déplacer. Ces séances de permanence n’auront lieu que si certains parmi vous m’ont fait part de difficultés ou ont formulé des questions en amont des séances. Si aucune question ne m’a été posée en amont, les permanences n’auront pas lieu. Si une permanence a lieu, elle est ouverte à tous, quel que soit votre groupe de TP. Vous n’êtes d’ailleurs pas tenus de rester pendant 90 minutes : vous venez avec votre question, on y répond ensemble, et vous êtes libres de repartir quand bon vous semble. Les années précédentes, je voyais certains de vos collègues à chaque séance de permanence alors que d’autres ne sont jamais venus. Si vous n’en avez pas besoin, libre à vous de ne pas venir. Tant que le travail est fait et que les exercices ne vous posent pas de problème, vous êtes libres de vous organiser comme vous l’entendez.\nAttention toutefois, venir à une séance de permanence en n’ayant pas préparé de question au préalable ne vous sera d’aucune aide. C’est parce que vous avez travaillé en amont de ces séances et que vous arrivez avec des questions que ces permanences sont utiles et efficaces. Donc si vous venez, c’est que vous avez bossé en amont !\nCe fonctionnement très souple a de nombreux avantages :\n\nvous vous organisez comme vous le souhaitez\nvous ne venez que lorsque vous en avez vraiment besoin\ncelles et ceux qui se déplacent reçoivent une aide personnalisée “sur mesure”\nvous travaillez sur vos ordinateurs\nles effectifs étant réduits, les conditions de travail sont idéales\n\nToutefois, pour que cette organisation fonctionne, cela demande de la rigueur de votre part, en particulier sur la régularité du travail que vous devez fournir. Si la présence en salle de TP n’est pas requise, le travail demandé est bel et bien obligatoire ! Si vous venez en salle de TP sans avoir travaillé en amont, votre venue sera totalement inutile puisque vous n’aurez pas de question à poser et que vous passerez votre séance à lire ce livre en ligne. Vous perdrez donc votre temps, celui de vos collègues, et le mien. De même, si vous attendez la 3e semaine pour vous y mettre, vous irez droit dans le mur. Outre les heures de TP/TEA prévues dans vos emplois du temps, vous devez donc prévoir du travail personnel supplémentaire, chaque jour ou presque.\n\n\nUtilisation de Slack\n\n\n\n\n\n\nComment savoir si une séance de permanence a lieu, comment poser une question ?\n\n\n\nTout se passera en ligne, grâce au logiciel Slack, qui fonctionne un peu comme un “twitter privé”.\n\n\nSlack facilite la communication des équipes et permet de travailler ensemble. Créez-vous un compte en ligne et installez le logiciel sur votre ordinateur (il existe aussi des versions pour tablettes et smartphones). Lorsque vous aurez installé le logiciel, cliquez sur ce lien pour vous connecter à notre espace de travail commun, et reprenez la lecture de ce document.\nVous verrez que 3 “chaînes” sont disponibles :\n\n#organisation : c’est là que les questions liées à l’organisation du cours, des TP et TEA doivent être posées. Si vous ne savez pas si une séance de permanence a lieu, posez la question ici.\n#rstudio : c’est ici que toutes les questions pratiques liées à l’utilisation de R et RStudio devront êtres posées. Problèmes de syntaxe, problèmes liés à l’interface, à l’installation des packages ou à l’utilisation des fonctions… Tout ce qui concerne R ou RStudio mais pas directement les statistiques sera traité ici. Vous êtes libres de poser des questions, de poster des captures d’écran, des morceaux de code, des messages d’erreur. Et vous êtes bien entendus vivement encouragés à vous entraider et à répondre aux questions de vos collègues. Je n’interviendrai ici que pour répondre aux questions laissées sans réponse ou si les réponses apportées sont inexactes. Le fonctionnement est celui d’un forum de discussion instantané. Vous en tirerez le plus grand bénéfice en participant et en n’ayant pas peur de poser des questions, même si elles vous paraissent idiotes. Rappelez-vous toujours que si vous vous posez une question, d’autres se la posent aussi probablement.\n#statistiques : c’est ici que toutes les questions liées aux méthodes statistiques devront être posées. Comme pour la chaîne #rstudio, vous êtes encouragés à poster des questions mais aussi des réponses. Le fonctionnement de l’ensemble se veut participatif.\n\nAinsi, quand vous travaillerez à vos TP ou TEA, prenez l’habitude de garder Slack ouvert sur votre ordinateur. Même si vous n’avez pas de question à poser, votre participation active pour répondre à vos collègues est souhaitable et souhaitée. Votre niveau de participation sur Slack pourra faire partie de votre note finale.\nSi toutes les questions posées sur Slack ont trouvé une réponse, alors, inutile d’organiser une permanence. Si en revanche, certains n’ont pas compris, si les mêmes questions reviennent fréquemment, ou si des explications “en direct” sont plus efficaces qu’un long message sur Slack, alors une permanence aura lieu.\n\n\nLe TEA\nLes séances de TEA auront toutes lieu “à distance”. Je ne suis pas tenu d’être présent lors des séances de TEA, même si une salle banalisée est systématiquement réservée pour vous permettre de vous retrouver et de travailler ensemble. Je m’engage en revanche à être disponible sur Slack pour répondre rapidement aux questions posées lors des TEA. Et si certaines questions n’ont pas trouvé de réponse pendant les séances de TEA, nous y répondront lors du TP suivant.\nGénéralement, l’organisation de votre journée sera la suivante :\n\nEn début de matinée, 1h30 ou 3h de cours magistraux\nEn milieu de journée du temps libre ou pour avancer sur ce document, les exercices, la prise en main de R et RStudio, etc.\nEn fin de journée une séance de TEA et/ou de TP/permanence non obligatoire de 90 minutes pour ceux qui en ont besoin et se manifestent."
  },
  {
    "objectID": "index.html#progession-conseillée",
    "href": "index.html#progession-conseillée",
    "title": "Analyse de Données",
    "section": "Progession conseillée",
    "text": "Progession conseillée\nPour apprendre à utiliser un logiciel comme R, il faut faire les choses soi-même, ne pas avoir peur des messages d’erreurs (il faut d’ailleurs apprendre à les déchiffrer pour comprendre d’où viennent les problèmes), essayer maintes fois, se tromper beaucoup, recommencer, et surtout, ne pas se décourager. J’utilise ce logiciel presque quotidiennement depuis plus de 15 ans et à chaque session de travail, je rencontre des messages d’erreur. Avec suffisamment d’habitude, on apprend à les déchiffrer, et on corrige les problèmes en quelques secondes. Ce livre est conçu pour vous faciliter la tâche, mais ne vous y trompez pas, vous rencontrerez des difficultés, et c’est normal. C’est le prix à payer pour profiter de la puissance du meilleur logiciel permettant d’analyser des données, de produire des graphiques de qualité et de réaliser toutes les statistiques dont vous aurez besoin d’ici la fin de vos études et au-delà.\nPour que cet apprentissage soit le moins problématique possible, il convient de prendre les choses dans l’ordre. C’est la raison pour laquelle les chapitres de ce livre doivent être lus dans l’ordre, et les exercices d’application faits au fur et à mesure de la lecture.\nUne fois compilé en pdf, ce document représente plus de 350 pages, ce qui veut dire que vous devriez vous approprier environ 25 pages par jour. En particulier, la Chapitre 3 est très longue et il est facile de se laisser dépasser.\n\n\n\n\n\n\nTravaillez régulièrement !\n\n\n\nQue vous veniez aux séances de permanence ou non, j’insiste sur l’importance de travailler cette matière régulièrement. Vous devez vous y mettre dès maintenant et y consacrer quelques heures chaque jour. Interrogez vos collègues de M2 qui ont eu cet enseignement l’an dernier : il y a beaucoup de temps à y passer et il est hélas facile de prendre et d’accumuler du retard…\n\n\nUne fois cette UE terminée, vous pourrez évidemment consulter ce livre quand bon vous semblera, et dans n’importe quel ordre. Le champ de recherche situé en haut à gauche est d’ailleurs très utile pour (re)trouver les passages que vous recherchez. Ce livre restera en ligne et vous pourrez y accéder même après avoir quitté l’université de La Rochelle. Vos prédécesseurs me confirment régulièrement à quel point il leur est resté utile bien après le master. Soyez toutefois prévenu que les contenus de ce livre peuvent évoluer avec le temps : j’essaie en effet de remettre à jour tout ce qui doit l’être le plus régulièrement possible. Et cela signifie parfois que des sections peuvent disparaître ou être remplacées si des façons de procéder plus modernes sont préférables."
  },
  {
    "objectID": "index.html#lévaluation",
    "href": "index.html#lévaluation",
    "title": "Analyse de Données",
    "section": "L’évaluation",
    "text": "L’évaluation\nVous aurez plusieurs types d’évaluations cette année :\n\nUne évaluations par les pairs qui portera sur la qualité de vos scripts. Cette évaluation qui entrera pour une toute petite partie dans la note finale de l’EC a pour objectif principal de vous permettre de vous situer dans vos apprentissages. Vous évaluerez vous même, et de façon anonyme, plusieurs copies de vos camarades en suivant une grille d’évaluation critériée que nous construirons ensemble. De même, votre copie sera évaluée par plusieurs de vos camarades. Cette approche a de nombreux avantages. Elle vous permet notamment de mieux vous approprier les grilles de notations (par exemple, qu’est-ce qu’un bon script sous R ? À l’inverse, qu’est-ce qu’un script médiocre ? Comment être sûr que la méthode statistique choisie est la bonne pour répondre à une question donnée ? Suis-je capable de décrire correctement un tableau de données de grande taille ? Suis-je capable de produire des graphiques informatifs ?) et rends possible un retour personnalisé sur vos travaux beaucoup plus rapidement que si votre enseignant était le seul à corriger l’ensemble de vos travaux. Pas d’inquiétude, vous serez guidés à chaque étape.\nUne évaluation individuelle courte qui ne portera pas sur les analyses statistiques à proprement parler, mais sur votre capacité à produire un graphique de qualité, original et qui raconte une histoire intéressante sur un jeu de données imposé. Cet exercice n’est pas réalisé chaque année faute de temps.\nUne évaluation individuelle plus classique, sur table ou à la maison, avec quelques exercices qui vous demanderont de mettre en œuvre les méthodes statistiques décrites lors de cours magistraux.\nEnfin, une évaluation qui prendra la forme d’un rapport et qui sera réalisé conjointement avec les travaux de stratégie d’échantillonnage réalisés avec Fanny Cusset. Cette partie de l’EC est en effet complémentaire de l’analyse de données puisqu’elle permet d’avoir une approche globale, de la question scientifique à la production d’un rapport et d’une soutenance, en passant par la réflexion sur la stratégie d’échantillonnage, la mise en œuvre sur le terrain, le traitement des échantillons au laboratoire, et l’exploitation statistique des résultats. Ce travail sera donc évalué conjointement par Fanny Cusset et moi. La note de la partie analyse de données portera essentiellement sur les parties “matériels et méthodes” et “résultats” du rapport. Il est en effet important de comprendre dès maintenant que l’analyse de données n’est pas une fin en soi : on ne fait pas des statistiques pour le plaisir, ou sans but précis. Ça n’est qu’un outil de votre panoplie d’écologue au service d’une question scientifique. L’analyse de données et les statistiques vous permettront de répondre à des questions scientifiques de façon objective, mais leur utilisation appropriée suppose que vous ayez les idées claires en amont sur la question scientifique à laquelle vous tentez de répondre. C’est cette démarche qui devrait vous guider tout au long de votre cursus de master et au-delà, dans votre vie professionnelle.\n\nDans le cadre de l’approche compétences, j’essaierai d’indiquer, dans la mesure du possible, quelles sont les compétences et résultats d’apprentissages dont vous devrez faire l’acquisition pour chaque évaluation. À l’issue de cet enseignement, vous devriez être capables de :\n\nMettre en forme des données acquises sur le terrain ou au laboratoire afin d’en permettre l’importation dans R ou RStudio.\nProduire des statistiques descriptives informatives permettant de comprendre la structure et les tendances principales d’un jeu de données.\nCréer dans R ou RStudio des graphiques lisibles et informatifs permettant de mettre en évidence les tendances principales d’un jeu de données.\nProduire des scripts clairs sous R ou RStudio, permettant la reproductibilité des traitements de données et des analyses statistiques ainsi que la communication avec vos pairs.\nAnalyser des données uni-, bi- ou multi-variées issues d’observations et de mesures sur le terrain et au laboratoire en choisissant les méthodes appropriées pour répondre à une problématique scientifique précise.\nMaîtriser les logiciels R ou RStudio pour réaliser des analyses statistiques, des représentations graphiques ou des simulations numériques."
  },
  {
    "objectID": "index.html#licence",
    "href": "index.html#licence",
    "title": "Analyse de Données",
    "section": "Licence",
    "text": "Licence\nCe livre est ligne est sous licence Creative Commons (CC BY-NC-ND 4.0)\n\n\n\n\n\nVous êtes autorisé à partager, copier, distribuer et communiquer ce matériel par tous moyens et sous tous formats, tant que les conditions suivantes sont respectées :\n\n\n Attribution : vous devez créditer ce travail (donc citer son auteur), fournir un lien vers ce livre en ligne, intégrer un lien vers la licence Creative Commons et indiquer si des modifications du contenu original ont été effectuées. Vous devez indiquer ces informations par tous les moyens raisonnables, sans toutefois suggérer que l’auteur vous soutient ou soutient la façon dont vous avez utilisé son travail.\n\n\n Pas d’utilisation commerciale : vous n’êtes pas autorisé à faire un usage commercial de cet ouvrage, ni de tout ou partie du matériel le composant. Cela comprend évidemment la diffusion sur des plateformes de partage telles que studocu.com qui tirent profit d’œuvres dont elles ne sont pas propriétaires, souvent à l’insu des auteurs.\n\n\n Pas de modifications : dans le cas où vous effectuez un remix, que vous transformez, ou créez à partir du matériel composant l’ouvrage original, vous n’êtes pas autorisé à distribuer ou mettre à disposition l’ouvrage modifié.\n\n\n Pas de restrictions complémentaires : vous n’êtes pas autorisé à appliquer des conditions légales ou des mesures techniques qui restreindraient légalement autrui à utiliser cet ouvrage dans les conditions décrites par la licence."
  },
  {
    "objectID": "01-R-basics.html#préambule",
    "href": "01-R-basics.html#préambule",
    "title": "1  R et RStudio : les bases",
    "section": "1.1 Préambule",
    "text": "1.1 Préambule\nAvant de commencer à explorer des données dans R, il y a plusieurs concepts clés qu’il faut comprendre en premier lieu :\n\nQue sont R et RStudio ?\nComment s’y prend-on pour coder dans R ?\nQue sont les packages ?\n\nMême si vous pensez être déjà à l’aise avec ces concepts, lisez attentivement ce chapitre et faites les exercices demandés. Cela vous rafraîchira probablement la mémoire, et il n’est pas impossible que vous appreniez une chose ou deux au passage. Une bonne maîtrise des éléments présentés dans ce chapitre est indispensable pour aborder sereinement les chapitres suivants, à commencer par le Chapitre 2, qui présente un jeu de données que nous explorerons en détail un peu plus tard. Lisez donc attentivement ce chapitre et faites bien tous les exercices demandés.\nCe chapitre est en grande partie basé sur les 3 ressources suivantes que je vous encourage à consulter si vous souhaitez obtenir plus de détails :\n\nL’ouvrage intitulé ModernDive, de Chester Ismay et Albert Y. Kim. Une bonne partie de ce livre est très largement inspirée de cet ouvrage. C’est en anglais, mais c’est un très bon texte d’introduction aux statistiques sous R et RStudio.\nL’ouvrage intitulé Getting used to R, RStudio, and R Markdown de Chester Ismay, comprend des podcasts (en anglais toujours) que vous pouvez suivre en apprenant.\nLes tutoriels en ligne de DataCamp. DataCamp est une plateforme de e-learning accessible depuis n’importe quel navigateur internet et dont la priorité est l’enseignement des “data sciences”. Leurs tutoriels vous aideront à apprendre certains des concepts de développés dans ce livre.\n\n\n\n\n\n\n\nImportant\n\n\n\nAvant d’aller plus loin, rendez-vous sur le site de DataCamp, créez-vous un compte gratuit, et reprenez la lecture de ce livre."
  },
  {
    "objectID": "01-R-basics.html#que-sont-r-et-rstudio",
    "href": "01-R-basics.html#que-sont-r-et-rstudio",
    "title": "1  R et RStudio : les bases",
    "section": "1.2 Que sont R et RStudio ?",
    "text": "1.2 Que sont R et RStudio ?\nPour l’ensemble de ces TP, j’attends de vous que vous utilisiez R via RStudio. Les utilisateurs novices confondent souvent les deux. Pour tenter une analogie simple :\n\nR est le moteur d’une voiture\nRStudio est l’habitacle, le tableau de bord, les pédales…\n\nSi vous n’avez pas de moteur, vous n’irez nulle part. En revanche, un moteur sans tableau de bord est difficile à manœuvrer. Il est en effet beaucoup plus simple de faire avancer une voiture depuis l’habitacle, plutôt qu’en actionnant à la main les câbles et leviers du moteur.\nEn l’occurrence, R est un langage de programmation capable de produire des graphiques et de réaliser des analyses statistiques, des plus simples aux plus complexes. RStudio est un “emballage” qui rend l’utilisation de R plus aisée. RStudio est ce qu’on appelle un IDE ou “Integrated Development Environment”. On peut utiliser R sans RStudio, mais c’est nettement plus compliqué, nettement moins pratique.\n\n1.2.1 Installation\n\n\n\n\n\n\nAvertissement\n\n\n\nSi vous travaillez exclusivement sur les ordinateurs de l’Université, vous pouvez passer cette section. En revanche, si vous souhaitez utiliser R et RStudio sur votre ordinateur personnel, alors lisez attentivement la suite !\n\n\nAvant tout, vous devez télécharger et installer R, puis RStudio, dans cet ordre :\n\nTéléchargez et installez R\n\n\nVous devez installer ce logiciel en premier.\nCliquez sur le lien de téléchargement qui correspond à votre système d’exploitation, puis, sur “base”, si vous êtes sous Windows, sur “R-4.3.1-x86_64.pkg” si vous êtes sous Mac avec processeur Intel, ou sur R-4.3.1-arm64.pkg si vous êtes sous Mac avec processeur M1 ou M2 (sous Mac, cliquez sur le Menu , puis sur “À propos de ce Mac” et regardez à la rubrique “Processeur”), et suivez les instructions.\n\n\nTéléchargez et installez RStudio\n\n\nCliquez sur “RStudio Desktop”, puis sur “Download RStudio Desktop”.\nChoisissez la version gratuite et cliquez sur le lien de téléchargement qui correspond à votre système d’exploitation.\n\n\n\n1.2.2 Utiliser R depuis RStudio\nPuisqu’il est beaucoup plus facile d’utiliser Rstudio pour interagir avec R, nous utiliserons exclusivement l’interface de RStudio. Après les installations réalisées à la Section 1.2.1, vous disposez de 2 nouveaux logiciels sur votre ordinateur. RStudio ne peut fonctionner sans R, mais nous travaillerons exclusivement dans RStudio :\n\nR, ne pas ouvrir ceci :   \nRStudio, ouvrir cela : \n\nÀ l’université, vous trouverez RStudio dans le menu Windows, à condition d’être connecté à la machine virtuelle bio. Quand vous ouvrez RStudio pour la première fois, vous devriez obtenir une fenêtre qui ressemble à ceci :\n\nPrenez le temps d’explorer cette interface, cliquez sur les différents onglets, ouvrez les menus, allez faire un tour dans les préférences du logiciel pour découvrir les différents panneaux de l’application, en particulier la Console dans laquelle nous exécuterons très bientôt du code R."
  },
  {
    "objectID": "01-R-basics.html#sec-code",
    "href": "01-R-basics.html#sec-code",
    "title": "1  R et RStudio : les bases",
    "section": "1.3 Comment exécuter du code R ?",
    "text": "1.3 Comment exécuter du code R ?\nContrairement à d’autres logiciels comme Excel, STATA ou SAS qui fournissent des interfaces où tout se fait en cliquant avec sa souris, R est un langage interprété, ce qui signifie que vous devez taper des commandes, écrites en code R. C’est-à-dire que vous devez programmer en R (j’utilise les termes “coder” et “programmer” de manière interchangeable dans ce livre).\nIl n’est pas nécessaire d’être un programmeur pour utiliser R, néanmoins, il est nécessaire de programmer ! Il existe en effet un ensemble de concepts de programmation de base que les utilisateurs de R doivent comprendre et maîtriser. Et progresser en programmation vous permettra d’automatiser de plus en plus de choses, et donc, à terme, de gagner beaucoup de temps. Par conséquent, bien que ce livre ne soit pas un livre sur la programmation, vous en apprendrez juste assez en programmation pour explorer et analyser efficacement des données.\n\n1.3.1 La console\nLa façon la plus simple d’interagir avec RStudio (mais pas du tout la meilleure !) consiste à taper directement des commandes que R pourra comprendre dans la Console.\nCliquez dans la console (après le symbole &gt;) et tapez ceci, sans oublier de valider en tapant sur la touche Entrée :\n\n3 + 8\n\n[1] 11\n\n\nFélicitations, vous venez de taper votre première instruction R : vous savez maintenant faire des additions !\nDans la version en ligne de ce livre (en html), à chaque fois que du code R sera fourni, il apparaîtra dans un cadre grisé avec une ligne bleue à gauche, comme ci-dessus. Vous pourrez toujours taper dans RStudio, les commandes qui figurent dans ces blocs de code, afin d’obtenir vous même les résultats souhaités. Dans ce livre, lorsque les commandes R produisent des résultats, ils sont affichés juste en dessous des blocs de code. Enfin, en passant la souris sur les blocs de code, vous verrez apparaître, à droite, une icône de presse-papier qui vous permettra de copier-coller les commandes du livre dans la console de RStudio ou, très bientôt, dans vos scripts.\n\n\n\n\n\n\nLes risques du “copier-coller” \n\n\n\nAttention : il est fortement conseillé de réserver les copier-coller aux blocs de commandes de (très) grande taille, ou en cas d’erreur de syntaxe inexplicable. L’expérience a en effet montré qu’on apprend beaucoup mieux en tapant soi-même les commandes. Ça n’est que comme cela que l’on peut prendre conscience de toutes les subtilités du langage (par exemple, faut-il mettre une virgule ou un point, une parenthèse ou un crochet, le symbole moins ou un tilde, etc.). Je vous conseille donc de taper vous-même les commandes autant que possible.\n\n\n\n\n1.3.2 Les scripts\nTaper du code directement dans la console est probablement la pire façon de travailler dans RStudio. Cela est parfois utile pour faire un rapide calcul, ou pour vérifier qu’une commande fonctionne correctement. Mais la plupart du temps, vous devriez taper vos commandes dans un script.\n\n\n\n\n\n\nDéfinition importante !\n\n\n\nUn script est un fichier au format “texte brut” (cela signifie qu’il n’y a pas de mise en forme et que ce fichier peut-être ouvert par n’importe quel éditeur de texte, y compris les plus simples comme le bloc notes de Windows), dans lequel vous pouvez taper :\n\ndes instructions qui seront comprises par R comme si vous les tapiez directement dans la console\ndes lignes de commentaires, qui doivent obligatoirement commencer par le symbole #.\n\n\n\nLes avantages de travailler dans un script sont nombreux :\n\nVous pouvez sauvegarder votre script à tout moment (vous devriez prendre l’habitude de le sauvegarder très régulièrement). Vous gardez ainsi la trace de toutes les commandes que vous avez tapées.\nVous pouvez aisément partager votre script pour collaborer avec vos collègues de promo et enseignants.\nVous pouvez documenter votre démarche et les différentes étapes de vos analyses. Vous devez ajouter autant de commentaires que possible. Cela permettra à vos collaborateurs de comprendre ce que vous avez fait. Et dans 6 mois, cela vous permettra de comprendre ce que vous avez fait. Si votre démarche vous paraît cohérente aujourd’hui, il n’est en effet pas garanti que vous vous souviendrez de chaque détail quand vous vous re-plongerez dans vos analyses dans quelques temps. Donc aidez-vous vous même en commentant vos scripts dès maintenant.\nUn script bien structuré, bien indenté (avec les bons retours à la ligne, des sauts de lignes, des espaces, bref, de l’air) et clair permet de rendre vos analyses répétables. Si vous passez 15 heures à analyser un tableau de données précis, il vous suffira de quelques secondes pour analyser un nouveau jeu de données similaire : vous n’aurez que quelques lignes à modifier dans votre script original pour l’appliquer à de nouvelles données.\n\nVous pouvez créer un script en cliquant dans le menu “File &gt; New File &gt; R Script”. Un nouveau panneau s’ouvre dans l’application. Pensez à sauvegarder immédiatement votre nouveau script en cliquant dans le menu “File &gt; Save” ou “File &gt; Save as…”. Il faut pour cela lui donner un nom et choisir un emplacement sur votre disque dur.\n\n\n\n\n\n\nOù sauvegarder vos scripts ? \n\n\n\nJe vous encourage vivement à créer, sur votre disque dur, un nouveau dossier spécifique, que vous nommerez par exemple Data_Analysis. Il est important que le nom de ce dossier ne contienne pas de caractères spéciaux (e.g. accents, cédilles, apostrophes, espaces, etc.). Ce dossier devrait être facilement accessible : vous y enregistrerez tous vos scripts, vos jeux de données, vos graphiques, etc.\nSi vous travaillez sur les ordinateurs de l’université, créez obligatoirement votre dossier sur le disque W:\\. Il s’agit de votre espace personnel sur le réseau de l’université. Cela vous garantit que vous retrouverez votre script la prochaine fois, même si vous utilisez un ordinateur différent.\n\n\nÀ partir de maintenant, vous ne devriez plus taper de commande directement dans la console. Tapez systématiquement vos commandes dans un script et sauvegardez-le régulièrement.\nPour exécuter les commandes du script dans la console, il suffit de placer le curseur sur la ligne contenant la commande et de presser les touches ctrl + enter (ou command + enter sous macOS). Si un message d’erreur s’affiche dans la console, c’est que votre instruction était erronée. Modifiez la directement dans votre script et pressez à nouveau les touches ctrl + enter (ou command + enter sous macOS) pour tenter à nouveau votre chance. Idéalement, votre script ne devrait contenir que des commandes qui fonctionnent et des commentaires expliquant à quoi servent ces commandes.\nVoici un exemple de script que je ne vous demande pas de reproduire. Lisez simplement attentivement son contenu :\n\n# Penser à installer le package ggplot2 si besoin\n# install.packages(\"ggplot2\")\n\n# Chargement du package\nlibrary(ggplot2)\n\n# Mise en mémoire des données de qualité de l'air à New-York de mai à\n# septembre 1973\ndata(airquality)\n\n# Affichage des premières lignes du tableau de données\nhead(airquality)\n\n# Quelle est la structure de ce tableau ?\nstr(airquality)\n\n# Réalisation d'un graphique présentant la relation entre la concentration\n# en ozone atmosphérique en ppb et la température en degrés Fahrenheit\nggplot(data = airquality, mapping = aes(x = Temp, y = Ozone)) +\n  geom_point() +\n  geom_smooth(method = \"loess\")\n\n# On constate une augmentation importante de la concentration d'ozone \n# pour des températures supérieures à 75ºF\n\nMême si vous ne comprenez pas encore les commandes qui figurent dans ce script (ça viendra !), voici ce que vous devez en retenir :\n\nLe script contient plus de lignes de commentaires que de commandes R.\nChaque étape de l’analyse est décrite en détail.\nLes 2 dernières lignes du script décrivent les résultats obtenus (ici, un graphique).\nSeules des commandes pertinentes et qui fonctionnent ont été conservées dans ce script.\nChaque ligne de commentaire commence par #. Il est ainsi possible de conserver certaines commandes R dans le script, “pour mémoire”, sans pour autant qu’elle ne soient exécutées. C’est le cas pour la ligne # install.packages(\"ggplot2\").\n\nSi j’exécute ce script dans la console de RStudio (en sélectionnant toutes les lignes et en pressant les touches ctrl + enter ou command + enter sous macOS), voilà ce qui est produit :\n\n\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1\n2    36     118  8.0   72     5   2\n3    12     149 12.6   74     5   3\n4    18     313 11.5   62     5   4\n5    NA      NA 14.3   56     5   5\n6    28      NA 14.9   66     5   6\n\n\n'data.frame':   153 obs. of  6 variables:\n $ Ozone  : int  41 36 12 18 NA 28 23 19 8 NA ...\n $ Solar.R: int  190 118 149 313 NA NA 299 99 19 194 ...\n $ Wind   : num  7.4 8 12.6 11.5 14.3 14.9 8.6 13.8 20.1 8.6 ...\n $ Temp   : int  67 72 74 62 56 66 65 59 61 69 ...\n $ Month  : int  5 5 5 5 5 5 5 5 5 5 ...\n $ Day    : int  1 2 3 4 5 6 7 8 9 10 ...\n\n\n\n\n\n\n\n1.3.3 Les projets, ou Rprojects\nPour travailler le plus efficacement possible avec RStudio, vous devriez créer, à l’intérieur de votre dossier de travail, un nouveau fichier très particulier, qui s’appelle, dans le jargon de RStudio, un Rproject.\nPour le créer, cliquez simplement dans le Menu “File &gt; New Project…”. Cette boîte de dialogue devrait apparaître :\n\n\n\n\n\nChoisissez “Existing Directory”, puis, dans la boîte de dialogue suivante :\n\n\n\n\n\ncliquez sur “Browse…”, naviguez jusqu’au dossier que vous avez créé plus tôt sur votre disque dur et qui contient votre script, puis cliquez sur “Create Project”. La fenêtre de RStudio se ferme, puis une nouvelle fenêtre vierge apparaît. En apparence, rien n’a changé ou presque. Pourtant :\n\nen haut à droite de la fenêtre de RStudio, le logiciel indique maintenant que vous êtes bel et bien à l’intérieur d’un Rproject. Au lieu de Project: (None), on lit maintenant le nom du Rproject (chez moi, Data_Analysis)\ndans le quart inférieur droit de l’interface, l’onglet “Files” ne présente plus le même aspect. Avant de créer le Rproject, cet onglet présentait le chemin vers le dossier utilisé par défaut par le logiciel, ainsi que son contenu. Il s’agissait d’un dossier système auquel il vaut mieux ne pas toucher pour éviter les problèmes. Après la création du Rproject, l’onglet “Files” indique le contenu du dossier contenant le projet. Autrement dit, c’est ici que vous trouverez vos scripts, tableaux de données dans différents formats, figures sauvegardées, etc. Dans cet onglet, vous pouvez donc cliquer sur le nom de votre script pour l’ouvrir à nouveau, le modifier, l’exécuter…\n\n\n\n\n\n\n\nSans Rproject\n\n\n\n\n\n\n\nAvec RProject\n\n\n\n\n\n\nun nouveau fichier portant l’extension .Rproj a été créé dans votre dossier de travail. La prochaine fois que vous voudrez travailler dans RStudio, il vous suffira de double-cliquer sur ce fichier dans l’explorateur de fichier de Windows ou le Finder de MacOS, pour que RStudio s’ouvre, et que vous retrouviez tous vos fichiers et scripts de la fois précédente\n\n\n\n\n\n\nPour vérifier que tout s’est bien passé jusqu’ici, tapez la commande suivante dans votre script puis envoyez-la dans la console en pressant les touches ctrl + entrée (ou command + entrée sous MacOS).\n\ngetwd()\n\nRStudio doit vous afficher, dans la console, le chemin jusqu’à votre répertoire de travail ou “Working Directory” en anglais (getwd() est l’abréviation de “GET Working Directory”). Si tout s’est bien passé, ce chemin doit être celui du dossier qui contient votre script et le fichier .Rproj que vous venez de créer. Si ce n’est pas le cas, reprenez calmement toutes les étapes décrites depuis le début de la Section 1.3.2. Si ça ne fonctionne toujours pas, contactez-moi sur Slack.\n\n\n\n\n\n\nPour résumer… \n\n\n\nLes Rprojects sont un moyen très pratique de travailler efficacement dans RStudio car ils permettent de gérer facilement la question du répertoire de travail. Lorsque vous envisagez de travailler sur un nouveau sujet/projet/jeu de données/compte-rendu de TP…, les étapes à suivre, pour vous mettre dans une configuration idéale qui vous évitera bien des problèmes par la suite, sont donc les suivantes :\n\nSur votre ordinateur, créez un nouveau dossier avec un nom simple, et à un endroit facile d’accès (pas de caractères spéciaux dans le chemin du dossier si possible)\nDémarrez RStudio\nDans le logiciel, cliquez dans le menu “File &gt; New Project…”\nChoisissez “Existing Directory”, puis naviguez jusqu’au dossier que vous venez de créer\nCliquez sur “Create Project”\nCréer un nouveau script (menu “File &gt; New File &gt; R script”)\nDonnez un nom à votre script (menu “File &gt; Save As…”) pour le sauvegarder. Par défaut, RStudio vous propose d’enregistrer votre script dans le dossier de votre Rproject, ce qui est parfait.\nTapez getwd() dans votre script et exécutez cette commande en l’envoyant dans la console.\n\nSi le chemin qui s’affiche est celui du dossier contenant votre Rproject et votre script, félicitation, vous êtes prêt·e à travailler. Avec un peu d’habitude, ces étapes ne prennent qu’une à deux minutes.\n\n\n\n\n1.3.4 Concepts de base en programmation et terminologie\nAprès ces considérations techniques sur l’utilisation et les réglages de RStudio, nous entrons maintenant dans le vif du sujet avec la découverte des premiers éléments de syntaxe du langage R.\n\n1.3.4.1 Objets, types, vecteurs, facteurs et tableaux de données\nPour vous présenter les concepts de base et la terminologie de la programmation dont nous aurons besoin, vous allez suivre des tutoriels en ligne sur le site de DataCamp. Pour cette première prise en main, tout va maintenant se passer dans votre navigateur internet, et vous pouvez donc mettre de côté RStudio pour l’instant. Vous allez voir que l’interface de DataCamp ressemble à une version simplifiée de l’éditeur de script et de la console de RStudio : vous n’aurez pas à vous soucier des réglages, de Rprojects ou de sauvegarder quoi que ce soit. Si vous avez correctement créé votre compte gratuit DataCamp comme indiqué au tout début de la Chapitre 1, votre progression sera sauvegardée automatiquement. Il vous suffit de cliquer sur les liens direct ci-dessous pour démarrer les tutoriels en ligne.\nAvant de démarrer, quelques précisions :\n\npour chaque tutoriel que je vous demande de suivre, j’indique ci-dessous une liste des concepts de programmation qui sont couverts. N’hésitez pas à vous y référer (et à y revenir) tout au long du semestre si vous avez oublié certaines choses\nce tutoriel DataCamp contient 6 chapitres. Seuls les chapitres 1, 2, 4, et 5 doivent être suivis. Nous ne travaillerons pas sur les matrices ni sur les listes\nà la fin de chaque chapitre du tutoriel, revenez à ce livre en ligne pour cliquer sur le lien direct ver le chapitre suivant. Procéder ainsi vous évitera de suivre des chapitres inutiles du tutoriel, et cela vous permettra également d’éviter les demandes d’inscriptions payantes à DataCamp\n\nIl est important de noter que, bien que ces tutoriels sont d’excellentes introductions, une lecture seule, même attentive, est insuffisante pour un apprentissage en profondeur et une rétention à long terme. Il faut pour cela pratiquer et répéter. Outre les exercices demandés dans DataCamp, que vous devez effectuer directement dans votre navigateur, je vous encourage à prendre des notes, à multiplier les essais, directement dans la console de RStudio, ou, de préférence, dans un script que vous annoterez, pour vous assurer que vous avez bien compris chaque partie.\nAllez maintenant découvrir le cours d’introduction à R sur DataCamp, et cliquez sur les liens des chapitres ci-dessous. Au fur et à mesure de votre travail, notez les termes importants et ce à quoi ils font référence.\n\nChapitre 1 : introduction\n\nLa console : l’endroit où vous tapez des commandes\nLes objets : où les valeurs sont stockées, comment assigner des valeurs à des objets\nLes types de données : entiers, doubles/numériques, caractères et logiques\n\nChapitre 2 : vecteurs\n\nLes vecteurs : des collections de valeurs du même type\n\nChapitre 4 : les facteurs\n\nDes données catégorielles (et non pas numériques) représentées dans R sous forme de factors\n\nChapitre 5 : les jeux de données ou data.frame\n\nLes data.frames sont similaires aux feuilles de calcul rectangulaires que l’on peut produire dans un tableur. Dans R, ce sont des objets rectangulaires (des tableaux !) contenant des jeux de données : les lignes correspondent aux observations et les colonnes aux variables décrivant les observations. La plupart du temps, c’est le format de données que nous utiliserons. Plus de détails dans le Chapitre 2\n\n\nAvant de passer à la suite, il nous reste 2 grandes notions à découvrir dans le domaine du code et de la syntaxe afin de pouvoir travailler efficacement dans R : les opérateurs de comparaison d’une part, et les fonctions d’autre part. Pour les découvrir et expérimenter, et puisque vous avez terminé les tutoriels DataCamp, reprenez maintenant RStudio et travaillez dans votre script.\n\n\n1.3.4.2 Opérateurs de comparaison\nComme leur nom l’indique, ils permettent de comparer des valeurs ou des objets. Les principaux opérateurs de comparaison sont :\n\n== : égal à\n!= : différent de\n&gt; : supérieur à\n&lt; : inférieur à\n&gt;= : supérieur ou égal à\n&lt;= : inférieur ou égal à\n\nAinsi, on peut tester si 3 est égal à 5 :\n\n3 == 5\n\n[1] FALSE\n\n\nLa réponse est bien entendu FALSE. Est-ce que 3 est inférieur à 5 ?\n\n3 &lt; 5\n\n[1] TRUE\n\n\nLa réponse est maintenant TRUE. Lorsque l’on utilise un opérateur de comparaison, la réponse est toujours soit vrai (TRUE), soit faux (FALSE).\nIl est aussi possible de comparer des chaînes de charactères :\n\n\"Bonjour\" == \"Au revoir\"\n\n[1] FALSE\n\n\"Bonjour\" &gt;= \"Au revoir\"\n\n[1] TRUE\n\n\nManifestement, “Bonjour” est supérieur ou égal à “Au revoir”. En fait, R utilise l’ordre alphabétique pour comparer les chaînes de caractères. Puisque dans l’alphabet, le “B” de “Bonjour” arrive après le “A” de “Au revoir”, pour R, “Bonjour” est supérieur à “Au revoir”.\nIl est également possible d’utiliser ces opérateurs pour comparer un chiffre et un vecteur :\n\ntailles_pop1 &lt;- c(112, 28, 86, 14, 154, 73, 63, 48)\ntailles_pop1 &gt; 80\n\n[1]  TRUE FALSE  TRUE FALSE  TRUE FALSE FALSE FALSE\n\n\nIci, l’opérateur nous permet d’identifier quels éléments du vecteur taille_pop1 sont supérieurs à 80. Il s’agit des éléments placés en première, troisième et cinquième positions.\nIl est aussi possible de comparer 2 vecteurs qui contiennent le même nombre d’éléments :\n\ntailles_pop2 &lt;- c(114, 27, 38, 91, 54, 83, 33, 68)\ntailles_pop1 &gt; tailles_pop2\n\n[1] FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE FALSE\n\n\nLes comparaisons sont ici faites élément par élément. Ainsi, les observations 2, 3, 5 et 7 du vecteur tailles_pop1 sont supérieures aux observations 2, 3, 5 et 7 du vecteur tailles_pop2 respectivement.\nCes vecteurs de vrais/faux sont très utiles car ils peuvent permettre de compter le nombre d’éléments répondant à une certains condition :\n\nsum(tailles_pop1 &gt; tailles_pop2)\n\n[1] 4\n\n\nLorsque l’on effectue une opération arithmétique (comme le calcul d’une somme ou d’une moyenne) sur un vecteur de vrais/faux, les TRUE sont remplacés par 1 et les FALSE par 0. La somme nous indique donc le nombre de vrais dans un vecteur de vrais/faux, et la moyenne nous indique la proportion de vrais :\n\nmean(tailles_pop1 &gt; tailles_pop2)\n\n[1] 0.5\n\n\nNote : Attention, si les vecteurs comparés n’ont pas la même taille, un message d’avertissement est affiché :\n\ntailles_pop3 &lt;- c(43, 56, 92)\ntailles_pop1\n\n[1] 112  28  86  14 154  73  63  48\n\ntailles_pop3\n\n[1] 43 56 92\n\ntailles_pop3 &gt; tailles_pop1\n\nWarning in tailles_pop3 &gt; tailles_pop1: la taille d'un objet plus long n'est\npas multiple de la taille d'un objet plus court\n\n\n[1] FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE\n\n\nIci, R renvoie un résultat, accompagné d’un message d’avertissement qui nous indique que tout ne s’est probablement pas déroulé comme on le pensait. Dans un cas comme celui là, R va en effet recycler l’objet le plus court, ici tailles_pop3 pour qu’une comparaison puisse être faite avec chaque élément de l’objet le plus long (ici, tailles_pop1). Ainsi, 43 est comparé à 112, 56 est comparé à 28 et 92 est comparé à 86. Puisque tailles_pop3 ne contient plus d’éléments, ils sont recyclés, dans le même ordre : 43 est comparé à 14, 56 est comparé à 154, et ainsi de suite jusqu’à ce que tous les éléments de tailles_pop1 aient été passés en revue.\nCe type de recyclage est très risqué car il est difficile de savoir ce qui a été comparé avec quoi. En travaillant avec des tableaux plutôt qu’avec des vecteurs, le problème est généralement évité puisque toutes les colonnes d’un data.frame contiennent le même nombre d’éléments.\n\n\n\n\n\n\nErreur ou avertissement ?  ou  ?\n\n\n\nIl ne faut pas confondre message d’erreur et message d’avertissement :\n\nUn message d’erreur commence généralement par Error ou Erreur et indique que R n’a pas compris ce que vous lui demandiez. Il n’a donc pas été en mesure de faire quoi que ce soit et votre commande n’a donc pas été exécutée. Vous devez absolument revenir à votre code et corriger la commande fautive car il y a fort à parier que si vous ne le faites pas, les commandes suivantes renverrons à leur tour un message d’erreur. Il est donc important de toujours revenir à la première erreur d’un script et de la corriger avant de passer à la suite.\nUn message d’avertissement commence généralement par Warning et vous indique que quelque chose d’inhabituel, ou de “non-optimal” a été réalisé. Un résultat a été produit, mais peut-être n’est-il pas conforme à ce que vous attendiez. La prudence est donc requise.\n\nDans les deux cas, un message explique de façon plus ou moins claire ce qui a posé problème. Progresser dans la maîtrise du logiciel et du langage signifie en grande partie progresser dans la compréhension de la signification de ces messages parfois obscures. Pour progresser, il faut donc commencer par lire attentivement ces messages, et tenter de comprendre ce qu’ils veulent dire.\n\n\nDernière chose concernant les opérateurs de comparaison : la question des données manquantes. Dans R les données manquantes sont symbolisées par cette notation : NA, abréviation de “Not Available”. Le symbole NaN (comme “Not a Number”) est parfois aussi observé lorsque des opérations ont conduit à des indéterminations. Mais c’est plus rare et la plupart du temps, les NaNs peuvent être traités comme les NAs. L’un des problèmes des données manquantes est qu’il est nécessaire de prendre des précautions pour réaliser des comparaisons les impliquant :\n\n3 == NA\n\n[1] NA\n\n\nOn s’attend logiquement à ce que 3 ne soit pas considéré comme égal à NA, et donc, on s’attend à obtenir FALSE. Pourtant, le résultat est NA. La comparaison d’un élément quelconque à une donnée manquante fournit toujours une donnée manquante : la comparaison ne peut pas se faire, R n’a donc rien à retourner. C’est également le cas aussi lorsque l’on compare deux valeurs manquantes :\n\nNA == NA\n\n[1] NA\n\n\nC’est en fait assez logique. Imaginons que j’ignore l’âge de Pierre et l’âge de Marie. Il n’y a aucune raison pour que leur âge soit le même, mais il est tout à fait possible qu’il le soit. C’est impossible à déterminer :\n\nage_Pierre &lt;- NA\nage_Marie &lt;- NA\nage_Pierre == age_Marie\n\n[1] NA\n\n\nMais alors comment faire pour savoir si une valeur est manquante puisqu’on ne peut pas utiliser les opérateurs de comparaison ? On utilise la fonction is.na() :\n\nis.na(age_Pierre)\n\n[1] TRUE\n\nis.na(tailles_pop3)\n\n[1] FALSE FALSE FALSE\n\n\nD’une façon générale, le point d’exclamation permet de signifier à R que nous souhaitons obtenir le contraire d’une expression :\n\n!is.na(age_Pierre)\n\n[1] FALSE\n\n!is.na(tailles_pop3)\n\n[1] TRUE TRUE TRUE\n\n\nCette fonction nous sera très utile plus tard pour éliminer toutes les lignes d’un tableau contenant des valeurs manquantes.\n\n\n1.3.4.3 L’utilisation des fonctions\nDans R, les fonctions sont des objets particuliers qui permettent d’effectuer des tâches très variées. Du calcul d’une moyenne à la création d’un graphique, en passant par la réalisation d’analyses statistiques complexes ou simplement l’affichage du chemin du répertoire de travail, tout, dans R, repose sur l’utilisation de fonctions. Vous en avez déjà vu un certain nombre :\n\n\n\n\n\n\n\nFonction\nPour quoi faire ?\n\n\n\n\nc()\nCréer des vecteurs\n\n\nclass()\nAfficher ou modifier la classe d’un objet\n\n\nfactor()\nCréer des facteurs\n\n\ngetwd()\nAfficher le chemin du répertoire de travail\n\n\nhead()\nAfficher les premiers éléments d’un objet\n\n\nis.na()\nTester si un objet contient des valeurs manquantes\n\n\nmean()\nCalculer une moyenne\n\n\nnames()\nAfficher ou modifier le nom des éléments d’un vecteur\n\n\norder()\nOrdonner les éléments d’un objet\n\n\nsubset()\nExtraire une partie des éléments d’un objet\n\n\nsum()\nCalculer une somme\n\n\ntail()\nAfficher les derniers éléments d’un objet\n\n\n\nCette liste va très rapidement s’allonger au fil des séances. Je vous conseille donc vivement de tenir à jour une liste des fonctions décrites, avec une explication de leur fonctionnement et éventuellement un exemple de syntaxe.\nCertaines fonctions ont besoin d’arguments (par exemple, la fonction factor()), d’autres peuvent s’en passer (par exemple, la fonction getwd()). Pour apprendre comment utiliser une fonction particulière, pour découvrir quels sont ses arguments possibles, quel est leur rôle et leur intérêt, la meilleure solution est de consulter l’aide de cette fonction. Il suffit pour cela de taper un ? suivi du nom de la fonction :\n\n?factor()\n\nToutes les fonctions et jeux de données disponibles dans R disposent d’un fichier d’aide similaire. Cela peut faire un peu peur au premier abord (tout est en anglais !), mais ces fichiers d’aide ont l’avantage d’être très complets, de fournir des exemples d’utilisation, et ils sont tous construits sur le même modèle. Vous avez donc tout intérêt à vous familiariser avec eux. Vous devriez d’ailleurs prendre l’habitude de consulter l’aide de chaque fonction qui vous pose un problème. Par exemple, le logarithme (en base 10) de 100 devrait faire 2, car 100 est égal à 10^2. Pourtant :\n\nlog(100)\n\n[1] 4.60517\n\n\nQue se passe-t’il ? Pour le savoir, il faut consulter l’aide de la fonction log :\n\n?log()\n\nCe fichier d’aide nous apprend que par défaut, la syntaxe de la fonction log() est la suivante :\n\nlog(x, base = exp(1))\n\nPar défaut, la base du logarithme est fixée à exp(1). Nous avons donc calculé un logarithme népérien (en base e). Cette fonction prend donc 2 arguments :\n\nx ne possède pas de valeur par défaut : il nous faut obligatoirement fournir quelque chose (la rubrique “Argument” du fichier d’aide nous indique que x doit être un vecteur numérique ou complexe) afin que la fonction puisse calculer un logarithme\nbase possède un argument par défaut. Si nous ne spécifions pas nous même la valeur de base, elle sera fixée à sa valeur par défaut, c’est à dire exp(1).\n\nPour calculer le logarithme de 100 en base 10, il faut donc taper, au choix, l’une de ces 3 expressions :\n\nlog(x = 100, base = 10)\n\n[1] 2\n\nlog(100, base = 10)\n\n[1] 2\n\nlog(100, 10)\n\n[1] 2\n\n\nLe nom des arguments d’une fonction peut être omis tant que ses arguments sont indiqués dans l’ordre attendu par la fonction (cet ordre est celui qui est précisé à la rubrique “Usage” du fichier d’aide de la fonction). Il est possible de modifier l’ordre des arguments d’une fonction, mais il faut alors être parfaitement explicite et utiliser les noms des arguments tels que définis dans le fichier d’aide.\nAinsi, pour calculer le logarithme de 100 en base 10, on ne peut pas taper :\n\nlog(10, 100)\n\n[1] 0.5\n\n\ncar cela revient à calculer le logarithme de 10 en base 100. On peut en revanche taper :\n\nlog(base = 10, x = 100)\n\n[1] 2"
  },
  {
    "objectID": "01-R-basics.html#sec-packages",
    "href": "01-R-basics.html#sec-packages",
    "title": "1  R et RStudio : les bases",
    "section": "1.4 Les packages additionels",
    "text": "1.4 Les packages additionels\nUne source de confusion importante pour les nouveaux utilisateurs de R est la notion de package. Les packages étendent les fonctionnalités de R en fournissant des fonctions, des données et de la documentation supplémentaires et peuvent être téléchargés gratuitement sur Internet. Ils sont écrits par une communauté mondiale d’utilisateurs de R. Par exemple, parmi les plus de 18000 packages disponibles à l’heure actuelle, nous utiliseront fréquemment :\n\nLe package ggplot2 pour la visualisation des données dans le Chapitre 3\nLe package dplyr pour manipuler des tableaux de données dans le Chapitre 5\n\nUne bonne analogie pour les packages R : ils sont comme les apps que vous téléchargez sur un téléphone portable. R est comme un nouveau téléphone mobile. Il est capable de faire certaines choses lorsque vous l’utilisez pour la première fois, mais il ne sait pas tout faire. Les packages sont comme les apps que vous pouvez télécharger dans l’App Store et Google Play. Pour utiliser un package, comme pour utiliser Instagram, vous devez :\n\nLe télécharger et l’installer. Vous ne le faites qu’une fois grâce à la commande install.packages()\nLe charger (en d’autres termes, l’ouvrir) en utilisant la commande library() à chaque nouvelle session de travail\n\nDonc, tout comme vous ne pouvez commencer à partager des photos avec vos amis sur Instagram que si vous installez d’abord l’application et que vous l’ouvrez, vous ne pouvez accéder aux données et fonctions d’un package R que si vous installez d’abord le package et le chargez avec la fonction library(). Passons en revue ces 2 étapes.\n\n1.4.1 Installation d’un package\nIl y a deux façons d’installer un package. Par example, pour installer le package ggplot2 :\n\nLe plus simple : Dans le quart inférieur droit de l’interface de Rstudio :\n\nCliquez sur l’onglet “Packages”\nCliquez sur “Install”\nTapez le nom du package dans le champ “Packages (separate multiple with space or comma):” Pour notre exemple, tapez ggplot2\nCliquez sur “Install”\n\nMétode alternative : Dans la console, tapez install.packages(\"ggplot2\") (vous devez inclure les guillemets).\n\nEn procédant de l’une ou l’autre façon, installez également les packages suivants : tidyverse et palmerpenguins. Le tidyverse est un “méta-package”, qui permet en fait d’installer de nombreux packages en une seule commande, dont ggplot2, tidyr, dplyr, magrittr et bien d’autres. Le package palmerpenguins contient un jeu de données dont nous nous servirons copieusement dans les chapitres suivants.\n\n\n\n\n\n\nNote : install.packages()\n\n\n\nUn package doit être installé une fois seulement sur un ordinateur, sauf si une version plus récente est disponible et que vous souhaitez mettre à jour ce package. Il n’est donc pas nécessaire de laisser ces commandes dans votre script. Sinon, vous risquez de ré-installer les packages à chaque nouvelle session de travail, ce qui est inutile et consomme inutilement de la bande passante, des ressources numériques, et donc, du carbone…  \n\n\n\n\n1.4.2 Charger un package en mémoire\nAprès avoir installé un package, vous pouvez le charger en utilisant la fonction library(). Par exemple, pour charger ggplot2 et dplyr tapez ceci dans la console :\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\nPuisque ces packages font partie du tidyverse, on aurait pu les charger tous les deux (et d’autres) en une seule étape en tapant :\n\nlibrary(tidyverse)\n\nQuand vous exécutez une commande, si vous voyez un message d’erreur commençant par :\nError: could not find function...\nc’est probablement parce que vous tentez d’utiliser une fonction qui fait partie d’un package que vous n’avez pas chargé. Pour corriger l’erreur, il suffit donc de charger le package approprié avec la commande library().\n\n\n\n\n\n\nNote : library()\n\n\n\nVous devrez charger à nouveau chaque package que vous souhaitez utiliser à chaque fois que vous ouvrirez une nouvelle session de travail dans RStudio (à chaque nouveau démarrage du logiciel, donc). C’est une erreur fréquente pour les débutants. Pour l’éviter, pensez bien à intégrer, tout en haut de votre script, les commandes library() nécessaires pour chaque package que vous comptez utiliser."
  },
  {
    "objectID": "01-R-basics.html#sec-exo-1",
    "href": "01-R-basics.html#sec-exo-1",
    "title": "1  R et RStudio : les bases",
    "section": "1.5 Exercice",
    "text": "1.5 Exercice\nDans votre dossier de travail, créez un nouveau script que vous nommerez ExoDiamonds.R. Vous prendrez soin d’ajouter autant de commentaires que nécessaire dans votre script afin de le structurer correctement.\n\nTéléchargez (si besoin) et chargez le package ggplot2\nChargez le jeu de données diamonds grâce à la commande data(diamonds)\nDéterminez le nombre de lignes et de colonnes de ce tableau nommé diamonds\nCréez un nouveau tableau que vous nommerez diamants_chers qui contiendra uniquement les informations des diamants dont le prix est supérieur ou égal à $15000.\nCombien de diamants coûtent $15000 ou plus ?\nCela représente quelle proportion du jeu de données de départ ?\nTriez ce tableau par ordre de prix décroissants et affichez les informations des 20 diamants les plus chers."
  },
  {
    "objectID": "02-dataset.html#préambule",
    "href": "02-dataset.html#préambule",
    "title": "2  Explorez votre premier jeu de données",
    "section": "2.1 Préambule",
    "text": "2.1 Préambule\nMettons en pratique tout ce que nous avons appris pour commencer à explorer un jeu de données réel. Les données nous parviennent sous différents formats, des images au texte en passant par des tableaux de chiffres. Tout au long de ce document, nous nous concentrerons sur les ensembles de données qui peuvent être stockés dans une feuille de calcul, car il s’agit de la manière la plus courante de collecter des données dans de nombreux domaines. N’oubliez pas ce que nous avons appris dans la Section 1.3.4.1 : ces ensembles de données de type “tableurs” sont appelés data.frame dans R, et nous nous concentrerons sur l’utilisation de ces objets tout au long de ce livre. S’il est évidemment possible d’importer dans R des données stockées dans des fichiers Excel ou des fichiers textes, nous allons dans un premier temps faire plus simple : nous travaillerons avec des données déjà disponibles dans un packages que nous avons installé dans la Section 1.4.\nAinsi, commençons par charger les packages nécessaires pour ce chapitre (cela suppose que vous les ayez déjà installés ; relisez la Section 1.4 pour plus d’informations sur l’installation et le chargement des packages R si vous ne l’avez pas déjà fait). Au début de chaque chapitre, nous aurons systématiquement besoin de charger quelques packages. Donc n’oubliez pas de les installer au préalable si besoin.\n\n# Pensez à installer ces packages avant de les charger si besoin \nlibrary(dplyr)\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "02-dataset.html#le-package-palmerpenguins",
    "href": "02-dataset.html#le-package-palmerpenguins",
    "title": "2  Explorez votre premier jeu de données",
    "section": "2.2 Le package palmerpenguins",
    "text": "2.2 Le package palmerpenguins\nCe package (Horst, Hill, et Gorman 2022) contient un jeu de données collectées par Kristen Gorman (membre du ``Long Term Ecological Research Network’’) et la station de Palmer en Antarctique (Gorman, Williams, et Fraser 2014). Les données contiennent des informations au sujet de 330 individus appartenant à 3 espèces de manchots (voir Figure 2.1) étudiés sur 3 îles de l’archipel de Palmer, an Antarctique. Ces espèces ont fait l’objet de nombreuses études comparatives, notamment afin de déterminer comment elles utilisent le milieu pour acquérir des ressources. Puisque ces 3 espèces sont proches sur le plan phylogénétique et qu’elles occupent le même habitat, la question de la compétition inter-spécifique, pour l’espace et les ressources, se pose tout naturellement.\n\n\n\nFigure 2.1: Les 3 espèces de manchots de l’archipel de Palmer. Illustration : Allison Horst"
  },
  {
    "objectID": "02-dataset.html#le-data-frame-penguins",
    "href": "02-dataset.html#le-data-frame-penguins",
    "title": "2  Explorez votre premier jeu de données",
    "section": "2.3 Le data frame penguins",
    "text": "2.3 Le data frame penguins\nNous allons commencer par explorer le jeu de données penguins qui est inclus avec le package palmerpenguins afin de nous faire une idée de sa structure. Dans votre script, tapez la commande suivante et exécutez la dans la console (selon les réglages de RStudio et la largeur de votre console, l’affichage peut varier légèrement) :\n\npenguins\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nEssayons de décrypter cet affichage :\n\nA tibble: 344 x 8 : un tibble est un data.frame amélioré. Il a toutes les caractéristiques d’un data.frame, (tapez class(penguins) pour vous en convaincre), mais en plus, il a quelques propriétés intéressantes sur lesquelles nous reviendrons plus tard. Ce tibble possède donc :\n\n344 lignes\n8 colonnes, qui correspondent aux variables. Dans un tibble, les observations sont toujours en lignes et les variables en colonnes\n\nspecies, island, bill_length_mm, bill_depth_mm, flipper_length_mm… sont les noms des colonnes, c’est à dire les variables de ce jeu de données\nNous avons ensuite les 10 premières lignes du tableau\n... with 334 more rows, and abbreviated variable names..., nous indique que 334 lignes ne logent pas à l’écran et que le nom de certains variables a été abrégé afin de permettre un affichage plus clair. Ces données font toutefois partie intégrante du tableau penguins\nles noms complets de toutes les variables abrégées sont également indiqués\n\nCette façon d’afficher les tableaux est spécifique des tibbles. Vous noterez que le type de chaque variable est indiqué entre &lt;...&gt;, juste sous les noms de colonnes. Voici certains des types de données que vous pourrez rencontrer :\n\n&lt;int&gt; : nombres entiers (“integers”)\n&lt;dbl&gt; : nombres réels (“doubles”)\n&lt;chr&gt; : caractères (“characters”)\n&lt;fct&gt; : facteurs (“factors”)\n&lt;ord&gt; : facteurs ordonnés (“ordinals”)\n&lt;lgl&gt; : logiques (colonne de vrais/faux : “logical”)\n&lt;date&gt; : dates\n&lt;time&gt; : heures\n&lt;dttm&gt; : combinaison de date et d’heure (“date time”)\n\nCette façon d’afficher le contenu d’un tableau permet d’y voir (beaucoup) plus clair que l’affichage classique d’un data.frame. Malheureusement, ce n’est pas toujours suffisant. Voyons quelles sont les autres méthodes permettant d’explorer un data.frame."
  },
  {
    "objectID": "02-dataset.html#explorer-un-data.frame",
    "href": "02-dataset.html#explorer-un-data.frame",
    "title": "2  Explorez votre premier jeu de données",
    "section": "2.4 Explorer un data.frame",
    "text": "2.4 Explorer un data.frame\nParmi les nombreuses façons d’avoir une idée des données contenues dans un data.frame tel que penguins, on présente ici 3 fonctions qui prennent le nom du data.frame en guise d’argument, et un opérateur :\n\nla fonction View() intégrée à RStudio. C’est celle que vous utiliserez le plus souvent. Attention, elle s’écrit avec un “V” majuscule\nla fonction glimpse() chargée avec le package dplyr. Elle est très similaire à la fonction str() découverte dans les tutoriels de DataCamp\nl’opérateur $ permet d’accéder à une unique variable d’un data.frame\nla fonction skim() du package skimr permet d’obtenir un résumé complet mais très synthétique et visuel des variables d’un data.frame\n\n\n2.4.1 View()\nTapez View(penguins) dans votre script et exécutez la commande. Un nouvel onglet contenant ce qui ressemble à un tableur doit s’ouvrir.\n\n\n\n\n\n\nQuizz : à quoi correspondent chacune des lignes de ce tableau ?\n\n\n\n\naux données d’une espèce\naux données d’une île\naux données d’un individu\naux données d’une population (plusieurs manchots à la fois)\n\n\n\nIci, vous pouvez donc explorer la totalité du tableau, passer chaque variable en revue, et même appliquer des filtres pour ne visualiser qu’une partie des données. Par exemple, essayez de déterminer combien d’individus sont issus de l’île “Biscoe”.\nCe tableau n’est pas facile à manipuler. Il est impossible de corriger des valeurs, et lorsque l’on applique des filtres, il est impossible de récupérer uniquement les données filtrées. Nous verrons plus tard comment les obtenir en tapant des commandes simples dans un script. La seule utilité de ce tableau est donc l’exploration visuelle des données.\n\n\n2.4.2 glimpse()\nLa seconde façon d’explorer les données contenues dans un tableau est d’utiliser la fonction glimpse() après avoir chargé le package dplyr :\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\nIci, les premières observations sont présentées en lignes pour chaque variable du jeu de données. Là encore, le type de chaque variable est précisé. Essayez d’identifier 3 variables catégorielles. À quoi correspondent-elles ? En quoi sont-elles différentes des variables numériques ?\n\n\n2.4.3 L’opérateur $\nL’opérateur $ permet d’accéder à une unique variable grâce à son nom. Par exemple on peut accéder à toutes les données concernant les noms d’espèces (variable species du tableau penguins) en tapant :\n\npenguins$species\n\n  [1] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n  [8] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [15] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [22] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [29] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [36] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [43] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [50] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [57] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [64] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [71] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [78] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [85] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [92] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n [99] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[106] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[113] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[120] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[127] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[134] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[141] Adelie    Adelie    Adelie    Adelie    Adelie    Adelie    Adelie   \n[148] Adelie    Adelie    Adelie    Adelie    Adelie    Gentoo    Gentoo   \n[155] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[162] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[169] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[176] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[183] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[190] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[197] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[204] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[211] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[218] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[225] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[232] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[239] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[246] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[253] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[260] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[267] Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo    Gentoo   \n[274] Gentoo    Gentoo    Gentoo    Chinstrap Chinstrap Chinstrap Chinstrap\n[281] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[288] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[295] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[302] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[309] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[316] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[323] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[330] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[337] Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap Chinstrap\n[344] Chinstrap\nLevels: Adelie Chinstrap Gentoo\n\n\nCela nous permet de récupérer les données sous la forme d’un vecteur ou, comme ici, d’un facteur. Attention toutefois, le tableau penguins contient beaucoup de lignes. Récupérer une variable grâce à cet opérateur peut rapidement saturer la console. Nous serons amenés à manipuler des tableaux contenant plusieurs dizaines ou centaines de milliers de lignes. C’est le cas du tableau diamonds du package ggplot2 que vous avez découvert dans les exercice de la Section 1.5.\nSi, par exemple, vous souhaitez extraire les données relatives à la clarté des diamants (colonne clarity) du tableau diamonds, vous pouvez taper ceci :\n\nlibrary(ggplot2)\ndiamonds$clarity\n\nLe résultat est pour le moins indigeste ! Lorsqu’un tableau contient de nombreuses lignes, c’est rarement une bonne idée de transformer l’une de ses colonnes en vecteur. Dans la mesure du possible, les données d’un tableau doivent rester dans le tableau.\n\n\n2.4.4 skim()\nPour utiliser la fonction skim(), vous devez au préalable installer le package skimr :\n\ninstall.packages(\"skimr\")\n\nCe package est un peu “expérimental” et il se peut que l’installation pose problème. Si un message d’erreur apparaît lors de l’installation, procédez comme suit :\n\nQuittez RStudio (sans oublier de sauvegarder votre travail au préalable)\nRelancez RStudio et dans la console, tapez ceci :\n\n\ninstall.packages(\"rlang\")\n\n\nTentez d’installer skimr à nouveau.\nExécutez à nouveau tout votre script afin de retrouver votre travail dans l’état où il était avant de quitter RStudio.\n\nSi l’installation de skimr s’est bien passée, vous pouvez maintenant taper ceci :\nlibrary(skimr)\nskim(penguins)\n\n\nData summary\n\n\nName\npenguins\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nspecies\n0\n1.00\nFALSE\n3\nAde: 152, Gen: 124, Chi: 68\n\n\nisland\n0\n1.00\nFALSE\n3\nBis: 168, Dre: 124, Tor: 52\n\n\nsex\n11\n0.97\nFALSE\n2\nmal: 168, fem: 165\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nbill_length_mm\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\n▃▇▇▆▁\n\n\nbill_depth_mm\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\n▅▅▇▇▂\n\n\nflipper_length_mm\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\n▂▇▃▅▂\n\n\nbody_mass_g\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\n▃▇▆▃▂\n\n\nyear\n0\n1.00\n2008.03\n0.82\n2007.0\n2007.00\n2008.00\n2009.0\n2009.0\n▇▁▇▁▇\n\n\n\n\nNous aurons l’occasion de revenir en détail sur la signification de tous ces indices au semestre prochain. À ce stade, retenez que cette fonction skim() permet d’accéder à un résumé très détaillé de chaque variable d’un jeu de données. Par exemple, on apprend ici que la masse corporelle moyenne des manchots de l’ensemble du jeu de données vaut 4201.75 grammes (ligne body_mass_g, colonne mean), avec un écart-type de 0.82 grammes (colonne sd), et que la masse de 2 individus est manquante (colonne n_missing). Cette fonction nous sera donc très utile au semestre prochain lorsque nous aborderons la question des statistiques descriptives.\n\n\n2.4.5 Les fichiers d’aide\nUne fonctionnalité particulièrement utile de R est son système d’aide. On peut obtenir de l’aide au sujet de n’importe quelle fonction et de n’importe quel jeu de données en tapant un “?” immédiatement suivi du nom de la fonction ou de l’objet.\nPar exemple, examinez l’aide du jeu de données penguins :\n\n?penguins\n\nVous devriez absolument prendre l’habitude d’examiner les fichiers d’aide des fonctions ou jeux de données pour lesquels vous avez des questions. Ces fichiers sont très complets, et même s’il peuvent paraître impressionnants au premier abord, ils sont tous structurés sur le même modèle et vous aideront à comprendre comment utiliser les fonctions, quels sont les arguments possibles, à quoi ils servent et comment les utiliser.\nPrenez le temps d’examiner le fichier d’aide du jeu de données penguins. Avant de passer à la suite, assurez-vous d’avoir compris à quoi correspondent chacune des 8 variables de ce tableau."
  },
  {
    "objectID": "02-dataset.html#sec-exo-2",
    "href": "02-dataset.html#sec-exo-2",
    "title": "2  Explorez votre premier jeu de données",
    "section": "2.5 Exercices",
    "text": "2.5 Exercices\nConsultez l’aide du jeu de données diamonds du package ggplot2.\n\nQuel est le code de la couleur la plus prisée ?\nQuel est le code de la moins bonne clarté ?\nÀ quoi correspond la variable z ?\nEn quoi la variable depth est-elle différente de la variable z ?\n\nInstallez le package nycflights13 et consultez son aide en tapant help(package=\"nycflights13\").\n\nConsultez l’aide des 5 jeux de données de ce package.\nÀ quoi correspond la variable visib ?\nDans quel tableau se trouve-t-elle ?\nCombien de lignes possède ce tableau ?\n\n\n\n\n\nGorman, Kristen B., Tony D. Williams, et William R Fraser. 2014. « Ecological Sexual Dimorphism and Environmental Variability within a Community of Antarctic Penguins (Genus Pygoscelis) ». PLOS ONE 9 (mars): 1‑14. https://doi.org/10.1371/journal.pone.0090081.\n\n\nHorst, Allison, Alison Hill, et Kristen Gorman. 2022. palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins."
  },
  {
    "objectID": "03-visualization.html#préambule",
    "href": "03-visualization.html#préambule",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.1 Préambule",
    "text": "3.1 Préambule\nDans le Chapitre 1 et le Chapitre 2, vous avez découvert les concepts essentiels qu’il est important de maîtriser avant de commencer à explorer en détail des données dans R. Les éléments de syntaxe abordés dans la Section 1.3 sont nombreux et vous n’avez probablement pas tout retenu. C’est pourquoi je vous conseille de garder les tutoriels de DataCamp à portée de main afin de pouvoir refaire les parties que vous maîtrisez le moins. Ce n’est qu’en répétant plusieurs fois ces tutoriels que les choses seront vraiment comprises et que vous les retiendrez. Ainsi, si des éléments de code présentés ci-dessous vous semblent obscurs, revenez en arrière : toutes les réponses à vos questions se trouvent probablement dans les chapitres précédents.\nAprès la découverte des bases du langage R, nous abordons maintenant les parties de ce livre qui concernent la “science des données” (ou “Data Science” pour nos amis anglo-saxons). Nous allons voir dans ce chapitre qu’outre les fonctions View() et glimpse(), l’exploration visuelle via la représentation graphique des données est un moyen indispensable et très puissant pour comprendre ce qui se passe dans un jeu de données.\n\n\n\n\n\n\nImportant\n\n\n\nLa visualisation de vos données est un préalable indispensable à toute analyse statistique.\n\n\nLa visualisation des données est en outre un excellent point de départ quand on découvre la programmation sous R, car ses bénéfices sont clairs et immédiats : vous pouvez créer des graphiques élégants et informatifs qui vous aident à comprendre les données. Dans ce chapitre, vous allez donc plonger dans l’art de la visualisation des données, en apprenant la structure de base des graphiques réalisés avec ggplot2 qui permettent de transformer des données numériques et catégorielles en graphiques.\nToutefois, la visualisation seule ne suffit généralement pas. Il est en effet souvent nécessaire de transformer les données pour produire des représentations plus parlantes. Ainsi, dans le Chapitre 5, vous découvrirez les fonctions clés qui vous permettront de sélectionner des variables importantes, de filtrer des observations, de créer de nouvelles variables, ou d’en modifier la forme.\nCe n’est qu’en combinant les transformations de données et représentations graphiques d’une part, avec votre curiosité et votre esprit critique d’autre part, que vous serez véritablement en mesure de réaliser une analyse exploratoire de vos données à la fois utile et pertinente. C’est la seule façon d’identifier des questions intéressantes sur vos données, afin de tenter d’y répondre par les analyses statistiques et la modélisation qui seront abordées lors des prochains semestres."
  },
  {
    "objectID": "03-visualization.html#prérequis",
    "href": "03-visualization.html#prérequis",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.2 Prérequis",
    "text": "3.2 Prérequis\nDans ce chapitre, nous aurons besoin des packages suivants :\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(nycflights13)\nlibrary(gapminder)\nlibrary(scales)\n\nSi ce n’est pas déjà fait, pensez à les installer avant de les charger en mémoire.\nAu niveau le plus élémentaire, les graphiques permettent de comprendre comment les variables se comparent en termes de tendance centrale (à quel endroit les valeurs ont tendance à être localisées, regroupées) et leur dispersion (comment les données varient autour du centre). La chose la plus importante à savoir sur les graphiques est qu’ils doivent être créés pour que votre public (le professeur qui vous évalue, le collègue avec qui vous collaborez, votre futur employeur, etc.) comprenne bien les résultats et les informations que vous souhaitez transmettre. Il s’agit d’un exercice d’équilibriste : d’une part, vous voulez mettre en évidence autant de relations significatives et de résultats intéressants que possible, mais de l’autre, vous ne voulez pas trop en inclure, afin d’éviter de rendre votre graphique illisible ou de submerger votre public. Tout comme n’importe quel paragraphe de document écrit, un graphique doit permettre de communiquer un message (une idée forte, un résultat marquant, une hypothèse nouvelle, etc).\nComme nous le verrons, les graphiques nous aident également à repérer les tendances extrêmes et les valeurs aberrantes dans nos données. Nous verrons aussi qu’une façon de faire, assez classique, consiste à comparer la distribution d’une variable quantitative pour les différents niveaux d’une variable catégorielle.\n\n\n\n\n\n\nObjectifs\n\n\n\nDans ce chapitre, vous apprendrez à :\n\nfaire différents types de graphiques exploratoires avec le package ggplot2   \nchoisir le ou les graphiques appropriés selon la nature des variables dont vous disposez ou que vous souhaitez mettre en relation\nmettre vos graphiques en forme pour les intégrer dans vos rapports ou compte-rendus de TP"
  },
  {
    "objectID": "03-visualization.html#sec-gggraph",
    "href": "03-visualization.html#sec-gggraph",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.3 La grammaire des graphiques",
    "text": "3.3 La grammaire des graphiques\nLes lettres gg du package ggplot2 sont l’abréviation de “grammar of graphics” : la grammaire des graphiques. De la même manière que nous construisons des phrases en respectant des règles grammaticales précises (usage des noms, des verbes, des sujets et adjectifs…), la grammaire des graphiques établit un certain nombre de règles permettant de construire des graphiques : elle précise les composants d’un graphique en suivant le cadre théorique défini par Wilkinson (2005).\n\n3.3.1 Éléments de la grammaire\nEn bref, la grammaire des graphiques nous dit que :\n\nUn graphique est l’association (mapping) de données/variables (data) à des attributs esthétiques (aesthetics) d’objets géométriques (geometric objects).\n\nPour clarifier, on peut disséquer un graphique en 3 éléments essentiels :\n\ndata : le jeu de données contenant les variables que l’on va associer à des objets géométriques. Pour ggplot2 les données doivent obligatoirement être stockées dans un data.frame ou un tibble\ngeom : les objets géométriques en question. Cela fait référence aux types d’objets que l’on peut observer sur le graphique (des points, des lignes, des barres, etc.)\naes : les attributs esthétiques des objets géométriques présents sur le graphique. Par exemple, la position sur les axes x et y, la couleur, la taille, la transparence, la forme, etc. Chacun de ces attributs esthétiques peut-être associé à une variable de notre jeu de données.\n\nExaminons un exemple pour bien comprendre.\n\n\n3.3.2 Gapminder\nEn février 2006, un statisticien du nom de Hans Rosling a donné un TED Talk intitulé “The best stats you’we ever seen”. Au cours de cette conférence, Hans Rosling présente des données sur l’économie mondiale, la santé et le développement des pays du monde. Les données sont disponibles sur ce site et dans le package gapminder.\nPour l’année 2007, le jeu de données contient des informations pour 142 pays. Examinons les premières lignes de ce jeu de données :\n\n\n\nLes 6 premières lignes du jeu de données gapminder pour l’année 2007.\n\n\nCountry\nContinent\nLife Expectancy\nPopulation\nGDP per Capita\n\n\n\n\nAfghanistan\nAsia\n43.828\n31889923\n974.5803\n\n\nAlbania\nEurope\n76.423\n3600523\n5937.0295\n\n\nAlgeria\nAfrica\n72.301\n33333216\n6223.3675\n\n\nAngola\nAfrica\n42.731\n12420476\n4797.2313\n\n\nArgentina\nAmericas\n75.320\n40301927\n12779.3796\n\n\nAustralia\nOceania\n81.235\n20434176\n34435.3674\n\n\n\n\n\nPour chaque ligne, les variables suivantes sont décrites :\n\nCountry : le pays\nContinent : le continent\nLife Expectancy : espérance de vie à la naissance\nPopulation : nombre de personnes vivant dans le pays\nGDP per Capita : produit intérieur brut (PIB) par habitant en dollars américains. GDP est l’abréviation de “Growth Domestic Product”. C’est un indicateur de l’activité économique d’un pays, parfois utilisé comme une approximation du revenu moyen par habitant.\n\nExaminons maintenant la Figure 3.1 qui représente ces variables pour chacun des 142 pays de ce jeu de données (notez l’utilisation de la notation scientifique dans la légende, et de l’échelle logarithmique de l’axe des abscisses).\n\n\n\n\n\nFigure 3.1: Espérance de vie en fonction du PIB par habitant en 2007.\n\n\n\n\nSi on décrypte ce graphique du point de vue de la grammaire des graphiques, on voit que :\n\nla variable GDP per Capita est associée à l’aesthetic x de la position des points\nla variable Life Expectancy est associée à l’aesthetic y de la position des points\nla variable Population est associée à l’aesthetic size (taille) des points\nla variable Continent est associée à l’aesthetic color (couleur) des points\n\nIci, l’objet géométrique (ou geom) qui représente les données est le point. Les données (ou data) sont contenues dans le tableau gapminder et chacune de ces variables est associée (mapping) aux caractéristiques esthétiques des points.\n\n\n3.3.3 Autres éléments de la grammaire des graphiques\nOutre les éléments indispensables évoqués ici (data, mapping, aes, et geom), il existe d’autres aspects de la grammaire des graphiques qui permettent de contrôler l’aspect des graphiques. Ils ne sont pas toujours indispensables. Nous en verrons néanmoins quelque-uns particulièrement utiles :\n\nfacet : c’est un moyen très pratique de scinder le jeu de données en plusieurs sous-groupes et de produire automatiquement un graphique pour chacun d’entre eux.\nposition : permet notamment de modifier la position des barres d’un barplot.\nlabs : permet de définir les titres, sous-titres et légendes des axes d’un graphique\ntheme : permet de modifier l’apect général des graphiques en appliquant des thèmes prédéfinis ou en modifiant certains aspects de thèmes existants\n\n\n\n3.3.4 Le package ggplot2\nComme indiqué plus haut, le package ggplot2 (Wickham et al. 2023) permet de réaliser des graphiques dans R en respectant les principes de la grammaire des graphiques. Vous avez probablement remarqué que depuis le début de la section Section 3.3, beaucoup de termes sont écrits dans la police réservée au code informatique. C’est parce que les éléments de la grammaire des graphiques sont tous précisés dans la fonction ggplot() qui demande, au grand minimum, que les éléments suivants soient spécifiés :\n\nle nom du data.frame contenant les variables qui seront utilisées pour le graphique. Ce nom correspond à l’argument data de la fonction ggplot().\nl’association des variables à des attributs esthétiques. Cela se fait grâce à l’argument mapping et la fonction aes()\n\nAprès avoir spécifié ces éléments, on ajoute des couches supplémentaires au graphique grâce au signe +. La couche la plus essentielle à ajouter à un graphique, est une couche contenant un élément géométrique, ou geom (par exemple des points, des lignes ou des barres). D’autres couches peuvent s’ajouter pour spécifier des titres, des facets ou des modifications des axes et des thèmes du graphique.\nDans le cadre de ce cours, nous verrons un grand nombre de types de gra[hiques distincts, y compris les 5 types de graphiques les plus courants :\n\nles nuages de points\nles graphiques en lignes\nles histogrammes\nles diagrammes bâtons\nles boîtes à moustaches\n\n\n\n3.3.5 Votre premier graphique\nReprenons maintenant le jeu de données penguins :\n\npenguins\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nComme évoqué plus haut, il s’agit d’un tibble. Plusieurs de ses variables concernent la biométrie des manchots, en particulier de son bec (voir Figure 3.2).\n\n\n\nFigure 3.2: Morphométrie du bec des manchots. Illustration de Allison Horst\n\n\nSupposons qu’on cherche à déterminer si la longueur du bec des manchots est proportionnelle à leur masse. Pour produire un graphique permettant de le déterminer, nous avons besoin des éléments suivants :\n\ndata : le tableau penguins\nun objet géométrique, ici, des points (geom_point()) puisque nous disposons de 2 variables numériques (plus de détails à ce sujet plus bas)\nl’association de certaines variables du jeu de données (ici, body_mass_g et bill_length_mm) à certaines caractéristiques esthétiques du graphiques (ici, la position sur les axes des x et des y), grâce à l’argument mapping et la fonction aes().\n\nConcrètement, voilà le code qu’il faut taper dans votre script :\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = bill_length_mm))\n\n\n\n\nCette première ligne de code permet de faire plusieurs choses :\n\non indique à R qu’on souhaite faire un graphique (avec la fonction ggplot())\non indique à R que les données sont contenues dans l’objet penguins avec data = penguins\non associe (avec mapping = la variable body_mass_g à l’axe des x et la variable bill_length_mm à l’axe des y. On fait cela grâce à aes(x = body_mass_g, y = bill_length_mm)\n\nCette commande génère la première couche du graphique. Il n’y a pas encore de données car nous n’avons pas indiqué quel type d’objet géométrique nous souhaitons afficher, mais la fenêtre graphique est bel et bien créée, les axes apparaissent, ils sont légendés et leur échelle est adaptée aux variables du tableau penguins que nous avons sélectionnées. Pour terminer le graphique, il nous faut donc ajouter une seconde couche, celle de l’objet géométrique :\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = bill_length_mm)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nRelation entre masse corporelle et longueur du bec chez les manchots de l’archipel de Palmer\n\n\n\n\nAu moment de produire ce graphique, R nous indique que 2 lignes du tableau penguins ne figurent pas sur ce graphique car elles possèdent des données manquantes (NA), pour l’une et/ou l’autre des variables que nous avons sélectionnées. La fonction geom-point() est donc incapable de les placer sur le graphique.\nVous avez donc ici un premier exemple de graphique très simple. Il est loin d’être parfait (à minima, le titre des axes devrait être modifié), mais il a le mérite de vous présenter la syntaxe que vous devrez utiliser pour produire presque tous les graphiques qui vous seront utiles avec ggplot2. En outre, on peut percevoir qu’il semble exister une relation positive (mais imparfaite) entre longueur des becs et masse des individus. Il faut toutefois être prudent car nous avons ici utilisé toutes les données disponibles (donc les données des 3 espèces à la fois), ce qui est loin d’être pertinent.\n\n\n\n\n\n\nEn résumé\n\n\n\n\nAu sein de la fonction ggplot(), on spécifie 2 composants de la grammaire des graphiques :\n\nle nom du tableau contenant les données grâce à l’argument data = penguins\nl’association (mapping) des variables du tableau de données à des caractéristiques esthétiques (aes()) en précisant aes(x = body_mass_g, y = bill_length_mm) :\n\nla variable body_mass_g est associée à l’esthétique de position x\nla variable bill_length_mm est associée à l’esthétique de position y\n\n\nOn ajoute une couche au graphique ggplot() grâce au symbole +. La couche en question précise le troisième élément indispensable de la grammaire des graphiques : l’objet geométrique. Ici, les objets sont des points. On le spécifie grâce à la fonction geom_point().\n\n\n\nQuelques remarques concernant les couches :\n\nNotez que le signe + est placé à la fin de la ligne. Vous recevrez un message d’erreur si vous le placez au début.\nQuand vous ajoutez une couche à un graphique, je vous encourage vivement à presser la touche enter de votre clavier juste après le symbole +. Ainsi, le code correspondant à chaque couche sera sur une ligne distincte, ce qui augmente considérablement la lisibilité de votre code.\nComme indiqué dans la Section 1.3.4.3, tant que les arguments d’une fonction sont spécifiés dans l’ordre, on peut se passer d’écrire leur nom. Ainsi, les deux blocs de commande suivants produisent exactement le même résultat :\n\n\n# Le nom des arguments est précisé\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = bill_length_mm)) +\n  geom_point()\n\n# Le nom des arguments est omis\nggplot(penguins, aes(x = body_mass_g, y = bill_length_mm)) +\n  geom_point()\n\n\n\n3.3.6 Exercices\n\nDonnez une raison pratique expliquant pourquoi les variables body_mass_g et bill_length_mm ont une relation positive\nQuelles variables (pas nécessairement dans le tableau penguins) pourraient avoir une corrélation négative (relation négative) avec body_mass_g ? Pourquoi ? Rappelez-vous que nous étudions ici des variables numériques.\nCitez les éléments de ce graphique/de ces données qui vous sautent le plus aux yeux ?\nCréez un nouveau nuage de points en utilisant d’autres variables du jeu de données penguins"
  },
  {
    "objectID": "03-visualization.html#quel-graphique-dans-quelle-situation",
    "href": "03-visualization.html#quel-graphique-dans-quelle-situation",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.4 Quel graphique dans quelle situation ?",
    "text": "3.4 Quel graphique dans quelle situation ?\nIl n’est pas possible de faire n’importe quel type de graphique dans n’importe quelle situation. Selon le nombre de variables dont on dispose ou que l’on souhaite examiner, et selon la nature de ces variables (numériques et/ou catégorielles), le choix des types de graphiques possibles sera limité. Par exemple, les diagrammes bâtons sont réservés aux variables catégorielles, alors que les histogrammes sont possibles uniquement avec les variables numériques continues. Néanmoins, dans certaines situations, plusieurs choix de graphiques seront possibles, et vous aurez donc une certaine liberté. Vos choix seront alors guidés par les objectifs que vous souhaiterez atteindre grâce aux graphiques, ainsi que par vos préférences.\n\n\n\n\n\n\nObjectifs\n\n\n\nDans la suite de ce chapitre, nous traiterons donc des situations les plus courantes : quel(s) type(s) de graphique(s) produire lorsque l’on dispose d’une, deux ou trois variables ? Quel(s) type(s) de graphique(s) produire lorsque les variables sont toutes numériques, toutes catégorielles, ou lorsqu’on dispose de variables des deux types ?\nPour chaque situation, un ou des exemples seront fournis à partir des données du tableau penguins. Cela sera aussi l’occasion de présenter quelques-unes des nombreuses subtilités liées à l’utilisation du package ggplot2."
  },
  {
    "objectID": "03-visualization.html#une-seule-variable-numérique",
    "href": "03-visualization.html#une-seule-variable-numérique",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.5 Une seule variable numérique",
    "text": "3.5 Une seule variable numérique\nLorsque l’on souhaite examiner une unique variable numérique, deux types de représentations graphiques sont en général possibles :\n\nles histogrammes : la variable d’intérêt est placée sur l’axe des x du graphique. Les valeurs utilisées sur l’axe des y est calculée automatiquement par le logiciel.\nles nuages de points : la variable d’intérêt est placée sur l’axe des y. L’axe des x porte soit un simple numéro d’indice pour chaque observation, soit une unique valeur sans importance, la même pour toutes les observations.\n\nLes syntaxes et options pour ces 2 types de graphiques sont présentées ci-dessous.\n\n3.5.1 Les histogrammes\n\n3.5.1.1 Syntaxe élémentaire\nImaginons que l’on s’intéresse à la variable body_mass_g du jeu de données penguins.\nLa syntaxe permettant de produire un histogramme, sous sa forme la plus simple, est la suivante :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nDeux messages nous sont adressés par le logiciel :\n\nMessage d'avis: Removed 2 rows containing non-finite values (stat_bin). Ce message indique, comme pour le premier nuage de points, que 2 individus du tableau penguins ont une masse corporelle inconnue (NA). Ces 2 individus (donc les deux lignes correspondantes), ont été ignorés pour produire ce graphique\n'stat_bin()' using 'bins = 30'. Pick better value with 'binwidth'. Ce message indique que R a choisi pour nous les limites des classes utilisées pour faire l’histogramme. Sur un histogramme, la variable d’intérêt (toujours numérique et continue), qui apparaît sur l’axe des abscisses, est en effet “découpée” en plusieurs classes, en général de même taille, afin de permettre une représentation de la distribution des valeurs. Ici, R indique qu’il a créé 30 catégories pour nous, et que nous pouvons faire un choix différent grâce à l’argument binwidth. Nous y reviendrons un peu plus loin.\n\nSur ce graphique, l’axe des abscisses porte donc la variable continue “découpée” en classes de mêmes largeur, et l’axe des ordonnées renseigne sur le nombre (count ou fréquence absolue) d’individus observés dans chaque classe. Les zones du graphique où les barres sont les plus hautes indiquent donc les caractéristiques des individus observés le plus fréquemment. À l’inverse, les barres les plus courtes correspondent à des valeurs de masse rarement observées. Au final, ce type de graphique permet de visualiser la distribution des données pour une variable numérique continue.\nIci, on constate qu’une majorité d’individus semble avoir des masses proches de 3500 grammes. Une autre portion non négligeable des individus (mais moins importante) semble avoir une masse légèrement supérieure à 4500 grammes. Enfin, les masses supérieures à 6000 grammes sont très rares. L’histogramme nous permet également de visualiser l’étendue des données : les manchots étudiés ici ont des masses qui s’étalent d’un peu plus de 2500 grammes à un peu moins de 6500 grammes.\n\n\n3.5.1.2 Couleur\nPour rendre ce graphique plus facilement lisible, on peut en modifier la couleur :\n\nla couleur de remplissage des barres peut-être spécifiée grâce à l’argument fill =\nla couleur de contour des barres peut-être spécifiée grâce à l’argument color =\n\nUne liste des couleurs disponibles dans R peut être affichée dans la console en tapant :\n\ncolors()\n\nVous pouvez voir à quelle couleur correspond chacun de ces noms dans ce document pdf.\nMettons à jour notre histogramme en ajoutant un peu de couleur :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nLes 30 classes de masses sont maintenant plus facilement visibles et distingables.\n\n\n3.5.1.3 À l’intérieur ou à l’extérieur de aes() ?\nLes couleurs de remplissage et de contour des barres d’un histogramme font partie des caractéristiques esthétiques du graphique. Pourtant, elles ne sont pas précisées à l’intérieur de la fonction aes(). La raison est simple mais importante :\n\n\n\n\n\n\nImportant\n\n\n\nOn place à l’intérieur de aes() uniquement les caractéristiques esthétiques du graphique que l’on souhaite associer à des variables du jeu de données.\n\n\nIci, les couleurs que l’on indique sont des constantes : toutes les barres ont les mêmes couleur de remplissage et de contour. On n’associe pas une variable du jeu de données à ces caractéristiques esthétiques. On place donc fill = et color = à l’extérieur de aes(). Si on se trompe, voilà ce qui se produit :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(aes(fill = \"steelblue\", color = \"black\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nLes couleurs qui apparaissent ne correspondent pas à ce qui est demandé, et une légende ne correspondant à rien apparaît à droite du graphique. La syntaxe utilisée ici suppose en effet que \"steelblue\" et \"black\" seraient des variables du jeu de données penguins. Puisqu’elles n’existent pas, R essaie de se débrouiller pour interpréter comme il peut ce qu’on lui demande, et finit par produire ce graphique incohérent. La couleur utilisée est la première couleur de la palette par défaut de ggplot2.\nPour élaborer des graphiques plus avancés, il faudra donc toujours vous poser la question suivante : la caractéristique esthétique que je souhaite modifier doit-elle être associée à une valeur constante que je fixe pour toutes les barres ou tous les points d’un graphique, et alors, je l’indique en dehors de aes(), ou est-elle au contraire associée à une variable du jeu de données, et alors, je l’indique à l’intérieur de aes().\nIl est bien sûr possible d’avoir un mélange des deux. Par exemple, le code suivant permet d’associer la couleur de remplissage au sexe des individus étudiés (variable sex du jeu de données penguins), et de spécifier une valeur constante pour la couleur de contour des barres (ici, le noir) :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(aes(fill = sex), color = \"black\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nOn constate que toutes les barres ont un contour noir, mais que plusieurs couleurs de remplissage apparaissent maintenant, selon le sexe des individus, dans chaque classe de masse. Une légende adaptée est aussi créée automatiquement à droite du graphique. On apprend ainsi que les individus les plus lourds sont tous des mâles. On constate également que le sexe de certains individus est inconnu.\nAu final, nous ne sommes déjà plus dans la situation où on examine une unique variable numérique. Nous avons en effet ici un graphique nous permettant de mettre en relation une variable numérique (la masse des individus en grammes) et une variable catégorielle (le sexe des individus). Nous reviendrons plus tard sur ce type de graphiques.\n\n\n3.5.1.4 La largeur des classes\nComme évoqué plus haut, par défaut, R choisit arbitrairement de découper la variable numérique utilisée en 30 classes de même largeur afin de produire l’histogramme. Ça n’est que rarement un bon choix, et malheureusement, il n’y a pas de règle permettant de définir à coup sûr le bon nombre de classes pour visualiser au mieux la distribution d’une variable numérique. Il faut en effet presque toujours procéder par essais-erreurs successifs. Il est possible d’ajuster les caractéristiques (nombre et/ou largeur) des classes de l’histogramme de l’une des 3 façons suivantes :\n\nEn ajustant le nombre de classes avec bins.\nEn précisant la largeur des classes avec binwidth.\nEn fournissant manuellement les limites des classes avec breaks.\n\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\",\n                 bins = 10)\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nIci, diminuer le nombre de classes à 10 a pour effet de trop lisser la distribution des données. On ne visualise plus les variations subtiles de la distribution. À l’inverse, trop augmenter le nombre de classes n’est pas pertinent non plus :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\",\n                 bins = 100)\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nIci, passer à 100 classes de taille génère un histogramme plein de trous, avec des classes très étroites, dont certaines sont très représentées, et immédiatement suivies ou précédées par des classes très peu représentées. Cela n’a pas de logique, et c’est presque toujours le signe qu’il faut réduire le nombre de classes.\nAu final, pour ces données, un nombre de classes compris entre 20 et 30 semble un bon choix :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\",\n                 bins = 25)\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nC’est un bon choix, entre trop peu d’information, et trop de bruit visuel. Évidemment, ce nombre sera différent pour chaque jeu de données. On constate ici à peu près 3 pics (autour de 3500 grammes, un peu au-dessus de 4500 grammes, et autour de 5500 grammes) qui reflètent bien la distribution de ces données.\nOn peut également modifier la largeur des classes (et non plus leur nombre) avec binwidth :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\",\n                 binwidth = 200)\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nIci, chaque catégorie recouvre 200 grammes. Avec l’argument bins, on indique à R combien on souhaite obtenir de classes, et il détermine automatiquement leur largeur. Avec binwidth, on indique la largeur des classes souhaitées, et R détermine automatiquement le nombre de classes nécessaires pour couvrir la totalité des données.\nEnfin, il est possible de déterminer manuellement les limites des classes souhaitées avec l’argument breaks :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\",\n                 breaks = c(2500, 2750, 3000, 3500, 4000, 4500, 5000, 6000, 7000))\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nVous constatez ici que les choix effectués ne sont pas très pertinents : toutes les classes n’ont pas la même largeur. Cela rend l’interprétation difficile. Il est donc vivement conseillé, pour spécifier breaks, de créer des suites régulières, comme avec la fonction seq() (consultez son fichier d’aide et les exemples) :\n\nlimites &lt;- seq(from = 2500, to = 6500, by = 250)\nlimites\n\n [1] 2500 2750 3000 3250 3500 3750 4000 4250 4500 4750 5000 5250 5500 5750 6000\n[16] 6250 6500\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\",\n                 breaks = limites)\n\n\n\n\nUn exemple d’utilisation de l’argument breaks\n\n\n\n\nIl est important que toute la gamme des valeurs de body_mass_g soit bien couverte par les limites des classes que nous avons définies, sinon, certaines valeurs sont omises et l’histogramme est donc incomplet/incorrect. Une façon de s’en assurer est d’afficher le résumé des données pour la colonne body_mass_g du jeu de données penguins :\n\nsummary(penguins$body_mass_g)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   2700    3550    4050    4202    4750    6300       2 \n\n\nOn voit ici que les masses varient de 2700 à 6300 grammes. Les classes que nous avons définies couvrent une plage de masses plus large (de 2500 à 6500). Toutes les données sont donc bien intégrées à l’histogramme.\n\n\n3.5.1.5 geom_rug et geom_density\nLa fonction geom_histogram() n’est pas la seule qui permette de visualiser la distribution des données. Il est en effet possible d’utiliser d’autres objets géométriques, en plus ou à la place de geom_histogram() pour ajouter de l’information sur le graphique, ou pour visualiser différemment la distribution des mêmes données.\nLa fonction geom_rug() permet d’ajouter les données réelles sous forme de segments, sous un histogramme. Cela prend souvent l’aspect d’une sorte de tapis, d’où le nom de la fonction (“rug” signifie “tapis” en anglais). Pour ajouter une couche supplémentaire au graphique, on ajoute simplement un + à la fin de la dernière ligne, et sur la ligne suivante, on ajoute un objet géométrique supplémentaire :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\",\n                 bins = 25) +\n  geom_rug()\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nLes tirets qui sont maintenant visibles en-dessous de l’histogramme correspondent aux 342 valeurs de masses réellement observées dans le jeu de données. Puisque certaines tailles ont été observées plusieurs fois, faire des tirets semi-transparents nous permettra de mieux visualiser quelles tailles ont été observées fréquemment ou rarement. On peut régler la transparence des éléments d’un graphique avec l’argument alpha =, qui prend des valeurs comprises entre 0 (transparence totale) et 1 (opacité totale) :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\",\n                 bins = 25) +\n  geom_rug(alpha = 0.3)\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nLes tirets sont maintenant d’autant plus foncés que les tailles ont été observées un grand nombre de fois. On retrouve bien ici la distribution décrite plus haut, avec 3 principaux groupes de valeurs. Cela révèle certainement en partie la complexité des données : ces tailles correspondent en effet aux mesures effectuées chez 3 espèces distinctes qui peuvent avoir des caractéristiques différentes, sans compter que le sexe des individus, qui n’apparaît pas ici, entre aussi probablement en jeu. Nous y reviendrons plus tard.\nLa fonction geom_density() permet de s’affranchir de la question du nombre ou de la largeur des classes de taille :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_density(fill = \"steelblue\", color = \"black\", alpha = 0.7, bw = 300)\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nOn obtient une sorte d’histogramme lissé qui fait bien apparaître les 3 tailles les plus fréquentes (au niveau des 3 “bosses” du graphique). Inutile ici de spécifier un nombre de classes de taille, ou leur largeur : le lissage est ici automatique. On peut modifier l’importance du lissage avec l’argument bw, mais la valeur choisie par défaut par R est généralement tout à fait satisfaisante. Vous pouvez essayer avec une valeur de lissage de 30, puis de 500 pour vous rendre compte de l’effet de ce paramètre.\nNotez également que si l’histogramme présentait des valeurs d’abondance sur l’axe des y (des nombres d’individus), le graphique de densité présente, comme son nom l’indique, l’information de densité des observations. Cela signifie que la surface totale sous la courbe (en bleu) vaut 1. Cela peut s’avérer utile pour comparer plusieurs distributions pour lesquelles on disposes de tailles d’échantillons très différentes.\nEnfin, on peut créer un graphique qui présentera à la fois l’histogramme (avec geom_histogram()), les données individuelles (avec geom_rug()) et la courbe de densité (avec geom_density()). Mais pour que tout s’affiche correctement, il faut indiquer à geom_histogram que l’axe des y doit porter les densités et non les abondances. On fait cela en précisant y = after_stat(density), cela indique à R que la variable density ne figure pas dans le tableau penguins, mais qu’elle est calculée par la fonction geom_histogram() :\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(aes(y = after_stat(density)),\n                 fill = \"steelblue\", color = \"black\",\n                 bins = 25, alpha = 0.7) +\n  geom_rug(alpha = 0.3) +\n  geom_density(color = \"purple\", linewidth = 2)\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nNotez l’utilisation des arguments alpha, color et size, pour modifier l’aspect de différents éléments du graphique. Assurez-vous d’avoir compris comment on les utilise, et faites vos propres expériences.\n\n\n3.5.1.6 Un mot sur la position de la fonction aes()\nSur le dernier exemple, vous constatez que la fonction aes() apparaît une fois à l’intérieur de la fonction ggplot(), et une autre fois à l’intérieur de geom_histogram(). Pourquoi ne pas avoir tapé, plus simplement :\n\nggplot(penguins, aes(x = body_mass_g, y = after_stat(density))) +\n  geom_histogram(fill = \"steelblue\", color = \"black\",\n                 bins = 25, alpha = 0.7) +\n  geom_rug(alpha = 0.3) +\n  geom_density(color = \"purple\", linewidth = 2)\n\nL’explication est relativement simple, mais importante :\n\n\n\n\n\n\nImportant\n\n\n\nCe qui est spécifié dans la fonction ggplot() s’applique à toutes les couches du graphiques (donc ici, aux 3 couches geom_histogram(), geom_rug() et geom_density()).\nCe qui est spécifié dans une fonction geom_...() ne s’applique qu’à cette couche géométrique particulière.\n\n\nAinsi, ajouter y = after_stat(density) à l’intérieur de ggplot() renvoie donc un message d’erreur, car seule la fonction geom_histogram() calcule la variable density, seule la fonction geom_histogram() sait quoi faire de cette variable. Dans notre exemple, il est en revanche logique d’ajouter aes(x = body_mass_g) dans la fonction ggplot(), car nos trois couches géométriques ont besoin de cet argument, et pour les 3 couches géométriques, on associe bien cette variable body_mass_g à l’axe des x. Toutefois, rien ne nous empêche d’écrire ceci à la place :\n\nggplot(data = penguins) +\n  geom_histogram(aes(x = body_mass_g, y = after_stat(density)),\n                 fill = \"steelblue\", color = \"black\",\n                 bins = 25, alpha = 0.7) +\n  geom_rug(aes(x = body_mass_g),\n           alpha = 0.3) +\n  geom_density(aes(x = body_mass_g),\n               color = \"purple\", linewidth = 2)\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nC’est plus long, mais c’est tout à fait correct et ça produit exactement le même résultat qu’auparavant.\n\n\n\n3.5.2 Les nuages de points et stripcharts\nPour ces deux types de graphiques, la variable numérique sera portée par l’axe des y, et toutes les valeurs seront visibles, de façon non agrégée (contrairement aux histogrammes où les valeurs individuelles sont rassemblées à l’intérieur de classes). La différence entre les deux types de graphiques tient à la nature des informations qui figureront sur l’axe des x :\n\nPour les nuages de points, l’axe des x portera simplement l’information du numéro d’observation pour chaque individu. L’individu placé sur la première ligne du tableau de données portera l’indice 1. L’individu placé sur la deuxième ligne du tableau de données portera l’indice 2, et ainsi de suite jusqu’à l’individu placé sur la dernière ligne du tableau (il portera ici l’indice 344 puisque le tableau compte 344 lignes)\nPour un stripchart, l’axe des x portera une unique valeur, la même pour tous les individus\n\nDans les deux cas, l’axe des x ne nous sera pas vraiment utile. Il nous servira simplement à afficher des points sur un graphique, mais puisque nous ne disposons que d’une unique variable, c’est bien l’axe des y qui nous intéressera en priorité. Pour faire un nuage de points, on utilise geom_point(), et pour un stripchart geom_jitter(). Commençons par examiner le nuage de points pour la variable body-mass-g :\n\nggplot(penguins, aes(x = seq_along(body_mass_g), y = body_mass_g)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nC’est la fonction seq_along(), que l’on associe à l’axe des x, qui permet de faire apparaître les numéros de lignes du tableau penguins. On constate ici que 3 groupes de points sont présents :\n\nPour les lignes 1 à 150 (environ), un premier groupe de points présente des masses comprises entre 3000 et 4800 grammes environ.\nPour les lignes 151 à 275 (environ), un second groupes de points présente des masses comprises entre 4000 et plus de 6000 grammes.\nPour les lignes 276 à 344 (environ), un troisième groupe de points présente des valeurs similaires à celles du premier groupe.\n\nEn examinant le tableau penguins de plus près, on se rend compte que les 3 espèces de manchots sont présentées dans l’ordre. Ainsi, ces 3 groupes correspondent à 3 espèces différentes. Pour le visualiser, il suffit d’associer la variable species à la couleur des points. Puisqu’on cherche à associer une variable du tableau de données à une caractéristique esthétique d’un objet géométrique, on renseigne color = species à l’intérieur de aes() :\n\nggplot(penguins, aes(x = seq_along(body_mass_g), y = body_mass_g)) +\n  geom_point(aes(color = species))\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nFigure 3.3: Nuage de points des masses corporelles des 3 espèces de manchots\n\n\n\n\nAttention, nous ne sommes déjà plus dans la situation d’une unique variable numérique : nous avons ici visualisé 2 variables : une numérique (portée par l’axe des y) et une catégorielle (l’espèce représentée par la couleur des points). Ici, on constate que les espèces Adélie et Chinstrap semblent avoir approximativement la même gamme de masses, alors que les Gentoo semblent nettement plus lourds.\nComme pour les histogrammes, on peut utiliser des caractéristiques esthétiques variées pour modifier l’apparence des points :\n\nalpha : la transparence. Choisir une valeur comprise entre 0 (invisible) et 1 (totalement opaque)\nsize : la taille des points\ncolor : la couleur des points (ou de leur contour pour les symboles qui permettent de spécifier une couleur de remplissage et une couleur de contour)\nfill : la couleur de remplissage des points (pour les symboles qui permettent de spécifier une couleur de remplissage et une couleur de contour)\nshape : pour modifier les symboles utilisés. Les symboles possibles sont codés ainsi :\n\n\n\n\nFigure 3.4: Liste des symboles et codes correspondants pour les graphiques faisant apparaître des points. Pour les symboles 21 à 25, il sera possible de spécifier une couleur de remplissage fill et une couleur de contour color. Pour tous les autres symboles, les changements de couleurs se feront avec l’argument color.\n\n\nChacune de ces caractéristiques esthétiques peut être associée à une variable d’un tableau (il faut alors le spécifier à l’intérieur de aes()), ou à une valeur unique, constante et identique pour tous les points du graphique (il faut alors le spécifier à l’extérieur de aes()). Par exemple :\n\nggplot(penguins, aes(x = seq_along(body_mass_g), y = body_mass_g)) +\n  geom_point(shape = 23, fill = \"steelblue\", color = \"black\", \n             size = 3, alpha = 0.5)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nL’ajout de la transparence permet de régler le problème des points qui se superposent (un phénomène nommé “overplotting”).\nExaminons à présent un exemple de stripchart :\n\nggplot(penguins, aes(x = \"\", y = body_mass_g)) +\n  geom_jitter()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nEn indiquant x = \"\", nous créons une unique catégorie pour l’axe des abscisses, qui sera utilisée pour placer les valeurs de tous les individus. Les valeurs de body_mass_g sont lues sur l’axe des y, comme pour un nuage de point classique. Si les points apparaissent dispersés, c’est en raison de 2 arguments spécifiques de la fonction geom_jitter() :\n\nwidth = permet de spécifier l’étendue horizontale du bruit aléatoire qui sera utilisé pour placer les points\nheight = permet de spécifier l’étendue verticale du bruit aléatoire qui sera utilisé pour placer les points\n\nSi nous ne renseignons pas nous même ces deux arguments, ils sont fixés automatiquement par le logiciel, ce qui n’est pas souhaitable, notamment pour le bruit vertical. Pour mieux comprendre, voyons ce qui se passe dans 3 situations :\n\nggplot(penguins, aes(x = \"\", y = body_mass_g)) +\n  geom_jitter(width = 0, height = 0)\n\nggplot(penguins, aes(x = \"\", y = body_mass_g)) +\n  geom_jitter(width = 0.1, height = 0)\n\nggplot(penguins, aes(x = \"\", y = body_mass_g)) +\n  geom_jitter(width = 0.1, height = 2000)\n\n\n\n\n\n\n\n(a) Pas de dispersion horizontale, pas de dispersion verticale\n\n\n\n\n\n\n\n(b) Faible dispersion horizontale, pas de dispersion verticale\n\n\n\n\n\n\n\n(c) Faible dispersion horizontale, forte dispersion verticale\n\n\n\n\nFigure 3.5: Trois exemples de stripchart\n\n\n\n\nLe premier exemple (Figure 3.5 (a)) ne présente aucune dispersion, ni horizontale (width = 0), ni verticale (height = 0). Les points apparaissent donc tous alignés, ils ont en effet tous la même valeur sur l’axe des abscisses. Leur position sur l’axe des y reflète la masse réellement observée pour chaque individu. Cette façon de représenter les données n’est pas très utile car la superposition des points vient empêcher la visualisation correcte de la distribution : ici, il est impossible de dire quelles sont les masses les plus fréquemment observées ou les plus rarement observées.\nLe second exemple (Figure 3.5 (b)) présente une dispersion horizontale modérée (width = 0.1) et pas de dispersion verticale (height = 0). Ici, tous les points ne sont plus alignés sur une seule droite. Puisque nous avons fixé width = 0.1, la position horizontale des points est choisie aléatoirement par R : il ajoute un léger bruit horizontal aléatoire, soit positif, soit négatif, avant de placer les points le long de l’axe des abscisses. Plus la valeur de width sera élevée, plus l’étendue du bruit horizontal sera importante. Sur l’axe des y en revanche, aucun bruit n’a été ajouté (height = 0). La position des points le long de cet axe reflète donc parfaitement la masse de chaque individu telle qu’enregistrées dans le tableau penguins et c’est bien ce que nous voulons. D’ailleurs, on constate que l’axe des ordonnées est strictement identique (même étendue, même graduations…) pour les 2 premiers sous-graphiques. C’est ce type de représentation que nous recherchons. En effet, l’absence de bruit vertical nous permet de visualiser correctement (donc sans distorsion) la variable numérique choisie (ici body_mass_g), et le bruit horizontal nous permet d’étaler légèrement les points de part et d’autres d’un axe vertical virtuel, ce qui a pour effet de réduire l’overplotting, et ce qui nous permet donc de visualiser les zones où les points sont plus nombreux/denses et les zones où les observations sont plus rares. Ici, on observe une majorité de points entre 3000 et 4000 grammes, une densité de points intermédiaire entre 4000 et 5000 grammes, et des points moins nombreux (donc moins d’individus) pour les masses supérieures à 5000 grammes.\nLe troisième exemple (Figure 3.5 (c)) présente une dispersion horizontale modérée (width = 0.1) et une importante dispersion verticale (height = 2000). Cela signifie que la position des points sur l’axe des y ne reflète plus les vraies valeurs de masses enregistrées dans le tableau penguins, mais des valeurs de masses auxquelles un bruit aléatoire a été ajouté ou retiré. C’est ce qui explique que l’axe des ordonnées ne présente pas la même échelle que pour les 2 autres graphiques. Ce n’est évidemment pas souhaitable, car si nous voulons bel et bien ajouter un bruit horizontal pour éviter la superposition des points, il est essentiel de ne pas modifier la position verticale des points qui nous renseigne sur la variable d’intérêt. Ici, la Figure 3.5 (c) présente un axe des y différent des 2 autres sous-figures, et la position verticale des points a été tellement altérée qu’on ne peut plus distinguer la sur-abondance de données entre 3000 et 4000 grammes, ni la sous-représentation des observations au-dessus de 5000 grammes. Il sera donc important à l’avenir de toujours fixer height = 0 pour faire un stripchart correct.\n\n\n\n\n\n\n\nImportant\n\n\n\nSur un stripchart :\n\nla position verticale des points ne doit jamais être modifiée. On fixera donc toujours height = 0\nla position horizontale des points doit être modifiée afin d’éviter l’overplotting et de visualiser les zones de fortes et faibles densités de points. On choisira donc en général des valeurs de width comprises entre 0.1 et 0.4\n\n\n\nEnfin, puisqu’un stripchart permet d’afficher des points sur un graphiques, les arguments permettant de modifier l’aspect des points sont les mêmes que pour les nuages de points. Par exemple :\n\nggplot(penguins, aes(x = \"\", y = body_mass_g)) +\n  geom_jitter(aes(color = species, shape = species),\n              size = 3, alpha = 0.6, \n              width = 0.1, height = 0)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nFigure 3.6: Un exemple de stripchart\n\n\n\n\nSur cette figure, comme pour le nuage de points réalisé plus haut, j’ai associé la variable species à la couleur des points (donc à l’intérieur de aes()). J’ai également associé cette variable à la forme des points shape = species à l’intérieur de aes(). C’est ce qui explique que chacune des 3 espèces apparaît sous la forme de symboles de formes et de couleurs différents. Pour limiter l’overplotting, j’ai spécifié un bruit horizontal, et j’ai fixé le bruit vertical à zéro. Enfin j’ai augmenté la taille des symboles (avec size = 3, en dehors de aes() car 3 est une constante qui s’appliquera à tous les points du graphique de la même manière) et leur transparence (avec alpha = 0.6, toujours en dehors de aes() pour la même raison). On constate ici encore que les masses corporelles des manchots Adélie et Chinstrap sont très similaires, et inférieures à celles de l’espèce Gentoo.\n\n\n3.5.3 Exercices\n\nÀ quoi sert l’argument stroke pour les nuages de points et les stripcharts ?\nCréez de nouveaux graphiques (histogramme et diagramme de densité) avec la variable contenant l’information de la longueur des nageoires des manchots flipper_length_mm. Décrivez les graphiques obtenus. Vos observations sont-elles cohérentes avec ce que nous savons maintenant des masses individuelles ?\nVisualisez ces données avec un nuage de points ou un stripchart. Retrouvez-vous les mêmes informations de distribution ?"
  },
  {
    "objectID": "03-visualization.html#une-seule-variable-catégorielle",
    "href": "03-visualization.html#une-seule-variable-catégorielle",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.6 Une seule variable catégorielle",
    "text": "3.6 Une seule variable catégorielle\n\n3.6.1 Les diagrammes bâtons\nComme nous l’avons vu plus haut, les histogrammes permettent de visualiser la distribution d’une variable numérique continue. Souvent, on souhaite visualiser la distribution d’une variable catégorielle. C’est une tâche relativement aisée puisqu’elle consiste simplement à compter combien d’éléments tombent dans chacune des catégories (ou modalités) de la variable catégorielle. Le meilleur moyen de visualiser de telles données de comptage (aka fréquences) est de réaliser un diagramme bâtons, autrement appelé barplot ou barchart.\nUne difficulté, toutefois, concerne la façon dont les données sont présentées : est-ce que la variable d’intérêt est “pré-comptée” ou non ? Par exemple, le code ci-dessous crée 2 data.frame qui représentent la même collection de fruits : 3 pommes, 2 oranges et 4 bananes :\n\npanier &lt;- tibble(\n  fruit = c(\"pomme\", \"pomme\", \"banane\", \"pomme\", \"orange\", \"banane\", \"orange\", \"banane\", \"banane\")\n)\n\npanier_counted &lt;- tibble(\n  fruit = c(\"pomme\", \"orange\", \"banane\"),\n  nombre = c(3, 2, 4)\n)\n\nLe tableau panier contient des données qui n’ont pas encore été comptées. Le tableau contient donc une unique variable nommée fruit :\n\npanier\n\n# A tibble: 9 × 1\n  fruit \n  &lt;chr&gt; \n1 pomme \n2 pomme \n3 banane\n4 pomme \n5 orange\n6 banane\n7 orange\n8 banane\n9 banane\n\n\nÀ l’inverse, le tableau panier_counted contient des données qui ont déjà été comptées. Le tableau contient donc 2 variables dans 2 colonnes distinctes : une colonne fruit et une colonne nombre, mais seulement 3 lignes puisque seulement 3 modalités (les catégories de la variable catégorielle) sont présentes pour la variable fruit :\n\npanier_counted\n\n# A tibble: 3 × 2\n  fruit  nombre\n  &lt;chr&gt;   &lt;dbl&gt;\n1 pomme       3\n2 orange      2\n3 banane      4\n\n\nLes deux tableaux panier et panier_counted représentent exactement les mêmes données, mais sous deux formats différents. Du fait de ces deux formats possibles, deux objets géométriques distincts devront être utilisés pour représenter les données. Le graphique obtenu sera le même, mais à chaque format de tableau son geom_...().\n\n3.6.1.1 geom_bar() et geom_col()\nPour visualiser les données non pré-comptées, on utilise geom_bar() :\n\nggplot(panier, aes(x = fruit)) +\n  geom_bar()\n\n\n\n\nFigure 3.7: Barplot pour des données non pré-comptées.\n\n\n\n\nPour visualiser les données déjà pré-comptées, on utilise geom_col() :\n\nggplot(panier_counted, aes(x = fruit, y = nombre)) +\n  geom_col()\n\n\n\n\nFigure 3.8: Barplot pour des données pré-comptées.\n\n\n\n\nNotez que les figures Figure 3.7 et Figure 3.8 sont absolument identiques (à l’exception du titre de l’axe des ordonnées), mais qu’elles ont été créées à partir de 2 tableaux de données différents. En particulier, notez que :\n\nLe code qui génère la figure Figure 3.7 utilise le jeu de données panier, et n’associe pas de variable à l’axe des ordonnées : dans la fonction aes(), seule la variable associée à x est précisée. C’est la fonction geom_bar() qui calcule automatiquement les abondances (ou fréquences) pour chaque catégorie de la variable fruit. La variable count est ainsi générée automatiquement et associée à y.\nLe code qui génère la figure Figure 3.8 utilise le jeu de données panier_counted. Ici, c’est bien l’utilisateur qui associe la variable nombre à l’axe des y à l’intérieur de la fonction aes(). La fonction geom_col() a besoin de 2 variables (une variable catégorielle pour l’axe des x et une numérique pour l’axe des y) pour fonctionner.\n\nAutrement dit, lorsque vous souhaiterez créer un diagramme bâtons, il faudra donc au préalable vérifier de quel type de données vous disposez pour choisir l’objet géométrique approprié :\n\n\n\n\n\n\nDiagrammes bâtons\n\n\n\n\nSi la variable catégorielle n’est pas pré-comptée dans le tableau de données  geom_bar(). La variable catégorielle est associée à l’esthétique x du graphique. On ne renseigne pas y.\nSi la variable catégorielle est pré-comptée dans le tableau de données  geom_col(). La variable catégorielle est associée à l’esthétique x du graphique. On associe explicitement les comptages à l’esthétique y du graphique.\n\n\n\nEnfin, notez que l’ordre des modalité (ou catégories) qui apparaissent sur l’axe des abscisses est l’ordre alphabétique : la modalité banane apparaît à gauche, puis la modalité orange et enfin la modalité pomme. Bien souvent, cet ordre alphabétique n’est pas pertinent. Nous verrons plus loin comment faire pour trier les catégories par ordre croissant ou décroissant. C’est en effet une possibilité intéressante qui est impossible pour les histogrammes (car l’axe des x porte une variable numérique continue qu’il est impossible de “mélanger”), mais souvent vivement recommandée pour les diagrammes bâtons.\n\n\n3.6.1.2 Un exemple concret\nRevenons aux manchots. Imaginons que nous souhaitions connaître le nombre d’individus étudiés pour chaque espèce. Dans le jeu de données penguins, la variable species indique à quelle espèce appartiennent chacun des 344 individus étudiés. Une façon simple de représenter ces données est donc la suivante :\n\nggplot(penguins, aes(x = species)) +\n  geom_bar()\n\n\n\n\nFigure 3.9: Effectifs pour les 3 espèces de manchots étudiées\n\n\n\n\nIci, geom_bar() a compté le nombre d’occurrences de chaque espèce dans le tableau penguins et a automatiquement associé ce nombre à l’axe des ordonnées.\nLà encore, les modalités sont triées par ordre alphabétique sur l’axe des abscisses. Il est généralement plus utile de trier les catégories par ordre décroissant. Nous pouvons faire cela facilement grâce à la fonction fct_infreq() du package forcats, qui permet de modifier l’ordre des modalités d’une variable catégorielle (ou facteur). Si vous avez installé le tidyverse, le package forcast doit être disponible sur votre ordinateur. N’oubliez pas de le charger si besoin :\n\nlibrary(forcats)\nggplot(penguins, aes(x = fct_infreq(species))) +\n  geom_bar()\n\n\n\n\nFigure 3.10: Effectifs pour les 3 espèces de manchots étudiées, triés en ordre décroissant\n\n\n\n\nOrdonner les catégories par ordre décroissant est souvent indispensable afin de faciliter la lecture du graphique et les comparaisons entre catégories.\nSi nous souhaitons connaître le nombre précis d’individus de chaque espèce, il nous faut faire appel à plusieurs fonctions du package dplyr que nous détaillerons dans le chapitre Chapitre 5. Ci-dessous, nous créons un nouveau tableau species_table contenant le nombre d’individus de chaque espèce et les espèces sont ordonnées par abondance décroissante :\n\nspecies_table &lt;- penguins %&gt;%   # On prend le tableau penguins, puis...\n  count(species) %&gt;%            # On compte les effectifs de chaque espèce, puis...\n  arrange(desc(n))              # On trie par effectif décroissants ...\nspecies_table                   # Enfin, on affiche la nouvelle table\n\n# A tibble: 3 × 2\n  species       n\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Gentoo      124\n3 Chinstrap    68\n\n\nIci, la table a été triée par effectifs décroissants. Mais attention, les niveaux du facteur species n’ont pas été modifiés :\n\nfactor(species_table$species)\n\n[1] Adelie    Gentoo    Chinstrap\nLevels: Adelie Chinstrap Gentoo\n\n\nLe premier niveau est toujours Adélie, puis Chinstrap, en enfin Gentoo, et non pas l’ordre du tableau nouvellement créé (Adelie, puis Gentoo, puis Chinstrap) car les niveaux sont toujours triés par ordre alphabétique. La conséquence est que si nous devions faire un diagramme bâtons avec ces données, la fonction geom_col() ne permettrait pas d’ordonner les catégories correctement :\n\nggplot(species_table, aes(x = species, y = n)) +\n  geom_col()\n\n\n\n\nSi nous souhaitons trier ces catégories par effectif décroissant, la fonction fct_infreq() ne nous est ici d’aucune utilité. En effet, le tableau species_table contient une seule ligne pour chaque espèce, donc une fréquence de 1 pour chaque espèce. Le critère de la fréquence d’occurrence des modalités dans le tableau de données ne peut donc pas être utilisé. Pour parvenir à nos fins avec ce tableau déjà précompté, il faut cette fois utiliser la fonction fct_reorder() pour ordonner correctement les catégories. Cette fonction prends 3 arguments :\n\nLa variable catégorielle dont on souhaite réordonner les niveaux (ici, la variable species du tableau species_table).\nUne variable numérique qui permet d’ordonner les catégories (ici, la variable n du même tableau).\nL’argument optionnel .desc qui permet de préciser si le tri doit être fait en ordre croissant (c’est le cas par défaut) ou décroissant.\n\n\nggplot(species_table, \n       aes(x = fct_reorder(species, n, .desc = TRUE), y = n)) +\n  geom_col()\n\n\n\n\nVous voyez donc que selon le type de données dont vous disposez (soit un tableau comme penguins, avec toutes les observations, soit un tableau beaucoup plus compact comme species_table), la démarche permettant de produire un diagramme bâtons, dans lequel les catégories seront triées, sera différente.\nUne dernière précision : inverser l’ordre des variables sur les axes du graphiques permet de faire un diagramme bâtons horizontal. C’est parfois très utile lorsque les modalités de la variable catégorielle sont nombreuses et/ou que leur nom est long. Faire apparaître les modalités sur l’axe des y au lieu de l’axe des x peut rendre leur lecture plus aisée :\n\nggplot(penguins, aes(y = fct_infreq(species))) +\n  geom_bar(fill = \"steelblue\", color = \"black\", alpha = 0.7)\n\n\n\nggplot(species_table, \n       aes(y = fct_reorder(species, n, .desc = TRUE), x = n)) +\n  geom_col(fill = \"firebrick\", color = \"black\", alpha = 0.7)\n\n\n\n\n\n\n3.6.1.3 Exercices\n\nQuelle est la différence entre un histogramme et un diagramme bâtons ?\nPourquoi les histogrammes sont-ils inadaptés pour visualiser des données catégorielles ?\nPourquoi ne peut-on pas trier un histogramme par ordre croissant ?\nQuelle île de l’archipel Palmer a fourni le plus grand nombre de manchots pour cette étude ?\n\n\n\n\n3.6.2 Éviter à tout prix les diagrammes circulaires\nÀ mon grand désarroi, l’un des graphiques classiquement utilisé pour représenter la distribution d’une variable catégorielle est le diagramme circulaire (ou diagramme camembert, piechart en anglais). C’est presque toujours la plus mauvaise visualisation possible pour représenter les effectifs ou pourcentages associés aux modalités d’une variable catégorielle. Je vous demande de l’éviter à tout prix. Notre cerveau n’est en effet pas correctement équipé pour comparer des angles et des surfaces. Ainsi, par exemple, nous avons naturellement tendance à surestimer les angles supérieurs à 90º, et à sous-estimer les angles inférieurs à 90º. En d’autres termes, il est difficile pour les humains de comparer des grandeurs sur des diagrammes circulaires.\nÀ titre d’exemple, examinez ce diagramme, qui reprend les mêmes chiffres que précédemment, et tentez de répondre aux questions suivantes :\n\n\n\n\n\nFigure 3.11: Répartition des effectifs par espèce et par sexe\n\n\n\n\n\nQuelle est la catégorie la plus représentée ?\nDe combien de fois la part des Gentoo mâles est-elle supérieure à celle des Chinstrap femelles ? (1,5 fois, 2 fois, 2.5 fois ?…)\nQuelle est la quatrième catégorie la plus représentée ?\n\nIl est difficile (voir impossible) de répondre précisément à ces questions avec le diagramme circulaire de la Figure 3.11, alors qu’il est très simple d’obtenir des réponses précises avec un diagramme bâtons tel que présenté à la Figure 3.12 ci-dessous (vérifiez-le !) :\n\n\n\n\n\nFigure 3.12: Répartition des effectifs par espèce et par sexe"
  },
  {
    "objectID": "03-visualization.html#deux-variables-numériques",
    "href": "03-visualization.html#deux-variables-numériques",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.7 Deux variables numériques",
    "text": "3.7 Deux variables numériques\nLa représentation graphique la plus adaptée à la visualisation des relations entre deux variables numériques est aussi l’une des plus simples : il s’agit des nuages de points que nous avons déjà évoqués. Ici dépendant, puisque nous disposons de 2 variables numériques, nous allons en associer une à l’axe des x et l’autre à l’axe des y. Si l’on pressent que l’une des deux variables pourrait “expliquer” la seconde, ou être en partie responsable de ses variations, on l’appelle variable explicative et on la placera alors sur l’axe des x. L’autre variable, celle que l’on suppose influencée par la première est appelée variable expliquée, et sera associée à l’axe des y.\nLes nuages de points de 2 variables numériques permettent donc de visualiser les relations (supposées ou réelles) entre deux variables.\n\n3.7.1 Nuage de points\n\n3.7.1.1 Syntaxe élémentaire\nPrenons un exemple : nous souhaitons examiner les relations qui existent entre la masse corporelle des individus et la longueur de leur nageoire. Une relation allométrique simple suppose en effet que plus un individu est grand et lourd, plus ses membres seront développés. La nature de la relation allométrique peut toutefois être radicalement différente selon les espèces. Pour l’instant, nous ne nous intéressons pas aux éventuelles différences entre espèces et nous examinerons donc l’ensemble des données, toutes espèces confondues.\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nIci, j’associe body_mass_g à l’axe des x car je suppose que c’est la variable explicative. Il est en effet plus logique de considérer que la masse corporelle influence la longueur des nageoires plutôt que le contraire. La variable expliquée, ici flipper_length_mm est associée à l’axe des y.\nLa syntaxe est donc très simple, et le graphique obtenu permet de constater que plus les individus sont lourds, plus leurs nageoires sont longues.\n\n\n3.7.1.2 Droite de tendance\nSi l’on souhaite visualiser (modéliser !) cette association entre les deux variables, on peut ajouter sur ce graphique une courbe de tendance ou une droite de régression avec l’objet géométrique geom_smooth() :\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nL’argument method = \"lm\" indique que nous souhaitons ajouter une droite de régression (lm est l’abréviation de “linear model”). L’intervalle grisé autour de la droite représente l’incertitude associée à la régression et indique que la “vraie” droite de régression, dans la population générale (et pas seulement dans notre échantillon de 344 individus) est probablement située dans cette zone grisée. Nous aurons l’occasion de revenir en détail sur la notion de régression linéaire et d’incertitude associée au semestre 6 de la licence SV.\n\n\n3.7.1.3 Autres caractéristiques esthétiques\nComme pour tous les graphiques faisant apparaître des points, il est possible de modifier les caractéristiques esthétiques habituelles, soit en les associant à des variables du jeu de données (et en l’indiquant à l’intérieur de aes()), soit en les fixant à des valeurs constantes qui s’appliqueront à tous les points (et en l’indiquant alors en dehors de aes()). L’exemple ci-dessous illustre ces possibilités :\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm, fill = species)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  geom_smooth(aes(color = species), method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nL’argument se = FALSE de la fonction geom_smooth() permet de ne pas afficher l’intervalle d’incertitude de la régression linéaire. Ici, j’ai associé la couleur de remplissage des points et la couleur des droites de régression aux espèces (donc à l’intérieur de aes(), soit dans ggplot() soit dans geom_smooth()), et j’ai fixé pour tous les points, le choix du type de symbole (shape = 21, voir Figure 3.4), la couleur de contour (color = \"black\") et la transparence alpha = 0.6.\nLà encore, il ne s’agit plus strictement d’un graphique représentant les relations entre 2 variables numériques, mais bien entre 3 variables : deux variables numériques (body_mass_g et flipper_length_mm) et une variable catégorielle ou facteur (species). Il est finalement très simple d’ajouter d’autres variables sur un graphique bivarié tel qu’un nuage de points.\n\n\n\n3.7.2 Les graphiques en lignes\nLes graphiques en lignes, ou “linegraphs” sont généralement utilisés lorsque l’axe des x porte une information temporelle, et l’axe des y une autre variable numérique. Le temps est une variable naturellement ordonnée : les jours, semaines, mois, années, se suivent naturellement. Les graphiques en lignes devraient être évités lorsqu’il n’y a pas une organisation séquentielle évidente de la variable portée par l’axe des x. Ainsi, lorsque l’une des 2 variables dont on dispose est une variable numérique temporelle (des dates, des heures, etc.), on la place sur l’axe des x et la seconde variable, dont on étudiera les fluctuations au cours du temps, sur l’axe des y. On peut alors relier les valeurs grâce à l’objet géométrique geom_line() afin de créer une série temporelle. Pour illustrer cela, examinons un autre jeu de données qui contient une variable temporelle :\n\neconomics\n\n# A tibble: 574 × 6\n   date         pce    pop psavert uempmed unemploy\n   &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1 1967-07-01  507. 198712    12.6     4.5     2944\n 2 1967-08-01  510. 198911    12.6     4.7     2945\n 3 1967-09-01  516. 199113    11.9     4.6     2958\n 4 1967-10-01  512. 199311    12.9     4.9     3143\n 5 1967-11-01  517. 199498    12.8     4.7     3066\n 6 1967-12-01  525. 199657    11.8     4.8     3018\n 7 1968-01-01  531. 199808    11.7     5.1     2878\n 8 1968-02-01  534. 199920    12.3     4.5     3001\n 9 1968-03-01  544. 200056    11.7     4.1     2877\n10 1968-04-01  544  200208    12.3     4.6     2709\n# ℹ 564 more rows\n\n\nLe jeu de données economics est fourni avec le package ggplot2. Puisque vous avez chargé ce package (ou le tidyverse qui contient ce package), vous devriez pouvoir accéder à ce tableau sans difficulté. Nous nous intéresserons ici à la variable date que nous placerons sur l’axe des x et à la variable uempmed qui est la durée de chômage médiane dans la population américaine, en nombre de semaines, que nous placerons sur l’axe des y. Examinons donc comment la durée médiane du du chômage a évolué au fil du temps :\n\nggplot(economics, aes(x = date, y = uempmed)) +\n  geom_line()\n\n\n\n\nNotez que puisque la variable date du tableau economics est comprise par R comme étant du type “variable temporelle” (le type indiqué dans le tableau, juste sous le nom de variable, est &lt;date&gt;), l’axe des abscisses du graphique, qui est associé à cette variable, est correctement mis en forme : seules les années apparaissent.\nLes graphiques en lignes permettent de visualiser des progressions/évolutions lorsqu’il existe une temporalité entre les données. Sur l’exemple, traité plus haut, du lien entre masse et longueur des nageoire des manchots, relier les points n’aurait absolument aucun sens puisque toutes les observations sont indépendantes : elles correspondent à des individus différents. Soyez donc prudents lorsque vous reliez les points dur un graphique. Cela n’est possible que lorsque les données le permettent. Vous devez donc toujours vous poser la question de la pertinence de vos choix de représentations.\nComme pour les autres types de graphiques, il est possible de modifier les caractéristiques esthétiques des lignes sur un graphique, en particulier :\n\ncolor : la couleur des lignes\nsize : l’épaisseur des lignes\nlinetype : le type de ligne (continue, pointillée, tirets, etc. Essayez plusieurs valeurs entières pour comparer les types de lignes)\n\n\nggplot(economics, aes(x = date, y = uempmed)) +\n  geom_line(color = \"orange\", linetype = 2)\n\n\n\n\nL’argument linetype est également utilisable par l’objet géométrique geom_smooth() :\n\nggplot(economics, aes(x = date, y = uempmed)) +\n  geom_line() +\n  geom_smooth(se = FALSE, linetype = 4, color = \"red\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nGlobalement, la durée médiane de chômage aux USA varie de façon cyclique. La durée des cycles varie selon les période entre 5 et 10 ans environ. Depuis les années 2000, la durée de chômage a augmenté de façon très importante, pour passer de 5 à 6 semaines en 2001, à plus de 25 semaines en 2011.\n\n\n3.7.3 Les cartes\nLes latitudes et longitudes sont un autre type de variable numériques très particulières qui permettent notamment de produire des cartes. Il s’agit ici d’un domaine extrêmement vaste qui dépasse largement le cadre de ce livre et des cours de la licence SV. Retenez simplement qu’il est possible de produire des cartes très informatives avec ggplot2, et quelques autres packages spécialisés :\n En règle général, les cartes portent un grand nombre de variables, numériques et/ou catégorielles. Mais tout commence toujours par 2 variables numériques, les latitudes et longitude des structures/informations que l’on souhaite représenter (traits de côte, profiles bathymétriques, lieux d’observations diverses, …)."
  },
  {
    "objectID": "03-visualization.html#deux-variables-catégorielles",
    "href": "03-visualization.html#deux-variables-catégorielles",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.8 Deux variables catégorielles",
    "text": "3.8 Deux variables catégorielles\nLorsque l’on souhaite examiner les relations entre deux variables catégorielles (ou facteurs), on a en général le choix entre les types de représentations graphiques suivants :\n\nles diagrammes bâtons empilés\nles diagrammes bâtons juxtaposés\nles diagrammes bâtons “facettés”\nles graphiques en mosaïque (ou mosaic plots)\n\nPour toutes ces méthodes, des données qui n’ont pas été comptées au préalable sont requises. Il est en effet beaucoup plus simple de travailler avec le tidyverse (donc avec ggplot2) lorsque chaque ligne d’un tableau correspond à une observation plutôt qu’à une somme d’observation. C’est le concept de tableau rangé, central dans le traitement de données ainsi que pour l’utilisation de tous les packages du tidyverse, et qui stipule qu’un tableau de données devrait contenir une unique ligne pour chaque observation, et une unique colonne pour chaque variable. Nous aurons l’occasion (notamment en L3) de voir des tableaux qui ne respectent pas ces règles et que nous devrons donc ré-organiser pour permettre leur analyse et les représentations graphiques.\nNous allons passer ces différentes possibilités en revue pour examiner les liens entre 2 variables catégorielles du jeu de données penguins : species et sex. La première renseigne sur l’espèce à laquelle un individu étudié appartient. La seconde renseigne sur le sexe de chaque individu. L’étude du sex-ratio est en effet souvent essentielle pour comprendre l’écologie des espèces. Les sexe-ratios sont-ils équilibrés ou non. Et s’ils ne sont pas équilibrés, sont-ils en faveur des mâles ou des femelles ?\n\n3.8.1 Diagrammes bâtons empilés\nLa façon la plus simple (mais rarement la meilleure) de procéder pour visualiser 2 facteurs conjointement est de créer un diagramme bâtons empilés :\n\nggplot(penguins, aes(x = species, fill = sex)) +\n  geom_bar()\n\n\n\n\nIci, les espèces sont associées à l’axe des x (x = species) et la couleur de remplissage des barres est associée au sexe des individus (fill = sex), à l’intérieur de la fonction aes(). Comme toujours, on peut modifier certaines caractéristiques esthétiques (couleur de contour des barres, transparence, etc.) et ré-ordonner les espèces sur l’axe des abscisses :\n\nggplot(penguins, aes(x = fct_infreq(species), fill = sex)) +\n  geom_bar(alpha = 0.6, color = \"black\")\n\n\n\n\nCe type de visualisation est utile pour se rendre compte des ordres de grandeur. On voit ici clairement que l’espèce Adélie est la plus représentée dans cette étude, suivie par l’espèce Gentoo, et enfin l’espèce Chinstrap. Pour chacune de ces 3 espèces, le sex-ratio a l’air très équilibré. Toutefois, des différences subtiles de proportions entre mâles et femelles selon les espèces pourraient être masqués par les effectifs inégaux entre espèces. Il peut donc être préférable, pour comparer des proportions, de normaliser les effectifs de toutes les espèces pour ramener chaque barre du graphique à la même hauteur :\n\nggplot(penguins, aes(x = fct_infreq(species), fill = sex)) +\n  geom_bar(alpha = 0.6, color = \"black\", position = \"fill\")\n\n\n\n\nL’argument position = \"fill\" de la fonction geom_bar() permet de transformer en proportions les abondances de chaque modalités de la variable portée par l’axe des x. L’axe des ordonnées varie maintenant entre 0 et 1 (0% et 100%), ce qui rend les comparaisons plus aisées. Ici, le fait que le sexe de quelques individus n’ait pas pu être déterminé vient gêner la lecture du graphique. On peut supprimer ces valeurs grâce à la fonction filter() du packages dplyr. Nous verrons dans le #sec-wrangling la signification du code suivant. Pour l’instant retenez simplement qu’il permet d’éliminer les individus dont le sexe est inconnu :\n\npenguins %&gt;% \n  filter(!is.na(sex)) %&gt;% \n  ggplot(aes(x = fct_infreq(species), fill = sex)) +\n  geom_bar(alpha = 0.6, color = \"black\", position = \"fill\")\n\n\n\n\nOn peut maintenant constater très facilement que le sex-ratio est parfaitement équilibré pour les espèces Adélie et Chinstrap, et qu’il est très légèrement en faveur des mâles pour l’espèce Gentoo.\n\n\n3.8.2 Diagrammes bâtons juxtaposés\nLa syntaxe permettant de produire un diagramme bâtons juxtaposé est très similaire à celle décrite ci-dessus :\n\nggplot(penguins, aes(x = fct_infreq(species), fill = sex)) +\n  geom_bar(alpha = 0.6, color = \"black\", position = \"dodge\")\n\n\n\n\nLa seule chose qui a changé est la valeur prise par l’argument position, que l’on fixe ici à dodge. L’avantage de cette représentation est qu’elle permet à la fois de visualiser les effectifs de chaque catégorie et sous-catégorie (espèce et sexe), ainsi que de comparer les proportions au sein de chaque espèce. Un inconvénient et que lorsque les catégories n’ont pas toutes le même nombre de sous-catégories, les barres ont des largeurs différentes. Ici, l’espèce Chinstrap, qui n’a que 2 sous catégories (female et male) présente des barres plus larges que les deux autres espèces qui présentent chacune 3 sous-catégories (female, male et NA). Pour y remédier, on peut :\n\nsoit retirer les données manquantes, comme précédemment :\n\n\npenguins %&gt;% \n  filter(!is.na(sex)) %&gt;% \n  ggplot(aes(x = fct_infreq(species), fill = sex)) +\n  geom_bar(alpha = 0.6, color = \"black\", position = \"dodge\")\n\n\n\n\n\nsoit imposer que toutes les sous-catégories apparaissent pour chaque catégorie :\n\n\nggplot(penguins, aes(x = fct_infreq(species), fill = sex)) +\n  geom_bar(alpha = 0.6, color = \"black\",\n           position = position_dodge(preserve = \"single\") )\n\n\n\n\nIci, l’argument position prend une valeur plus complexe puisque nous faisons appel à une fonction nommée position_dodge(). C’est l’argument preserve = \"single\" qui permet de s’assurer que toutes les sous-catégories sont bien représentées au sein de chaque catégorie, et donc, que toutes les barres ont bien la même largueur.\nLe choix d’une méthode ou de l’autre dépend de ce que l’on souhaite montrer : il n’y a pas une façon de faire meilleure ou moins bonne que l’autre. Tout dépend de l’objectif poursuivi par l’auteur du graphique.\n\n\n3.8.3 Diagrammes bâtons “facettés”\nDans le jargon de ggplot2, les facets sont simplement des sous-graphiques. Typiquement, une variable catégorielle peut être utilisée pour représenter un sous-graphique pour chaque modalité de cette variable. Ici, on peut par exemple produire un diagramme bâton pour chaque espèce, et l’axe des x de chaque graphique portera la variable sex :\n\nggplot(penguins, aes(x = sex)) +\n  geom_bar() +\n  facet_wrap(~species)\n\n\n\n\nC’est la fonction facet_wrap() qui permet de produire plusieurs sous graphiques. Examinons quelques-une de ces particularités :\n\nsa syntaxe fait appel à la notion de “formule”, utilisée pour certaines fonctions spécifiques dans le langage R. Nous en verrons des exemples en L3 pour illustrer certains tests statistiques. Le tilde ~ se lit “en fonction de”. Ici ~species signifie “crée des facets en fonction des espèces”, autrement dit, produit un sous-graphique par modalité de la variable species.\npar défaut, les axes de tous les sous graphiques sont strictement identiques, en abscisse comme en ordonnée. On peut modifier ce comportement grâce à l’un des arguments suivants : scales = \"free_x\" (pour que les axes des abscisses soient indépendants entre les sous-graphiques), scales = \"free_y\" (pour que les axes des ordonnées soient indépendants entre les sous-graphiques) ou scales = \"free\" (pour quelles deux axes soient indépendants entre les sous-graphiques)\nl’argument ncol = permet de spécifier le nombre de colonnes souhaité pour l’organisation des sous-graphiques\n\nVoici un exemple de ces syntaxes :\n\nggplot(penguins, aes(x = sex)) +\n  geom_bar() +\n  facet_wrap(~species, scales = \"free_y\", ncol = 2)\n\n\n\n\nLes 3 sous-graphiques sont maintenant disposés dans 2 colonnes, et si l’axe des x est toujours le même pour chaque sous-graphique, les axes des y sont différents pour les 3 sous-graphiques.\nPour égayer un peu ce graphique, ajoutons une couleur de remplissage pour les barres, selon l’espèce :\n\nggplot(penguins, aes(x = sex, fill = species)) +\n  geom_bar(color = \"black\", alpha = 0.7) +\n  facet_wrap(~species, scales = \"free_y\", ncol = 2)\n\n\n\n\nLa légende qui est automatiquement créée à droite est inutile puisque les sous-graphiques indiquent déjà le nom des espèces. Pour retirer une légende inutile, on peut utiliser l’argument show.legend = FALSE de la plupart des objets géométriques :\n\nggplot(penguins, aes(x = sex, fill = species)) +\n  geom_bar(color = \"black\", alpha = 0.7, show.legend = FALSE) +\n  facet_wrap(~species, scales = \"free_y\", ncol = 2)\n\n\n\n\n\n\n3.8.4 Mosaïc plots\nLes graphiques en mosaïque sont une alternative aux diagrammes bâtons en tous genre. Ils permettent de visualiser à la fois les effectifs et de comparer les proportions. La difficulté de ce genre de graphique est qu’il n’existe pas d’objet géométrique permettant de les représenter simplement dans le package ggplot2. Le package ggmosaic de Jeppson, Hofmann, et Cook (2021) est toutefois entièrement dédié à ce type de graphique. Installez ce package puis chargez-le en mémoire :\n\ninstall.packages(\"ggmosaic\")\nlibrary(ggmosaic)\n\nOn peut maintenant accéder à un nouvel objet géométrique, geom_mosaic(), dont l’utilisation est un peu différente de celle que nous avons vu jusqu’ici :\n\nggplot(penguins) +\n  geom_mosaic(aes(x = product(species), fill = sex))\n\n\n\n\nIl faut obligatoirement :\n\nspécifier aes() à l’intérieur de geom_mosaic() et non à l’intérieur de ggplot()\nutiliser la fonction product() (qui fait elle aussi partie du package ggmosaic) pour indiquer quelle variable catégorielle on souhaite associer à l’axe des x\nComme pour les diagrammes bâtons, la couleur de remplissage est associée à la seconde variable catégorielle de façon tout à fait classique\n\nComme pour les diagrammes en bâtons empilés pour lesquels on spécifie position = \"fill\", toutes les barres d’un graphique en mosaïque ont la même hauteur, ce qui permet de visualiser les proportions de chaque sexe pour chaque espèce, mais pas les effectifs. C’est ici la largueur des barres qui est proportionnelle aux effectifs de chaque espèce. Si on n’accède par directement aux valeurs absolues, on peut néanmoins effectuer des comparaisons d’ordres de grandeur. L’espèce Adélie est ainsi la plus représentée dans nos données, suivie de l’espèce Gentoo puis de l’espèce Chinstrap.\nAu final, le choix d’un graphique doit vous permettre de mettre en évidence les relations qui vous paraissent importantes de la façon la plus visuelle et évidente possible pour une personne ne connaissant pas vos données. Votre choix dépendra donc des données disponibles et de votre objectif (p. ex. comparaisons de proportions ou de valeurs absolues, nombreuses modalités ou seulement quelques unes, etc.)."
  },
  {
    "objectID": "03-visualization.html#une-variable-de-chaque-type",
    "href": "03-visualization.html#une-variable-de-chaque-type",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.9 Une variable de chaque type",
    "text": "3.9 Une variable de chaque type\nLes représentations graphiques réalisables et pertinentes lorsque l’on dispose d’une variable numérique et d’un facteur sont souvent des adaptations des graphiques précédents. Globalement, trois choix s’offrent à nous :\n\nles histogrammes facettés\nles stripcharts\nles boîtes à moustaches, que nous détaillerons au semestre 4. Nous donnerons ici un simple exemple sans expliquer la signification de tous les éléments de ces graphiques\n\nPour illustrer ces différentes possibilités, intéressons nous maintenant à la relation qui existe entre l’épaisseur du bec des manchots (bill_depth_mm, variable numérique) et l’espèce (species, variable catogorielle ou facteur)\n\n3.9.1 Histogrammes “facettés”\nLa syntaxe est ici tout à fait classique. Pour réaliser un histogramme, on place la variable numérique sur l’axe des abscisses. La variable catégorielle nous servira à créer les sous graphiques, ici, un par espèce. Afin de faciliter les comparaisons, nous placerons les sous-graphiques les uns sous les autres en spécifiant ncol = 1. Enfin, l’aspect général sera amélioré en modifiant quelques caractéristiques esthétiques :\n\nggplot(penguins, aes(x = bill_depth_mm)) +\n  geom_histogram(fill = \"steelblue\", color = \"black\", \n                 alpha = 0.6, bins = 20) +\n  facet_wrap(~species, ncol = 1)\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nOn peut aussi choisir d’utiliser une couleur pour chaque espèce (mais on n’affichera pas la légende puisque les espèces sont déjà séparées dans les sous graphiques). En outre, puisque les effectifs des Chinstrap sont bien plus faibles que pour les deux autres espèces, on a intérêt à “libérer” l’axe des y afin que l’histogramme des Chinstrap soit plus facilement lisible (il apparaît pour l’instant très “écrasé” comparé aux autres).\n\nggplot(penguins, aes(x = bill_depth_mm, fill = species)) +\n  geom_histogram(show.legend = FALSE, color = \"black\", \n                 alpha = 0.6, bins = 20) +\n  facet_wrap(~species, ncol = 1, scales = \"free_y\")\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nLes Gentoo, qui ont pourtant des masses corporelles supérieures à celle des deux autres espèces (voir Figure 3.3 de la Section 3.5.2), ont visiblement des becs moins épais (entre 12 et 17 mm) que les deux autres espèces (entre 16 et 22 mm).\n\n\n\n\n\n\nImportant\n\n\n\nC’est la position des données le long de l’axe des x qui nous permet de faire des comparaisons pertinentes. Il est donc essentiel de présenter les différents histogrammes les uns sous les autres, en conservant la même échelle pour les abscisses de tous les sous-graphiques.\n\n\nIci, on peut donc discuter de la distribution de la variable numérique pour chaque modalité de la variable catégorielle (i.e. quelle distribution de l’épaisseur des becs pour chaque espèce), mais on peut en plus faire des comparaisons entre modalités (entre les espèces). Cela est beaucoup plus pertinent que de s’intéresser à la distribution de l’épaisseur des becs toutes espèces confondues.\n\n\n3.9.2 Les stripcharts\nNous avons déjà abordé ce type de graphique dans la Section 3.5.2. Contrairement à la situation où nous n’avions qu’une variable numérique et où nous devions fixer x = \"\" pour que toutes les observations se placent au même niveau de l’axe des abscisses (voir Figure 3.6), nous allons ici associer la variable catégorielle à l’axe des x. La variable numérique sera quant-à-elle toujours associée à l’axe des ordonnées :\n\nggplot(penguins, aes(x = species, y = bill_depth_mm)) +\n  geom_jitter(width = 0.20, height = 0)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nFigure 3.13: Un exemple de stripchart\n\n\n\n\nNotez que la position des points sur l’axe des y doit parfaitement correspondre aux valeurs contenues dans le jeu de données pour la variable numérique d’intérêt. Cela signifie que l’argument height doit obligatoirement être fixé à 0.\nComme pour les diagrammes bâtons, il est possible de produire des stripcharts horizontaux. Les modifications à apporter sont alors les suivantes :\n\nla variable numérique est associée à l’axe des x\nla variable catégorielle est associée à l’axe des y\nla dispersion horizontale width doit obligatoirement être fixée à 0\nla dispersion verticale height doit être comprise entre 0.1 et 0.4 pour étaler les points de chaque modalité et ainsi éviter l’overplotting\n\n\nggplot(penguins, aes(x = bill_depth_mm, y = species)) +\n  geom_jitter(width = 0, height = 0.20, alpha = 0.6)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n3.9.3 Les boîtes à moustaches ou boxplots\nVoilà à quoi ressemble un graphique de ce type pour les données qui nous intéressent (épaisseur des becs selon l’espèce) :\n\nggplot(penguins, aes(x = species, y = bill_depth_mm)) +\n  geom_boxplot()\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nDans la forme, ça ressemble un à un stripchart (comparez par exemple avec la syntaxe et les résultats obtenus à la Figure 3.13). Néanmoins, ici, au lieu de visualiser tous les points du jeu de données, seules quelques valeurs caractéristiques sont utilisées pour construire le boîte à moustache de chaque espèce. Les différents éléments d’un boxplot, sont les suivants :\n\nLa limite inférieure de la boîte correspond au premier quartile : 25% des données de l’échantillon sont situées au-dessous de cette valeur.\nLa limite supérieure de la boîte correspond au troisième quartile : 25% des données de l’échantillon sont situées au-dessus de cette valeur.\nLe segment épais à l’intérieur de la boîte correspond au second quartile : c’est la médiane de l’échantillon. 50% des données de l’échantillon sont situées au-dessus de cette valeur, et 50% au-dessous.\nLa hauteur de la boîte correspond à ce que l’on appelle l’étendue inter-quartile ou Inter Quartile Range (IQR) en anglais. On trouve dans cette boîte 50% des observations de l’échantillon. C’est une mesure de la dispersion des 50% des données les plus centrales. Une boîte plus allongée indique donc une plus grande dispersion.\nLes moustaches correspondent à des valeurs qui sont en dessous du premier quartile (pour la moustache du bas) et au-dessus du troisième quartile (pour la moustache du haut). La règle utilisée dans R est que ces moustaches s’étendent jusqu’aux valeurs minimales et maximales de l’échantillon, mais elles ne peuvent en aucun cas s’étendre au-delà de 1,5 fois la hauteur de la boîte (1,5 fois l’IQR) vers le haut et le bas. Si des points apparaissent au-delà des moustaches (vers le haut ou le bas), ces points sont appelés “outliers”. On peut en observer un pour l’espèce Adélie. Ce sont des points qui s’éloignent du centre de la distribution de façon importante puisqu’ils sont au-delà de 1,5 fois l’IQR de part et d’autre du premier ou du troisième quartile. Il peut s’agir d’anomalies de mesures, d’anomalies de saisie des données, ou tout simplement, d’enregistrements tout à fait valides mais atypiques ou extrêmes. J’attire votre attention sur le fait que la définition de ces outliers est relativement arbitraire. Nous pourrions faire le choix d’étendre les moustaches jusqu’à 1,8 fois l’IQR (ou 2, ou 2,5). Nous observerions alors beaucoup moins d’outliers. D’une façons générale, la longueur des moustaches renseigne sur la variabilité des données en dehors de la zone centrale. Plus elles sont longues, plus la variabilité est importante. Et dans tous les cas, l’examen attentif des outliers est utile car il nous permet d’en apprendre plus sur le comportement extrême de certaines observations.\n\nLorsque les boîtes ont une forme à peu près symétrique de part et d’autre de la médiane (c’est le cas pour notre exemple), cela signifie qu’un histogramme des mêmes données serait symétrique également (on peut le vérifier avec les histogrammes de la Section 3.9.1).\n\n3.9.3.1 L’intervalle de confiance à 95% de la médiane\nOn peut également ajouter une encoche autour de la valeur de médiane en ajoutant l’argument notch = TRUE à la fonction geom_boxplot() :\n\nggplot(penguins, aes(x = species, y = bill_depth_mm)) +\n  geom_boxplot(notch = TRUE)\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nL’encoche qui apparaît sur chaque boîte à moustache correspond à l’étendue de l’intervalle de confiance à 95% de la médiane. Pour chaque échantillon, nous espérons que la médiane calculée soit le reflet fidèle de la vraie valeur de médiane de la population générale. Mais il sera toujours impossible d’en avoir la certitude absolue. Le mieux que l’on puisse faire, c’est quantifier l’incertitude associée à l’estimation de la médiane à partir des données d’un échantillon. L’intervalle de confiance nous indique qu’il y a de bonnes chances que la vraie valeur de médiane de la population générale (qui restera à jamais inconnue) se trouve dans cet intervalle.\nNous reviendrons sur cette notion importante plus tard dans le cursus, car ce type de graphique nous permettra d’anticiper sur les résultats des tests statistiques de comparaison de moyennes.\nAu final, nous avons 3 moyens d’obtenir des informations de distribution :\n\nobserver l’ensemble des données brutes grâce à un nuage de points ou stripchart\nregrouper en partie les données brutes dans les classes d’un histogramme. On ne visualise plus l’ensemble des données individuelles, mais un résumé de ces données puisqu’on ne dispose plus que d’une unique valeur pour chaque classe de l’histogramme. L’histogramme peut donc résumer des centaines voire des milliers de points sous la forme d’un petit nombre de classes (entre 10 et 40 en général)\nregrouper très fortement les données brutes sous la forme d’une boîte à moustache. Les boîtes à moustaches permettent de résumer l’information de centaines ou milliers de points sous la forme d’un résumé statistique composé de 5 valeurs (minimum et maximum, médiane, premier et troisième quartiles), ou 7 si l’on ajoute les encoches des intervalles de confiance à 95% des médianes. On observe alors moins facilement les nuances subtiles de distribution qu’avec un histogramme ou les données brutes, mais l’avantage est qu’on peut comparer facilement les grandes tendances d’un grand nombre de séries de données (parfois plusieurs dizaines) en plaçant des boîtes à moustaches côte à côte.\n\nLa Figure 3.14 illustre ces 3 possibilités de visualisation de la distribution d’une variable numérique (ici, la distribution des masses corporelles des manchots Adélie) :\n\n\n\n\n\nFigure 3.14: Trois façons de visualiser la distribution des masses des manchots Adélie"
  },
  {
    "objectID": "03-visualization.html#trois-variables-et-plus",
    "href": "03-visualization.html#trois-variables-et-plus",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.10 Trois variables (et plus !)",
    "text": "3.10 Trois variables (et plus !)\nLorsque l’on dispose de 3 variables, les situations possibles commencent à être nombreuses :\n\ntrois variables numériques\ndeux variables numériques et un facteur\nune variable numérique et deux facteurs\ntrois facteurs\n\nPour chacune de ces situations, on peut en générale reprendre les types de graphiques proposés dans les 3 sections précédentes consacrées aux situations où l’on dispose de 2 variables (), et :\n\nsoit ajouter une variable sous forme de code couleur (avec color ou fill à l’intérieur de aes())\nsoit ajouter une variable sous forme de facets (avec facet_wrap() ou avec facet_grid())\n\nLes possibilités sont très nombreuses et il ne sera pas possible d’être exhaustif ici. Je fournis néanmoins quelques exemples ci-dessous afin que vous compreniez bien la logique. Ensuite, ça sera à vous d’expérimenter selon les données dont vous disposez, les questions scientifiques que vous vous posez, et les relations que vous souhaitez explorer/visualiser.\n\n3.10.1 Trois variables numériques\nDans cette situation, on fait en général un nuage de points qui porte une variable numérique sur chaque axe, et on associe la troisième variable numérique soit à la couleur des points, soit à leur taille (soit aux deux à la fois). Par exemple, pour examiner les relations entre longueur du bec, épaisseur du bec, et masse corporelle, on peut procéder ainsi :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     size = body_mass_g)) +\n  geom_point(shape = 21, fill = \"steelblue\", color = \"black\", alpha = 0.6)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nC’est ce qu’on appelle un “bubble plot”. Ici on constate que les individus qui ont les becs les plus courts, sont aussi ceux qui ont un bec épais (groupe de points en haut à gauche). Ces individus sont parmi les plus légers (symboles de petite taille). À l’inverse, les individus ayant les becs les plus longs ont aussi des becs peu épais (groupes de points situés en bas à droite). Ces individus sont parmi les plus lourds du jeu de données (symboles de grandes taille).\nUne autre façon de visualiser ces mêmes données consiste à associer la masse des individus à la couleur de remplissage des symboles :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6, size = 2)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nCette fois, les individus les plus légers apparaissent en bleu très sombre, et les individus les plus lourds en bleu très clair. Ce choix de couleur nous est imposé, mais nous verrons plus loin comment le modifier pour rendre ce type de graphique plus facile à lire. Lorsque nous associons une variable numérique continue à la couleur des points, la légende qui est générée automatiquement pour nous par R sera toujours un gradient de couleurs. Si vous revenez en arrière au niveau des graphiques en mosaïques (Section 3.8.4), ou au niveau des diagrammes bâtons juxtaposés (Section 3.8.2), vous verrez que lorsque la couleur est associée à une variable catégorielle (ou facteur), la légende présente des couleurs distinctes, une pour chaque modalité du facteur considéré. Là encore, R choisit les couleurs pour nous. Mais là encore, nous verrons comment imposer des couleurs différentes si les choix par défaut ne nous conviennent pas.\nEnfin, il est évidemment possible de jouer à la fois sur la couleur et sur la taille des symboles :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nIci, l’information de masse est donc associée à 2 caractéristiques esthétiques distinctes : la couleur de remplissage des points et leur taille. Cela rend la lecture plus facile dans certaines situations.\nAu final, nous avons donc associé 3 variables numériques à 4 caractéristiques esthétiques du graphique :\n\nbill_length_mm est associée à x\nbill_depth_mm est associée à y\nbody_mass_g est associé à fill\nbody_mass_g est associé à size\n\nRien ne nous empêche d’ajouter des variables et des caractéristiques esthétiques. C’est ce que nous allons voir tout de suite.\n\n\n3.10.2 Cinq variables !\nPour commencer, essayez de reproduire le graphique suivant :\n\n\nWarning: Removed 11 rows containing missing values (`geom_point()`).\n\n\n\n\n\nIci, 5 variables du jeu de données (3 numériques et 2 facteurs) sont associées à 5 caractéristiques esthétiques du graphique. Le graphique est donc très riche, on peut voir par exemple :\n\nque les 3 espèces ont des morphologies de bec assez distinctes : les Gentoo ont des becs longs et fins, les Chinstrap ont des becs longs et épais, et les Adélie ont des becs courts et épais.\nqu’un dimorphisme sexuel est présent au niveau du bec : pour chaque espèce, les mâles ont des becs plus longs et épais que les femelles\nqu’un dimorphisme sexuel est présent au niveau des masses : pour chaque espèce, les mâles sont plus lourds que les femelles\n\nAu final, beaucoup d’informations sont présentées sur ce graphique et c’est presque trop. Même en améliorant l’aspect général du graphique pour le rendre plus lisible (voir ci-dessous), il vaut parfois mieux se limiter à 2 ou 3 variables et faire plusieurs graphiques, plutôt que de tout mettre sur le même. Une bonne solution consiste souvent à mettre 2 ou 3 variables sur un graphique, mais à faire plusieurs sous-graphiques pour chaque modalité d’une 4ème et/ou d’une 5ème variable catégorielle.\n\n\n\n\n\nEn particulier, sur ce graphique, il est presque impossible de déterminer la masse des individus mâles. La légende indique en effet des tailles de cercles qui correspondent à des masses spécifiques. Mais nous n’avons aucune indication pour la taille des triangles. Il vaudrait donc mieux procéder ainsi :\n\n\n\n\n\nFigure 3.15: Relation entre la morphologie du bec, la masse et le sexe chez trois espèces de manchots de l’archipel Palmer\n\n\n\n\nEn associant le sexe des individus à la couleur de remplissage plutôt qu’à la forme des points, et en faisant un sous-graphique par espèce, on élimine la difficulté de lecture liée à la taille des symboles triangulaires. L’information concernant la masse des individus est donc plus facile à visualiser. Le dimorphisme sexuel de taille des becs, présent pour chaque espèce, apparaît beaucoup plus clairement qu’avant (les mâles ont des becs plus longs et épais que les femelles). Mais les différences inter-spécifiques de morphologie des becs sont moins visibles qu’avant, notamment pour les différences de longueur des becs selon les espèces. On ne peut malheureusement pas gagner sur les tableaux à la fois. C’est la raison pour laquelle les choix de graphiques que vous ferez devront refléter les questions auxquelles vous vous intéressez, et les messages que vous souhaitez faire passer.\n\n\n3.10.3 Deux variables numériques et un facteur\nL’exemple qui suit est fondamental pour bien comprendre l’importance d’explorer en détail tous les aspects d’un jeu de données pour éviter de dire de grosses bêtises.\nImaginez que dans le jeu de données penguins, on souhaite étudier la relation qui existe entre l’épaisseur du bec des individus et la longueur des nageoires. Ces deux variables étant numériques, il semble logique de commencer par faire un nuage de points :\n\nggplot(penguins, aes(x = bill_depth_mm, y = flipper_length_mm)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nNous avons vu plus haut que pour visualiser le relations qui existent entre deux variables numériques, il est possible d’ajouter une courbe ou une droite de tendance avec la fonction geom_smooth() :\n\nggplot(penguins, aes(x = bill_depth_mm, y = flipper_length_mm)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nSi l’on s’en tient à ça, la relation semble claire : plus le bec des individus est épais, plus leurs nageoires sont courtes, et inversement. En outre, nous avons visiblement deux groupes d’individus qui présentent des caractéristiques distinctes : certains ont des becs fins et des nageoires très longues, quand d’autres ont des becs épais et des nageoires courtes. Et quasiment aucun individu ne présente de caractéristiques intermédiaires (becs d’épaisseur moyenne épais et nageoires moyennes).\nEn réalité, cette vision des choses est totalement trompeuse ! N’oubliez pas que nous avons 3 espèces distinctes dans ce jeu de données, et que ces espèces peuvent présenter des caractéristiques morphologiques très variées. Examiner la relation becs-nageoires tel que nous l’avons fait, sans considérer les espèces, n’a strictement aucun sens ! Pour s’en convaincre, il suffit d’associer la couleur (des points et des lignes) à l’espèce :\n\nggplot(penguins, aes(x = bill_depth_mm, y = flipper_length_mm,\n                     color = species)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nLe résultat obtenu ici est à l’opposé de nos conclusions précédentes : la relation entre les deux variables numérique est en fait positive ! Au sein de chaque espèce, les individus possédant les becs les plus épais sont aussi ceux qui possèdent les nageoires les plus longues !\nEn statistiques ce phénomène (observer une relation inverse lorsque plusieurs groupes sont combinés) s’appelle le paradoxe de Simpson, et je vous encourage à consulter la page wikipédia qui y est consacrée.\nIci, si la relation entre nos deux variables numériques s’inverse lorsque l’on examine cette relation à l’échelle de chaque modalité de la variable catégorielle. Une façon encore plus nette de mettre la relation positive en évidence est la suivante :\n\nggplot(penguins, aes(x = bill_depth_mm, y = flipper_length_mm,\n                     color = species)) +\n  geom_point(show.legend = FALSE) +\n  geom_smooth(method = \"lm\", show.legend = FALSE) +\n  facet_wrap(~species, scales = \"free\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nMême sans connaître en détail le principe et les limites de la régression linéaire, vous comprenez j’espère à quel point l’exploration rigoureuse d’un jeu de données est importante. Par exemple, nous avons vu que plus tôt que, pour chaque espèce, les mâles sont plus lourds que les femelles. Est-ce que des différences morphologiques entre les sexes pourraient expliquer la relation que nous observons ici entre épaisseur du bec et longueur des nageoires ? Est-il possible qu’un second effet Simpson se cache dans ces données ? Si on distingue les deux sexes au sein de chaque espèce, la relation existe-t-elle toujours ? Et si oui, est-elle toujours positive ou s’inverse-t-elle à nouveau ? Pour le savoir, on peut utiliser une autre fonction permettant de produire des sous-graphiques, la fonction facte_grid(), qui permet de faire un sous graphique pour chaque combinaison de modalités de 2 variables catégorielles :\n\npenguins %&gt;% \n  filter(!is.na(sex)) %&gt;%    # Elimine les individus dont le sexe est inconnu\n  ggplot(aes(x = bill_depth_mm, y = flipper_length_mm,\n                     color = species, shape = sex)) +\n  geom_point(show.legend = FALSE) +\n  geom_smooth(method = \"lm\", show.legend = FALSE) +\n  facet_grid(sex ~ species, scales = \"free\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nLa syntaxe sex ~ species indique que l’on souhaite un sous-graphique pour chaque combinaison des modalités des facteurs sex et species. Les graphiques correspondant aux différents sexes apparaîtront sur des lignes distinctes, et les espèces sur des colonnes distinctes. On constate ici que si la relation semble toujours positive et assez nette pour les mâles des 3 espèces, la situation est moins tranchée pour les femelles, en particulier pour les espèces Adélie et Chinstrap.\nNous avons vu dans ce chapitre quelques exemples et des règles à suivre strictement (notamment, quels types de graphiques pour quelles types de variables). Mais les possibilités sont infinies, et je vous encourage donc à poursuivre l’exploration. Toutes les combinaisons des éléments que nous avons décrits sont possibles. Entre les facets, qui permettent de faire des sous graphiques pour chaque modalités (ou combinaisons de modalités) d’une ou deux variables catégorielles, les caractéristiques esthétiques auxquelles ont peut associer un nombre conséquent de variables numériques et/ou catégorielles, et les nombreux objets géométriques existants (nous n’avons fait qu’utiliser les plus courants, mais il en existe beaucoup d’autres), les possibilités sont infinies. À vous de faire preuve de curiosité et d’explorer d’autres types de visualisation. L’avantage de ggplot2 est que tous les graphiques se construisent sur le même modèle :\n\n\n\n\n\n\nImportant\n\n\n\n\nggplot(TABLEAU, aes(x = VAR1, y = VAR2, fill = VAR3, ...)) +\n  geom_XXX() +\n  geom_YYY() +\n  facet_ZZZ()\n\n\n\nQuand on a bien compris ce principe, on peut quasiment tout faire, les réponses aux questions qu’on se pose se trouvant presque toujours dans les fichiers d’aide des fonctions."
  },
  {
    "objectID": "03-visualization.html#peaufiner-lapparence",
    "href": "03-visualization.html#peaufiner-lapparence",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.11 Peaufiner l’apparence",
    "text": "3.11 Peaufiner l’apparence\nJusqu’ici, les morceaux de code que nous avons vus permettent de produire une large gamme de graphiques exploratoires. Mais il y a une différence de taille entre des graphiques que l’on fait pour soi, afin de comprendre et explorer des données, et des graphiques que l’on fait pour communiquer à autrui des informations ou le fruit de nos découvertes.\nLes graphiques que l’on souhaite intégrer à un compte-rendu ou un rapport doivent :\n\navoir des labels corrects pour les axes (penser à toujours indiquer l’unité des variables portées par les axes)\navoir des labels corrects pour les légendes situées à droite de la plupart des graphiques (voir les nombreux exemples décrits plus haut)\navoir éventuellement un titre. Il ne sera pas toujours utile de l’intégrer à la figure car la plupart du temps, les titres sont ajoutés manuellement dans le traitement de texte que vous utilisez\nutiliser des couleurs agréables et faciles à distinguer (y compris pour les personnes atteintes de daltonisme)\nutiliser des échelles adaptées (ordres de grandeur, échelles logarithmiques, etc.)\nsi possible avoir tous le même thème (mêmes choix de couleurs, de contours, de polices de caractères, etc.)\n\nDonc, lorsqu’on obtient un graphique exploratoire parlant et que l’on souhaite l’intégrer à un rapport ou un compte-rendu, 3 étapes sont nécessaires à sa mise en forme :\n\nmodifier les légendes avec la fonction labs()\nmodifier les échelles avec les nombreuses fonctions scale_XXX_YYY()\nmodifier le thème général avec les fonctions theme_XX()\n\n\n3.11.1 Les légendes ou labels\nLe point de départ le plus évident est d’ajouter des labels de qualité. La fonction labs() du package ggplot2 permet d’ajouter plusieurs types de labels sur vos graphiques :\n\nUn titre (title =) : il doit résumer les résultats les plus importants.\nUn sous-titre (subtitle =) : il permet de donner quelques détails supplémentaires.\nUne légende (caption =) : souvent utilisée pour présenter la source des données du graphique.\nUn titre pour chaque axe (x = et y =) : permet de préciser les variables portées par les axes et leurs unités.\nUn titre pour les échelles de couleurs, de forme, de taille, etc.\n\nReprenons par exemple le graphique permettant de visualiser la relation entre épaisseur et longueur du bec selon la masse des individus :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nNous préciser les légendes en ajoutant la fonction labs() sur une nouvelle couche du graphique :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nPour annoter correctement les légendes situées à droite, il convient d’avoir bien compris ce qui, dans notre code, a permis à R de générer automatiquement ces légendes. Le gradient de couleur a été créé parce que nous avons tapé fill = body_mass_g. Et l’échelle de taille des symboles a été créée parce que nous avons tapé size = body_mass_g. Dans la fonction labs(), nous devons donc préciser fill = \"...\" et size = \"...\" pour modifier le titre de ces 2 légendes :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Masse (g)\",\n       size = \"Masse (g)\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nFigure 3.16: Une figure correctement légendée\n\n\n\n\nÀ partir de maintenant, vous devriez systématiquement légender les axes de vos graphiques et annoter vos légendes correctement, en n’oubliant pas de préciser les unités lorsque c’est pertinent, pour tous les graphiques que vous intégrez dans vos rapports, compte-rendus, mémoires, présentation, etc.\n\n\n3.11.2 Les échelles\nTous les détails des graphiques que vous produisez peuvent être édités. C’est notamment le cas des échelles. Qu’il s’agisse de modifier l’étendue des axes, la densité du quadrillage, la position des tirets sur les axes, le nom des catégories figurant sur les axes ou dans les légendes ou encore les couleurs utilisées pour différentes catégories d’objets géométriques, tout est possible dans ggplot2.\nNous n’avons pas le temps ici d’aborder toutes ces questions en détail. Je vous encourage donc à consulter l’ouvrage en ligne intitulé R for data science, et en particulier son chapitre dédié aux échelles, si vous avez besoin d’apporter des modifications à vos graphiques et que vous ne trouvez pas comment faire dans cet ouvrage.\n\n3.11.2.1 La gestion des couleurs\nNous allons néanmoins examiner quelques possibilités, à commencer par la façon de procéder pour modifier les couleurs choisies par défaut par ggplot2. Reprenons la figure Figure 3.16, et changeons le gradient de couleur proposé par défaut par R. Il est possible de modifier ces couleurs de plusieurs façons :\n\nsoit en utilisant d’autres palettes de couleurs prédéfinies\nsoit en choisissant manuellement les couleurs\n\nToutes les fonctions permettant d’altérer les légendes commencent par scale_. Vient ensuite le nom de l’esthétique que l’on souhaite modifier (ici fill_) et enfin, le nom d’une fonction à appliquer. Les possibilités sont nombreuses et vous pouvez en avoir un aperçu en tapant le début du nom de la fonction et en parcourant la liste proposée par RStudio sous le curseur. Il faut toutefois distinguer 2 types d’échelles de couleurs : les échelles continues (c’est notre cas ici) et les échelles discrètes (quand l’esthétique de couleur est associée à une variable catégorielle, nous en verrons un exemple plus loin).\nPar exemple, il est possible d’utiliser la palette viridis. Selon ses auteurs :\n\n“Use [this palette] to make plots that are pretty, better represent your data, easier to read by those with colorblindness, and print well in gray scale.\n\nPour utiliser cette palette, il suffit d’ajouter une couche à notre graphique :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Masse (g)\",\n       size = \"Masse (g)\") +\n  scale_fill_viridis_c()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nLa palette viridis est proposée pour les échelles continues (d’où le _c à la fin du nom de fonction), ou pour les échelles discrètes (scale_fill_viridis_d). Des fonctions équivalentes existent pour les couleurs de contour (scale_color_viridis_c et scale_color_viridis_d). Allez lire le fichier d’aide de cette fonction pour en apprendre plus sur son fonctionnement et ses nombreuses options.\nIci, les individus les plus lourds apparaissent en jaune, et les plus légers en bleu sombre. Si on souhaite faire le contraire, c’est possible :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Masse (g)\",\n       size = \"Masse (g)\") +\n  scale_fill_viridis_c(direction = -1)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nD’autres palettes de couleurs sont également accessibles grâce à l’argument option = de ces fonctions :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Masse (g)\",\n       size = \"Masse (g)\") +\n  scale_fill_viridis_c(option = \"A\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nVoici toutes les possibilités :\n\n\n\n\n\nDernière chose concernant viridis : la fonction scale_fill_viridis_b() discrétise la variable continue pour en faire une échelle discontinue. Il est en effet parfois plus facile de repérer une couleur parmi une palette de 4 ou 5 couleurs distinctes, plutôt qu’au sein d’un gradient. Voilà à quoi cela ressemble :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Masse (g)\",\n       size = \"Masse (g)\") +\n  scale_fill_viridis_b(option = \"E\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nOutre les fonctions d’échelles proposant les palettes viridis, les fonctions se terminant par _gradient(), _gradient2() et _gradientn() permettent de spécifier manuellement les couleurs à intégrer dans un dégradé. Avec la fonction scale_fill_gradient() on indique simplement les couleurs du début de de la fin du gradient :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Masse (g)\",\n       size = \"Masse (g)\") +\n  scale_fill_gradient(low = \"gold\", high = \"firebrick3\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nN’importe quelle nom de couleur valide, ou n’importe que code couleur hexadécimal fonctionne (voir par exemple ce site pour trouver les codes hexadécimaux dont vous avez besoin) :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Masse (g)\",\n       size = \"Masse (g)\") +\n  scale_fill_gradient(low = \"#A0F87D\", high = \"#151197\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nAvec la fonction scale_fill_gradient2(), nous avons plus de contrôle : on indique une couleur de départ, une couleur d’arrivée, mais aussi, une couleur intermédiaire, et la valeur numérique à laquelle cette couleur doit apparaître :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = body_mass_g, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Masse (g)\",\n       size = \"Masse (g)\") +\n  scale_fill_gradient2(low = \"deeppink\", high = \"gold\", mid = \"darkslateblue\",\n                       midpoint = 4500)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nJe vous laisse explorer l’aide de cette fonction ainsi que celle de scale_fill_gradientn() pour savoir comment en utiliser toutes les possibilités.\nLorsqu’une variable catégorielle est associée à la couleur, il est évidemment possible aussi d’effectuer les choix de palettes. Voyons en exemple en associant la couleur de remplissage des points à l’espèce plutôt qu’à la masse :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = species, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Espèce\",\n       size = \"Masse (g)\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nLa version discrète de viridis peut maintenant être appliquée. Les mêmes options que pour la version continue sont disponibles :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = species, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Espèce\",\n       size = \"Masse (g)\") +\n  scale_fill_viridis_d(option = \"B\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nLes possibilités sont nombreuses, notamment grâce aux fonctions scale_fill_brewer() (pour les couleurs de remplissages associées à une variable catégorielle) et scale_color_brewer() (pour les couleurs de contour associées à une variable catégorielle). L’utilisation est simple, un précise simplement quelle palette on souhaite utiliser parmi la liste des palettes disponibles :\n\nCertaines palettes sont séquentielles (lorsque les catégories se suivent logiquement, pour les variables catégorielles ordinales en particulier), d’autres contiennent des couleurs indépendantes :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = species, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Espèce\",\n       size = \"Masse (g)\") +\n  scale_fill_brewer(palette = \"Accent\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nEnfin, il est possible de spécifier manuellement la liste des couleurs que l’on souhaite utiliser avec la fonction scale_fill_manual(). il faut bien entendu indiquer autant de couleurs que de modalités pour notre variable catégorielle (ici 3 espèces dont 3 couleurs) :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = species, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Espèce\",\n       size = \"Masse (g)\") +\n  scale_fill_manual(values = c(\"deepskyblue\", \"darkorchid3\", \"lightsalmon\"))\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nDernière chose concernant les couleurs : un choix de fonction scale_XXX_XXX() inapproprié est une cause d’erreur très fréquente ! Par exemple, pour la première figure de la partie consacrée au paradoxe de Simpson (Section 3.10.3), la couleur des points et des lignes n’est pas spécifiée avec fill mais avec color. C’est donc bien une fonction qui commence par scale_color_ qu’il faut utiliser :\n\nggplot(penguins, aes(x = bill_depth_mm, y = flipper_length_mm,\n                     color = species)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(x = \"Épaisseur du bec (mm)\", y = \"Longueur des nageoires (mm)\",\n       color = \"Espèce\") +\n  scale_color_brewer(palette = \"Set2\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nComme pour les fonctions geom_XXX(), les fonctions scale_color_XXX() et scale_fill_XXX() sont très nombreuses. Je vous encourage donc à explorer les fichiers d’aide et à faire des essais.\n\n\n3.11.2.2 Les autres échelles\nLes deux autres échelles que vous pourrez être couramment appelés à modifier sont les échelles des axes des x et des y. Les fonctions qui permettent de la faire sont construites comme ces des échelles de couleurs : scale_x_XXX() et scale_y_XXX(). La dernière partie du nom de la fonction sera, la plupart du temps, soit discrete si une variable catégorielle est associée à l’axe, soit continuous si une variable numérique y est associée.\nReprenons l’exemple du stripchart suivant :\n\nggplot(penguins, aes(x = species, y = bill_depth_mm)) +\n  geom_jitter(width = 0.20, height = 0)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nOn commence par légender les axes avec labs() :\n\nggplot(penguins, aes(x = species, y = bill_depth_mm)) +\n  geom_jitter(width = 0.20, height = 0) +\n  labs(x = \"Espèce\", y = \"Épaisseur du bec (mm)\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nSi on souhaite renommer l’espèce Adelie en Adélie (avec un accent sur le “e” donc), il faut modifier l’échelle de l’axe des x, qui porte une variable catégorielle :\n\nggplot(penguins, aes(x = species, y = bill_depth_mm)) +\n  geom_jitter(width = 0.20, height = 0) +\n  labs(x = \"Espèce\", y = \"Épaisseur du bec (mm)\") +\n  scale_x_discrete(label = c(\"Adélie\", \"Chinstrap\", \"Gentoo\"))\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nPour l’axe des y, qui porte une variable continue, on peut avoir besoin de faire apparaître des graduations tous les 2 millimètres (au lieu de tous les 2,5 millimètres) :\n\nggplot(penguins, aes(x = species, y = bill_depth_mm)) +\n  geom_jitter(width = 0.20, height = 0) +\n  labs(x = \"Espèce\", y = \"Épaisseur du bec (mm)\") +\n  scale_x_discrete(label = c(\"Adélie\", \"Chinstrap\", \"Gentoo\")) +\n  scale_y_continuous(breaks = seq(from = 12, to = 22, by = 2))\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nIl est également très fréquent de souhaiter étendre les axes au-delà des seules valeurs observées, pour faire apparaître le 0 par exemple. C’est tellement fréquent qu’une fonction de raccourci très facile à utiliser nous permet d’éviter le recours à une fonction scale_XXX_XXX(). Même si dans ce cas précis, ça n’est pas très pertinent, voilà un exemple :\n\nggplot(penguins, aes(x = species, y = bill_depth_mm)) +\n  geom_jitter(width = 0.20, height = 0) +\n  labs(x = \"Espèce\", y = \"Épaisseur du bec (mm)\") +\n  scale_x_discrete(label = c(\"Adélie\", \"Chinstrap\", \"Gentoo\")) +\n  expand_limits(y = 0)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nEnfin, il arrive que les valeurs prises par une variable numérique recouvrent plusieurs ordres de grandeurs (avec par exemple des valeurs de l’ordre des dizaines, des centaines et des milliers). Utiliser une échelle logarithmique permet, dans cette situation, de mieux visualiser la variabilité des données, notamment parmi les valeurs les plus faibles. Les fonctions scale_x_log10() et scale_y_log10() permettent d’effectuer ce changement d’échelle tout en conservant des valeurs normales sur les axes.\nOutre ces changements d’échelles pour les axes et les couleurs, il est possible de modifier manuellement toutes les échelles générées automatiquement par les fonction geom_XXX() (par exemple, l’échelle des tailles, ou les types de symboles utilisés pour distinguer plusieurs catégories de points). Il “suffit” pour cela de trouver la bonne fonction (par exemple scale_size_continuous(), scale_shape_manual(), … Il est evidemment impossible de faire le tour de toutes ces fonctions. Mais sachez qu’elles existent et consultez leurs fichiers d’aide le jour où vous en avez besoin.\n\n\n\n3.11.3 Les thèmes\nL’apparence de tout ce qui ne concerne pas directement les données d’un graphique est sous le contrôle d’un thème. Les thèmes contrôlent l’apparence générale du graphique : quelles polices et tailles de caractères sont utilisées, quel sera l’arrière plan du graphique, faut-il intégrer un quadrillage sous le graphique, et si oui, quelles doivent être ses caractéristiques ?\nIl est possible de spécifier chaque élément manuellement. Nous nous contenterons ici de passer en revue quelques thèmes prédéfinis qui devraient couvrir la plupart de vos besoins.\nReprenons par exemple le code suivant :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = species, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Espèce\",\n       size = \"Masse (g)\") +\n  scale_fill_viridis_d(option = \"B\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nLe thème utilisé par défaut est theme_gray(). Il est notamment responsable de l’arrière plan gris et du quadrillage blanc. Pour changer de thème, il suffit d’ajouter une couche au graphique en donnant le nom du nouveau thème :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = species, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Espèce\",\n       size = \"Masse (g)\") +\n  scale_fill_viridis_d(option = \"B\") +\n  theme_bw()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nLe fond gris a disparu, et le quadrillage a changé de couleur. Les thèmes complets proposés par ggplot2 que vous pouvez utiliser sont les suivants :\n\ntheme_bw() : fond blanc et quadrillage.\ntheme_classic() : thème classique, avec des axes mais pas de quadrillage.\ntheme_dark() : fond sombre pour augmenter le contraste.\ntheme_gray() : thème par défaut : fond gris et quadrillage blanc.\ntheme_light() : axes et quadrillages discrets.\ntheme_linedraw() : uniquement des lignes noires.\ntheme_minimal() : pas d’arrière plan, pas d’axes, quadrillage discret.\ntheme_void() : thème vide, seuls les objets géométriques restent visibles.\n\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = species, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Espèce\",\n       size = \"Masse (g)\") +\n  scale_fill_viridis_d(option = \"B\") +\n  theme_minimal()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nTous les thèmes possèdent la même liste d’argument. L’un d’entre eux est l’argument base_family, qui permet de spécifier une police de caractères différente de celle utilisée par défaut. Évidemment, vous ne pourrez utiliser que des polices qui sont disponibles sur l’ordinateur que vous utilisez. Un bon tutoriel expliquant comment indiquer à R les polices qui sont disponibles sur votre ordinateur est disponible ici. N’hésitez pas à revenir vers moi pour toute question à ce sujet.\nDans l’exemple ci-dessous, j’utilise la police “Gill Sans”. Si cette police n’est pas disponible sur votre ordinateur, ce code produira une erreur (ou R prendra simplement la police par défaut. Si c’est le cas, remplacez-la par une police de votre ordinateur. Attention, son nom exact doit être utilisé. Cela signifie bien sûr le respect des espaces, majuscules, etc.\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = species, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec de 3 espèces de manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Espèce\",\n       size = \"Masse (g)\") +\n  scale_fill_viridis_d(option = \"B\") +\n  theme_minimal(base_family = \"Gill Sans\")\n\n\nIl est également possible de spécifier la taille de police qui devrait être utilisée par défaut. On spécifie la taille de base avec l’argument base_size =, et toutes les autres tailles de polices seront mises à jour pour refléter le changement. Ainsi, les différences de tailles entre titre, sous-titres, légendes des axes, etc, seront maintenues :\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm,\n                     fill = species, size = body_mass_g)) +\n  geom_point(shape = 21, color = \"black\", alpha = 0.6) +\n  labs(title = \"Forme du bec des manchots et relation avec leur masse\",\n       subtitle = \"Les manchots les plus lourds ont des becs longs et fins\",\n       x = \"Longueur du bec (mm)\",\n       y = \"Épaisseur du bec (mm)\",\n       caption = \"Source :  package 'palmerpenguins'\",\n       fill = \"Espèce\",\n       size = \"Masse (g)\") +\n  scale_fill_viridis_d(option = \"B\") +\n  theme_minimal(base_family = \"Gill Sans\", base_size = 14)\n\n\nLe choix d’un thème et d’une police adaptés doivent vous permettre de faire des graphiques originaux et clairs. Rappelez-vous toujours que vos choix en matière de graphiques doivent avoir pour objectif principal de rendre les tendances plus faciles à décrypter pour un lecteur non familier de vos données. C’est un outil de communication au même titre que n’importe quel paragraphe d’un rapport ou compte-rendu. Et comme pour un paragraphe, la première version d’un graphique est rarement la bonne.\nVous devriez donc maintenant être bien armés pour produire 95% des graphiques dont vous aurez besoin tout au long de votre cursus universitaire. Toutefois, un point important a pour l’instant été omis : l’ajout de barres d’erreurs sur vos graphiques. Nous verrons comment faire cela au prochain semestre, après avoir appris à manipuler efficacement des tableaux de données avec les packages tidyr et dplyr.\nQuoi qu’il en soit, il est maintenant attendu de vous que vous utilisez R et ce que vous avez appris de ggplot2 pour produire tous les graphiques que vous serez amenés à intégrer à vos comptes-rendus de TP et à vos rapports."
  },
  {
    "objectID": "03-visualization.html#exercices",
    "href": "03-visualization.html#exercices",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.12 Exercices",
    "text": "3.12 Exercices\n\nAvec le jeu de données diamonds, du packages ggplot2, tapez les commandes suivantes pour créer un nouveau tableau diams contenant moins de lignes (3000 au lieu de près de 54000) :\n\n\nlibrary(dplyr)\nset.seed(4532) # Afin que tout le monde récupère les mêmes lignes\ndiams &lt;- diamonds %&gt;%\n  sample_n(3000)\n\n\nAvec ce nouveau tableau diams, tapez le code permettant de créer le graphique ci-dessous. Indice : affichez le tableau diams dans la console afin de voir quelles sont les variables disponibles.\n\n\n\n\n\n\nPrix de 3000 diamants en fonction de leur taille en carats et de leur clarté.\n\n\n\n\n\nSelon vous, à quoi sont dues les bandes verticales que l’on observe sur ce graphique ?\nInstallez et chargez en mémoire le package nycflights13\nExaminez le tableau flights de ce package, et lisez son fichier d’aide pour comprendre à quoi correspondent ces données\nCréer un nouveau jeu de données en exécutant ces commandes :\n\n\nset.seed(1234)\nsmall_flights &lt;- flights %&gt;%\n  filter(!is.na(arr_delay),\n         distance &lt; 3000)  %&gt;%\n  sample_n(1000)\n\n\nCe nouveau jeu de données de petite taille (1000 lignes) est nommé small_flights. Il contient les mêmes variables que le tableau flights mais ne contient qu’une petite fraction de ses lignes. Les lignes retenues ont été choisies au hasard. Vous pouvez visualiser son contenu en tapant son nom dans la console ou en utilisant la fonction View().\n\nEn vous appuyant sur les fonctions et les principes de la grammaire des graphiques que vous avez découverts dans ce chapitre, et en vous servant de ce nouveau jeu de données, tapez les commandes qui permettent de produire le graphique ci-dessous :\n\n\n\n\n\nQuelques indices :\n\nLes couleurs utilisées sont celles de la palette Set1 du package RColorBrewer.\nLes variables utilisées sont origin, air_time et distance.\nLa transparence des symboles est fixée à 0.8.\n\n\nToujours avec ce jeu de données small-flights, tapez les commandes permettant de produire le graphique ci-dessous :\n\n\n\n\n\n\nQuelques indices :\n\nLes couleurs utilisées sont celles de la palettes Accent du package RColorBrewer.\nLes variables utilisées sont month, carrier et origin.\nLa variable month est codée sous forme numérique dans le tableau de données. Il faudra la transformer en facteur avec la fonction factor(month) au moment de l’associer à un axe du graphique.\n\n\n\n\n\n\nJeppson, Haley, Heike Hofmann, et Di Cook. 2021. ggmosaic: Mosaic Plots in the ggplot2 Framework. https://github.com/haleyjeppson/ggmosaic.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, et Dewey Dunnington. 2023. ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWilkinson, Leland. 2005. The grammar of graphics. 2nd éd. New-York: Springer-Verlag. https://www.springer.com/us/book/9780387245447."
  },
  {
    "objectID": "04-tidy-Data.html#sec-prerek",
    "href": "04-tidy-Data.html#sec-prerek",
    "title": "4  (Ar)ranger des données avec tidyr",
    "section": "4.1 Pré-requis",
    "text": "4.1 Pré-requis\nDans ce chapitre, nous aurons besoin des packages suivants :\n\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(nycflights13)\nlibrary(ggplot2)\nlibrary(readxl)  # la dernière lettre est un \"L\" minuscule, pas le chiffre 1...\nlibrary(readr)\n\nComme d’habitude, si vous recevez des messages d’erreur, c’est probablement parce que le package que vous essayez de charger en mémoire n’a pas été installé au préalable. Consultez la Section 1.4 si vous ne savez plus comment procéder.\nOutre ces packages classiques, nous aurons aussi besoin du package EDAWR qui n’est pas disponible sur les serveurs habituels de R. Pour l’installer, on procède de la façon suivante :\n\nInstallez et chargez en mémoire le package remotes :\n\n\ninstall.packages(\"remotes\")\nlibrary(remotes)\n\n\nInstallez le package EDAWR grâce à la fonction install_github() du package remotes qui va chercher le package sur le site https://github.com :\n\n\ninstall_github(\"rstudio/EDAWR\")\n\nAttention, sur les ordinateurs de l’université cette procédure ne fonctionne pas toujours. Si vous rencontrez des difficultés, suivez les instructions décrites à la fin de cette Section 4.1.\n\nChargez le package EDAWR de la façon habituelle :\n\n\nlibrary(EDAWR)\n\nLe package EDAWR contient plusieurs jeux de données dont nous allons nous servir pour illustrer les questions liées au format des tableaux de données. Pour en avoir la liste, vous pouvez taper :\n\ndata(package = \"EDAWR\")\n\nEn cas de problème pour installer le package EDAWR sur les ordinateurs de l’université.\nVous pouvez télécharger manuellement les 4 jeux de données dont nous aurons besoin grâce à ces 4 liens :\n\ncases\npopulation\nrates\nstorms\n\nUne fois téléchargés, les données contenues dans ces 4 fichiers peuvent être importées dans RStudio en cliquant sur File &gt; Open File..., puis en sélectionnant un à un chacun des fichiers. Pour chaque fichier un nouvel objet doit apparaître dans votre environnement de travail (onglet Environnement, dans le panneau en haut à droite de RStudio). L’inconvénient de cette méthode est que les fichiers d’aide de ces jeux de données ne seront pas disponibles dans RStudio. Vous pouvez toutefois en consulter une version brute (non mise en forme) en cliquant ici."
  },
  {
    "objectID": "04-tidy-Data.html#cest-quoi-des-tidy-data",
    "href": "04-tidy-Data.html#cest-quoi-des-tidy-data",
    "title": "4  (Ar)ranger des données avec tidyr",
    "section": "4.2 C’est quoi des “tidy data” ?",
    "text": "4.2 C’est quoi des “tidy data” ?\nLes “tidy data” (nous les appellerons “données rangées” dans la suite de ce livre), sont des données qui respectent un format standardisé. En particulier :\n\nChaque variable est dans une colonne unique.\nChaque colonne contient une unique variable.\nChaque ligne correspond à une observation pour chaque variable.\nLes cellules du tableau représentent les valeurs de chaque observation pour chaque variable.\n\n\n\n\n\n\nFigure 4.1: La définition des ‘données rangées’, d’après http://r4ds.had.co.nz/tidy-data.html.\n\n\n\n\nMalheureusement, les données peuvent être présentées sous de nombreux formats qui ne respectent pas ces règles de base. La modification des tableaux est donc souvent un préambule nécessaire à toute analyse statistique ou représentation graphique.\nPar exemple, examinez le tableau cases du package EDAWR, qui présente le nombre de cas de tuberculose dans 3 pays en 2011, 2012 et 2013.\n\ncases\n\n  country  2011  2012  2013\n1      FR  7000  6900  7000\n2      DE  5800  6000  6200\n3      US 15000 14000 13000\n\n\nDans ce tableau, essayez d’identifier quelles sont les variables en présence. Indice, vous devriez en trouver 3.\nEssayez d’identifier également où se trouvent ces variables.\nPour ma part, je compte les 3 variables suivantes :\n\ncountry : qui indique les pays dans lesquels les cas de tuberculose ont été dénombrés. Cette variable occupe la première colonne du tableau.\nLa seconde variable est l’année, qui peut prendre les valeurs 2011, 2012 ou 2013. Cette variable occupe la ligne des titres des 3 colonnes de droite du tableau.\nEt enfin, la troisième variable est le nombre de cas de tuberculose observés dans chaque pays et chaque année. Cette troisième variable occupe 3 lignes et 3 colonnes du tableau.\n\nAutrement dit, les variables peuvent être visualisées de la façon suivante :\n\n\n\n\n\nFigure 4.2: Position des variables dans le tableau cases du package EDAWR.\n\n\n\n\nDonc même si nous disposons ici d’un tableau rectangulaire classique, nous sommes bien loin du format des données rangées.\n\n4.2.1 La fonction pivot_longer()\nAfin de transformer les données non rangées du tableau cases en données rangées, nous allons utiliser la fonction pivot_longer() du package tidyr. Avant d’aller plus loin, essayez d’imaginer à quoi le tableau rangé devrait ressembler.\nLa fonction pivot_longer() prend 4 arguments :\n\ndata : le nom du tableau de données que l’on souhaite “ranger”.\ncols : La liste des colonnes du tableau initial que l’on souhaite rassembler en 2 nouvelles variables. Ici, les colonnes 2, 3 et 4 (on pourra les noter 2:4 ou, en utilisant leur nom, \"2011\":\"2013\").\nnames_to : le nom d’une nouvelle variable qui contiendra les en-têtes des colonnes qui constituent la seconde variable. Ici, nous nommerons cette seconde variable year car elle devra contenir les années 2011, 2012 et 2013.\nvalues_to : le nom d’une nouvelle variable qui contiendra les informations correspondant à la troisième variable identifiée plus haut. Nous appellerons cette variables n_cases car elle contiendra les nombres de cas de tuberculose (7000, 5800, 15000, etc).\n\n\npivot_longer(data = cases, \n             cols = `2011`:`2013`, \n             names_to = \"year\", \n             values_to = \"n_cases\")\n\n# A tibble: 9 × 3\n  country year  n_cases\n  &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n1 FR      2011     7000\n2 FR      2012     6900\n3 FR      2013     7000\n4 DE      2011     5800\n5 DE      2012     6000\n6 DE      2013     6200\n7 US      2011    15000\n8 US      2012    14000\n9 US      2013    13000\n\n\nNous avons bien transformé le tableau de départ en un “tableau rangé” : chacune de nos 3 variables se trouve dans une unique colone, et chaque ligne correspond à une observation pour chacune de ces 3 variables. Comme d’habitude, si nous souhaitons pouvoir utiliser ce nouveau tableau, il faut lui donner un nom :\n\ncases_tidy &lt;- pivot_longer(data = cases, \n                           cols = `2011`:`2013`, \n                           names_to = \"year\", \n                           values_to = \"n_cases\")\n\nIl nous est maintenant plus facile de manipuler ces données pour en tirer de l’information, grâce à des analyses statistiques ou des représentations graphiques :\n\nggplot(cases_tidy, aes(x = country, y = n_cases, fill = year)) +\n  geom_col(position = \"dodge\", color = \"black\") +\n  scale_fill_brewer(palette = \"Accent\") +\n  theme_minimal() +\n  labs(x = \"Pays\",\n       y = \"Nombre de cas\",\n       fill = \"Année\",\n       title = \"Évolution du nombre de cas de tuberculose entre 2011 et 2013\",\n       subtitle = \"DE : Allemagne, FR : France, US : États-Unis\")\n\n\n\n\nFigure 4.3: Évolution du nombre de cas de tuberculose dans 3 pays, de 2011 à 2013.\n\n\n\n\nOn constate ici qu’entre 2011 et 2013, le nombre de cas de tuberculose a légèrement augmenté en Allemagne, est resté stable en France, et a diminué aux États-Unis.\nNotez ici que la variable year de notre nouveau tableau est considérée comme une variable de type “chaîne de caractères” et non comme une variable numérique. On peut le voir en affichant notre tableau en tapant son nom, ou en utilisant la fonction str() déjà décrite plus tôt :\n\nstr(cases_tidy)\n\ntibble [9 × 3] (S3: tbl_df/tbl/data.frame)\n $ country: chr [1:9] \"FR\" \"FR\" \"FR\" \"DE\" ...\n $ year   : chr [1:9] \"2011\" \"2012\" \"2013\" \"2011\" ...\n $ n_cases: num [1:9] 7000 6900 7000 5800 6000 6200 15000 14000 13000\n\n\nC’est le comportement par défaut de la fonction pivot_longer() : les anciens titres de colonnes sont convertis en chaînes de caractères. Si ce comportement n’est pas souhaitable, il y a 2 alternatives possibles :\n\nutiliser les arguments names_transform et/ou values_transform de la fonction pivot_longer(). Cela permet de spécifier comment transformer les variables nouvellement créées au moment de leur création.\nutiliser les fonctions mutate() et as.numeric() ou as.integer() après avoir modifié le tableau de départ avec pivot_longer(). Cette façon de faire sera décrite dans la Section 5.7.\n\n\n# On commence par afficher `cases`\ncases \n\n  country  2011  2012  2013\n1      FR  7000  6900  7000\n2      DE  5800  6000  6200\n3      US 15000 14000 13000\n\n# On utilise ensuite pivot_longer() avec l'argument \n# names_transform pour transformer year en facteur\npivot_longer(data = cases, \n             cols = `2011`:`2013`, \n             names_to = \"year\", \n             values_to = \"n_cases\",\n             names_transform = list(year = as.integer))\n\n# A tibble: 9 × 3\n  country  year n_cases\n  &lt;chr&gt;   &lt;int&gt;   &lt;dbl&gt;\n1 FR       2011    7000\n2 FR       2012    6900\n3 FR       2013    7000\n4 DE       2011    5800\n5 DE       2012    6000\n6 DE       2013    6200\n7 US       2011   15000\n8 US       2012   14000\n9 US       2013   13000\n\n\nOn voit ici que la variable year est maintenant une colonne numérique (&lt;int&gt; : nombres entiers), et non plus une variable de type “character”. En utilisant as.numeric() au lieu de as.integer(), on aurait transformé la variable year en &lt;dbl&gt; (nombre réel au lieu de nombre entier), ce qui ici, reviendrait exactement au même.\nDe la même façon, on peut avoir besoin de presenter la colonne year sous la forme d’un facteur :\n\npivot_longer(data = cases, \n             cols = `2011`:`2013`, \n             names_to = \"year\", \n             values_to = \"n_cases\",\n             names_transform = list(year = as.factor))\n\n# A tibble: 9 × 3\n  country year  n_cases\n  &lt;chr&gt;   &lt;fct&gt;   &lt;dbl&gt;\n1 FR      2011     7000\n2 FR      2012     6900\n3 FR      2013     7000\n4 DE      2011     5800\n5 DE      2012     6000\n6 DE      2013     6200\n7 US      2011    15000\n8 US      2012    14000\n9 US      2013    13000\n\n\n\n\n4.2.2 La fonction pivot_wider()\nLa fonction pivot_wider() permet de réaliser l’opération inverse de pivot_longer(). Elle “disperse” une unique colonne catégorielle en plusieurs colonnes, le tableau obtenue est donc plus large (“wider”) que le tableau de départ.\nReprenons par exemple notre tableau cases_tidy :\n\ncases_tidy\n\n# A tibble: 9 × 3\n  country year  n_cases\n  &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n1 FR      2011     7000\n2 FR      2012     6900\n3 FR      2013     7000\n4 DE      2011     5800\n5 DE      2012     6000\n6 DE      2013     6200\n7 US      2011    15000\n8 US      2012    14000\n9 US      2013    13000\n\n\nLa fonction pivot_wider() prend 3 arguments :\n\nLe nom du tableau contenant les données (ici, cases_tidy).\nnames_from : le nom de la variable contenant les catégories qui devront être transformées en colonnes (ici, year).\nvalues_from : le nom de la variable contenant les valeurs qui devront remplir les nouvelles colonnes (ici, n_cases).\n\n\npivot_wider(data = cases_tidy, \n            names_from = year, \n            values_from = n_cases)\n\n# A tibble: 3 × 4\n  country `2011` `2012` `2013`\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 FR        7000   6900   7000\n2 DE        5800   6000   6200\n3 US       15000  14000  13000\n\n\nCette fonction sera donc rarement utilisée puisqu’elle ne permet pas d’obtenir des “tableaux rangés”. Toutefois, elle pourra vous être utile pour présenter des résultats sous forme synthétique. Prenons un exemple avec le jeu de données flights. Imaginons que vous deviez créer un tableau n_vols présentant, pour chacun des 3 aéroports de New York, le nombre de vols affrétés par chaque compagnie aérienne en 2013. Une possibilité serait de taper ceci :\n\nn_vols &lt;- flights |&gt; \n  group_by(origin, carrier) |&gt; \n  count()\nn_vols\n\n# A tibble: 35 × 3\n# Groups:   origin, carrier [35]\n   origin carrier     n\n   &lt;chr&gt;  &lt;chr&gt;   &lt;int&gt;\n 1 EWR    9E       1268\n 2 EWR    AA       3487\n 3 EWR    AS        714\n 4 EWR    B6       6557\n 5 EWR    DL       4342\n 6 EWR    EV      43939\n 7 EWR    MQ       2276\n 8 EWR    OO          6\n 9 EWR    UA      46087\n10 EWR    US       4405\n# ℹ 25 more rows\n\n\nLes commandes permettant de produire ce tableau seront expliquées dans le Chapitre 5. On peut cependant constater ici que ce tableau contient 35 lignes et 3 colonnes. Il s’agit bien d’un “tableau rangé” parfaitement adapté pour faire des statistiques et des visualisations graphiques, mais son format n’est pas terrible si notre objectif est de le faire figurer dans un rapport. La solution : utiliser pivot_wider() :\n\npivot_wider(n_vols, \n            names_from = origin, \n            values_from = n)\n\n# A tibble: 16 × 4\n# Groups:   carrier [16]\n   carrier   EWR   JFK   LGA\n   &lt;chr&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1 9E       1268 14651  2541\n 2 AA       3487 13783 15459\n 3 AS        714    NA    NA\n 4 B6       6557 42076  6002\n 5 DL       4342 20701 23067\n 6 EV      43939  1408  8826\n 7 MQ       2276  7193 16928\n 8 OO          6    NA    26\n 9 UA      46087  4534  8044\n10 US       4405  2995 13136\n11 VX       1566  3596    NA\n12 WN       6188    NA  6087\n13 HA         NA   342    NA\n14 F9         NA    NA   685\n15 FL         NA    NA  3260\n16 YV         NA    NA   601\n\n\nCe nouveau tableau contient maintenant 16 lignes (une par compagnie aérienne), et 4 colonnes : une pour la variable carrier, et 3 pour la variable origin, soit une colonne pour chacun des 3 aéroports de New York. On parle de tableau au format large (par opposition au “tableau rangé”, dit “format long”). Cela rend la présentation dans un rapport plus aisée.\nNotez également que certaines compagnies aériennes ne desservent pas tous les aéroports. Par exemple, la compagnie Alaska Airlines (AS) ne dessert ni JFK, ni La Guardia. Pour ces catégories, notre nouveau tableau au format large indique NA. Or, NA signifie “Not Available”, autrement dit : données manquantes. Ici, il ne s’agit pas du tout de données manquantes. Cela signifie simplement qu’aucun vol d’Alaska Airline n’a décollé de ces 2 aéroports. Nous pouvons donc indiquer à R quelle valeur utiliser pour les catégories qui ne sont pas représentées dans le tableau de départ grâce à l’argument values_fill :\n\npivot_wider(n_vols, \n            names_from = origin, \n            values_from = n, \n            values_fill = 0)\n\n# A tibble: 16 × 4\n# Groups:   carrier [16]\n   carrier   EWR   JFK   LGA\n   &lt;chr&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1 9E       1268 14651  2541\n 2 AA       3487 13783 15459\n 3 AS        714     0     0\n 4 B6       6557 42076  6002\n 5 DL       4342 20701 23067\n 6 EV      43939  1408  8826\n 7 MQ       2276  7193 16928\n 8 OO          6     0    26\n 9 UA      46087  4534  8044\n10 US       4405  2995 13136\n11 VX       1566  3596     0\n12 WN       6188     0  6087\n13 HA          0   342     0\n14 F9          0     0   685\n15 FL          0     0  3260\n16 YV          0     0   601\n\n\nD’autres arguments existent. Je vous encourage vivement à consulter l’aide des fonctions pivot_longer() et pivot_wider() et à faire des essais.\n\n\n4.2.3 Les fonctions separate() et unite()\nCes fonctions sont complémentaires : tout comme pivot_longer() et pivot_wider(), elles effectuent 2 opérations opposées. Reprenons le jeu de données cases_tidy :\n\ncases_tidy\n\n# A tibble: 9 × 3\n  country year  n_cases\n  &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n1 FR      2011     7000\n2 FR      2012     6900\n3 FR      2013     7000\n4 DE      2011     5800\n5 DE      2012     6000\n6 DE      2013     6200\n7 US      2011    15000\n8 US      2012    14000\n9 US      2013    13000\n\n\nImaginons que nous ayons besoin de séparer les données de la colonne year en 2 variables : le siècle d’une part, et l’année d’autre part. La fonction separate() permet de faire exactement cela :\n\nseparate(cases_tidy, year, into = c(\"century\", \"year\"), sep = 2)\n\n# A tibble: 9 × 4\n  country century year  n_cases\n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n1 FR      20      11       7000\n2 FR      20      12       6900\n3 FR      20      13       7000\n4 DE      20      11       5800\n5 DE      20      12       6000\n6 DE      20      13       6200\n7 US      20      11      15000\n8 US      20      12      14000\n9 US      20      13      13000\n\n\n\nLe premier argument est le nom du tableau de données.\nLe second argument est la variable que l’on souhaite scinder en plusieurs morceaux.\ninto est un vecteur qui contient le nom des nouvelles colonnes à créer\nsep peut prendre plusieurs formes. Lorsqu’on utilise un nombre, ce nombre correspond à la position de la coupure dans la variable d’origine. Ici, la variable d’origine a été coupée après le second caractère. Il est aussi possible d’utiliser un symbole. Par exemple, certaines variables contiennent des tirets - ou des slash \\. Utiliser ces caractères en guise de séparateur permet de couper les variables à ce niveau là. Nous en verrons un exemple plus tard.\n\nNotez ici que les 2 nouvelles variables sont de type &lt;chr&gt;. Si nous souhaitons que ces variables soient considérées comme numériques, nous devons ajouter un argument lorsque nous utilisons separate() :\n\ncases_split &lt;- separate(cases_tidy, \n                        year, \n                        into = c(\"century\", \"year\"), \n                        sep = 2, \n                        convert = TRUE)\ncases_split\n\n# A tibble: 9 × 4\n  country century  year n_cases\n  &lt;chr&gt;     &lt;int&gt; &lt;int&gt;   &lt;dbl&gt;\n1 FR           20    11    7000\n2 FR           20    12    6900\n3 FR           20    13    7000\n4 DE           20    11    5800\n5 DE           20    12    6000\n6 DE           20    13    6200\n7 US           20    11   15000\n8 US           20    12   14000\n9 US           20    13   13000\n\n\nNotre nouvel objet cases_split contient maintenant 2 nouvelles colonnes de nombres entiers, l’une contenant le siècle, l’autre contenant l’année.\nLa fonction unite() fait exactement le contraire : elle fusionne 2 colonnes existantes en accolant leurs contenus (et en ajoutant un séparateur) :\n\nunite(cases_split, new, century, year)\n\n# A tibble: 9 × 3\n  country new   n_cases\n  &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n1 FR      20_11    7000\n2 FR      20_12    6900\n3 FR      20_13    7000\n4 DE      20_11    5800\n5 DE      20_12    6000\n6 DE      20_13    6200\n7 US      20_11   15000\n8 US      20_12   14000\n9 US      20_13   13000\n\n\nLa colonne new a été créée par la fusion des colonnes century et year du tableau cases_split. Si l’on souhaite supprimer le tiret, il nous faut le spécifier explicitement :\n\nunite(cases_split, new, century, year, sep = \"\")\n\n# A tibble: 9 × 3\n  country new   n_cases\n  &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n1 FR      2011     7000\n2 FR      2012     6900\n3 FR      2013     7000\n4 DE      2011     5800\n5 DE      2012     6000\n6 DE      2013     6200\n7 US      2011    15000\n8 US      2012    14000\n9 US      2013    13000\n\n\n\n\n4.2.4 Exercices\nExaminez les tableaux rates, storms et population du package EDAWR.\n\nCes tableaux sont-ils des “tableaux rangés” (tidy data) ?\nSi oui, quelles sont les variables représentées ?\nSi non, transformez-les en “tableaux rangés”."
  },
  {
    "objectID": "04-tidy-Data.html#importer-des-données-depuis-un-tableur",
    "href": "04-tidy-Data.html#importer-des-données-depuis-un-tableur",
    "title": "4  (Ar)ranger des données avec tidyr",
    "section": "4.3 Importer des données depuis un tableur",
    "text": "4.3 Importer des données depuis un tableur\n\n4.3.1 Les règles de base\nJusqu’à maintenant, nous avons travaillé exclusivement avec des jeux de données déjà disponibles dans R. La plupart du temps, les données sur lesquelles vous devrez travailler devront au préalable être importées dans R, à partir de fichiers issus de tableurs. De tels fichiers se présentent généralement sous l’un des 2 formats suivants :\n\nFichiers au format “.csv” : il s’agit d’un format de fichier dit “texte brut”, c’est à dire qu’il peut être ouvert avec n’importe quel éditeur de texte, y compris le bloc notes de Windows. L’extension “.csv” est l’abbréviation de Comma Separated Values, autrement dit, dans ce type de fichiers, les colonnes sont séparées par des virgules. Cela peut poser problème en France puisque le symbole des décimales est souvent aussi la virgule (et non le point comme dans les pays anglo-saxons). Le séparateur de colonnes utilisé en France dans les fichiers .csv est alors souvent le point-virgule. Il est possible de créer des fichiers .csv à partir de n’importe quel tableur en choisissant Fichier &gt; Exporter... ou Fichier &gt; Enregistrer sous... puis en sélectionnant le format approprié (les dénomminations sont variables selon les logiciels : format texte brut, format csv, plain text, etc…).\nFichiers au format tableur : .xls ou .xlsx pour Excel, .calc pour Open Office.\n\nDans les 2 cas, pour que R puisse importer les données contenues dans ces fichiers, un certain nombre de règles doivent être respectées :\n\nLa première chose à laquelle il faut veiller est la présentation des données. Les variables doivent être en colonnes et les observations en lignes. Dans l’idéal, les données doivent donc être “rangées”.\nLes cases vides qui correspondent à des données manquantes doivent contenir les lettres NA en majuscule. Il est important de bien faire la distinction entre les vrais zéros (i.e. les grandeurs mesurées pour lesquelles un zéro a été obtenu), et les valeurs manquantes, c’est à dire pour lesquelles aucune valeur n’a pu être obtenue (e.g. variable non mesurée pour un individu donné ou à une station donnée).\nIl est généralement conseillé d’utiliser la première ligne du tableau pour stocker le nom des variables et la première colonne pour stocker le nom des observations (identifiant des individus, des échantillons ou des stations par exemple).\nNe jamais utiliser de caractères spéciaux tels que #, $, %, ^, &, *, (, ), {, }, [, ], des accents, des cédilles des guillemets ou des apostrophes… Cela pourrait causer des erreurs dans R. Si votre fichier en contient, faites une recherche (via le menu Edition &gt; Rechercher et remplacer...) pour remplacer chaque instance par un caractère qui ne posera pas de problème.\nÉvitez les espaces dans vos noms de variables, d’observations ou de catégories et remplacez-les par des points ou des _.\nSi des noms de lignes sont présents dans votre tableau, chaque ligne doit avoir un nom unique (il ne faut pas que plusieurs lignes portent le même nom).\nDes noms courts pour les variables sont généralement plus faciles à manipuler par la suite.\nLa première valeur de votre tableau derait toujours se trouver dans la cellule A1 du tableur. Autrement dit, il ne devrait jamais y avoir de lignes incomplètes ou de lignes de commentaires au-dessus des données, ou de colonne vide à gauche de votre tableau. D’ailleurs, il ne devrait jamais y avoir de commentaires à droite ou en dessous de vos données non plus.\n\n\n\n4.3.2 Fichiers au format tableur (.xls ou .xlsx)\nÀ titre d’exemple, téléchargez le fichier dauphin.xls et placez-le dans votre répertoire de travail. Ce jeu de données contient des résultats de dosages de différents métaux lourds (cadmium, cuivre et mercure) dans différents organes (foie et rein) de plusieurs dauphins communs Delphinus delphis. Les informations de taille, d’âge et de statut reproducteur sont également précisées. Ouvrez ce fichier dans un tableur. Vous constaterez que son format ne permet pas de l’importer tel quel dans R :\n\nIl contient des lignes vides inutiles au-dessus des données.\nIl contient des commentaires inutiles au-dessus des données.\nLes titres de colonnes sont complexes et contiennent des caractères spéciaux.\nDans le tableau, les données manquantes sont représentées soit par des “*”, soit par des cellules vides.\n\nImporter un tel jeu de données dans R par les méthodes classiques (c’est-à-dire sans utiliser RStudio et uniquement grâce aux fonctions de base de R) demanderait donc un gros travail de mise en forme préalable. Heureusement, RStudio et le package readxl facilitent grandement le processus.\nDans RStudio, localisez l’onglet Files situé dans le panneau en bas à droite de l’interface du logiciel. Dans ce panneau, naviguez jusqu’à votre répertoire de travail, qui doit maintenant contenir le fichier daupin.xls que vous avez téléchargé. Cliquez sur son nom, puis, dans le menu qui s’affiche, choisissez Import Dataset... :\n\n\n\n\n\nFigure 4.4: L’option Import Dataset... dans la fenêtre Files de RStudio.\n\n\n\n\nLa nouvelle fenêtre qui s’ouvre est un “assistant d’importation” (Figure 4.5).\n\n\n\n\n\nFigure 4.5: L’assistant d’importation de RStudio.\n\n\n\n\nCette fenêtre contient plusieurs zones importantes :\n\nFile/URL (en haut) : lien vers le fichier contenant les données, sur votre ordinateur ou en ligne.\nData Preview : zone principale affichant les 50 premières lignes du fichier que l’on souhaite importer.\nImport Options (en bas à gauche) : zone dans laquelle des options permettant d’importer les données correctement peuvent être spécifiées.\nCode Preview (en bas à droite) : les lignes de codes que vous pourrez copier-coller dans votre script une fois les réglages corrects effectués.\n\nIci, nous constatons que les données ne sont pas au bon format. La première chose que nous pouvons faire est d’indiquer à R que nous souhaitons ignorer les 9 premières lignes du fichier. Ensuite, nous précisons à RStudio que l’étoile “*” a été utilisée pour indiquer des données manquantes (Figure 4.6) :\n\n\n\n\n\nFigure 4.6: Les bons réglages pour ce fichier.\n\n\n\n\nNotez qu’à chaque fois que vous modifiez une valeur dans la zone Import Options, 2 choses se produisent simultanément :\n\nLa zone Data Preview est mise à jour. Cela permet de s’assurer que les changements effectués ont bien les effets escomptés.\nLa zone Code Preview est mise à jour. Cela permet de copier-coller dans un script les commandes permettant d’importer correctement les données. Ici, voilà le code que nous devons ajouter à notre script :\n\n\ndauphin &lt;- read_excel(\"data/dauphin.xls\", na = \"*\", skip = 9)\n\nLa commande library(readxl) est inutile puisque nous l’avons déjà saisie au début de ce chapitre. Nous disposons maintenant d’un nouvel objet nommé dauphin. Il est stocké sous la forme d’un tibble :\n\ndauphin\n\n# A tibble: 93 × 9\n   `N°`      Sexe  `Statut reproducteur` `Taille en cm` `Age en années`\n   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;                          &lt;dbl&gt;           &lt;dbl&gt;\n 1 Numéro 1  f     imm                              315               3\n 2 Numéro 2  f     imm                              357               4\n 3 Numéro 3  f     pnl                              439              34\n 4 Numéro 4  f     imm                              316               4\n 5 Numéro 5  f     l                                435              26\n 6 Numéro 6  f     pnl                              388               6\n 7 Numéro 7  f     mat                              410              NA\n 8 Numéro 8  m     imm                              355              NA\n 9 Numéro 9  m     imm                              222              NA\n10 Numéro 10 m     imm                              412               9\n# ℹ 83 more rows\n# ℹ 4 more variables: `Cd (mg.kg-1)` &lt;dbl&gt;, `Cu (mg.kg-1)` &lt;dbl&gt;,\n#   `Hg (mg.kg-1)` &lt;dbl&gt;, Organe &lt;chr&gt;\n\n\nNotez toutefois que les noms de colonnes complexes sont toujours présents. Avec de tels noms, les variables ne seront pas faciles à manipuler et les risques d’erreurs de frappes seront nombreux. Nous avons tout intérêt à les modifier à l’aide de la fonction names() :\n\nnames(dauphin) &lt;- c(\"ID\", \"Sexe\", \"Statut\", \"Taille\",\n                    \"Age\", \"Cd\", \"Cu\", \"Hg\", \"Organe\")\ndauphin\n\n# A tibble: 93 × 9\n   ID        Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n 1 Numéro 1  f     imm       315     3  29.6   3.24 NA    rein  \n 2 Numéro 2  f     imm       357     4  55.1   4.42 NA    rein  \n 3 Numéro 3  f     pnl       439    34 129.    5.01  9.02 rein  \n 4 Numéro 4  f     imm       316     4  71.2   4.33 NA    rein  \n 5 Numéro 5  f     l         435    26 192     5.15 NA    rein  \n 6 Numéro 6  f     pnl       388     6  NA     4.12  4.53 rein  \n 7 Numéro 7  f     mat       410    NA  76     5.1  33.9  foie  \n 8 Numéro 8  m     imm       355    NA  74.4   4.72 13.3  foie  \n 9 Numéro 9  m     imm       222    NA   0.09  9.5   2.89 foie  \n10 Numéro 10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nEnfin, vous pouvez également noter que certaines variables devraient être modifiées :\n\nLes variables Sexe, Statut (qui contient l’information de statut reproducteur des dauphins) et Organe (qui indique dans quel organe les métaux ont été dosés) sont de type &lt;chr&gt;. L’idéal serait de disposer de facteurs puisqu’ils s’agit de variables catégorielles.\nLa variable ID est totalement inutile puisqu’elle est parfaitement redondante avec le numéro de ligne. Nous pourrions donc la supprimer.\nCertaines catégories (ou niveaux) de la variable Statut devraient être ordonnées puisqu’elles reflètent une progression logique : imm (immature), mat (mature), pnl (pregnant not lactating), pl (pregnant lactating), l (lactating), repos (repos somatique).\n\nNous verrons dans le Chapitre 5 comment effectuer simplement ces différentes opérations.\n\n\n4.3.3 Fichiers au format texte brut (.csv)\nNous allons utiliser les mêmes données que précédemment, mais cette fois-ci, elles sont contenues dans un fichier au format .csv. Téléchargez le fichier dauphin.csv (pour cela, faites un clic droit sur le lien et choisissez Enregistrez la cible du lien sous... ou une mention équivalente), placez-le dans votre répertoire de travail, et ouvrez-le avec le bloc notes Windows ou tout autre éditeur de texte brut disponible sur votre ordinateur. Attention : Microsoft Word n’est pas un éditeur de texte brut. Un fichier au format .doc ou .docx est illisible dans un éditeur de texte brut car outre le texte, ces formats de documents contiennent toutes les informations concernant la mise en forme du texte (polices de caractères, tailles, couleurs et autres attributs, présence de figures, de tableaux dans le document, etc.).\nÀ l’inverse, les fichiers au format .txt, .csv et même .R (vos scripts !) sont des fichiers au format texte brut. Vous pouvez d’ailleurs essayer d’ouvrir dauphin.csv depuis RStudio, en allant dans la fenêtre Files puis en cliquant sur le nom du fichier et en choisissant View File. RStudio ouvre un nouvel onglet à côté de votre script vous permettant d’inspecter le contenu de ce fichier. Par rapport au fichier Excel, vous pouvez noter un certain nombre de différences :\n\nLes colonnes sont séparées par des tabulations.\nLes nombres décimaux utilisent la virgule (et non le point comme dans les pays anglo-saxons).\nLes noms de colonnes ont déjà été corrigés/simplifiés par rapport au tableau d’origine.\nLes valeurs manquantes sont toutes codées par des NAs.\n\nUn travail d’édition du fichier .xls de départ a donc été réalisé en amont de l’enregistrement au format .csv.\nAttention, à ce stade, vous avez ouvert un fichier au format texte brut dans RStudio, mais les données contenues dans ce fichier n’ont pas été importées dans R pour autant. Pour les importer, on procède comme pour les fichiers au format tableur (voir Section 4.3.2 ci-dessus).\nOn commence par cliquer sur dauphin.csv dans l’onglet Files de RStudio. On sélectionne ensuite Import Dataset... :\n\n\n\n\n\nFigure 4.7: Importer un fichier .csv depuis l’onglet Files de RStudio.\n\n\n\n\nLa fenêtre qui s’ouvre est en tous points identique à celle obtenue pour l’importation de fichiers tableurs (Figure 4.8).\n\n\n\n\n\nFigure 4.8: Importer un fichier .csv depuis l’onglet Files de RStudio.\n\n\n\n\nNous voyons ici que par défaut, RStudio considère qu’une unique colonne est présente. En effet, les fichiers .csv utilisent généralement la virgule pour séparer les colonnes. Ce n’est pas le cas ici. Il nous faut donc sélectionner, dans le champ Delimiter, l’option Tab (tabulation) et non Comma (virgule).\nÀ ce stade, chaque variable est maintenant reconnue comme telle, chaque variable occupe donc une colonne distincte. Mais les colonnes Cd, Cu et Hg ne contiennent pas les bonnes valeurs (vous pouvez le vérifier en consultant l’onglet dauphin.csv que vous avez ouvert un peu plus tôt à côté de votre script). La cause est simple : R s’attend à ce que les nombres décimaux utilisent le point en guise de symbole des décimales. Or, notre fichier .csv utilise la virgule. C’est une convention qui dépend du pays dans lequel vous vous trouvez, et de la langue de votre système d’exploitation (en langage technique, on parle de Locale). Le fichier dauphin.csv ayant été créé sur un ordinateur français, la virgule a été utilisée en guise de symbole des décimales. Pour l’indiquer à R, cliquez sur Locale &gt; Configure..., changez le . en , dans le champ Decimal Mark et validez en cliquant sur Configure.\n\n\n\n\n\nFigure 4.9: Changement du symbole utilisé pour les décimales.\n\n\n\n\nLes données sont maintenant au bon format, prêtes à être importées dans RStudio. Afin de ne pas écraser l’objet dauphin que nous avons créé à partir du fichier tableur un peu plus tôt, nous stockerons ces nouvelles données dans un objet nommé dauphin2. Pour cela, ajoutez un 2 au nom dauphin dans le champ Name en bas à gauche :\n\n\n\n\n\nFigure 4.10: Les données, dans un format correct permettant l’importation.\n\n\n\n\nNous n’avons plus qu’à copier-coller dans notre script le code généré automatiquement en bas à droite de la fenêtre (comme précédemment, la ligne library(readr) est inutile : nous avons déjà chargé ce package en début de chapitre).\n\ndauphin2 &lt;- read_delim(\"data/dauphin.csv\", \n    \"\\t\", escape_double = FALSE, locale = locale(decimal_mark = \",\"), \n    trim_ws = TRUE)\n\nRows: 93 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (3): Sexe, Statut, Organe\ndbl (6): Id, Taille, Age, Cd, Cu, Hg\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNotez que :\n\nC’est le package readr et non plus readxl qui est utilisé.\nLa fonction read_delim() a remplacé la fonction read_excel(). Il existe beaucoup d’autres fonctions selon le format de vos données (par exemple read_csv() et read_csv2()). Il est inutile de toutes les connaître dans la mesure où généralement, RStudio vous propose automatiquement la plus appropriée.\nR indique de quelle façon les colonnes ont été “parsées”, autrement dit, R indique quelles fonctions ont été utilisées pour reconnaître le type des données présentes dans chaque colonne.\n\nToutes les fonctions permettant d’importer des données n’ont pas nécessairement le même comportement. Ainsi, si l’on compare les objets importés depuis le fichier tableur (dauphin) et depuis le fichier texte brut (dauphin2), le type de certaines variables peut être différent :\n\ndauphin\n\n# A tibble: 93 × 9\n   ID        Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n 1 Numéro 1  f     imm       315     3  29.6   3.24 NA    rein  \n 2 Numéro 2  f     imm       357     4  55.1   4.42 NA    rein  \n 3 Numéro 3  f     pnl       439    34 129.    5.01  9.02 rein  \n 4 Numéro 4  f     imm       316     4  71.2   4.33 NA    rein  \n 5 Numéro 5  f     l         435    26 192     5.15 NA    rein  \n 6 Numéro 6  f     pnl       388     6  NA     4.12  4.53 rein  \n 7 Numéro 7  f     mat       410    NA  76     5.1  33.9  foie  \n 8 Numéro 8  m     imm       355    NA  74.4   4.72 13.3  foie  \n 9 Numéro 9  m     imm       222    NA   0.09  9.5   2.89 foie  \n10 Numéro 10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\ndauphin2\n\n# A tibble: 93 × 9\n      Id Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n 1     1 f     imm       315     3  29.6   3.24 NA    rein  \n 2     2 f     imm       357     4  55.1   4.42 NA    rein  \n 3     3 f     pnl       439    34 129.    5.01  9.02 rein  \n 4     4 f     imm       316     4  71.2   4.33 NA    rein  \n 5     5 f     l         435    26 192     5.15 NA    rein  \n 6     6 f     pnl       388     6  NA     4.12  4.53 rein  \n 7     7 f     mat       410    NA  76     5.1  33.9  foie  \n 8     8 m     imm       355    NA  74.4   4.72 13.3  foie  \n 9     9 m     imm       222    NA   0.09  9.5   2.89 foie  \n10    10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nEn particulier selon la version des packages que vosu utilisez et les réglages spéifiques de vos systèmes d’exploitation, les variables Taille et Age sont parfois considérées comme réelles dans dauphin mais comme entières dans dauphin2 (ce n’est pas le cas ici). Afin d’éviter les confusions dans la suite du document, nous allons supprimer dauphin2 en tapant :\n\nrm(dauphin2)\n\nTaper dauphin2 dans la console devrait maintenant produire une erreur :\n\ndauphin2\n\nError in eval(expr, envir, enclos): objet 'dauphin2' introuvable\n\n\n\n\n4.3.4 En cas de problème…\nIl arrive parfois que l’importation de fichiers textes bruts par la méthode décrite ci-dessus échoue en raison d’un bug du package readr qui gère mal la présence de caractères spéciaux (accents, cédilles, etc) dans le chemin des fichiers que l’on tente d’importer. À l’heure où j’écris ces lignes (28 novembre 2018), le bug a été corrigé dans la version de développement du package, mais toujours pas dans la version stable disponible au téléchargement sur les serveurs du CRAN. Il est donc utile de connaître une méthode alternative pour importer de tels fichiers dans R. Cette méthode repose sur “la mère de toutes les fonctions d’importation” : read.table().\nLa fonction read.table() est à la base de la plupart des fonctions d’importation décrites dans ce chapitre. Il est donc important d’en connaître la syntaxe et les arguments les plus importants. Cette fonction requiert en général les arguments suivants :\n\nLe chemin du fichier texte contenant les données à importer. Si le fichier se trouve dans votre répertoire de travail, il suffit de donner son nom. S’il est dans un sous-dossier de votre répertoire de travail, il faut donner le nom complet : \"sous_dossier/nom_du_fichier.csv\".\nsep : la spécification du symbole utilisé en guise de séparateur de colonnes dans le fichier texte. Cela peut-être la virgule (sep = \",\"), le point virgule (sep = \";\") ou encore la tabulation (sep = \"\\t\") selon les fichiers importés.\ndec : la spécification du symbole utilisé en guise de symbole pour les décimales. Il n’est pas nécessaire de spécifier cet argument lorsque le symbole dans le fichier source est le point. Mais si c’est une virgule (comme c’est souvent le cas dans les pays francophones), il faut alors préciser dec = \",\".\nheader : la première ligne du fichier source contient-elle des noms de variables. Si oui, il faut indiquer header = TRUE.\n\nAinsi, par exemple, pour le fichier dauphin.csv, on peut taper ceci :\n\ndauph &lt;- read.table(\"data/dauphin.csv\",\n                    sep = \"\\t\",\n                    dec = \",\",\n                    header = TRUE)\ndauph &lt;- as_tibble(dauph)\ndauph\n\n# A tibble: 93 × 9\n      Id Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;   &lt;int&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n 1     1 f     imm       315     3  29.6   3.24 NA    rein  \n 2     2 f     imm       357     4  55.1   4.42 NA    rein  \n 3     3 f     pnl       439    34 129.    5.01  9.02 rein  \n 4     4 f     imm       316     4  71.2   4.33 NA    rein  \n 5     5 f     l         435    26 192     5.15 NA    rein  \n 6     6 f     pnl       388     6  NA     4.12  4.53 rein  \n 7     7 f     mat       410    NA  76     5.1  33.9  foie  \n 8     8 m     imm       355    NA  74.4   4.72 13.3  foie  \n 9     9 m     imm       222    NA   0.09  9.5   2.89 foie  \n10    10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nPuisque la fonction read.table() importe les données sous la forme d’un data.frame, il est nécessaire de transformer le tableau obtenu en tibble grâce à la fonction as_tibble() afin de bénéficier de tous les avantages de ce format d’objet.\n\n\n4.3.5 Exercices\n\nL’objet dauphin est-il “tidy” (autrement dit, s’agit-il de “données rangées”) ? Justifiez.\nProduisez le graphique ci-dessous :\n\n\n\n\n\n\nFigure 4.11: Figure à reproduire.\n\n\n\n\nIndice : les droites de régression avec les intervalles de confiance sont ajoutés grâce à la fonction geom_smooth(method = \"lm\").\n\nImportez dans R le jeu de données whoTB.csv. Ce jeu de données contient les cas de tuberculose (TB) rapportés par l’Organisation Mondiale de la Santé (OMS, ou WHO en anglais : World Health Organization). Les cas sont répertoriés par année, pays, âge, sexe, type de tuberculose et méthode de diagnostique. Selon vous, ce jeu de données est-il “rangé” ? Pourquoi ?\nSi ce jeu de données n’est pas rangé, rangez-le en utilisant les fonctions du packages tidyr que nous avons découvertes dans ce chapitre : pivot_longer(), pivot_wider(), separate() et unite() (vous n’aurez pas nécessairement besoin d’utiliser ces 4 fonctions, et à l’inverse, certaines devront peut-être être utilisées plusieurs fois).\n\nPour vous aider, l’OMS donne la signification des codes utilisés en guise de noms pour la plupart des colonnes. Ainsi :\n\nnew indique des nouveaux cas, old des anciens (ici, seuls des nouveaux cas sont rapportés).\nLe type de cas est précisé ensuite :\n\nsp signifie “Smear Positive” (tuberculose pulmonaire à frottis positif).\nsn signifie “Smear Negative” (tuberculose pulmonaire à frottis négatif).\nrel signifie “relapse” (rechute).\nep signifie “Extra Pulmonary” (tuberculose extra-pulmonaire).\n\nLe sexe est codé par m (male) ou f (female).\nEnfin, les chiffres correspondent à des tranches d’âges : 014 signifie “de 0 à 14 ans”, “1524” signifie “de 15 à 24 ans”, etc.\n\nDans ces colonnes aux noms composés, les nombres de cas de tuberculose sont rapportés."
  },
  {
    "objectID": "05-DataWrangling.html#pré-requis",
    "href": "05-DataWrangling.html#pré-requis",
    "title": "5  Tripatouiller les données avec dplyr",
    "section": "5.1 Pré-requis",
    "text": "5.1 Pré-requis\nNous abordons ici une étape essentielle de toute analyse de données : la manipulation de tableaux, la sélection de lignes, de colonnes, la création de nouvelles variables, etc. Bien souvent, les données brutes que nous importons dans R ne sont pas utiles en l’état. Il nous faut parfois sélectionner seulement certaines lignes pour travailler sur une petite partie du jeu de données. Il nous faut parfois modifier des variables existantes (pour modifier les unités par exemple) ou en créer de nouvelles à partir des variables existantes. Nous avons aussi très souvent besoin de constituer des groupes et d’obtenir des statistiques descriptives pour chaque groupe (moyenne, écart-type, erreur type, etc). Nous verrons dans ce chapitre comment faire tout cela grâce au package dplyr qui fournit un cadre cohérent et des fonctions simples permettant d’effectuer tous les tripatouillages de données dont nous pourrons avoir besoin.\nDans ce chapitre, nous aurons besoin des packages suivants :\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(nycflights13)\nlibrary(forcats)"
  },
  {
    "objectID": "05-DataWrangling.html#le-pipe",
    "href": "05-DataWrangling.html#le-pipe",
    "title": "5  Tripatouiller les données avec dplyr",
    "section": "5.2 Le pipe |>",
    "text": "5.2 Le pipe |&gt;\nAvant d’entrer dans le vif du sujet, je souhaite introduire ici la notion de “pipe” (prononcer à l’anglo-saxonne). Le pipe est un opérateur que nous avons déjà vu apparaître à plusieurs reprises dans les chapitres précédents sans expliquer son fonctionnement.\n\n\n\n\n\n\nFigure 5.1: Pour que ces raccourcis fonctionnent, assurez-vous que l’option Use native pipe operator est bien cochée dans les préférences de RStudio.\n\n\n\nLe pipe, noté |&gt;, peut être obtenu en pressant les touches ctrl + shift + M de votre clavier (ou command + shift + M sous macOS). Il permet d’enchaîner logiquement des actions les unes à la suite des autres. Globalement, le pipe prend l’objet situé à sa gauche, et le transmet à la fonction situé à sa droite. En d’autres termes, les 2 expressions suivantes sont strictement équivalentes :\n\n# Ici, \"f\" est une fonction quelconque, \n# \"x\" et \"y\" sont 2 objets dont la fonction a besoin.\n\n# Il s'agit d'un exemple fictif : ne tapez pas ceci dans votre script !\nf(x, y)\nx |&gt; f(y)\n\nTravailler avec le pipe est très intéressant car toutes les fonctions de dplyr que nous allons décrire ensuite sont construites autour de la même syntaxe : on leur fournit un data.frame (ou encore mieux, un tibble), elles effectuent une opération et renvoient un nouveau data.frame (ou un nouveau tibble). Il est ainsi possible de créer des groupes de commandes cohérentes qui permettent, grâce à l’enchaînement d’étapes simples, d’aboutir à des résultats complexes.\nDe la même façon que le + permet d’ajouter une couche supplémentaire à un graphique ggplot2, le pipe |&gt; permet d’ajouter une opération supplémentaire dans un groupe de commandes.\nPour reprendre un exemple de la ?sec-clouds sur les nuages de points, nous avions commencé par créer un objet nommé alaska_flights à partir de l’objet flights :\n\nalaska_flights &lt;- flights |&gt;\n  filter(carrier == \"AS\")\n\nNous avions ensuite créé notre premier nuage de points avec ce code :\n\nggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) + \n  geom_point()\n\nNous savons maintenant qu’il n’est pas indispensable de faire figurer le nom des arguments data = et mapping =. Mais nous pouvons aller plus loin. En fait, il n’était même pas nécessaire de créer l’objet alaska_flights : nous aurions pu utiliser le pipe pour enchaîner les étapes suivantes :\n\nOn prend le tableau flights, puis…\nOn filtre les données pour ne retenir que la compagnie aérienne AS, puis…\nOn réalise le graphique.\n\nVoilà comment traduire cela avec le pipe :\n\nflights |&gt; \n  filter(carrier == \"AS\") |&gt; \n  ggplot(aes(x = dep_delay, y = arr_delay)) + \n    geom_point()\n\n\n\n\nFigure 5.2: Notre premier graphique, produit grâce au pipe.\n\n\n\n\nNotez bien qu’ici, aucun objet intermédiaire n’a été créé. Notez également que le premier argument de la fonction ggplot() a disparu : le pipe a fourni automatiquement à ggplot() les données générées au préalable (les données flights filtrées grâce à la fonction filter()).\nComme pour le + de ggplot2, il est conseillé de placer un seul pipe par ligne, de le placer en fin de ligne et de revenir à la ligne pour préciser l’étape suivante.\nToutes les commandes que nous utiliserons à partir de maintenant reposeront sur le pipe puisqu’il permet de rendre le code plus lisible."
  },
  {
    "objectID": "05-DataWrangling.html#les-verbes-du-tripatouillage-de-données",
    "href": "05-DataWrangling.html#les-verbes-du-tripatouillage-de-données",
    "title": "5  Tripatouiller les données avec dplyr",
    "section": "5.3 Les verbes du tripatouillage de données",
    "text": "5.3 Les verbes du tripatouillage de données\nNous allons ici nous concentrer sur les fonctions les plus couramment utilisées pour manipuler et résumer des données. Nous verrons 6 verbes principaux, chacun correspondant à une fonction précise de dplyr. Chaque section de ce chapitre sera consacrée à la présentation d’un exemple utilisant un ou plusieurs de ces verbes.\nLes 6 verbes sont :\n\nfilter() : choisir des lignes dans un tableau à partir de conditions spécifiques (filtrer).\narrange() : trier les lignes d’un tableau selon un ou plusieurs critères (arranger).\nselect() : sélectionner des colonnes d’un tableau.\nmutate() : créer de nouvelles variables en transformant et combinant des variables existantes (muter).\nsummarise() : calculer des résumés statistiques des données (résumer). Souvent utilisé en combinaison avec group_by() (grouper par), qui permet de constituer des groupes au sein des données.\njoin() : associer, fusionner 2 data.frames en faisant correspondre les éléments d’une colonne commune entre les 2 tableaux (joindre). Il y a de nombreuses façons de joindre des tableaux. Nous nous contenterons d’examiner les fonctions left_join() et inner_join().\n\nToutes ces fonctions, tous ces verbes, sont utilisés de la même façon : on prend un data.frame, grâce au pipe, on le transmet à l’une de ces fonctions dont on précise les arguments entre parenthèses, la fonction nous renvoie un nouveau tableau modifié. Évidemment, on peut enchaîner les actions pour modifier plusieurs fois le même tableau, c’est tout l’intérêt du pipe.\nEnfin, gardez en tête qu’il existe beaucoup plus de fonctions dans dplyr que les 6 que nous allons détailler ici. Nous verrons parfois quelques variantes, mais globalement, maîtriser ces 6 fonctions simples devrait vous permettre de conduire une très large gamme de manipulations de données, et ainsi vous faciliter la vie pour la production de graphiques et l’analyse statistique de vos données."
  },
  {
    "objectID": "05-DataWrangling.html#filtrer-des-lignes-avec-filter",
    "href": "05-DataWrangling.html#filtrer-des-lignes-avec-filter",
    "title": "5  Tripatouiller les données avec dplyr",
    "section": "5.4 Filtrer des lignes avec filter()",
    "text": "5.4 Filtrer des lignes avec filter()\n\n5.4.1 Principe\n\n\n\n\n\nFigure 5.3: Schéma de la fonction filter() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nComme son nom l’indique, filter() permet de filtrer des lignes en spécifiant un ou des critères de tri portant sur une ou plusieurs variables. Nous avons déjà utilisé cette fonction à plusieurs reprises pour créer les jeux de données alaska_flights et small_weather :\n\nalaska_flights &lt;- flights |&gt; \n  filter(carrier == \"AS\")\n\n\nsmall_weather &lt;- weather |&gt; \n  filter(origin == \"EWR\",\n         month == 1,\n         day &lt;= 15)\n\nDans les 2 cas, la première ligne de code nous permet :\n\nD’indiquer le nom du nouvel objet dans lequel les données modifiées seront stockées (alaska_flights et small-weather).\nD’indiquer de quel objet les données doivent être extraites (flights et weather).\nDe passer cet objet à la fonction suivante avec un pipe |&gt;.\n\nLe premier argument de la fonction filter() doit être le nom d’un data.frame ou d’un tibble. Ici, puisque nous utilisons le pipe, il est inutile de spécifier cet argument : c’est ce qui est placé à gauche du pipe qui est utilisé comme premier argument de la fonction filter(). Les arguments suivants constituent la ou les conditions qui doivent être respectées par les lignes du tableau de départ afin d’être intégrées au nouveau tableau de données.\n\n\n5.4.2 Exercice\nDans la Section 2.4.1, nous avons utilisé la fonction View et l’application manuelle de filtres pour déterminer combien de vols avaient quitté l’aéroport JFK le 12 février 2013. En utilisant la fonction filter(), créez un objet nommé JFK_12fev qui contiendra les données de ces vols.\nVérifiez que cet objet contient bien 282 lignes.\n\n\n5.4.3 Les conditions logiques\nDans la Section 1.3.4.2, nous avons présenté en détail le fonctionnement des opérateurs de comparaison dans R. Relisez cette section si vous ne savez plus de quoi il s’agit. Les opérateurs de comparaison permettent de vérifier l’égalité ou l’inégalité entre des éléments. Ils renvoient TRUE ou FALSE et seront particulièrement utiles pour filtrer des lignes dans un tableau. Comme indiqué dans la Section 1.3.4.2, voici la liste des opérateurs de comparaison usuels :\n\n== : égal à\n!= : différent de\n&gt; : supérieur à\n&lt; : inférieur à\n&gt;= : supérieur ou égal à\n&lt;= : inférieur ou égal à\n\nÀ cette liste, nous pouvons ajouter quelques éléments utiles :\n\nis.na() : renvoie TRUE en cas de données manquantes.\n! : permet de tester le contraire d’une expression logique. Par exemple !is.na() renvoie TRUE s’il n’y a pas de données manquantes.\n%in% : permet de tester si l’élément de gauche est contenu dans la série d’éléments fournie à droite. Par exemple 2 %in% 1:5 renvoie TRUE, mais 2 %in% 5:10 renvoie FALSE.\n| : opérateur logique OU. Permet de tester qu’une condition OU une autre est remplie.\n& : opérateur logique ET. Permet de tester qu’une condition ET une autre sont remplies.\n\nVoyons comment utiliser ces opérateurs avec la fonction filter().\nDans le tableau flights, tous les vols prévus ont-ils effectivement décollé ? Une bonne façon de le savoir est de regarder si, pour la variable dep_time (heure de décollage), des données manquantes sont présentes :\n\nflights |&gt; \n  filter(is.na(dep_time))\n\n# A tibble: 8,255 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1       NA           1630        NA       NA           1815\n 2  2013     1     1       NA           1935        NA       NA           2240\n 3  2013     1     1       NA           1500        NA       NA           1825\n 4  2013     1     1       NA            600        NA       NA            901\n 5  2013     1     2       NA           1540        NA       NA           1747\n 6  2013     1     2       NA           1620        NA       NA           1746\n 7  2013     1     2       NA           1355        NA       NA           1459\n 8  2013     1     2       NA           1420        NA       NA           1644\n 9  2013     1     2       NA           1321        NA       NA           1536\n10  2013     1     2       NA           1545        NA       NA           1910\n# ℹ 8,245 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nSeules les lignes contenant NA dans la colonne dep_time sont retenues. Il y a donc 8255 vols qui n’ont finalement pas décollé.\nDans le même ordre d’idée, y a t-il des vols qui ont décollé mais qui ne sont pas arrivés à destination ? Là encore, une façon d’obtenir cette information est de sélectionner les vols qui ont décollé (donc pour lesquels l’heure de décollage n’est pas manquante), mais pour lesquels l’heure d’atterrissage est manquante :\n\nflights |&gt; \n  filter(!is.na(dep_time),\n         is.na(arr_time))\n\n# A tibble: 458 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1     2016           1930        46       NA           2220\n 2  2013     1     2     2041           2045        -4       NA           2359\n 3  2013     1     2     2145           2129        16       NA             33\n 4  2013     1     9      615            615         0       NA            855\n 5  2013     1     9     2042           2040         2       NA           2357\n 6  2013     1    11     1344           1350        -6       NA           1518\n 7  2013     1    13     1907           1634       153       NA           1837\n 8  2013     1    13     2239           2159        40       NA             30\n 9  2013     1    16      837            840        -3       NA           1030\n10  2013     1    25     1452           1500        -8       NA           1619\n# ℹ 448 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nNotez l’utilisation du ! pour la première condition. Nous récupérons ici les lignes pour lesquelles dep_time n’est pas NA et pour lesquelles arr_time est NA. Seules les lignes qui respectent cette double condition sont retenues. Cette syntaxe est équivalente à :\n\nflights |&gt; \n  filter(!is.na(dep_time) & is.na(arr_time))\n\n# A tibble: 458 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1     2016           1930        46       NA           2220\n 2  2013     1     2     2041           2045        -4       NA           2359\n 3  2013     1     2     2145           2129        16       NA             33\n 4  2013     1     9      615            615         0       NA            855\n 5  2013     1     9     2042           2040         2       NA           2357\n 6  2013     1    11     1344           1350        -6       NA           1518\n 7  2013     1    13     1907           1634       153       NA           1837\n 8  2013     1    13     2239           2159        40       NA             30\n 9  2013     1    16      837            840        -3       NA           1030\n10  2013     1    25     1452           1500        -8       NA           1619\n# ℹ 448 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nDans la fonction filter(), séparer plusieurs conditions par des virgules signifie que seules les lignes qui remplissent toutes les conditions seront retenues. C’est donc l’équivalent du ET logique.\nIl y a donc 458 vols qui ne sont pas arrivés à destination (soit moins de 0,2% des vols au départ de New York en 2013). Selon vous, quelles raisons peuvent expliquer qu’un vol qui a décollé n’ait pas d’heure d’atterrissage ?\nEnfin, pour illustrer l’utilisation de | (le OU logique) et de %in%, imaginons que nous souhaitions extraire les informations des vols ayant quitté l’aéroport JFK à destination d’Atlanta, Géorgie (ATL) et de Seatle, Washington (SEA), aux mois d’octobre, novembre et décembre :\n\natl_sea_fall &lt;- flights |&gt; \n  filter(origin == \"JFK\", \n         dest == \"ATL\" | dest == \"SEA\", \n         month &gt;= 10)\natl_sea_fall\n\n# A tibble: 962 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013    10     1      638            640        -2      839            905\n 2  2013    10     1      729            735        -6     1049           1040\n 3  2013    10     1      824            830        -6     1030           1059\n 4  2013    10     1      853            900        -7     1217           1157\n 5  2013    10     1     1328           1330        -2     1543           1553\n 6  2013    10     1     1459           1500        -1     1817           1829\n 7  2013    10     1     1544           1545        -1     1815           1819\n 8  2013    10     1     1754           1800        -6     2102           2103\n 9  2013    10     1     1825           1830        -5     2159           2150\n10  2013    10     1     1841           1840         1     2058           2116\n# ℹ 952 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nExaminez ce tableau avec View() pour vérifier que la variable dest contient bien uniquement les codes ATL et SEA correspondant aux 2 aéroports qui nous intéressent. Nous avons extrait ici les vols à destination d’Atlanta et Seatle, pourtant, il nous a fallu utiliser le OU logique. Car chaque vol n’a qu’une unique destination, or nous souhaitons récupérer toutes les lignes pour lesquelles la destination est soit ATL, soit SEA (l’une ou l’autre).\nUne autre solution pour obtenir le même tableau est de remplacer l’expression contenant | par une expression contenant %in% :\n\natl_sea_fall2 &lt;- flights |&gt; \n  filter(origin == \"JFK\", \n         dest %in% c(\"ATL\", \"SEA\"), \n         month &gt;= 10)\natl_sea_fall2\n\n# A tibble: 962 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013    10     1      638            640        -2      839            905\n 2  2013    10     1      729            735        -6     1049           1040\n 3  2013    10     1      824            830        -6     1030           1059\n 4  2013    10     1      853            900        -7     1217           1157\n 5  2013    10     1     1328           1330        -2     1543           1553\n 6  2013    10     1     1459           1500        -1     1817           1829\n 7  2013    10     1     1544           1545        -1     1815           1819\n 8  2013    10     1     1754           1800        -6     2102           2103\n 9  2013    10     1     1825           1830        -5     2159           2150\n10  2013    10     1     1841           1840         1     2058           2116\n# ℹ 952 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nIci, toutes les lignes du tableau dont la variable dest est égale à un élément du vecteur c(\"ATL\", \"SEA\") sont retenues. L’utilisation du OU logique peut être source d’erreur. Je préfère donc utiliser %in% qui me semble plus parlant. La fonction identical() nous confirme que les deux façons de faire produisent exactement le même résultat, libre à vous de privilégier la méthode qui vous convient le mieux :\n\nidentical(atl_sea_fall, atl_sea_fall2)\n\n[1] TRUE"
  },
  {
    "objectID": "05-DataWrangling.html#créer-des-résumés-avec-summarise-et-group_by",
    "href": "05-DataWrangling.html#créer-des-résumés-avec-summarise-et-group_by",
    "title": "5  Tripatouiller les données avec dplyr",
    "section": "5.5 Créer des résumés avec summarise() et group_by()",
    "text": "5.5 Créer des résumés avec summarise() et group_by()\n\n5.5.1 Principe de la fonction summarise()\n\n\n\n\n\nFigure 5.4: ?(caption)\n\n\n\n\n\n\n\n\n\nFigure 5.5: Schéma de la fonction summarise() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nLa Figure 5.5 ci-dessus indique comment fonctionne la fonction summarise() : elle prend plusieurs valeurs (potentiellement, un très grand nombre) et les réduit à une unique valeur qui les résume. Lorsque l’on applique cette démarche à plusieurs colonnes d’un tableau, on obtient un tableau qui ne contient plus qu’une unique ligne de résumé.\nLa valeur qui résume les données est choisie par l’utilisateur. Il peut s’agir par exemple d’un calcul de moyenne ou de variance, il peut s’agir de calculer une somme, ou d’extraire la valeur maximale ou minimale, ou encore, il peut tout simplement s’agir de déterminer un nombre d’observations.\nAinsi, pour connaître la température moyenne et l’écart-type des températures dans les aéroports de New York, il suffit d’utiliser le tableau weather et sa variable temp que nous avons déjà utilisés dans les chapitres précédents :\n\nweather |&gt; \n  summarise(moyenne = mean(temp),\n            ecart_type = sd(temp))\n\n# A tibble: 1 × 2\n  moyenne ecart_type\n    &lt;dbl&gt;      &lt;dbl&gt;\n1      NA         NA\n\n\nLes fonctions mean() et sd() permettent de calculer une moyenne et un écart-type respectivement. Ici, les valeurs retournées sont NA car une valeur de température est manquante :\n\nweather |&gt; \n  filter(is.na(temp))\n\n# A tibble: 1 × 15\n  origin  year month   day  hour  temp  dewp humid wind_dir wind_speed wind_gust\n  &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n1 EWR     2013     8    22     9    NA    NA    NA      320       12.7        NA\n# ℹ 4 more variables: precip &lt;dbl&gt;, pressure &lt;dbl&gt;, visib &lt;dbl&gt;,\n#   time_hour &lt;dttm&gt;\n\n\nPour obtenir les valeurs souhaitées, il faut indiquer à R d’exclure les valeurs manquantes lors des calculs de moyennes et écarts-types :\n\nweather |&gt; \n  summarise(moyenne = mean(temp, na.rm = TRUE),\n            ecart_type = sd(temp, na.rm = TRUE))\n\n# A tibble: 1 × 2\n  moyenne ecart_type\n    &lt;dbl&gt;      &lt;dbl&gt;\n1    55.3       17.8\n\n\nLa température moyenne est donc de 55.3 degrés Fahrenheit et l’écart-type vaut 17.8 degrés Fahrenheit.\n\n\n5.5.2 Intérêt de la fonction group_by()\nLa fonction devient particulièrement puissante lorsqu’elle est combinée avec la fonction group_by() :\n\n\n\n\n\nFigure 5.6: Fonctionnement de group_by() travaillant de concert avec summarise(), tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nComme son nom l’indique, la fonction group_by() permet de créer des sous-groupes dans un tableau, afin que le résumé des données soit calculé pour chacun des sous-groupes plutôt que sur l’ensemble du tableau. En ce sens, son fonctionnement est analogue à celui des facets de ggplot2 qui permettent de scinder les données d’un graphique en plusieurs sous-groupes.\nPour revenir à l’exemple des températures, imaginons que nous souhaitions calculer les températures moyennes et les écart-types pour chaque mois de l’année. Voilà comment procéder :\n\nweather |&gt; \n  group_by(month) |&gt; \n  summarise(moyenne = mean(temp, na.rm = TRUE),\n            ecart_type = sd(temp, na.rm = TRUE))\n\n# A tibble: 12 × 3\n   month moyenne ecart_type\n   &lt;int&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n 1     1    35.6      10.2 \n 2     2    34.3       6.98\n 3     3    39.9       6.25\n 4     4    51.7       8.79\n 5     5    61.8       9.68\n 6     6    72.2       7.55\n 7     7    80.1       7.12\n 8     8    74.5       5.19\n 9     9    67.4       8.47\n10    10    60.1       8.85\n11    11    45.0      10.4 \n12    12    38.4       9.98\n\n\nIci, les étapes sont les suivantes :\n\nOn prend le tableau weather, puis…\nOn groupe les données selon la variable month, puis…\nOn résume les données groupées sous la forme de moyennes et d’écart-types.\n\nNous pouvons aller plus loin. Ajoutons à ce résumé 2 variables supplémentaires : le nombre de mesures et l’erreur standard (notée \\(se\\)), qui peut être calculée de la façon suivante :\n\\[se \\approx \\frac{s}{\\sqrt{n}}\\]\navec \\(s\\), l’écart-type de l’échantillon et \\(n\\), la taille de l’échantillon. Cette grandeur est très importante en statistique puisqu’elle nous permet de quantifier l’imprécision de la moyenne. Elle intervient d’ailleurs dans le calcul de l’intervalle de confiance de la moyenne d’un échantillon. Nous allons donc calculer ici ces résumés, et nous donnerons un nom au tableau créé pour pouvoir ré-utiliser ces statistiques descriptives :\n\nmonthly_temp &lt;- weather |&gt; \n  group_by(month) |&gt; \n  summarise(moyenne = mean(temp, na.rm = TRUE),\n            ecart_type = sd(temp, na.rm = TRUE),\n            nb_obs = n(),\n            erreur_std = ecart_type / sqrt(nb_obs))\nmonthly_temp\n\n# A tibble: 12 × 5\n   month moyenne ecart_type nb_obs erreur_std\n   &lt;int&gt;   &lt;dbl&gt;      &lt;dbl&gt;  &lt;int&gt;      &lt;dbl&gt;\n 1     1    35.6      10.2    2226      0.217\n 2     2    34.3       6.98   2010      0.156\n 3     3    39.9       6.25   2227      0.132\n 4     4    51.7       8.79   2159      0.189\n 5     5    61.8       9.68   2232      0.205\n 6     6    72.2       7.55   2160      0.162\n 7     7    80.1       7.12   2228      0.151\n 8     8    74.5       5.19   2217      0.110\n 9     9    67.4       8.47   2159      0.182\n10    10    60.1       8.85   2212      0.188\n11    11    45.0      10.4    2141      0.226\n12    12    38.4       9.98   2144      0.216\n\n\nVous constatez ici que nous avons 4 statistiques descriptives pour chaque mois de l’année. Deux choses sont importantes à retenir ici :\n\nOn peut obtenir le nombre d’observations dans chaque sous-groupe d’un tableau groupé en utilisant la fonction n(). Cette fonction n’a besoin d’aucun argument : elle détermine automatiquement la taille des groupes créés par group_by().\nOn peut créer de nouvelles variables en utilisant le nom de variables créées auparavant. Ainsi, nous avons créé la variable erreur_std en utilisant deux variables créées au préalable : ecart-type et nb_obs.\n\n\n\n5.5.3 Ajouter des barres d’erreurs sur un graphique\nLe tableau monthly_temp que nous venons de créer contient donc les données nécessaires pour nous permettre de visualiser sur un graphique l’évolution des températures moyennes enregistrées dans les 3 aéroports de New York en 2013. Outre les température moyennes, nous devons faire figurer l’imprécision des estimations de moyenne avec des barres d’erreur (à l’aide de la fonction geom_linerange()). Comme expliqué plus haut, l’imprécision des moyennes calculées est estimée grâce à l’erreur standard. Toutefois, ici, les imprécisions sont tellement faibles que les barres d’erreurs resteront invisibles :\n\nmonthly_temp |&gt; \n  ggplot(aes(x = factor(month), y = moyenne, group = 1)) +\n    geom_line() + \n    geom_point() +\n    geom_linerange(aes(ymin = moyenne - erreur_std, \n                       ymax = moyenne + erreur_std),\n                   color = \"red\")\n\n\n\n\nFigure 5.7: Évolution des températures moyennes dans 3 aéroports de New York en 2013.\n\n\n\n\nVous remarquerez que :\n\nJ’associe factor(month), et non simplement month, à l’axe des x afin d’avoir, sur l’axe des abscisses, des chiffres cohérents allant de 1 à 12, et non des chiffres à virgules.\nL’argument group = 1 doit être ajouté pour que la ligne reliant les points apparaisse. En effet, les lignes sont censées relier des points qui appartiennent à une même série temporelle. Or ici, nous avons transformé month en facteur. Préciser group = 1 permet d’indiquer à geom_line() que toutes les catégories du facteur month appartiennent au même groupe, que ce facteur peut être considéré comme une variable continue, et qu’il est donc correct de relier les points.\nLa fonction geom_linerange() contient de nouvelles caractéristiques esthétiques qu’il nous faut obligatoirement renseigner : les extrémités inférieures et supérieures des barres d’erreur. Il nous faut donc associer 2 variables à ces caractéristiques esthétiques. Ici, nous utilisons moyenne - erreur_std pour la borne inférieure des barres d’erreur, et moyenne + erreur_std pour la borne supérieure. Les variables moyenne et erreur_std faisant partie du tableau monthly_temp, geom_linerange() les trouve sans difficulté.\nLes barres d’erreur produites sont minuscules. Je les ai fait apparaître en rouge afin de les rendre visibles, mais même comme cela, il faut zoomer fortement pour les distinguer. Afin de rendre l’utilisation de geom_linerange() plus explicite, je produis ci-dessous un autre graphique en remplaçant les erreurs standard par les écart-types en guise de barres d’erreur. Attention, ce n’est pas correct d’un point de vue statistique ! Les barres d’erreur doivent permettre de visualiser l’imprécision de la moyenne. C’est donc bien les erreurs standard qu’il faut faire figurer en guise de barres d’erreurs et non les écarty-types. Le graphique ci-dessous ne figure donc qu’à titre d’exemple, afin d’illustrer de façon plus parlante le fonctionnement de la fonction geom_linerange() :\n\n\nmonthly_temp |&gt; \n  ggplot(aes(x = factor(month), y = moyenne, group = 1)) +\n    geom_line() + \n    geom_point() +\n    geom_linerange(aes(ymin = moyenne - ecart_type,\n                       ymax = moyenne + ecart_type)) +\n  labs(x = \"Mois\",\n       y = \"Température (ºFahrenheit)\", \n       title = \"Évolution des températures\n                dans 3 aéroports de New York en 2013\",\n       subtitle = \"Attention : les barres d'erreurs sont les écarts-types.\\n\n                   Il faut normalement faire figurer les erreurs standard.\")\n\n\nmonthly_temp |&gt; \n  ggplot(aes(x = factor(month), y = moyenne, group = 1)) +\n    geom_line() + \n    geom_point() +\n    geom_linerange(aes(ymin = moyenne - ecart_type,\n                       ymax = moyenne + ecart_type)) +\n  labs(x = \"Mois\",\n       y = \"Température (ºFahrenheit)\", \n       title = \"Évolution des températures dans 3 aéroports de New York en 2013\",\n       subtitle = \"Attention : les barres d'erreurs sont les écarts-types.\\nIl faut normalement faire figurer les erreurs standard.\")\n\n\n\n\nFigure 5.8: Évolution des températures moyennes dans 3 aéroports de New York en 2013.\n\n\n\n\n\n\n5.5.4 Grouper par plus d’une variable\nJusqu’ici, nous avons groupé les données de température par mois. Il est tout à fait possible de grouper les données par plus d’une variable, par exemple, par mois et par aéroport d’origine :\n\nmonthly_orig_temp &lt;- weather |&gt; \n  group_by(origin, month) |&gt; \n  summarise(moyenne = mean(temp, na.rm = TRUE),\n            ecart_type = sd(temp, na.rm = TRUE),\n            nb_obs = n(),\n            erreur_std = ecart_type / sqrt(nb_obs))\n\n`summarise()` has grouped output by 'origin'. You can override using the\n`.groups` argument.\n\nmonthly_orig_temp\n\n# A tibble: 36 × 6\n# Groups:   origin [3]\n   origin month moyenne ecart_type nb_obs erreur_std\n   &lt;chr&gt;  &lt;int&gt;   &lt;dbl&gt;      &lt;dbl&gt;  &lt;int&gt;      &lt;dbl&gt;\n 1 EWR        1    35.6      10.8     742      0.396\n 2 EWR        2    34.3       7.28    669      0.282\n 3 EWR        3    40.1       6.72    743      0.247\n 4 EWR        4    53.0       9.60    720      0.358\n 5 EWR        5    63.3      10.6     744      0.389\n 6 EWR        6    73.3       8.05    720      0.300\n 7 EWR        7    80.7       7.37    741      0.271\n 8 EWR        8    74.5       5.87    740      0.216\n 9 EWR        9    67.3       9.32    719      0.348\n10 EWR       10    59.8       9.79    736      0.361\n# ℹ 26 more rows\n\n\nEn plus de la variable month, la tableau monthly_orig_temp contient une variable origin. Les statistiques que nous avons calculées plus tôt sont maintenant disponibles pour chaque mois et chacun des 3 aéroports de New York. Nous pouvons utiliser ces données pour comparer les 3 aéroports :\n\nmonthly_orig_temp |&gt; \n  ggplot(aes(x = factor(month), \n             y = moyenne,\n             group = origin,\n             color = origin)) +\n    geom_line() + \n    geom_point() +\n    geom_linerange(aes(ymin = moyenne - ecart_type,\n                       ymax = moyenne + ecart_type)) +\n  labs(x = \"Mois\",\n       y = \"Température (ºFahrenheit)\", \n       title = \"Évolution des températures\n                dans 3 aéroports de New York en 2013\",\n       subtitle = \"Attention : les barres d'erreurs sont les écarts-types.\\n\n                   Il faut normalement faire figurer les erreurs standard.\")\n\n\n\n\n\n\nFigure 5.9: Évolution des températures moyennes dans 3 aéroports de New York en 2013.\n\n\n\n\nNotez que j’utilise maintenant group = origin et non plus group = 1. Ici, les températures des 3 aéroports sont tellement similaires que les courbes sont difficiles à distinguer. Nous pouvons donc utiliser facet_wrap() pour tenter d’améliorer la visualisation :\n\nmonthly_orig_temp |&gt; \n  ggplot(aes(x = factor(month), \n             y = moyenne,\n             group = origin,\n             color = origin)) +\n    geom_line() + \n    geom_point() +\n    geom_linerange(aes(ymin = moyenne - ecart_type,\n                       ymax = moyenne + ecart_type)) +\n  facet_wrap(~origin, ncol = 1) +\n  labs(x = \"Mois\",\n       y = \"Température (ºFahrenheit)\", \n       title = \"Évolution des températures\n                dans 3 aéroports de New York en 2013\",\n       subtitle = \"Attention : les barres d'erreurs sont les écarts-types.\\n\n                   Il faut normalement faire figurer les erreurs standard.\")\n\n\n\n\n\n\nFigure 5.10: Évolution des températures moyennes dans 3 aéroports de New York en 2013.\n\n\n\n\nLorsque nous groupons par plusieurs variables, il peut-être utile d’ajouter l’argument .groups = \"drop\" à la fonction summarise() afin que le tibble obtenu soit un tibble “normal” et non un tibble toujours groupé par une ou plusieurs variables :\n\nmonthly_orig_temp &lt;- weather |&gt; \n  group_by(origin, month) |&gt; \n  summarise(moyenne = mean(temp, na.rm = TRUE),\n            ecart_type = sd(temp, na.rm = TRUE),\n            nb_obs = n(),\n            erreur_std = ecart_type / sqrt(nb_obs),\n            .groups = \"drop\")\nmonthly_orig_temp\n\n# A tibble: 36 × 6\n   origin month moyenne ecart_type nb_obs erreur_std\n   &lt;chr&gt;  &lt;int&gt;   &lt;dbl&gt;      &lt;dbl&gt;  &lt;int&gt;      &lt;dbl&gt;\n 1 EWR        1    35.6      10.8     742      0.396\n 2 EWR        2    34.3       7.28    669      0.282\n 3 EWR        3    40.1       6.72    743      0.247\n 4 EWR        4    53.0       9.60    720      0.358\n 5 EWR        5    63.3      10.6     744      0.389\n 6 EWR        6    73.3       8.05    720      0.300\n 7 EWR        7    80.7       7.37    741      0.271\n 8 EWR        8    74.5       5.87    740      0.216\n 9 EWR        9    67.3       9.32    719      0.348\n10 EWR       10    59.8       9.79    736      0.361\n# ℹ 26 more rows\n\n\nNotez qu’ajouter cet argument permet également de faire disparaître le message d’avertissement qui s’affichait après chaque utilisation de group_by(). C’est donc une bonne habitude d’ajouter cet argument systématiquement dans la fonction summarise() après utilisation de group_by().\nEnfin, lorsque nous groupons par plusieurs variables, il peut être utile de présenter les résultats sous la forme d’un tableau large (grâce à la fonction pivot_wider(), voir Section 4.2.2) pour l’intégration dans un rapport par exemple :\n\nweather |&gt; \n  group_by(origin, month) |&gt; \n  summarise(moyenne = mean(temp, na.rm = TRUE)) |&gt; \n  pivot_wider(names_from = origin, \n              values_from = moyenne)\n\n`summarise()` has grouped output by 'origin'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 12 × 4\n   month   EWR   JFK   LGA\n   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1  35.6  35.4  36.0\n 2     2  34.3  34.2  34.4\n 3     3  40.1  39.5  40.0\n 4     4  53.0  50.1  52.1\n 5     5  63.3  59.3  62.8\n 6     6  73.3  70.0  73.3\n 7     7  80.7  78.7  80.8\n 8     8  74.5  73.8  75.0\n 9     9  67.3  66.9  67.9\n10    10  59.8  59.8  60.6\n11    11  44.6  45.1  45.3\n12    12  38.0  38.6  38.8\n\n\nSous cette forme, les données ne sont plus “rangées”, nous n’avons plus des “tidy data”, mais nous avons un tableau plus synthétique, facile à inclure dans un rapport.\n\n\n5.5.5 Un raccourci pratique pour compter des effectifs\nIl est tellement fréquent d’avoir à grouper des données en fonction d’une variable puis à compter le nombre d’observations dans chaque catégorie avec n() que dplyr nous fournit un raccourci : la fonction count().\nCe code :\n\nweather |&gt; \n  group_by(month) |&gt; \n  summarise(n = n())\n\n# A tibble: 12 × 2\n   month     n\n   &lt;int&gt; &lt;int&gt;\n 1     1  2226\n 2     2  2010\n 3     3  2227\n 4     4  2159\n 5     5  2232\n 6     6  2160\n 7     7  2228\n 8     8  2217\n 9     9  2159\n10    10  2212\n11    11  2141\n12    12  2144\n\n\nest équivalent à celui-ci :\n\nweather |&gt; \n  count(month)\n\n# A tibble: 12 × 2\n   month     n\n   &lt;int&gt; &lt;int&gt;\n 1     1  2226\n 2     2  2010\n 3     3  2227\n 4     4  2159\n 5     5  2232\n 6     6  2160\n 7     7  2228\n 8     8  2217\n 9     9  2159\n10    10  2212\n11    11  2141\n12    12  2144\n\n\nComme avec group_by(), il est bien sûr possible d’utiliser count() avec plusieurs variables :\n\nweather |&gt; \n  group_by(origin, month) |&gt; \n  summarise(nombre = n())\n\n`summarise()` has grouped output by 'origin'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 36 × 3\n# Groups:   origin [3]\n   origin month nombre\n   &lt;chr&gt;  &lt;int&gt;  &lt;int&gt;\n 1 EWR        1    742\n 2 EWR        2    669\n 3 EWR        3    743\n 4 EWR        4    720\n 5 EWR        5    744\n 6 EWR        6    720\n 7 EWR        7    741\n 8 EWR        8    740\n 9 EWR        9    719\n10 EWR       10    736\n# ℹ 26 more rows\n\n\n\n\n5.5.6 Exercices\n\nFaites un tableau indiquant combien de vols ont été annulés après le décollage, pour chaque compagnie aérienne. Vous devriez obtenir le tableau suivant :\n\n\n\n# A tibble: 13 × 2\n   carrier cancelled\n   &lt;chr&gt;       &lt;int&gt;\n 1 9E             71\n 2 AA             34\n 3 B6             32\n 4 DL             15\n 5 EV            105\n 6 F9              1\n 7 FL              6\n 8 MQ             87\n 9 UA             63\n10 US             31\n11 VX              4\n12 WN              8\n13 YV              1\n\n\n\nFaites un tableau indiquant les vitesses de vents minimales, maximales et moyennes, enregistrées chaque mois dans chaque aéroport de New York. Votre tableau devrait ressembler à ceci :\n\n\n\n`summarise()` has grouped output by 'origin'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 36 × 5\n# Groups:   origin [3]\n   origin month max_wind min_wind moy_wind\n   &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 EWR        1     42.6        0     9.87\n 2 EWR        2   1048.         0    12.2 \n 3 EWR        3     29.9        0    11.6 \n 4 EWR        4     25.3        0     9.63\n 5 EWR        5     33.4        0     8.49\n 6 EWR        6     34.5        0     9.55\n 7 EWR        7     20.7        0     9.15\n 8 EWR        8     21.9        0     7.62\n 9 EWR        9     23.0        0     8.03\n10 EWR       10     26.5        0     8.32\n# ℹ 26 more rows\n\n\n\nSachant que les vitesses du vent sont exprimées en miles par heure, certaines valeurs sont-elles surprenantes ? À l’aide de la fonction filter(), éliminez la ou les valeurs aberrantes. Vous devriez obtenir ce tableau :\n\n\n\n`summarise()` has grouped output by 'origin'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 36 × 5\n# Groups:   origin [3]\n   origin month max_wind min_wind moy_wind\n   &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 EWR        1     42.6        0     9.87\n 2 EWR        2     31.1        0    10.7 \n 3 EWR        3     29.9        0    11.6 \n 4 EWR        4     25.3        0     9.63\n 5 EWR        5     33.4        0     8.49\n 6 EWR        6     34.5        0     9.55\n 7 EWR        7     20.7        0     9.15\n 8 EWR        8     21.9        0     7.62\n 9 EWR        9     23.0        0     8.03\n10 EWR       10     26.5        0     8.32\n# ℹ 26 more rows\n\n\n\nEn utilisant les données de vitesse de vent du tableau weather, produisez le graphique suivant :\n\n\n\n\n\n\nFigure 5.11: ?(caption)\n\n\n\n\nIndications :\n\nLes vitesses de vent aberrantes ont été éliminées grâce à la fonction filter().\nLa fonction geom_jitter() a été utilisée avec l’argument height = 0.\nLa transparence des points est fixée à 0.2.\n\nSelon vous, pourquoi les points sont-ils organisés en bandes horizontales ?\nSelon vous, pourquoi n’y a t’il jamais de vent entre 0 et environ 3 miles à l’heure (mph) ?\nSachant qu’en divisant des mph par 1.151 on obtient des vitesses en nœuds, que nous apprend cette commande ?\n\nsort(unique(weather$wind_speed)) / 1.151\n\n [1]   0.000000   2.999427   3.999235   4.999044   5.998853   6.998662\n [7]   7.998471   8.998280   9.998089  10.997897  11.997706  12.997515\n[13]  13.997324  14.997133  15.996942  16.996751  17.996560  18.996368\n[19]  19.996177  20.995986  21.995795  22.995604  23.995413  24.995222\n[25]  25.995030  26.994839  27.994648  28.994457  29.994266  30.994075\n[31]  31.993884  32.993692  33.993501  34.993310  36.992928 910.825873"
  },
  {
    "objectID": "05-DataWrangling.html#sélectionner-des-variables-avec-select",
    "href": "05-DataWrangling.html#sélectionner-des-variables-avec-select",
    "title": "5  Tripatouiller les données avec dplyr",
    "section": "5.6 Sélectionner des variables avec select()",
    "text": "5.6 Sélectionner des variables avec select()\n\n\n\n\n\nFigure 5.12: Schéma de la fonction select() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nIl n’est pas rare de travailler avec des tableaux contenant des centaines, voir des milliers de colonnes. Dans de tels cas, il peut être utile de réduire le jeu de données aux variables qui vous intéressent. Le rôle de la fonction select() est de retenir uniquement les colonnes dont on a spécifié le nom, afin de recentrer l’analyse sur les variables utiles.\nselect() n’est pas particulièrement utile pour le jeu de données flights puisqu’il ne contient que 19 variables. Toutefois, on peut malgré tout comprendre le fonctionnement général. Par exemple, pour sélectionner uniquement les colonnes year, month et day, on tape :\n\n# Sélection de variables par leur nom\nflights |&gt; \n  select(year, month, day)\n\n# A tibble: 336,776 × 3\n    year month   day\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1  2013     1     1\n 2  2013     1     1\n 3  2013     1     1\n 4  2013     1     1\n 5  2013     1     1\n 6  2013     1     1\n 7  2013     1     1\n 8  2013     1     1\n 9  2013     1     1\n10  2013     1     1\n# ℹ 336,766 more rows\n\n\nPuisque ces 3 variables sont placées les unes à côté des autres dans le tableau flights, on peut utiliser la notation “:” pour les sélectionner :\n\n# Sélection de toutes les variables entre `year` et `day` (inclues)\nflights |&gt; \n  select(year:day)\n\n# A tibble: 336,776 × 3\n    year month   day\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1  2013     1     1\n 2  2013     1     1\n 3  2013     1     1\n 4  2013     1     1\n 5  2013     1     1\n 6  2013     1     1\n 7  2013     1     1\n 8  2013     1     1\n 9  2013     1     1\n10  2013     1     1\n# ℹ 336,766 more rows\n\n\nÀ l’inverse, si on veut supprimer certaines colonnes, on peut utiliser la notation “-” :\n\n# Sélection de toutes les variables de `flights` à l'exception\n# de celles comprises entre `year` et `day` (inclues)\nflights |&gt; \n  select(-(year:day))\n\n# A tibble: 336,776 × 16\n   dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay carrier\n      &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;  \n 1      517            515         2      830            819        11 UA     \n 2      533            529         4      850            830        20 UA     \n 3      542            540         2      923            850        33 AA     \n 4      544            545        -1     1004           1022       -18 B6     \n 5      554            600        -6      812            837       -25 DL     \n 6      554            558        -4      740            728        12 UA     \n 7      555            600        -5      913            854        19 B6     \n 8      557            600        -3      709            723       -14 EV     \n 9      557            600        -3      838            846        -8 B6     \n10      558            600        -2      753            745         8 AA     \n# ℹ 336,766 more rows\n# ℹ 9 more variables: flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;,\n#   air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nIl y a beaucoup de fonctions permettant de sélectionner des variables dont les noms respectent certains critères. Par exemple :\n\nstarts_with(\"abc\") : renvoie toutes les variables dont les noms commencent par “abc”.\nends_with(\"xyz\") : renvoie toutes les variables dont les noms se terminent par “xyz”.\ncontains(\"ijk\") : renvoie toutes les variables dont les noms contiennent “ijk”.\n\nIl en existe beaucoup d’autres. Vous pouvez consulter l’aide de ?select() pour en savoir plus.\nPar exemple, il est possible de sélectionner toutes les variables contenant le mot “time” ainsi :\n\nflights |&gt; \n  select(contains(\"time\"))\n\n# A tibble: 336,776 × 6\n   dep_time sched_dep_time arr_time sched_arr_time air_time time_hour          \n      &lt;int&gt;          &lt;int&gt;    &lt;int&gt;          &lt;int&gt;    &lt;dbl&gt; &lt;dttm&gt;             \n 1      517            515      830            819      227 2013-01-01 05:00:00\n 2      533            529      850            830      227 2013-01-01 05:00:00\n 3      542            540      923            850      160 2013-01-01 05:00:00\n 4      544            545     1004           1022      183 2013-01-01 05:00:00\n 5      554            600      812            837      116 2013-01-01 06:00:00\n 6      554            558      740            728      150 2013-01-01 05:00:00\n 7      555            600      913            854      158 2013-01-01 06:00:00\n 8      557            600      709            723       53 2013-01-01 06:00:00\n 9      557            600      838            846      140 2013-01-01 06:00:00\n10      558            600      753            745      138 2013-01-01 06:00:00\n# ℹ 336,766 more rows\n\n\nÉvidemment, le tableau flights n’est pas modifié par cette opération : il contient toujours les 19 variables de départ. Pour travailler avec ces tableaux de données contenant moins de variables, il faut les stocker dans un nouvel objet en leur donnant un nom :\n\nflights_time &lt;- flights |&gt; \n  select(contains(\"time\"))\n\nEnfin, on peut utiliser select() pour renommer des variables. Mais ce n’est que rarement utile car select() élimine toutes les variables qui n’ont pas été explicitement nommées :\n\nflights |&gt; \n  select(year:day,\n         heure_depart = dep_time,\n         retard_depart = dep_delay)\n\n# A tibble: 336,776 × 5\n    year month   day heure_depart retard_depart\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;        &lt;int&gt;         &lt;dbl&gt;\n 1  2013     1     1          517             2\n 2  2013     1     1          533             4\n 3  2013     1     1          542             2\n 4  2013     1     1          544            -1\n 5  2013     1     1          554            -6\n 6  2013     1     1          554            -4\n 7  2013     1     1          555            -5\n 8  2013     1     1          557            -3\n 9  2013     1     1          557            -3\n10  2013     1     1          558            -2\n# ℹ 336,766 more rows\n\n\nIl est donc généralement préférable d’utiliser rename() pour renommer certaines variables sans en éliminer aucune :\n\nflights |&gt; \n  rename(heure_depart = dep_time,\n         retard_depart = dep_delay)\n\n# A tibble: 336,776 × 19\n    year month   day heure_depart sched_dep_time retard_depart arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;        &lt;int&gt;          &lt;int&gt;         &lt;dbl&gt;    &lt;int&gt;\n 1  2013     1     1          517            515             2      830\n 2  2013     1     1          533            529             4      850\n 3  2013     1     1          542            540             2      923\n 4  2013     1     1          544            545            -1     1004\n 5  2013     1     1          554            600            -6      812\n 6  2013     1     1          554            558            -4      740\n 7  2013     1     1          555            600            -5      913\n 8  2013     1     1          557            600            -3      709\n 9  2013     1     1          557            600            -3      838\n10  2013     1     1          558            600            -2      753\n# ℹ 336,766 more rows\n# ℹ 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;,\n#   flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;,\n#   distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "05-DataWrangling.html#sec-mutate",
    "href": "05-DataWrangling.html#sec-mutate",
    "title": "5  Tripatouiller les données avec dplyr",
    "section": "5.7 Créer de nouvelles variables avec mutate()",
    "text": "5.7 Créer de nouvelles variables avec mutate()\n\n5.7.1 Principe\n\n\n\n\n\nFigure 5.13: Schéma de la fonction mutate() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nLa fonction mutate() permet de créer de nouvelles variables à partir des variables existantes, ou de modifier des variables déjà présentes dans un jeu de données. Il est en effet fréquent d’avoir besoin de calculer de nouvelles variables, souvent plus informatives que les variables disponibles.\nVoyons un exemple. Nous commençons par créer un nouveau jeu de données flights_sml en sélectionnant uniquement les variables qui nous seront utiles :\n\nflights_sml &lt;- flights |&gt; \n  select(year:day,\n         ends_with(\"delay\"),\n         distance,\n         air_time)\nflights_sml\n\n# A tibble: 336,776 × 7\n    year month   day dep_delay arr_delay distance air_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1  2013     1     1         2        11     1400      227\n 2  2013     1     1         4        20     1416      227\n 3  2013     1     1         2        33     1089      160\n 4  2013     1     1        -1       -18     1576      183\n 5  2013     1     1        -6       -25      762      116\n 6  2013     1     1        -4        12      719      150\n 7  2013     1     1        -5        19     1065      158\n 8  2013     1     1        -3       -14      229       53\n 9  2013     1     1        -3        -8      944      140\n10  2013     1     1        -2         8      733      138\n# ℹ 336,766 more rows\n\n\nÀ partir de ce nouveau tableau, nous allons calculer 2 nouvelles variables :\n\ngain : afin de savoir si les avions peuvent rattraper une partie de leur retard en vol, nous allons calculer la différence entre le retard au départ et à l’arrivée (donc le gain de temps accumulé lors du vol). En effet, si un avion décolle avec 15 minutes de retard, mais qu’il atterrit avec seulement 5 minutes de retard, 10 minutes ont été gagnées en vol, et les passagers sont moins mécontents.\nspeed afin de connaitre la vitesse moyenne des avions en vol, nous allons diviser la distance parcourue par les avions par le temps passé en l’air. Il ne faudra pas oublier de multiplier par 60 car les temps sont exprimés en minutes. Nous en profiterons pour transformer les distances exprimées en miles par des distances exprimées en kilomètres en multipliant les distances en miles par 1.60934. Ainsi, la variable speed sera exprimée en kilomètres par heure.\n\n\nflights_sml |&gt; \n  mutate(gain = dep_delay - arr_delay,\n         distance = distance * 1.60934,\n         speed = (distance / air_time) * 60)\n\n# A tibble: 336,776 × 9\n    year month   day dep_delay arr_delay distance air_time  gain speed\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  2013     1     1         2        11    2253.      227    -9  596.\n 2  2013     1     1         4        20    2279.      227   -16  602.\n 3  2013     1     1         2        33    1753.      160   -31  657.\n 4  2013     1     1        -1       -18    2536.      183    17  832.\n 5  2013     1     1        -6       -25    1226.      116    19  634.\n 6  2013     1     1        -4        12    1157.      150   -16  463.\n 7  2013     1     1        -5        19    1714.      158   -24  651.\n 8  2013     1     1        -3       -14     369.       53    11  417.\n 9  2013     1     1        -3        -8    1519.      140     5  651.\n10  2013     1     1        -2         8    1180.      138   -10  513.\n# ℹ 336,766 more rows\n\n\nSi on souhaite conserver uniquement les variables nouvellement créées par mutate(), on peut utiliser transmute() :\n\nflights_sml |&gt; \n  transmute(gain = dep_delay - arr_delay,\n         distance = distance * 1.60934,\n         speed = (distance / air_time) * 60)\n\n# A tibble: 336,776 × 3\n    gain distance speed\n   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1    -9    2253.  596.\n 2   -16    2279.  602.\n 3   -31    1753.  657.\n 4    17    2536.  832.\n 5    19    1226.  634.\n 6   -16    1157.  463.\n 7   -24    1714.  651.\n 8    11     369.  417.\n 9     5    1519.  651.\n10   -10    1180.  513.\n# ℹ 336,766 more rows\n\n\nEt comme toujours, pour pouvoir réutiliser ces données, on leur donne un nom :\n\ngain_speed &lt;- flights_sml |&gt; \n  transmute(gain = dep_delay - arr_delay,\n         distance = distance * 1.60934,\n         speed = (distance / air_time) * 60)\n\n\n\n5.7.2 Transformer des variables en facteurs\nIl n’est pas rare que les tableaux de données que nous importons contiennent des colonnes numériques ou de chaînes de caractères qui devraient en réalité être reconnues en tant que facteurs. La fonction mutate() nous permet de changer rapidement le type d’une variable afin qu’elle soit reconnue comme un facteur.\nÀ titre d’exemple, nous allons importer le jeu de données contenu dans le fichier squid.txt que vous pourrez télécharger ici. Placez-le dans votre répertoire de travail et utilisez la méthode décrite à la Section 4.3.3 pour obtenir la commande suivante :\n\nlibrary(readr)\nsquid &lt;- read_delim(\"squid.txt\", \"\\t\", \n    escape_double = FALSE, trim_ws = TRUE)\nsquid\n\n\n\n# A tibble: 2,644 × 6\n   Sample  Year Month Location   Sex   GSI\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1      1     1     1        1     2 10.4 \n 2      2     1     1        3     2  9.83\n 3      3     1     1        1     2  9.74\n 4      4     1     1        1     2  9.31\n 5      5     1     1        1     2  8.99\n 6      6     1     1        1     2  8.77\n 7      7     1     1        1     2  8.26\n 8      8     1     1        3     2  7.40\n 9      9     1     1        3     2  7.22\n10     10     1     2        1     2  6.84\n# ℹ 2,634 more rows\n\n\nCe jeu de données contient des informations sur l’Indice Gonado-Somatique (GSI) de 2644 pieuvres collectées dans 4 stations d’échantillonnage sur une période de 2 ans. La variable Location est codée sous forme d’entiers, or il devrait s’agir d’un facteur. La fonction mutate() nous permet d’effectuer la transformation :\n\nsquid |&gt; \n  mutate(Location = factor(Location))\n\n# A tibble: 2,644 × 6\n   Sample  Year Month Location   Sex   GSI\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1      1     1     1 1            2 10.4 \n 2      2     1     1 3            2  9.83\n 3      3     1     1 1            2  9.74\n 4      4     1     1 1            2  9.31\n 5      5     1     1 1            2  8.99\n 6      6     1     1 1            2  8.77\n 7      7     1     1 1            2  8.26\n 8      8     1     1 3            2  7.40\n 9      9     1     1 3            2  7.22\n10     10     1     2 1            2  6.84\n# ℹ 2,634 more rows\n\n\nDe même, la variable Sex est codée sous forme numérique, or il devrait s’agir d’un facteur, les “1” correspondants aux mâles et les “2” aux femelles. Nous pouvons là encore faire la modification grâce à la fonction mutate() :\n\nsquid2 &lt;- squid |&gt; \n  mutate(Location = factor(Location),\n         Sex = factor(Sex, levels = c(1, 2), labels = c(\"Male\", \"Female\")))\n\nsquid2\n\n# A tibble: 2,644 × 6\n   Sample  Year Month Location Sex      GSI\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;\n 1      1     1     1 1        Female 10.4 \n 2      2     1     1 3        Female  9.83\n 3      3     1     1 1        Female  9.74\n 4      4     1     1 1        Female  9.31\n 5      5     1     1 1        Female  8.99\n 6      6     1     1 1        Female  8.77\n 7      7     1     1 1        Female  8.26\n 8      8     1     1 3        Female  7.40\n 9      9     1     1 3        Female  7.22\n10     10     1     2 1        Female  6.84\n# ℹ 2,634 more rows\n\n\nsquid2 contient maintenant le tableau de départ avec les variables Location et Sex codées sous forme de facteurs. Si nous faisons un graphique avec ces nouveaux facteurs, l’ordre des catégories sera celui spécifié par la fonction factor(). Ainsi, si nous faisons par exemple un boxplot de GSI en fonction du Sex, voilà ce que nous obtenons :\n\nsquid2 |&gt; \n  ggplot(aes(x = Sex, y = GSI)) +\n    geom_boxplot(notch = TRUE)\n\n\n\n\nIndice Gonado Somatique selon le sexe.\n\n\n\n\nComment faire pour inverser l’ordre des catégories sur l’axe des abscisses ? Il faut inverser l’ordre des catégories dans le facteur Sex. L’ordre dans lequel les catégories apparaissent sur un graphique est en effet déterminé par l’ordre dans lequel les niveaux du facteur sont organisés. D’habitude, les niveaux sont automatiquement triés par ordre alphabétique quand les catégories sont des chaînes de caractères, et en ordre croissant quand la variable est numérique. Ici les niveaux sont les suivants :\n\nlevels(squid2$Sex)\n\n[1] \"Male\"   \"Female\"\n\n\nMale apparaît avant Female, car les niveaux de départ étaient 1 pour les mâles et 2 pour les femelles. C’est donc cet ordre qui est conservé. Le package forcats fournit de nombreuses fonctions permettant de manipuler les facteurs. Toutes commencent par fct_. Nous pouvons ici utiliser fct_rev() pour inverser l’ordre des niveaux. Pensez à installer et charger forcats si ce n’est pas déjà fait. Si vous avez chargé le tidyverse, forcats est déjà disponible :\n\nlibrary(forcats)\nsquid3 &lt;- squid2 |&gt; \n  mutate(Sex = fct_rev(Sex))\n\nlevels(squid3$Sex)\n\n[1] \"Female\" \"Male\"  \n\n\n\nsquid3 |&gt; \n  ggplot(aes(x = Sex, y = GSI)) +\n    geom_boxplot(notch = TRUE)\n\n\n\n\nIndice Gonado Somatique selon le sexe.\n\n\n\n\nRevenons maintenant au jeu de données dauphin.\n\ndauphin\n\n# A tibble: 93 × 9\n   ID        Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n 1 Numéro 1  f     imm       315     3  29.6   3.24 NA    rein  \n 2 Numéro 2  f     imm       357     4  55.1   4.42 NA    rein  \n 3 Numéro 3  f     pnl       439    34 129.    5.01  9.02 rein  \n 4 Numéro 4  f     imm       316     4  71.2   4.33 NA    rein  \n 5 Numéro 5  f     l         435    26 192     5.15 NA    rein  \n 6 Numéro 6  f     pnl       388     6  NA     4.12  4.53 rein  \n 7 Numéro 7  f     mat       410    NA  76     5.1  33.9  foie  \n 8 Numéro 8  m     imm       355    NA  74.4   4.72 13.3  foie  \n 9 Numéro 9  m     imm       222    NA   0.09  9.5   2.89 foie  \n10 Numéro 10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nCommençons par supprimer la variable ID, qui est totalement redondante avec les numéros de ligne :\n\ndauphin &lt;- dauphin |&gt; \n  select(-ID)\ndauphin\n\n# A tibble: 93 × 8\n   Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n 1 f     imm       315     3  29.6   3.24 NA    rein  \n 2 f     imm       357     4  55.1   4.42 NA    rein  \n 3 f     pnl       439    34 129.    5.01  9.02 rein  \n 4 f     imm       316     4  71.2   4.33 NA    rein  \n 5 f     l         435    26 192     5.15 NA    rein  \n 6 f     pnl       388     6  NA     4.12  4.53 rein  \n 7 f     mat       410    NA  76     5.1  33.9  foie  \n 8 m     imm       355    NA  74.4   4.72 13.3  foie  \n 9 m     imm       222    NA   0.09  9.5   2.89 foie  \n10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nLes variables Sexe, Statut et Organe devraient elles aussi être encodées sous forme de facteurs. Plutôt que de taper le code ci dessous (qui fonctionne très bien) :\n\ndauphin |&gt; \n  mutate(Sexe = factor(Sexe),\n         Statut = factor(Statut),\n         Organe = factor(Organe))\n\nNous pouvons utiliser la fonction mutate_if(), qui appliquera la même fonction à toutes les variables respectant une condition précise. Ici, toutes les colonnes possédant le type &lt;chr&gt; sont des colonnes que nous souhaitons transformer en facteur. Nous pouvons donc taper ceci :\n\ndauphin &lt;- dauphin |&gt; \n  mutate_if(is.character, as.factor)\ndauphin\n\n# A tibble: 93 × 8\n   Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;fct&gt; &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; \n 1 f     imm       315     3  29.6   3.24 NA    rein  \n 2 f     imm       357     4  55.1   4.42 NA    rein  \n 3 f     pnl       439    34 129.    5.01  9.02 rein  \n 4 f     imm       316     4  71.2   4.33 NA    rein  \n 5 f     l         435    26 192     5.15 NA    rein  \n 6 f     pnl       388     6  NA     4.12  4.53 rein  \n 7 f     mat       410    NA  76     5.1  33.9  foie  \n 8 m     imm       355    NA  74.4   4.72 13.3  foie  \n 9 m     imm       222    NA   0.09  9.5   2.89 foie  \n10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nNous constatons ici que nos 3 variables catégorielles ont bien été transformées en facteurs (et seulement ces variables).\nNous allons encore réaliser 2 modifications :\n\nNous allons transformer les niveaux f et m du facteur Sexe en Female et Male respectivement.\nNous allons réordonner les niveaux du facteur Statut. Actuellement, les niveaux de ce facteur sont les suivants :\n\n\nlevels(dauphin$Statut)\n\n[1] \"imm\"   \"l\"     \"mat\"   \"pl\"    \"pnl\"   \"repos\"\n\n\nOr il exsite un ordre des statuts reproducteurs qui reflète une progression biologique : imm (immature), mat (mature), pnl (pregnant non lactating), l (lactating), pl (pregnant lactating), repos (repos somatique).\nCommençons par changer les niveaux du facteur Sexe. Pour cela, nous pouvons utiliser la fonction fct_recode() :\n\ndauphin |&gt; \n  mutate(Sexe = fct_recode(Sexe, \n                           \"Female\" = \"f\",\n                           \"Male\" = \"m\"))\n\n# A tibble: 93 × 8\n   Sexe   Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;fct&gt;  &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; \n 1 Female imm       315     3  29.6   3.24 NA    rein  \n 2 Female imm       357     4  55.1   4.42 NA    rein  \n 3 Female pnl       439    34 129.    5.01  9.02 rein  \n 4 Female imm       316     4  71.2   4.33 NA    rein  \n 5 Female l         435    26 192     5.15 NA    rein  \n 6 Female pnl       388     6  NA     4.12  4.53 rein  \n 7 Female mat       410    NA  76     5.1  33.9  foie  \n 8 Male   imm       355    NA  74.4   4.72 13.3  foie  \n 9 Male   imm       222    NA   0.09  9.5   2.89 foie  \n10 Male   imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nNous pouvons maintenant modifier l’ordre des niveaux de Satut avec la fonction fct_relevel() :\n\ndauphin &lt;- dauphin |&gt; \n  mutate(Sexe = fct_recode(Sexe, \n                           \"Female\" = \"f\",\n                           \"Male\" = \"m\"),\n         Statut = fct_relevel(Statut,\n                              \"imm\", \"mat\", \"pnl\", \"l\", \"pl\", \"repos\"))\ndauphin\n\n# A tibble: 93 × 8\n   Sexe   Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;fct&gt;  &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; \n 1 Female imm       315     3  29.6   3.24 NA    rein  \n 2 Female imm       357     4  55.1   4.42 NA    rein  \n 3 Female pnl       439    34 129.    5.01  9.02 rein  \n 4 Female imm       316     4  71.2   4.33 NA    rein  \n 5 Female l         435    26 192     5.15 NA    rein  \n 6 Female pnl       388     6  NA     4.12  4.53 rein  \n 7 Female mat       410    NA  76     5.1  33.9  foie  \n 8 Male   imm       355    NA  74.4   4.72 13.3  foie  \n 9 Male   imm       222    NA   0.09  9.5   2.89 foie  \n10 Male   imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\nlevels(dauphin$Statut)\n\n[1] \"imm\"   \"mat\"   \"pnl\"   \"l\"     \"pl\"    \"repos\"\n\n\nToutes les transformations que nous avons fait subir à ce jeu de données n’ont qu’un seul objectif : “ranger” ce jeu de données. Nous avons importé dauphin depuis un fichier externe, puis nous avons supprimé les variables inutiles et modifié celles qui devaient l’être. Toutes ces étapes peuvent être enchaînées grâce au pipe, de la façon suivante :\n\n# Importation et mise en forme du jeu de données `dauphin`\nlibrary(readxl)\ndauphin &lt;- read_excel(\"data/dauphin.xls\", \n                      na = \"*\", skip = 9) |&gt;   # Importer, puis\n  rename(ID = `N°`,                 # Raccourcir les noms, puis\n         Statut = `Statut reproducteur`,\n         Taille = `Taille en cm`,\n         Age = `Age en années`,\n         Cd = `Cd (mg.kg-1)`,\n         Cu = `Cu (mg.kg-1)`,\n         Hg = `Hg (mg.kg-1)`) |&gt; \n  select(-ID) |&gt;                   # Supprimer la variable `ID`, puis\n  mutate_if(is.character,           # 'Factoriser' les variables &lt;chr&gt;, puis\n            as.factor) |&gt;          \n  mutate(Sexe = fct_recode(Sexe,    # Modifier l'ordre des niveaux\n                           \"Female\" = \"f\",\n                           \"Male\" = \"m\"),\n         Statut = fct_relevel(Statut,\n                              \"imm\", \"mat\", \"pnl\", \"l\", \"pl\", \"repos\"))\n\ndauphin\n\n# A tibble: 93 × 8\n   Sexe   Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;fct&gt;  &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; \n 1 Female imm       315     3  29.6   3.24 NA    rein  \n 2 Female imm       357     4  55.1   4.42 NA    rein  \n 3 Female pnl       439    34 129.    5.01  9.02 rein  \n 4 Female imm       316     4  71.2   4.33 NA    rein  \n 5 Female l         435    26 192     5.15 NA    rein  \n 6 Female pnl       388     6  NA     4.12  4.53 rein  \n 7 Female mat       410    NA  76     5.1  33.9  foie  \n 8 Male   imm       355    NA  74.4   4.72 13.3  foie  \n 9 Male   imm       222    NA   0.09  9.5   2.89 foie  \n10 Male   imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nOutre les fonctions fct_rev(), fct_recode() et fct_relevel() abordées ici, on peut aussi noter :\n\nfct_reorder() et fct_reorder2(), pour ordonner automatiquement les niveaux d’un facteur en fonction d’une autre variable numérique (pour avoir par exemple des séries rangées par ordre de moyennes croissantes sur un graphique).\nfct_infreq(), pour ordonner automatiquement les niveaux d’un facteur par ordre de fréquence croissante, ce qui est notamment utile pour faire des barplots ordonnés.\nfct_collapse(), pour fusionner deux ou plusieurs niveaux d’un facteur.\n\nNous n’avons pas le temps de développer ici des exemples pour chacune de ces fonctions, mais sachez que ces fonctions existent. Vous trouverez des exemples détaillés dans le chapitre consacré aux facteurs de l’ouvrage en ligne R for Data Science. C’est en anglais, mais les exemples sont très parlants. N’hésitez pas à consulter cet ouvrage et à faire des essais de mise en application avec les jeux de données vus ici (e.g. dauphin ou squid).\n\n\n5.7.3 Exercices\n\nDans ggplot2 le jeu de données mpg contient des informations sur 234 modèles de voitures. Examinez ce jeu de données avec la fonction View() et consultez l’aide de ce jeu de données pour savoir à quoi correspondent les différentes variables. Quelle(s) variable(s) nous renseignent sur la consommation des véhicules ? À quoi correspond la variable disp ?\nLa consommation sur autoroute est donnée en miles par gallon. Créez une nouvelle variable conso qui contiendra la consommation sur autoroute exprimée en nombre de litres pour 100 kilomètres.\nFaites un graphique présentant la relation entre la cylindrée en litres et la consommation sur autoroute exprimée en nombre de litres pour 100 kilomètres. Vous excluerez de ce graphique les véhicules dont la classe est 2seater (il s’agit de voitures de sports très compactes qu’il est difficile de mesurer aux autres). Sur votre graphique, la couleur devrait représenter le type de véhicule. Vous ajouterez une droite de régression en utilisant geom_smooth(method = \"lm\"). Votre graphique devrait ressembler à ceci :\n\n\n\n\n\n\nFigure 5.14: Consommation en fonction de la cylindrée\n\n\n\n\n\nCe graphique présente-t-il correctement l’ensemble des données de ces 2 variables ? Pourquoi ? Comparez la Figure 5.14 de la question 3 ci-dessus et la Figure 5.15 présentée ci-dessous. Selon vous, quels arguments et/ou fonctions ont été modifiés pour arriver à ce nouveau graphique ? Quels sont les avantages et les inconvénients de ce graphique par rapport au précédent ?\n\n\n\n\n\n\nFigure 5.15: Consommation en fonction de la cylindrée"
  },
  {
    "objectID": "05-DataWrangling.html#sec-arrange",
    "href": "05-DataWrangling.html#sec-arrange",
    "title": "5  Tripatouiller les données avec dplyr",
    "section": "5.8 Trier des lignes avec arrange()",
    "text": "5.8 Trier des lignes avec arrange()\n\n\n\n\n\nFigure 5.16: Schéma de la fonction arrange() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nLa fonction arrange() permet de trier des tableaux en ordonnant les éléments d’une ou plusieurs colonnes. Les tris peuvent être en ordre croissants (c’est le cas par défaut) ou décroissants (grâce à la fonction desc(), abréviation de “descending”).\narrange() fonctionne donc comme filter(), mais au lieu de sélectionner des lignes, cette fonction change leur ordre. Il faut lui fournir le nom d’un tableau et au minimum le nom d’une variable selon laquelle le tri doit être réalisé. Si plusieurs variables sont fournies, chaque variable supplémentaire permet de résoudre les égalités. Ainsi, pour ordonner le tableau flights par ordre croissant de retard au départ (dep_delay), on tape :\n\nflights |&gt; \n  arrange(dep_delay)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013    12     7     2040           2123       -43       40           2352\n 2  2013     2     3     2022           2055       -33     2240           2338\n 3  2013    11    10     1408           1440       -32     1549           1559\n 4  2013     1    11     1900           1930       -30     2233           2243\n 5  2013     1    29     1703           1730       -27     1947           1957\n 6  2013     8     9      729            755       -26     1002            955\n 7  2013    10    23     1907           1932       -25     2143           2143\n 8  2013     3    30     2030           2055       -25     2213           2250\n 9  2013     3     2     1431           1455       -24     1601           1631\n10  2013     5     5      934            958       -24     1225           1309\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nNotez que la variable dep-delay est maintenant triée en ordre croissant. Notez également que 2 vols ont eu exactement 25 minutes d’avance. Comparez le tableau précédent avec celui-ci :\n\nflights |&gt; \n  arrange(dep_delay, month, day)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013    12     7     2040           2123       -43       40           2352\n 2  2013     2     3     2022           2055       -33     2240           2338\n 3  2013    11    10     1408           1440       -32     1549           1559\n 4  2013     1    11     1900           1930       -30     2233           2243\n 5  2013     1    29     1703           1730       -27     1947           1957\n 6  2013     8     9      729            755       -26     1002            955\n 7  2013     3    30     2030           2055       -25     2213           2250\n 8  2013    10    23     1907           1932       -25     2143           2143\n 9  2013     3     2     1431           1455       -24     1601           1631\n10  2013     5     5      934            958       -24     1225           1309\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nLes lignes des 2 vols ayant 25 minutes d’avance au décollage ont été inversées : le vol du mois de mars apparaît maintenant avant le vol du mois d’octobre. La variable month a été utilisée pour ordonner les lignes en cas d’égalité de la variable dep_delay.\nComme indiqué plus haut, il est possible de trier les données par ordre décroissant :\n\nflights |&gt; \n  arrange(desc(dep_delay))\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     9      641            900      1301     1242           1530\n 2  2013     6    15     1432           1935      1137     1607           2120\n 3  2013     1    10     1121           1635      1126     1239           1810\n 4  2013     9    20     1139           1845      1014     1457           2210\n 5  2013     7    22      845           1600      1005     1044           1815\n 6  2013     4    10     1100           1900       960     1342           2211\n 7  2013     3    17     2321            810       911      135           1020\n 8  2013     6    27      959           1900       899     1236           2226\n 9  2013     7    22     2257            759       898      121           1026\n10  2013    12     5      756           1700       896     1058           2020\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nCela est particulièrement utile après l’obtention de résumés groupés pour connaître la catégorie la plus représentée. Par exemple, si nous souhaitons connaître les destinations les plus fréquentes au départ de New York, on peut procéder ainsi :\n\nPrendre le tableau flights, puis…\nGrouper les données par destination (variable dest) et compter le nombre de vols. Ces deux opérations peuvent être effectuées avec group_by() puis summarise(), ou directement avec count(). Puis…\nTrier les données par effectif décroissant.\n\n\nflights |&gt; \n  count(dest) |&gt; \n  arrange(desc(n))\n\n# A tibble: 105 × 2\n   dest      n\n   &lt;chr&gt; &lt;int&gt;\n 1 ORD   17283\n 2 ATL   17215\n 3 LAX   16174\n 4 BOS   15508\n 5 MCO   14082\n 6 CLT   14064\n 7 SFO   13331\n 8 FLL   12055\n 9 MIA   11728\n10 DCA    9705\n# ℹ 95 more rows\n\n\nNous voyons ici que les aéroports ORD et ATL sont les 2 destinations les plus fréquentes, avec plus de 17000 vols par an."
  },
  {
    "objectID": "05-DataWrangling.html#associer-plusieurs-tableaux-avec-left_join-et-inner_join",
    "href": "05-DataWrangling.html#associer-plusieurs-tableaux-avec-left_join-et-inner_join",
    "title": "5  Tripatouiller les données avec dplyr",
    "section": "5.9 Associer plusieurs tableaux avec left_join() et inner_join()",
    "text": "5.9 Associer plusieurs tableaux avec left_join() et inner_join()\n\n5.9.1 Principe\nUne autre règle que nous n’avons pas encore évoquée au sujet des “tidy data” ou “données rangées” est la suivante :\n\nChaque tableau contient des données appartenant à une unité d’observation cohérente et unique.\n\nAutrement dit, les informations concernant les vols vont dans un tableau, les informations concernant les aéroports dans un autre tableau, et celles concernant les avions dans un troisième tableau. Cela semble évident, pourtant, on constate souvent qu’un même tableau contient des variables qui concernent des unités d’observations différentes.\nLorsque nous avons plusieurs tableaux à disposition, il peut alors être nécessaire de récuppérer des informations dans plusieurs d’entre eux afin, notamment de produire des tableaux de synthèse. Par exemple, dans la Section 5.8 ci-dessus, nous avons affiché les destinations les plus fréquentes au départ des aéroports de New York. Donnons un nom à ce tableau pour pouvoir le ré-utiliser :\n\npopular_dest &lt;- flights |&gt; \n  count(dest) |&gt; \n  arrange(desc(n))\npopular_dest\n\n# A tibble: 105 × 2\n   dest      n\n   &lt;chr&gt; &lt;int&gt;\n 1 ORD   17283\n 2 ATL   17215\n 3 LAX   16174\n 4 BOS   15508\n 5 MCO   14082\n 6 CLT   14064\n 7 SFO   13331\n 8 FLL   12055\n 9 MIA   11728\n10 DCA    9705\n# ℹ 95 more rows\n\n\nÀ quel aéroport correspondent les codes ORD et ATL ? S’agit-il d’Orlando et Atlanta ? Pour le savoir, il faut aller chercher l’information qui se trouve dans le tableau airports : il contient, parmi d’autres variables, les codes et les noms de 1458 aéroports aux État-Unis.\ndplyr fournit toute une gamme de fonctions permettant d’effectuer des associations de tableaux en fonction de critères spécifiés par l’utilisateur.\n\n\n5.9.2 inner_join()\n\n\n\n\n\nFigure 5.17: Schéma de la fonction inner_join() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nLa fonction inner_join() permet de relier deux tableaux en ne conservant que les lignes qui sont présentes à la fois dans l’un et dans l’autre. Il faut identifier, dans chacun des tableaux, une colonne contenant des données en commun, qui servira de guide pour mettre les lignes correctes les unes en face des autres. Ici, nous partons de notre tableau popular_dest, qui contient les codes des aéroports dans sa colonne dest, et nous faisons une “jointure interne” avec le tableau airports qui contient lui aussi une colonne contenant les codes des aéroports : la variable faa.\n\ninner_popular &lt;- popular_dest |&gt; \n  inner_join(airports, by = join_by(dest == faa))\ninner_popular\n\n# A tibble: 101 × 9\n   dest      n name                           lat    lon   alt    tz dst   tzone\n   &lt;chr&gt; &lt;int&gt; &lt;chr&gt;                        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n 1 ORD   17283 Chicago Ohare Intl            42.0  -87.9   668    -6 A     Amer…\n 2 ATL   17215 Hartsfield Jackson Atlanta …  33.6  -84.4  1026    -5 A     Amer…\n 3 LAX   16174 Los Angeles Intl              33.9 -118.    126    -8 A     Amer…\n 4 BOS   15508 General Edward Lawrence Log…  42.4  -71.0    19    -5 A     Amer…\n 5 MCO   14082 Orlando Intl                  28.4  -81.3    96    -5 A     Amer…\n 6 CLT   14064 Charlotte Douglas Intl        35.2  -80.9   748    -5 A     Amer…\n 7 SFO   13331 San Francisco Intl            37.6 -122.     13    -8 A     Amer…\n 8 FLL   12055 Fort Lauderdale Hollywood I…  26.1  -80.2     9    -5 A     Amer…\n 9 MIA   11728 Miami Intl                    25.8  -80.3     8    -5 A     Amer…\n10 DCA    9705 Ronald Reagan Washington Na…  38.9  -77.0    15    -5 A     Amer…\n# ℹ 91 more rows\n\n\nLe nouvel objet inner_popular contient donc les données du tableau popular_dest auxquelles ont été ajoutées les colonnes correspondantes du tableau airports. Si tout ce qui nous intéresse, c’est de connaître le nom complet des aéroports les plus populaires, on peut utiliser select() pour ne garder que les variables intéressantes :\n\ninner_popular &lt;- popular_dest |&gt; \n  inner_join(airports, by = join_by(dest == faa)) |&gt; \n  select(dest, name, n)\ninner_popular\n\n# A tibble: 101 × 3\n   dest  name                                   n\n   &lt;chr&gt; &lt;chr&gt;                              &lt;int&gt;\n 1 ORD   Chicago Ohare Intl                 17283\n 2 ATL   Hartsfield Jackson Atlanta Intl    17215\n 3 LAX   Los Angeles Intl                   16174\n 4 BOS   General Edward Lawrence Logan Intl 15508\n 5 MCO   Orlando Intl                       14082\n 6 CLT   Charlotte Douglas Intl             14064\n 7 SFO   San Francisco Intl                 13331\n 8 FLL   Fort Lauderdale Hollywood Intl     12055\n 9 MIA   Miami Intl                         11728\n10 DCA   Ronald Reagan Washington Natl       9705\n# ℹ 91 more rows\n\n\nOn peut noter plusieurs choses dans ce nouveau tableau :\n\nORD n’est pas l’aéroport d’Orlando mais l’aéroport international de Chicago Ohare. C’est donc la destination la plus fréquente au départ de New York.\nATL est bien l’aéroport d’Atlanta.\ninner_popular contient 101 lignes alors que notre tableau de départ en contenait 105.\n\n\nnrow(popular_dest)\n\n[1] 105\n\nnrow(inner_popular)\n\n[1] 101\n\n\nCertaines lignes ont donc été supprimées car le code aéroport dans popular_dest (notre tableau de départ) n’a pas été retrouvé dans la colonne faa du tableau airports. C’est le principe même de la jointure interne (voir Figure 5.17) : seules les lignes communes trouvées dans les 2 tableaux sont conservées. Si l’on souhaite absolument conserver toutes les lignes du tableau de départ, il faut faire une jointure gauche, ou “left join”.\n\n\n5.9.3 left_join()\n\n\n\n\n\nFigure 5.18: Schéma de la fonction left_join() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nComme indiqué par la Figure 5.18 ci-dessus, une jointure gauche permet de conserver toutes les lignes du tableau de gauche, et de leur faire correspondre des lignes du second tableau. Si aucune correspondance n’est trouvée dans le second tableau, des données manquantes sont ajoutées sous forme de NAs. Voyons ce que cela donne avec le même exemple que précédemment :\n\nleft_popular &lt;- popular_dest |&gt; \n  left_join(airports, by = join_by(dest == faa)) |&gt; \n  select(dest, name, n)\nleft_popular\n\n# A tibble: 105 × 3\n   dest  name                                   n\n   &lt;chr&gt; &lt;chr&gt;                              &lt;int&gt;\n 1 ORD   Chicago Ohare Intl                 17283\n 2 ATL   Hartsfield Jackson Atlanta Intl    17215\n 3 LAX   Los Angeles Intl                   16174\n 4 BOS   General Edward Lawrence Logan Intl 15508\n 5 MCO   Orlando Intl                       14082\n 6 CLT   Charlotte Douglas Intl             14064\n 7 SFO   San Francisco Intl                 13331\n 8 FLL   Fort Lauderdale Hollywood Intl     12055\n 9 MIA   Miami Intl                         11728\n10 DCA   Ronald Reagan Washington Natl       9705\n# ℹ 95 more rows\n\n\nEn apparence, le tableau left_popular, créé avec left_join() semble identique au tableau inner_popular créé avec inner_join(). Pourtant, ce n’est pas le cas :\n\nidentical(inner_popular, left_popular)\n\n[1] FALSE\n\n\nEn l’occurence, nous avons vu que inner_popular ne contenait pas autant de ligne que le tableau de départ popular_dest. Avec une jointure gauche, les lignes du tableau de départ sont toutes conservées. popular_dest et left_popular ont donc le même nombre de lignes.\n\nnrow(inner_popular)\n\n[1] 101\n\nnrow(left_popular)\n\n[1] 105\n\nnrow(popular_dest)\n\n[1] 105\n\n\nPour savoir quelles lignes de popular_dest manquent dans inner_dest (il devrait y en avoir 4), il suffit de filtrer les lignes de left_dest qui contiennent des données manquantes dans la colonne name :\n\nleft_popular |&gt; \n  filter(is.na(name))\n\n# A tibble: 4 × 3\n  dest  name      n\n  &lt;chr&gt; &lt;chr&gt; &lt;int&gt;\n1 SJU   &lt;NA&gt;   5819\n2 BQN   &lt;NA&gt;    896\n3 STT   &lt;NA&gt;    522\n4 PSE   &lt;NA&gt;    365\n\n\nUne rapide recherche sur internet vous apprendra que ces aéroports ne sont pas situés sur le sol américain. Trois d’entre eux sont situés à Puerto Rico (SJU, BQN et PSE) et le dernier (STT) est situé aux Îles Vierges.\nIl y aurait bien plus à dire sur les jointures :\n\nQuelles sont les autres possibilités de jointures (right_join(), outer_join(), full_join(), etc…) ?\nQue se passe-t’il si les colonnes communes des 2 tableaux contiennent des élements dupliqués ?\nEst-il toujours nécessaire d’utiliser l’argument by ?\nEst-il possible de joindre des tableaux en associant plus d’une colonne de chaque tableau d’origine ?\n\nPour avoir la réponse à toutes ces questions, je vous conseille de lire ce chapitre de cet ouvrage très complet sur “la science des données” avec R et le tidyverse : R for Data Science. Les deux fonctions inner_join() et left_join() décrites ici devraient néanmoins vous permettre de couvrir l’essentiel de vos besoins.\n\n\n5.9.4 Accoler deux tableaux\nOutre l’association de tableaux en utilisant des jointures, il est parfois utile d’accoler 2 tableaux :\n\nSoit l’un au-dessous de l’autre, quand ils ont les mêmes nombres de colonnes, et si possible, les mêmes variables aux mêmes endroits. La fonction bind_rows() permet de faire cela.\nSoit l’un à côté de l’autre quand ils ont le même nombre de lignes, et si possible les mêmes observations en lignes. La fonction bind_cols() permet de faire cela.\n\nPrenons un exemple. Imaginons que nous ayons 2 tableaux contenant les mêmes variables. Le premier, nommé colorado, contient les informations des vols ayant décollé de New York en 2013 et ayant atterri à l’aéroport de Yempa Valley au Colorado (aéroport HDN).\n\ncolorado &lt;- flights |&gt; \n  filter(dest == \"HDN\")\n\ncolorado\n\n# A tibble: 15 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     5      829            830        -1     1047           1111\n 2  2013     1    12      827            830        -3     1112           1111\n 3  2013     1    19      843            830        13     1123           1111\n 4  2013     1    26      828            830        -2     1114           1111\n 5  2013    12    21      916            830        46     1149           1117\n 6  2013    12    28      913            829        44     1128           1116\n 7  2013     2     2      858            830        28     1124           1111\n 8  2013     2     9       NA            830        NA       NA           1111\n 9  2013     2    16      834            830         4     1114           1111\n10  2013     2    23      826            830        -4     1050           1111\n11  2013     3     2      854            830        24     1104           1111\n12  2013     3     9      838            830         8     1107           1111\n13  2013     3    16      845            830        15     1154           1111\n14  2013     3    23      835            830         5     1104           1111\n15  2013     3    30      825            830        -5     1045           1111\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nLe second est nommé indiana. Il contient les informations des vols ayant décollé de New York en 2013 et ayant atterri à l’aéroport de South Bend en Indiana (aéroport SBN).\n\nindiana &lt;- flights |&gt; \n  filter(dest == \"SBN\")\n\nindiana\n\n# A tibble: 10 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013    10    18     1820           1745        35     2030           2011\n 2  2013    11     1     2012           1905        67     2221           2131\n 3  2013    11    22     2013           1905        68     2224           2131\n 4  2013    12     1     1241           1215        26     1431           1431\n 5  2013     8    30     1909           1910        -1     2117           2136\n 6  2013     9     1      833            840        -7     1030           1040\n 7  2013     9     8      847            840         7     1043           1040\n 8  2013     9    20     1948           1950        -2     2207           2216\n 9  2013     9    22      837            840        -3     1025           1040\n10  2013     9    27     2011           1950        21     2209           2216\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nPuisque les variables de ces 2 tableaux sont les mêmes, nous pouvons “empiler” ces 2 tableaux pour n’en former qu’un seul :\n\nbind_rows(colorado, indiana)\n\n# A tibble: 25 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     5      829            830        -1     1047           1111\n 2  2013     1    12      827            830        -3     1112           1111\n 3  2013     1    19      843            830        13     1123           1111\n 4  2013     1    26      828            830        -2     1114           1111\n 5  2013    12    21      916            830        46     1149           1117\n 6  2013    12    28      913            829        44     1128           1116\n 7  2013     2     2      858            830        28     1124           1111\n 8  2013     2     9       NA            830        NA       NA           1111\n 9  2013     2    16      834            830         4     1114           1111\n10  2013     2    23      826            830        -4     1050           1111\n# ℹ 15 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nVous noterez que le nombre de lignes du nouveau tableau est la somme des nombres de lignes des 2 tableaux de départ. Bien sûr, cette opération n’est utile que si les tableaux nous sont fournis séparément. Ici, il aurait été bien plus rapide d’obtenir le même résultat en tapant :\n\nflights |&gt; \n  filter(dest %in% c(\"HDN\", \"SBN\"))\n\n# A tibble: 25 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     5      829            830        -1     1047           1111\n 2  2013     1    12      827            830        -3     1112           1111\n 3  2013     1    19      843            830        13     1123           1111\n 4  2013     1    26      828            830        -2     1114           1111\n 5  2013    10    18     1820           1745        35     2030           2011\n 6  2013    11     1     2012           1905        67     2221           2131\n 7  2013    11    22     2013           1905        68     2224           2131\n 8  2013    12     1     1241           1215        26     1431           1431\n 9  2013    12    21      916            830        46     1149           1117\n10  2013    12    28      913            829        44     1128           1116\n# ℹ 15 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nLe fonctionnement de bind_cols() est le même :\n\na &lt;- tibble(x = 1:3, \n            y = c(2, 4, 6),\n            z = c(TRUE, FALSE, FALSE))\n\nb &lt;- tibble(r = 10:8, \n            s = rnorm(3))\n\na\n\n# A tibble: 3 × 3\n      x     y z    \n  &lt;int&gt; &lt;dbl&gt; &lt;lgl&gt;\n1     1     2 TRUE \n2     2     4 FALSE\n3     3     6 FALSE\n\nb\n\n# A tibble: 3 × 2\n      r       s\n  &lt;int&gt;   &lt;dbl&gt;\n1    10 -0.0287\n2     9  1.06  \n3     8 -0.344 \n\nbind_cols(a,b)\n\n# A tibble: 3 × 5\n      x     y z         r       s\n  &lt;int&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;int&gt;   &lt;dbl&gt;\n1     1     2 TRUE     10 -0.0287\n2     2     4 FALSE     9  1.06  \n3     3     6 FALSE     8 -0.344 \n\n\nIci, puisque a et b ont le même nombre de lignes, il est possible de les accoler. Cela n’a de sens que si les lignes des 2 tableaux correspondent aux mêmes observations."
  },
  {
    "objectID": "05-DataWrangling.html#sec-exo-13",
    "href": "05-DataWrangling.html#sec-exo-13",
    "title": "5  Tripatouiller les données avec dplyr",
    "section": "5.10 Exercices",
    "text": "5.10 Exercices\n\nCréez un tableau delayed indiquant, pour chaque compagnie aérienne et chaque mois de l’année, le nombre de vols ayant eu un retard supérieur à 30 minutes à l’arrivée à destination. Ce tableau devrait contenir uniquement 3 colonnes :\n\n\ncarrier : la compagnie aérienne.\nmonth : le mois de l’année 2013.\nn_delayed : le nombre de vols ayant plus de 30 minutes de retard.\n\n\nCréez un tableau total indiquant le nombre total de vols affrétés (et non annulés) par chaque compagnie aérienne et chaque mois de l’année. Ce tableau devrait contenir seulement 3 colonnes :\n\n\ncarrier : la compagnie aérienne.\nmonth : le mois de l’année 2013.\nn_total : le nombre total de vols arrivés à destination.\n\n\nFusionnez ces 2 tableaux en réalisant la jointure appropriée. Le tableau final, que vous nommerez carrier_stats devrait contenir 185 lignes. Si certaines colonnes contiennent des données manquantes, remplacez-les par des 0 à l’aide des fonctions mutate() et replace_na().\nAjoutez à votre tableau carrier_stats une variable rate qui contient la proportion de vols arrivés à destination avec plus de 30 minutes de retard, pour chaque compagnie aérienne et chaque mois de l’année.\nAjoutez à votre tableau carrier_stats le nom complet des compagnies aériennes en réalisant la jointure appropriée avec le tableau airlines.\nFaites un graphique synthétique présentant ces résultats de la façon la plus claire possible\nQuelle compagnie aérienne semble se comporter très différemment des autres ? À quoi pouvez-vous attribuer ce comportement atypique ?\nPour les compagnies affrétant un grand nombre de vols chaque année (e.g. UA, B6 et EV), quelles sont les périodes où les plus fortes proportions de vols en retard sont observées ? Et les plus faibles ? Quelle(s) hypothèse(s) pouvez-vous formuler pour expliquer ces observations ?\nFaites un tableau synthétique présentant ces résultats de la façon la plus compacte et claire que possible, afin par exemple de les intégrer à un rapport."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Gorman, Kristen B., Tony D. Williams, and William R Fraser. 2014.\n“Ecological Sexual Dimorphism and Environmental Variability Within\na Community of Antarctic Penguins (Genus Pygoscelis).” PLOS\nONE 9 (March): 1–14. https://doi.org/10.1371/journal.pone.0090081.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022.\nPalmerpenguins: Palmer Archipelago (Antarctica) Penguin Data.\nhttps://CRAN.R-project.org/package=palmerpenguins.\n\n\nJeppson, Haley, Heike Hofmann, and Di Cook. 2021. Ggmosaic: Mosaic\nPlots in the Ggplot2 Framework. https://github.com/haleyjeppson/ggmosaic.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen,\nKohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey\nDunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using\nthe Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. 2nd ed.\nNew-York: Springer-Verlag. https://www.springer.com/us/book/9780387245447."
  }
]