[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Analyse de Données",
    "section": "",
    "text": "Introduction"
  },
  {
    "objectID": "index.html#objectifs",
    "href": "index.html#objectifs",
    "title": "Analyse de Données",
    "section": "Objectifs",
    "text": "Objectifs\nCe livre contient l’ensemble du matériel (contenus, exemples, exercices…) nécessaire à la réalisation des travaux pratiques d’analyse de données consacrés à la prise en main de R et RStudio.\nCes travaux pratiques ont essentiellement 3 objectifs :\n\nVous faire (re)découvrir les logiciels R et Rstudio dans lesquels vous allez passer beaucoup de temps tout au long de votre cursus de master. Vous avez choisi une spécialité de master qui implique de traiter des données et de communiquer des résultats d’analyses statistiques : R et RStudio devraient être les logiciels vers lesquels vous vous tournez naturellement pour faire l’un et l’autre.\nVous faire prendre conscience de l’importance des visualisations graphiques :\n\n\nd’une part, pour comprendre à quoi ressemblent les données en votre possession,\nd’autre part, pour vous permettre de formuler des hypothèses pertinentes et intéressantes concernant les systèmes que vous étudiez,\net enfin, pour communiquer efficacement vos trouvailles à un public qui ne connaît pas vos données aussi bien que vous (cela inclut évidemment vos enseignants à l’issue de vos stages).\nLes données que vous serez amenés à traiter lors de vos stages, ou plus tard, lorsque vous serez en poste, ont souvent été acquises à grands frais, et au prix d’efforts importants. Il est donc de votre responsabilité d’en tirer le maximum. Et ça commence toujours (ou presque), par la réalisation de visualisations graphiques parlantes.\n\n\nVous apprendre comment calculer des statistiques descriptives simples, sur plusieurs types de variables, afin de vous mettre dans les meilleures conditions possibles pour aborder d’une part les statistiques plus avancées de cet EC et des EC des semestres 2 et 3, et d’autre part les comptes-rendus de TP et rapports de stage que vous aurez à produire dans ce cursus de master. Vos enseignants attendent de vous la plus grande rigueur lorsque vous analysez et présentez des résultats d’analyses statistiques. Ces TP ont pour objectifs de vous fournir les bases nécessaires pour satisfaire ce niveau d’exigence."
  },
  {
    "objectID": "index.html#organisation",
    "href": "index.html#organisation",
    "title": "Analyse de Données",
    "section": "Organisation",
    "text": "Organisation\nAu total, la partie “analyse de données” de l’EC “Stratégie d’échantillonnage et analyse de données” contient :\n\n15 heures de cours magistraux\n9 heures de travaux pratiques (pour chaque groupe)\n16 heures de TEA\n\n\nLes cours magistraux\nLes cours magistraux sont globalement découpés en 2 blocs à peu près indépendants :\n\nun bloc de 10 heures consacrées aux notions statistiques élémentaires, aux statistiques descriptives et aux statistiques inférentielles. Nous couvrirons notamment les notions d’incertitude et d’inférence, les tests d’hypothèses, la comparaison de proportions, l’ajustement de données observées à des distributions théoriques, l’analyse de tables de contingences, les comparaisons de moyennes, les régressions linéaires, les ANOVA et ANCOVA…\nun bloc de 5 heures consacrées aux statistiques multivariées telles que l’Analyse en Composantes Principales (ACP) et l’Analyse Factorielle des Correspondances (AFC).\n\nMon objectif n’est pas de survoler l’ensemble du matériel dans ce faible volume horaire : s’il n’est pas suffisant, nous ajouterons quelques séances afin de traiter correctement l’ensemble du matériel. Je suis convaincu que tout le monde est capable de comprendre les grands principes des statistiques, et de réaliser des analyses dans un logiciel tel que R, y compris les plus réfractaires aux mathématiques et à l’informatique. Mais il est nécessaire de démystifier cette discipline essentielle, et si certains ont besoin de plus de temps que d’autres, nous prendrons ce temps. Les TP et TEA, décrits plus bas, sont justement organisés pour permettre à chacun d’avancer à son rythme. Mais ne vous y trompez pas, cela vous demandera beaucoup de travail pendant ces 3 semaines.\nTous les aspects vu en cours seront en effet développés lors des séances de TP et de TEA. Vous aurez, pour chaque partie, des exercices à préparer et à déposer sur l’ENT. Ces exercices seront corrigés lors des séances de TP et/ou de TEA. Tout cela doit d’une part vous préparer à l’évaluation qui aura lieu conjointement avec les EC de stratégie d’échantillonnage, de remise à niveau en biologie marine et d’échantillonnage littoral, mais surtout, cela doit vous permettre d’acquérir des compétences en analyse de données, compétences qui seront attendues de vous lorsque vous sortirez diplômé·e de ce master.\n\n\nLes Travaux pratiques\nLe contenu des séances de travaux pratiques sera découpé en 3 parties :\n\nPrise en main des logiciels R et RStudio\nIllustration du cours sur les statistiques descriptives et inférentielles, mise en pratique et réalisation d’exercices\nIllustration du cours sur les statistiques multivariées, mise en pratique et réalisation d’exercices\n\nPour chaque séance de TP, vous travaillerez soit à distance, soit en salle banalisée, sur vos ordinateurs personnels. La première séance aura lieu en présentiel et sera consacrée à l’installation des logiciels ainsi qu’à la présentation de l’organisation des séances.\nLes séances de travaux pratiques ne seront pas toutes obligatoires : seules quelques séances en présentiel (les dates vous seront présentées ultérieurement) le seront, probablement pas plus d’une par semaine. Pour toutes les autres séances, le fonctionnement sera celui d’une permanence non obligatoire : seuls celles et ceux qui en éprouvent le besoin sont tenus de se déplacer. Ces séances de permanence n’auront lieu que si certains parmi vous m’ont fait part de difficultés ou ont formulé des questions en amont des séances. Si aucune question ne m’a été posée en amont, les permanences n’auront pas lieu. Si une permanence a lieu, elle est ouverte à tous, quel que soit votre groupe de TP. Vous n’êtes d’ailleurs pas tenus de rester pendant 90 minutes : vous venez avec votre question, on y répond ensemble, et vous êtes libres de repartir quand bon vous semble. Les années précédentes, je voyais certains de vos collègues à chaque séance de permanence alors que d’autres ne sont jamais venus. Si vous n’en avez pas besoin, libre à vous de ne pas venir. Tant que le travail est fait et que les exercices ne vous posent pas de problème, vous êtes libres de vous organiser comme vous l’entendez.\nAttention toutefois, venir à une séance de permanence en n’ayant pas préparé de question au préalable ne vous sera d’aucune aide. C’est parce que vous avez travaillé en amont de ces séances et que vous arrivez avec des questions que ces permanences sont utiles et efficaces. Donc si vous venez, c’est que vous avez bossé en amont !\nComment procéder pour savoir si une séance de permanence a lieu, ou pour poser une question ?\nTout se passera en ligne, grâce au logiciel Slack, qui fonctionne un peu comme un “twitter privé”. Slack facilite la communication des équipes et permet de travailler ensemble. Créez-vous un compte en ligne et installez le logiciel sur votre ordinateur (il existe aussi des versions pour tablettes et smartphones). Lorsque vous aurez installé le logiciel, cliquez sur ce lien pour vous connecter à notre espace de travail commun.\nVous verrez que 3 “chaînes” sont disponibles :\n\n#organisation : c’est là que les questions liées à l’organisation du cours, des TP et TEA doivent être posées. Si vous ne savez pas si une séance de permanence a lieu, posez la question ici.\n#rstudio : c’est ici que toutes les questions pratiques liées à l’utilisation de R et RStudio devront êtres posées. Problèmes de syntaxe, problèmes liés à l’interface, à l’installation des packages ou à l’utilisation des fonctions… Tout ce qui concerne R ou RStudio mais pas directement les statistiques sera traité ici. Vous êtes libres de poser des questions, de poster des captures d’écran, des morceaux de code, des messages d’erreur. Et vous êtes bien entendus vivement encouragés à vous entraider et à répondre aux questions de vos collègues. Je n’interviendrai ici que pour répondre aux questions laissées sans réponse ou si les réponses apportées sont inexactes. Le fonctionnement est celui d’un forum de discussion instantané. Vous en tirerez le plus grand bénéfice en participant et en n’ayant pas peur de poser des questions, même si elles vous paraissent idiotes. Rappelez-vous toujours que si vous vous posez une question, d’autres se la posent aussi probablement.\n#statistiques : c’est ici que toutes les questions liées aux méthodes statistiques devront être posées. Comme pour la chaîne #rstudio, vous êtes encouragés à poster des questions mais aussi des réponses. Le fonctionnement de l’ensemble se veut participatif.\n\nAinsi, quand vous travaillerez à vos TP ou TEA, prenez l’habitude de garder Slack ouvert sur votre ordinateur. Même si vous n’avez pas de question à poser, votre participation active pour répondre à vos collègues est souhaitable et souhaitée. Votre niveau de participation sur Slack pourra faire partie de votre note finale.\nSi toutes les questions posées sur Slack ont trouvé une réponse, alors, inutile d’organiser une permanence. Si en revanche, certains n’ont pas compris, si les mêmes questions reviennent fréquemment, ou si des explications “en direct” sont plus efficaces qu’un long message sur Slack, alors une permanence aura lieu.\n\n\nLe TEA\nLes séances de TEA auront toutes lieu “à distance”. Je ne suis pas tenu d’être présent lors des séances de TEA, même si une salle banalisée est systématiquement réservée pour vous permettre de vous retrouver et de travailler ensemble. Je m’engage en revanche à être disponible sur Slack pour répondre rapidement aux questions posées lors des TEA. Et si certaines questions n’ont pas trouvé de réponse pendant les séances de TEA, nous y répondront lors du TP suivant.\nGénéralement, l’organisation de votre journée sera la suivante :\n\nEn début de matinée, 1h30 ou 3h de cours magistraux\nEn milieu de journée du temps libre ou pour avancer sur ce document, les exercices, la prise en main de R, etc.\nEn fin de journée une séance de TEA et/ou de TP/permanence non obligatoire de 90 minutes pour ceux qui en ont besoin et se manifestent."
  },
  {
    "objectID": "index.html#progession-conseillée",
    "href": "index.html#progession-conseillée",
    "title": "Analyse de Données",
    "section": "Progession conseillée",
    "text": "Progession conseillée\nPour apprendre à utiliser un logiciel comme R, il faut faire les choses soi-même, ne pas avoir peur des messages d’erreurs (il faut d’ailleurs apprendre à les déchiffrer pour comprendre d’où viennent les problèmes), essayer maintes fois, se tromper beaucoup, recommencer, et surtout, ne pas se décourager. J’utilise ce logiciel presque quotidiennement depuis plus de 15 ans et à chaque session de travail, je rencontre des messages d’erreur. Avec suffisamment d’habitude, on apprend à les déchiffrer, et on corrige les problèmes en quelques secondes. Ce livre est conçu pour vous faciliter la tâche, mais ne vous y trompez pas, vous rencontrerez des difficultés, et c’est normal. C’est le prix à payer pour profiter de la puissance du meilleur logiciel permettant d’analyser des données, de produire des graphiques de qualité et de réaliser toutes les statistiques dont vous aurez besoin d’ici la fin de vos études et au-delà.\nPour que cet apprentissage soit le moins problématique possible, il convient de prendre les choses dans l’ordre. C’est la raison pour laquelle les chapitres de ce livre doivent être lus dans l’ordre, et les exercices d’application faits au fur et à mesure de la lecture.\nUne fois compilé en pdf, ce document représente plus de 180 pages, ce qui veut dire que vous devriez vous approprier environ 12 pages par jour. En particulier, la Chapitre 3 est très longue et il est facile de se laisser dépasser.\n\n\n\n\n\n\nTravaillez régulièrement !\n\n\n\nJ’insiste sur l’importance de travailler cette matière régulièrement. Vous devez vous y mettre dès maintenant et y consacrer plusieurs heures chaque jours. Interrogez vos collègues de M2 qui ont suivi cet enseignement l’an dernier : il y a beaucoup de temps à y passer et il est hélas facile de prendre et d’accumuler du retard…\n\n\nUne fois cette UE terminée, vous pourrez évidemment consulter ce livre quand bon vous semblera, et dans n’importe quel ordre. Le champ de recherche situé en haut à gauche est d’ailleurs très utile pour (re)trouver les passages que vosu recherchez. Ce livre restera en ligne et vous pourrez y accéder même après avoir quitté l’université de La Rochelle. Vos prédécesseurs me confirment régulièrement à quel point ce livre leur est resté utile bien après le master. Soyez toutefois prévenu que les contenus de ce livre peuvent évoluer avec le temps : j’essaie en effet de remettre à jour tout ce qui doit l’être le plus régulièrement possible. Et cela signifie parfois que des sections peuvent disparaître ou être remplacées si des façons de procéder plus modernes sont préférables."
  },
  {
    "objectID": "index.html#lévaluation",
    "href": "index.html#lévaluation",
    "title": "Analyse de Données",
    "section": "L’évaluation",
    "text": "L’évaluation\nVous aurez plusieurs types d’évaluations cette année :\n\nUne évaluations par les pairs qui portera sur la qualité de vos scripts. Cette évaluation qui entrera pour une toute petite partie dans la note finale de l’EC a pour objectif principal de vous permettre de vous situer dans vos apprentissages. Vous évaluerez vous même, et de façon anonyme, plusieurs copies de vos camarades en suivant une grille d’évaluation critériée que nous construirons ensemble. De même, votre copie sera évaluée par plusieurs de vos camarades. Cette approche a de nombreux avantages. Elle vous permet notamment de mieux vous approprier les grilles de notations (par exemple, qu’est-ce qu’un bon script sous R ? À l’inverse, qu’est-ce qu’un script médiocre ? Comment être sûr que la méthode statistique choisie est la bonne pour répondre à une question donnée ? Suis-je capable de décrire correctement un tableau de données de grande taille ? Suis-je capable de produire des graphiques informatifs ?) et rends possible un retour personnalisé sur vos travaux beaucoup plus rapidement que si votre enseignant était le seul à corriger l’ensemble de vos travaux. Pas d’inquiétude, vous serez guidés à chaque étape.\nUne évaluation individuelle courte qui ne portera pas sur les analyses statistiques à proprement parler, mais sur votre capacité à produire un graphique de qualité, original et qui raconte une histoire intéressante sur un jeu de données imposé. Cet exercice n’est pas réalisé chaque année faute de temps.\nUne évaluation individuelle plus classique avec quelques exercices qui vous demanderont de mettre en œuvre les méthodes statistiques décrites lors de cours magistraux.\nEnfin, une évaluation qui prendra la forme d’un rapport et qui sera réalisé conjointement avec les travaux de stratégie d’échantillonnage réalisés avec Fanny Cusset. Cette partie de l’EC est en effet complémentaire de l’analyse de données puisqu’elle permet d’avoir une approche globale, de la question scientifique à la production d’un rapport et d’une soutenance, en passant par la réflexion sur la stratégie d’échantillonnage, la mise en œuvre sur le terrain, le traitement des échantillons au laboratoire, et l’exploitation statistique des résultats. Ce travail sera donc évalué conjointement par Fanny Cusset et moi. La note de la partie analyse de données portera donc essentiellement sur les parties “matériels et méthodes” et “résultats” du rapport. Il est en effet important de comprendre dès maintenant que l’analyse de données n’est pas une fin en soi : on ne fait pas des statistiques pour le plaisir, ou sans but précis. Ça n’est qu’un outil de votre panoplie d’écologue au service d’une question scientifique. L’analyse de données et les statistiques vous permettront de répondre à des questions scientifiques de façon objective, mais leur utilisation appropriée suppose que vous ayez les idées claires en amont sur la question scientifique à laquelle vous tentez de répondre. C’est cette démarche qui devrait vous guider tout au long de votre cursus de master et au-delà, dans votre vie professionnelle.\n\nDans le cadre de l’approche compétences, j’essaierai d’indiquer, dans la mesure du possible, quelles sont les compétences et résultats d’apprentissages dont vous devrez faire l’acquisition pour chaque évaluation. À l’issue de cet enseignement, vous devriez être capables de :\n\nMettre en forme des données acquises sur le terrain ou au laboratoire afin d’en permettre l’importation dans R ou RStudio.\nProduire des statistiques descriptives informatives permettant de comprendre la structure et les tendances principales d’un jeu de données.\nCréer dans R ou RStudio des graphiques lisibles et informatifs permettant de mettre en évidence les tendances principales d’un jeu de données.\nProduire des scripts clairs sous R ou RStudio, permettant la reproductibilité des traitements de données et des analyses statistiques ainsi que la communication avec vos pairs.\nAnalyser des données uni-, bi- ou multi-variées issues d’observations et de mesures sur le terrain et au laboratoire en choisissant les méthodes appropriées pour répondre à une problématique scientifique précise.\nMaîtriser les logiciels R ou RStudio pour réaliser des analyses statistiques, des représentations graphiques ou des simulations numériques."
  },
  {
    "objectID": "index.html#licence",
    "href": "index.html#licence",
    "title": "Analyse de Données",
    "section": "Licence",
    "text": "Licence\nCe livre est ligne est sous licence Creative Commons (CC BY-NC-ND 4.0)\n\n\n\n\n\nVous êtes autorisé à partager, copier, distribuer et communiquer ce matériel par tous moyens et sous tous formats, tant que les conditions suivantes sont respectées :\n\n\n Attribution : vous devez créditer ce travail (donc citer son auteur), fournir un lien vers ce livre en ligne, intégrer un lien vers la licence Creative Commons et indiquer si des modifications du contenu original ont été effectuées. Vous devez indiquer ces informations par tous les moyens raisonnables, sans toutefois suggérer que l’auteur vous soutient ou soutient la façon dont vous avez utilisé son travail.\n\n\n Pas d’utilisation commerciale : vous n’êtes pas autorisé à faire un usage commercial de cet ouvrage, ni de tout ou partie du matériel le composant. Cela comprend évidemment la diffusion sur des plateformes de partage telles que studocu.com qui tirent profit d’œuvres dont elles ne sont pas propriétaires, souvent à l’insu des auteurs.\n\n\n Pas de modifications : dans le cas où vous effectuez un remix, que vous transformez, ou créez à partir du matériel composant l’ouvrage original, vous n’êtes pas autorisé à distribuer ou mettre à disposition l’ouvrage modifié.\n\n\n Pas de restrictions complémentaires : vous n’êtes pas autorisé à appliquer des conditions légales ou des mesures techniques qui restreindraient légalement autrui à utiliser cet ouvrage dans les conditions décrites par la licence."
  },
  {
    "objectID": "01-R-basics.html#préambule",
    "href": "01-R-basics.html#préambule",
    "title": "1  R et RStudio : les bases",
    "section": "1.1 Préambule",
    "text": "1.1 Préambule\nAvant de commencer à explorer des données dans R, il y a plusieurs concepts clés qu’il faut comprendre en premier lieu :\n\nQue sont R et RStudio ?\nComment s’y prend-on pour coder dans R ?\nQue sont les packages ?\n\nMême si vous pensez être déjà à l’aise avec ces concepts, lisez attentivement ce chapitre et faites les exercices demandés. Cela vous rafraîchira probablement la mémoire, et il n’est pas impossible que vous appreniez une chose ou deux au passage. Une bonne maîtrise des éléments présentés dans ce chapitre est indispensable pour aborder sereinement les chapitres suivants, à commencer par le Chapitre 2, qui présente un jeu de données que nous explorerons en détail un peu plus tard. Lisez donc attentivement ce chapitre et faites bien tous les exercices demandés.\nCe chapitre est en grande partie basé sur les 3 ressources suivantes que je vous encourage à consulter si vous souhaitez obtenir plus de détails :\n\nL’ouvrage intitulé ModernDive, de Chester Ismay et Albert Y. Kim. Une bonne partie de ce livre est très largement inspirée de cet ouvrage. C’est en anglais, mais c’est un très bon texte d’introduction aux statistiques sous R et RStudio.\nL’ouvrage intitulé Getting used to R, RStudio, and R Markdown de Chester Ismay, comprend des podcasts (en anglais toujours) que vous pouvez suivre en apprenant.\nLes tutoriels en ligne de DataCamp. DataCamp est une plateforme de e-learning accessible depuis n’importe quel navigateur internet et dont la priorité est l’enseignement des “data sciences”. Leurs tutoriels vous aideront à apprendre certains des concepts de développés dans ce livre.\n\n\n\n\n\n\n\nImportant\n\n\n\nAvant d’aller plus loin, rendez-vous sur le site de DataCamp, créez-vous un compte gratuit, et reprenez la lecture de ce livre."
  },
  {
    "objectID": "01-R-basics.html#que-sont-r-et-rstudio",
    "href": "01-R-basics.html#que-sont-r-et-rstudio",
    "title": "1  R et RStudio : les bases",
    "section": "1.2 Que sont R et RStudio ?",
    "text": "1.2 Que sont R et RStudio ?\nPour l’ensemble de ces TP, j’attends de vous que vous utilisiez R via RStudio. Les utilisateurs novices confondent souvent les deux. Pour tenter une analogie simple :\n\nR est le moteur d’une voiture\nRStudio est l’habitacle, le tableau de bord, les pédales…\n\nSi vous n’avez pas de moteur, vous n’irez nulle part. En revanche, un moteur sans tableau de bord est difficile à manœuvrer. Il est en effet beaucoup plus simple de faire avancer une voiture depuis l’habitacle, plutôt qu’en actionnant à la main les câbles et leviers du moteur.\nEn l’occurrence, R est un langage de programmation capable de produire des graphiques et de réaliser des analyses statistiques, des plus simples aux plus complexes. RStudio est un “emballage” qui rend l’utilisation de R plus aisée. RStudio est ce qu’on appelle un IDE ou “Integrated Development Environment”. On peut utiliser R sans RStudio, mais c’est nettement plus compliqué, nettement moins pratique.\n\n1.2.1 Installation\n\n\n\n\n\n\nAvertissement\n\n\n\nSi vous travaillez exclusivement sur les ordinateurs de l’Université, vous pouvez passer cette section. En revanche, si vous souhaitez utiliser R et RStudio sur votre ordinateur personnel, alors lisez attentivement la suite !\n\n\nAvant tout, vous devez télécharger et installer R, puis RStudio, dans cet ordre :\n\nTéléchargez et installez R\n\n\nVous devez installer ce logiciel en premier.\nCliquez sur le lien de téléchargement qui correspond à votre système d’exploitation, puis, sur “base”, si vous êtes sous Windows, sur “R-4.3.1-x86_64.pkg” si vous êtes sous Mac avec processeur Intel, ou sur R-4.3.1-arm64.pkg si vous êtes sous Mac avec processeur M1 ou M2 (sous Mac, cliquez sur le Menu , puis sur “À propos de ce Mac” et regardez à la rubrique “Processeur”), et suivez les instructions.\n\n\nTéléchargez et installez RStudio\n\n\nCliquez sur “RStudio Desktop”, puis sur “Download RStudio Desktop”.\nChoisissez la version gratuite et cliquez sur le lien de téléchargement qui correspond à votre système d’exploitation.\n\n\n\n1.2.2 Utiliser R depuis RStudio\nPuisqu’il est beaucoup plus facile d’utiliser Rstudio pour interagir avec R, nous utiliserons exclusivement l’interface de RStudio. Après les installations réalisées à la Section 1.2.1, vous disposez de 2 nouveaux logiciels sur votre ordinateur. RStudio ne peut fonctionner sans R, mais nous travaillerons exclusivement dans RStudio :\n\nR, ne pas ouvrir ceci :   \nRStudio, ouvrir cela : \n\nÀ l’université, vous trouverez RStudio dans le menu Windows, à condition d’être connecté à la machine virtuelle bio. Quand vous ouvrez RStudio pour la première fois, vous devriez obtenir une fenêtre qui ressemble à ceci :\n\nPrenez le temps d’explorer cette interface, cliquez sur les différents onglets, ouvrez les menus, allez faire un tour dans les préférences du logiciel pour découvrir les différents panneaux de l’application, en particulier la Console dans laquelle nous exécuterons très bientôt du code R."
  },
  {
    "objectID": "01-R-basics.html#sec-code",
    "href": "01-R-basics.html#sec-code",
    "title": "1  R et RStudio : les bases",
    "section": "1.3 Comment exécuter du code R ?",
    "text": "1.3 Comment exécuter du code R ?\nContrairement à d’autres logiciels comme Excel, STATA ou SAS qui fournissent des interfaces où tout se fait en cliquant avec sa souris, R est un langage interprété, ce qui signifie que vous devez taper des commandes, écrites en code R. C’est-à-dire que vous devez programmer en R (j’utilise les termes “coder” et “programmer” de manière interchangeable dans ce livre).\nIl n’est pas nécessaire d’être un programmeur pour utiliser R, néanmoins, il est nécessaire de programmer ! Il existe en effet un ensemble de concepts de programmation de base que les utilisateurs de R doivent comprendre et maîtriser. Et progresser en programmation vous permettra d’automatiser de plus en plus de choses, et donc, à terme, de gagner beaucoup de temps. Par conséquent, bien que ce livre ne soit pas un livre sur la programmation, vous en apprendrez juste assez en programmation pour explorer et analyser efficacement des données.\n\n1.3.1 La console\nLa façon la plus simple d’interagir avec RStudio (mais pas du tout la meilleure !) consiste à taper directement des commandes que R pourra comprendre dans la Console.\nCliquez dans la console (après le symbole &gt;) et tapez ceci, sans oublier de valider en tapant sur la touche Entrée :\n\n3 + 8\n\n[1] 11\n\n\nFélicitations, vous venez de taper votre première instruction R : vous savez maintenant faire des additions !\nDans la version en ligne de ce livre (en html), à chaque fois que du code R sera fourni, il apparaîtra dans un cadre grisé avec une ligne bleue à gauche, comme ci-dessus. Vous pourrez toujours taper dans RStudio, les commandes qui figurent dans ces blocs de code, afin d’obtenir vous même les résultats souhaités. Dans ce livre, lorsque les commandes R produisent des résultats, ils sont affichés juste en dessous des blocs de code. Enfin, en passant la souris sur les blocs de code, vous verrez apparaître, à droite, une icône de presse-papier qui vous permettra de copier-coller les commandes du livre dans la console de RStudio ou, très bientôt, dans vos scripts.\n\n\n\n\n\n\nLes risques du “copier-coller” \n\n\n\nAttention : il est fortement conseillé de réserver les copier-coller aux blocs de commandes de (très) grande taille, ou en cas d’erreur de syntaxe inexplicable. L’expérience a en effet montré qu’on apprend beaucoup mieux en tapant soi-même les commandes. Ça n’est que comme cela que l’on peut prendre conscience de toutes les subtilités du langage (par exemple, faut-il mettre une virgule ou un point, une parenthèse ou un crochet, le symbole moins ou un tilde, etc.). Je vous conseille donc de taper vous-même les commandes autant que possible.\n\n\n\n\n1.3.2 Les scripts\nTaper du code directement dans la console est probablement la pire façon de travailler dans RStudio. Cela est parfois utile pour faire un rapide calcul, ou pour vérifier qu’une commande fonctionne correctement. Mais la plupart du temps, vous devriez taper vos commandes dans un script.\n\n\n\n\n\n\nDéfinition importante !\n\n\n\nUn script est un fichier au format “texte brut” (cela signifie qu’il n’y a pas de mise en forme et que ce fichier peut-être ouvert par n’importe quel éditeur de texte, y compris les plus simples comme le bloc notes de Windows), dans lequel vous pouvez taper :\n\ndes instructions qui seront comprises par R comme si vous les tapiez directement dans la console\ndes lignes de commentaires, qui doivent obligatoirement commencer par le symbole #.\n\n\n\nLes avantages de travailler dans un script sont nombreux :\n\nVous pouvez sauvegarder votre script à tout moment (vous devriez prendre l’habitude de le sauvegarder très régulièrement). Vous gardez ainsi la trace de toutes les commandes que vous avez tapées.\nVous pouvez aisément partager votre script pour collaborer avec vos collègues de promo et enseignants.\nVous pouvez documenter votre démarche et les différentes étapes de vos analyses. Vous devez ajouter autant de commentaires que possible. Cela permettra à vos collaborateurs de comprendre ce que vous avez fait. Et dans 6 mois, cela vous permettra de comprendre ce que vous avez fait. Si votre démarche vous paraît cohérente aujourd’hui, il n’est en effet pas garanti que vous vous souviendrez de chaque détail quand vous vous re-plongerez dans vos analyses dans quelques temps. Donc aidez-vous vous même en commentant vos scripts dès maintenant.\nUn script bien structuré, bien indenté (avec les bons retours à la ligne, des sauts de lignes, des espaces, bref, de l’air) et clair permet de rendre vos analyses répétables. Si vous passez 15 heures à analyser un tableau de données précis, il vous suffira de quelques secondes pour analyser un nouveau jeu de données similaire : vous n’aurez que quelques lignes à modifier dans votre script original pour l’appliquer à de nouvelles données.\n\nVous pouvez créer un script en cliquant dans le menu “File &gt; New File &gt; R Script”. Un nouveau panneau s’ouvre dans l’application. Pensez à sauvegarder immédiatement votre nouveau script en cliquant dans le menu “File &gt; Save” ou “File &gt; Save as…”. Il faut pour cela lui donner un nom et choisir un emplacement sur votre disque dur.\n\n\n\n\n\n\nOù sauvegarder vos scripts ? \n\n\n\nJe vous encourage vivement à créer, sur votre disque dur, un nouveau dossier spécifique, que vous nommerez par exemple Data_Analysis. Il est important que le nom de ce dossier ne contienne pas de caractères spéciaux (e.g. accents, cédilles, apostrophes, espaces, etc.). Ce dossier devrait être facilement accessible : vous y enregistrerez tous vos scripts, vos jeux de données, vos graphiques, etc.\nSi vous travaillez sur les ordinateurs de l’université, créez obligatoirement votre dossier sur le disque W:\\. Il s’agit de votre espace personnel sur le réseau de l’université. Cela vous garantit que vous retrouverez votre script la prochaine fois, même si vous utilisez un ordinateur différent.\n\n\nÀ partir de maintenant, vous ne devriez plus taper de commande directement dans la console. Tapez systématiquement vos commandes dans un script et sauvegardez-le régulièrement.\nPour exécuter les commandes du script dans la console, il suffit de placer le curseur sur la ligne contenant la commande et de presser les touches ctrl + enter (ou command + enter sous macOS). Si un message d’erreur s’affiche dans la console, c’est que votre instruction était erronée. Modifiez la directement dans votre script et pressez à nouveau les touches ctrl + enter (ou command + enter sous macOS) pour tenter à nouveau votre chance. Idéalement, votre script ne devrait contenir que des commandes qui fonctionnent et des commentaires expliquant à quoi servent ces commandes.\nVoici un exemple de script que je ne vous demande pas de reproduire. Lisez simplement attentivement son contenu :\n\n# Penser à installer le package ggplot2 si besoin\n# install.packages(\"ggplot2\")\n\n# Chargement du package\nlibrary(ggplot2)\n\n# Mise en mémoire des données de qualité de l'air à New-York de mai à\n# septembre 1973\ndata(airquality)\n\n# Affichage des premières lignes du tableau de données\nhead(airquality)\n\n# Quelle est la structure de ce tableau ?\nstr(airquality)\n\n# Réalisation d'un graphique présentant la relation entre la concentration\n# en ozone atmosphérique en ppb et la température en degrés Fahrenheit\nggplot(data = airquality, mapping = aes(x = Temp, y = Ozone)) +\n  geom_point() +\n  geom_smooth(method = \"loess\")\n\n# On constate une augmentation importante de la concentration d'ozone \n# pour des températures supérieures à 75ºF\n\nMême si vous ne comprenez pas encore les commandes qui figurent dans ce script (ça viendra !), voici ce que vous devez en retenir :\n\nLe script contient plus de lignes de commentaires que de commandes R.\nChaque étape de l’analyse est décrite en détail.\nLes 2 dernières lignes du script décrivent les résultats obtenus (ici, un graphique).\nSeules des commandes pertinentes et qui fonctionnent ont été conservées dans ce script.\nChaque ligne de commentaire commence par #. Il est ainsi possible de conserver certaines commandes R dans le script, “pour mémoire”, sans pour autant qu’elle ne soient exécutées. C’est le cas pour la ligne # install.packages(\"ggplot2\").\n\nSi j’exécute ce script dans la console de RStudio (en sélectionnant toutes les lignes et en pressant les touches ctrl + enter ou command + enter sous macOS), voilà ce qui est produit :\n\n\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1\n2    36     118  8.0   72     5   2\n3    12     149 12.6   74     5   3\n4    18     313 11.5   62     5   4\n5    NA      NA 14.3   56     5   5\n6    28      NA 14.9   66     5   6\n\n\n'data.frame':   153 obs. of  6 variables:\n $ Ozone  : int  41 36 12 18 NA 28 23 19 8 NA ...\n $ Solar.R: int  190 118 149 313 NA NA 299 99 19 194 ...\n $ Wind   : num  7.4 8 12.6 11.5 14.3 14.9 8.6 13.8 20.1 8.6 ...\n $ Temp   : int  67 72 74 62 56 66 65 59 61 69 ...\n $ Month  : int  5 5 5 5 5 5 5 5 5 5 ...\n $ Day    : int  1 2 3 4 5 6 7 8 9 10 ...\n\n\n\n\n\n\n\n1.3.3 Les projets, ou Rprojects\nPour travailler le plus efficacement possible avec RStudio, vous devriez créer, à l’intérieur de votre dossier de travail, un nouveau fichier très particulier, qui s’appelle, dans le jargon de RStudio, un Rproject.\nPour le créer, cliquez simplement dans le Menu “File &gt; New Project…”. Cette boîte de dialogue devrait apparaître :\n\n\n\n\n\nChoisissez “Existing Directory”, puis, dans la boîte de dialogue suivante :\n\n\n\n\n\ncliquez sur “Browse…”, naviguez jusqu’au dossier que vous avez créé plus tôt sur votre disque dur et qui contient votre script, puis cliquez sur “Create Project”. La fenêtre de RStudio se ferme, puis une nouvelle fenêtre vierge apparaît. En apparence, rien n’a changé ou presque. Pourtant :\n\nen haut à droite de la fenêtre de RStudio, le logiciel indique maintenant que vous êtes bel et bien à l’intérieur d’un Rproject. Au lieu de Project: (None), on lit maintenant le nom du Rproject (chez moi, Data_Analysis)\ndans le quart inférieur droit de l’interface, l’onglet “Files” ne présente plus le même aspect. Avant de créer le Rproject, cet onglet présentait le chemin vers le dossier utilisé par défaut par le logiciel, ainsi que son contenu. Il s’agissait d’un dossier système auquel il vaut mieux ne pas toucher pour éviter les problèmes. Après la création du Rproject, l’onglet “Files” indique le contenu du dossier contenant le projet. Autrement dit, c’est ici que vous trouverez vos scripts, tableaux de données dans différents formats, figures sauvegardées, etc. Dans cet onglet, vous pouvez donc cliquer sur le nom de votre script pour l’ouvrir à nouveau, le modifier, l’exécuter…\n\n\n\n\n\n\n\nSans Rproject\n\n\n\n\n\n\n\nAvec RProject\n\n\n\n\n\n\nun nouveau fichier portant l’extension .Rproj a été créé dans votre dossier de travail. La prochaine fois que vous voudrez travailler dans RStudio, il vous suffira de double-cliquer sur ce fichier dans l’explorateur de fichier de Windows ou le Finder de MacOS, pour que RStudio s’ouvre, et que vous retrouviez tous vos fichiers et scripts de la fois précédente\n\n\n\n\n\n\nPour vérifier que tout s’est bien passé jusqu’ici, tapez la commande suivante dans votre script puis envoyez-la dans la console en pressant les touches ctrl + entrée (ou command + entrée sous MacOS).\n\ngetwd()\n\nRStudio doit vous afficher, dans la console, le chemin jusqu’à votre répertoire de travail ou “Working Directory” en anglais (getwd() est l’abréviation de “GET Working Directory”). Si tout s’est bien passé, ce chemin doit être celui du dossier qui contient votre script et le fichier .Rproj que vous venez de créer. Si ce n’est pas le cas, reprenez calmement toutes les étapes décrites depuis le début de la Section 1.3.2. Si ça ne fonctionne toujours pas, contactez-moi sur Slack.\n\n\n\n\n\n\nPour résumer… \n\n\n\nLes Rprojects sont un moyen très pratique de travailler efficacement dans RStudio car ils permettent de gérer facilement la question du répertoire de travail. Lorsque vous envisagez de travailler sur un nouveau sujet/projet/jeu de données/compte-rendu de TP…, les étapes à suivre, pour vous mettre dans une configuration idéale qui vous évitera bien des problèmes par la suite, sont donc les suivantes :\n\nSur votre ordinateur, créez un nouveau dossier avec un nom simple, et à un endroit facile d’accès (pas de caractères spéciaux dans le chemin du dossier si possible)\nDémarrez RStudio\nDans le logiciel, cliquez dans le menu “File &gt; New Project…”\nChoisissez “Existing Directory”, puis naviguez jusqu’au dossier que vous venez de créer\nCliquez sur “Create Project”\nCréer un nouveau script (menu “File &gt; New File &gt; R script”)\nDonnez un nom à votre script (menu “File &gt; Save As…”) pour le sauvegarder. Par défaut, RStudio vous propose d’enregistrer votre script dans le dossier de votre Rproject, ce qui est parfait.\nTapez getwd() dans votre script et exécutez cette commande en l’envoyant dans la console.\n\nSi le chemin qui s’affiche est celui du dossier contenant votre Rproject et votre script, félicitation, vous êtes prêt·e à travailler. Avec un peu d’habitude, ces étapes ne prennent qu’une à deux minutes.\n\n\n\n\n1.3.4 Concepts de base en programmation et terminologie\nAprès ces considérations techniques sur l’utilisation et les réglages de RStudio, nous entrons maintenant dans le vif du sujet avec la découverte des premiers éléments de syntaxe du langage R.\n\n1.3.4.1 Objets, types, vecteurs, facteurs et tableaux de données\nPour vous présenter les concepts de base et la terminologie de la programmation dont nous aurons besoin, vous allez suivre des tutoriels en ligne sur le site de DataCamp. Pour cette première prise en main, tout va maintenant se passer dans votre navigateur internet, et vous pouvez donc mettre de côté RStudio pour l’instant. Vous allez voir que l’interface de DataCamp ressemble à une version simplifiée de l’éditeur de script et de la console de RStudio : vous n’aurez pas à vous soucier des réglages, de Rprojects ou de sauvegarder quoi que ce soit. Si vous avez correctement créé votre compte gratuit DataCamp comme indiqué au tout début de la Chapitre 1, votre progression sera sauvegardée automatiquement. Il vous suffit de cliquer sur les liens direct ci-dessous pour démarrer les tutoriels en ligne.\nAvant de démarrer, quelques précisions :\n\npour chaque tutoriel que je vous demande de suivre, j’indique ci-dessous une liste des concepts de programmation qui sont couverts. N’hésitez pas à vous y référer (et à y revenir) tout au long du semestre si vous avez oublié certaines choses\nce tutoriel DataCamp contient 6 chapitres. Seuls les chapitres 1, 2, 4, et 5 doivent être suivis. Nous ne travaillerons pas sur les matrices ni sur les listes\nà la fin de chaque chapitre du tutoriel, revenez à ce livre en ligne pour cliquer sur le lien direct ver le chapitre suivant. Procéder ainsi vous évitera de suivre des chapitres inutiles du tutoriel, et cela vous permettra également d’éviter les demandes d’inscriptions payantes à DataCamp\n\nIl est important de noter que, bien que ces tutoriels sont d’excellentes introductions, une lecture seule, même attentive, est insuffisante pour un apprentissage en profondeur et une rétention à long terme. Il faut pour cela pratiquer et répéter. Outre les exercices demandés dans DataCamp, que vous devez effectuer directement dans votre navigateur, je vous encourage à prendre des notes, à multiplier les essais, directement dans la console de RStudio, ou, de préférence, dans un script que vous annoterez, pour vous assurer que vous avez bien compris chaque partie.\nAllez maintenant découvrir le cours d’introduction à R sur DataCamp, et cliquez sur les liens des chapitres ci-dessous. Au fur et à mesure de votre travail, notez les termes importants et ce à quoi ils font référence.\n\nChapitre 1 : introduction\n\nLa console : l’endroit où vous tapez des commandes\nLes objets : où les valeurs sont stockées, comment assigner des valeurs à des objets\nLes types de données : entiers, doubles/numériques, caractères et logiques\n\nChapitre 2 : vecteurs\n\nLes vecteurs : des collections de valeurs du même type\n\nChapitre 4 : les facteurs\n\nDes données catégorielles (et non pas numériques) représentées dans R sous forme de factors\n\nChapitre 5 : les jeux de données ou data.frame\n\nLes data.frames sont similaires aux feuilles de calcul rectangulaires que l’on peut produire dans un tableur. Dans R, ce sont des objets rectangulaires (des tableaux !) contenant des jeux de données : les lignes correspondent aux observations et les colonnes aux variables décrivant les observations. La plupart du temps, c’est le format de données que nous utiliserons. Plus de détails dans le Chapitre 2\n\n\nAvant de passer à la suite, il nous reste 2 grandes notions à découvrir dans le domaine du code et de la syntaxe afin de pouvoir travailler efficacement dans R : les opérateurs de comparaison d’une part, et les fonctions d’autre part. Pour les découvrir et expérimenter, et puisque vous avez terminé les tutoriels DataCamp, reprenez maintenant RStudio et travaillez dans votre script.\n\n\n1.3.4.2 Opérateurs de comparaison\nComme leur nom l’indique, ils permettent de comparer des valeurs ou des objets. Les principaux opérateurs de comparaison sont :\n\n== : égal à\n!= : différent de\n&gt; : supérieur à\n&lt; : inférieur à\n&gt;= : supérieur ou égal à\n&lt;= : inférieur ou égal à\n\nAinsi, on peut tester si 3 est égal à 5 :\n\n3 == 5\n\n[1] FALSE\n\n\nLa réponse est bien entendu FALSE. Est-ce que 3 est inférieur à 5 ?\n\n3 &lt; 5\n\n[1] TRUE\n\n\nLa réponse est maintenant TRUE. Lorsque l’on utilise un opérateur de comparaison, la réponse est toujours soit vrai (TRUE), soit faux (FALSE).\nIl est aussi possible de comparer des chaînes de charactères :\n\n\"Bonjour\" == \"Au revoir\"\n\n[1] FALSE\n\n\"Bonjour\" &gt;= \"Au revoir\"\n\n[1] TRUE\n\n\nManifestement, “Bonjour” est supérieur ou égal à “Au revoir”. En fait, R utilise l’ordre alphabétique pour comparer les chaînes de caractères. Puisque dans l’alphabet, le “B” de “Bonjour” arrive après le “A” de “Au revoir”, pour R, “Bonjour” est supérieur à “Au revoir”.\nIl est également possible d’utiliser ces opérateurs pour comparer un chiffre et un vecteur :\n\ntailles_pop1 &lt;- c(112, 28, 86, 14, 154, 73, 63, 48)\ntailles_pop1 &gt; 80\n\n[1]  TRUE FALSE  TRUE FALSE  TRUE FALSE FALSE FALSE\n\n\nIci, l’opérateur nous permet d’identifier quels éléments du vecteur taille_pop1 sont supérieurs à 80. Il s’agit des éléments placés en première, troisième et cinquième positions.\nIl est aussi possible de comparer 2 vecteurs qui contiennent le même nombre d’éléments :\n\ntailles_pop2 &lt;- c(114, 27, 38, 91, 54, 83, 33, 68)\ntailles_pop1 &gt; tailles_pop2\n\n[1] FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE FALSE\n\n\nLes comparaisons sont ici faites élément par élément. Ainsi, les observations 2, 3, 5 et 7 du vecteur tailles_pop1 sont supérieures aux observations 2, 3, 5 et 7 du vecteur tailles_pop2 respectivement.\nCes vecteurs de vrais/faux sont très utiles car ils peuvent permettre de compter le nombre d’éléments répondant à une certains condition :\n\nsum(tailles_pop1 &gt; tailles_pop2)\n\n[1] 4\n\n\nLorsque l’on effectue une opération arithmétique (comme le calcul d’une somme ou d’une moyenne) sur un vecteur de vrais/faux, les TRUE sont remplacés par 1 et les FALSE par 0. La somme nous indique donc le nombre de vrais dans un vecteur de vrais/faux, et la moyenne nous indique la proportion de vrais :\n\nmean(tailles_pop1 &gt; tailles_pop2)\n\n[1] 0.5\n\n\nNote : Attention, si les vecteurs comparés n’ont pas la même taille, un message d’avertissement est affiché :\n\ntailles_pop3 &lt;- c(43, 56, 92)\ntailles_pop1\n\n[1] 112  28  86  14 154  73  63  48\n\ntailles_pop3\n\n[1] 43 56 92\n\ntailles_pop3 &gt; tailles_pop1\n\nWarning in tailles_pop3 &gt; tailles_pop1: la taille d'un objet plus long n'est\npas multiple de la taille d'un objet plus court\n\n\n[1] FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE\n\n\nIci, R renvoie un résultat, accompagné d’un message d’avertissement qui nous indique que tout ne s’est probablement pas déroulé comme on le pensait. Dans un cas comme celui là, R va en effet recycler l’objet le plus court, ici tailles_pop3 pour qu’une comparaison puisse être faite avec chaque élément de l’objet le plus long (ici, tailles_pop1). Ainsi, 43 est comparé à 112, 56 est comparé à 28 et 92 est comparé à 86. Puisque tailles_pop3 ne contient plus d’éléments, ils sont recyclés, dans le même ordre : 43 est comparé à 14, 56 est comparé à 154, et ainsi de suite jusqu’à ce que tous les éléments de tailles_pop1 aient été passés en revue.\nCe type de recyclage est très risqué car il est difficile de savoir ce qui a été comparé avec quoi. En travaillant avec des tableaux plutôt qu’avec des vecteurs, le problème est généralement évité puisque toutes les colonnes d’un data.frame contiennent le même nombre d’éléments.\n\n\n\n\n\n\nErreur ou avertissement ?  ou  ?\n\n\n\nIl ne faut pas confondre message d’erreur et message d’avertissement :\n\nUn message d’erreur commence généralement par Error ou Erreur et indique que R n’a pas compris ce que vous lui demandiez. Il n’a donc pas été en mesure de faire quoi que ce soit et votre commande n’a donc pas été exécutée. Vous devez absolument revenir à votre code et corriger la commande fautive car il y a fort à parier que si vous ne le faites pas, les commandes suivantes renverrons à leur tour un message d’erreur. Il est donc important de toujours revenir à la première erreur d’un script et de la corriger avant de passer à la suite.\nUn message d’avertissement commence généralement par Warning et vous indique que quelque chose d’inhabituel, ou de “non-optimal” a été réalisé. Un résultat a été produit, mais peut-être n’est-il pas conforme à ce que vous attendiez. La prudence est donc requise.\n\nDans les deux cas, un message explique de façon plus ou moins claire ce qui a posé problème. Progresser dans la maîtrise du logiciel et du langage signifie en grande partie progresser dans la compréhension de la signification de ces messages parfois obscures. Pour progresser, il faut donc commencer par lire attentivement ces messages, et tenter de comprendre ce qu’ils veulent dire.\n\n\nDernière chose concernant les opérateurs de comparaison : la question des données manquantes. Dans R les données manquantes sont symbolisées par cette notation : NA, abréviation de “Not Available”. Le symbole NaN (comme “Not a Number”) est parfois aussi observé lorsque des opérations ont conduit à des indéterminations. Mais c’est plus rare et la plupart du temps, les NaNs peuvent être traités comme les NAs. L’un des problèmes des données manquantes est qu’il est nécessaire de prendre des précautions pour réaliser des comparaisons les impliquant :\n\n3 == NA\n\n[1] NA\n\n\nOn s’attend logiquement à ce que 3 ne soit pas considéré comme égal à NA, et donc, on s’attend à obtenir FALSE. Pourtant, le résultat est NA. La comparaison d’un élément quelconque à une donnée manquante fournit toujours une donnée manquante : la comparaison ne peut pas se faire, R n’a donc rien à retourner. C’est également le cas aussi lorsque l’on compare deux valeurs manquantes :\n\nNA == NA\n\n[1] NA\n\n\nC’est en fait assez logique. Imaginons que j’ignore l’âge de Pierre et l’âge de Marie. Il n’y a aucune raison pour que leur âge soit le même, mais il est tout à fait possible qu’il le soit. C’est impossible à déterminer :\n\nage_Pierre &lt;- NA\nage_Marie &lt;- NA\nage_Pierre == age_Marie\n\n[1] NA\n\n\nMais alors comment faire pour savoir si une valeur est manquante puisqu’on ne peut pas utiliser les opérateurs de comparaison ? On utilise la fonction is.na() :\n\nis.na(age_Pierre)\n\n[1] TRUE\n\nis.na(tailles_pop3)\n\n[1] FALSE FALSE FALSE\n\n\nD’une façon générale, le point d’exclamation permet de signifier à R que nous souhaitons obtenir le contraire d’une expression :\n\n!is.na(age_Pierre)\n\n[1] FALSE\n\n!is.na(tailles_pop3)\n\n[1] TRUE TRUE TRUE\n\n\nCette fonction nous sera très utile plus tard pour éliminer toutes les lignes d’un tableau contenant des valeurs manquantes.\n\n\n1.3.4.3 L’utilisation des fonctions\nDans R, les fonctions sont des objets particuliers qui permettent d’effectuer des tâches très variées. Du calcul d’une moyenne à la création d’un graphique, en passant par la réalisation d’analyses statistiques complexes ou simplement l’affichage du chemin du répertoire de travail, tout, dans R, repose sur l’utilisation de fonctions. Vous en avez déjà vu un certain nombre :\n\n\n\n\n\n\n\nFonction\nPour quoi faire ?\n\n\n\n\nc()\nCréer des vecteurs\n\n\nclass()\nAfficher ou modifier la classe d’un objet\n\n\nfactor()\nCréer des facteurs\n\n\ngetwd()\nAfficher le chemin du répertoire de travail\n\n\nhead()\nAfficher les premiers éléments d’un objet\n\n\nis.na()\nTester si un objet contient des valeurs manquantes\n\n\nmean()\nCalculer une moyenne\n\n\nnames()\nAfficher ou modifier le nom des éléments d’un vecteur\n\n\norder()\nOrdonner les éléments d’un objet\n\n\nsubset()\nExtraire une partie des éléments d’un objet\n\n\nsum()\nCalculer une somme\n\n\ntail()\nAfficher les derniers éléments d’un objet\n\n\n\nCette liste va très rapidement s’allonger au fil des séances. Je vous conseille donc vivement de tenir à jour une liste des fonctions décrites, avec une explication de leur fonctionnement et éventuellement un exemple de syntaxe.\nCertaines fonctions ont besoin d’arguments (par exemple, la fonction factor()), d’autres peuvent s’en passer (par exemple, la fonction getwd()). Pour apprendre comment utiliser une fonction particulière, pour découvrir quels sont ses arguments possibles, quel est leur rôle et leur intérêt, la meilleure solution est de consulter l’aide de cette fonction. Il suffit pour cela de taper un ? suivi du nom de la fonction :\n\n?factor()\n\nToutes les fonctions et jeux de données disponibles dans R disposent d’un fichier d’aide similaire. Cela peut faire un peu peur au premier abord (tout est en anglais !), mais ces fichiers d’aide ont l’avantage d’être très complets, de fournir des exemples d’utilisation, et ils sont tous construits sur le même modèle. Vous avez donc tout intérêt à vous familiariser avec eux. Vous devriez d’ailleurs prendre l’habitude de consulter l’aide de chaque fonction qui vous pose un problème. Par exemple, le logarithme (en base 10) de 100 devrait faire 2, car 100 est égal à 10^2. Pourtant :\n\nlog(100)\n\n[1] 4.60517\n\n\nQue se passe-t’il ? Pour le savoir, il faut consulter l’aide de la fonction log :\n\n?log()\n\nCe fichier d’aide nous apprend que par défaut, la syntaxe de la fonction log() est la suivante :\n\nlog(x, base = exp(1))\n\nPar défaut, la base du logarithme est fixée à exp(1). Nous avons donc calculé un logarithme népérien (en base e). Cette fonction prend donc 2 arguments :\n\nx ne possède pas de valeur par défaut : il nous faut obligatoirement fournir quelque chose (la rubrique “Argument” du fichier d’aide nous indique que x doit être un vecteur numérique ou complexe) afin que la fonction puisse calculer un logarithme\nbase possède un argument par défaut. Si nous ne spécifions pas nous même la valeur de base, elle sera fixée à sa valeur par défaut, c’est à dire exp(1).\n\nPour calculer le logarithme de 100 en base 10, il faut donc taper, au choix, l’une de ces 3 expressions :\n\nlog(x = 100, base = 10)\n\n[1] 2\n\nlog(100, base = 10)\n\n[1] 2\n\nlog(100, 10)\n\n[1] 2\n\n\nLe nom des arguments d’une fonction peut être omis tant que ses arguments sont indiqués dans l’ordre attendu par la fonction (cet ordre est celui qui est précisé à la rubrique “Usage” du fichier d’aide de la fonction). Il est possible de modifier l’ordre des arguments d’une fonction, mais il faut alors être parfaitement explicite et utiliser les noms des arguments tels que définis dans le fichier d’aide.\nAinsi, pour calculer le logarithme de 100 en base 10, on ne peut pas taper :\n\nlog(10, 100)\n\n[1] 0.5\n\n\ncar cela revient à calculer le logarithme de 10 en base 100. On peut en revanche taper :\n\nlog(base = 10, x = 100)\n\n[1] 2"
  },
  {
    "objectID": "01-R-basics.html#sec-packages",
    "href": "01-R-basics.html#sec-packages",
    "title": "1  R et RStudio : les bases",
    "section": "1.4 Les packages additionels",
    "text": "1.4 Les packages additionels\nUne source de confusion importante pour les nouveaux utilisateurs de R est la notion de package. Les packages étendent les fonctionnalités de R en fournissant des fonctions, des données et de la documentation supplémentaires et peuvent être téléchargés gratuitement sur Internet. Ils sont écrits par une communauté mondiale d’utilisateurs de R. Par exemple, parmi les plus de 18000 packages disponibles à l’heure actuelle, nous utiliseront fréquemment :\n\nLe package ggplot2 pour la visualisation des données dans le Chapitre 3\nLe package dplyr pour manipuler des tableaux de données dans le Chapitre 5\n\nUne bonne analogie pour les packages R : ils sont comme les apps que vous téléchargez sur un téléphone portable. R est comme un nouveau téléphone mobile. Il est capable de faire certaines choses lorsque vous l’utilisez pour la première fois, mais il ne sait pas tout faire. Les packages sont comme les apps que vous pouvez télécharger dans l’App Store et Google Play. Pour utiliser un package, comme pour utiliser Instagram, vous devez :\n\nLe télécharger et l’installer. Vous ne le faites qu’une fois grâce à la commande install.packages()\nLe charger (en d’autres termes, l’ouvrir) en utilisant la commande library() à chaque nouvelle session de travail\n\nDonc, tout comme vous ne pouvez commencer à partager des photos avec vos amis sur Instagram que si vous installez d’abord l’application et que vous l’ouvrez, vous ne pouvez accéder aux données et fonctions d’un package R que si vous installez d’abord le package et le chargez avec la fonction library(). Passons en revue ces 2 étapes.\n\n1.4.1 Installation d’un package\nIl y a deux façons d’installer un package. Par example, pour installer le package ggplot2 :\n\nLe plus simple : Dans le quart inférieur droit de l’interface de Rstudio :\n\nCliquez sur l’onglet “Packages”\nCliquez sur “Install”\nTapez le nom du package dans le champ “Packages (separate multiple with space or comma):” Pour notre exemple, tapez ggplot2\nCliquez sur “Install”\n\nMétode alternative : Dans la console, tapez install.packages(\"ggplot2\") (vous devez inclure les guillemets).\n\nEn procédant de l’une ou l’autre façon, installez également les packages suivants : tidyverse et palmerpenguins. Le tidyverse est un “méta-package”, qui permet en fait d’installer de nombreux packages en une seule commande, dont ggplot2, tidyr, dplyr, magrittr et bien d’autres. Le package palmerpenguins contient un jeu de données dont nous nous servirons copieusement dans les chapitres suivants.\n\n\n\n\n\n\nNote : install.packages()\n\n\n\nUn package doit être installé une fois seulement sur un ordinateur, sauf si une version plus récente est disponible et que vous souhaitez mettre à jour ce package. Il n’est donc pas nécessaire de laisser ces commandes dans votre script. Sinon, vous risquez de ré-installer les packages à chaque nouvelle session de travail, ce qui est inutile et consomme inutilement de la bande passante, des ressources numériques, et donc, du carbone…  \n\n\n\n\n1.4.2 Charger un package en mémoire\nAprès avoir installé un package, vous pouvez le charger en utilisant la fonction library(). Par exemple, pour charger ggplot2 et dplyr tapez ceci dans la console :\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\nPuisque ces packages font partie du tidyverse, on aurait pu les charger tous les deux (et d’autres) en une seule étape en tapant :\n\nlibrary(tidyverse)\n\nQuand vous exécutez une commande, si vous voyez un message d’erreur commençant par :\nError: could not find function...\nc’est probablement parce que vous tentez d’utiliser une fonction qui fait partie d’un package que vous n’avez pas chargé. Pour corriger l’erreur, il suffit donc de charger le package approprié avec la commande library().\n\n\n\n\n\n\nNote : library()\n\n\n\nVous devrez charger à nouveau chaque package que vous souhaitez utiliser à chaque fois que vous ouvrirez une nouvelle session de travail dans RStudio (à chaque nouveau démarrage du logiciel, donc). C’est une erreur fréquente pour les débutants. Pour l’éviter, pensez bien à intégrer, tout en haut de votre script, les commandes library() nécessaires pour chaque package que vous comptez utiliser."
  },
  {
    "objectID": "01-R-basics.html#sec-exo-1",
    "href": "01-R-basics.html#sec-exo-1",
    "title": "1  R et RStudio : les bases",
    "section": "1.5 Exercice",
    "text": "1.5 Exercice\nDans votre dossier de travail, créez un nouveau script que vous nommerez ExoDiamonds.R. Vous prendrez soin d’ajouter autant de commentaires que nécessaire dans votre script afin de le structurer correctement.\n\nTéléchargez (si besoin) et chargez le package ggplot2\nChargez le jeu de données diamonds grâce à la commande data(diamonds)\nDéterminez le nombre de lignes et de colonnes de ce tableau nommé diamonds\nCréez un nouveau tableau que vous nommerez diamants_chers qui contiendra uniquement les informations des diamants dont le prix est supérieur ou égal à $15000.\nCombien de diamants coûtent $15000 ou plus ?\nCela représente quelle proportion du jeu de données de départ ?\nTriez ce tableau par ordre de prix décroissants et affichez les informations des 20 diamants les plus chers."
  },
  {
    "objectID": "02-dataset.html#le-package-nycflights13",
    "href": "02-dataset.html#le-package-nycflights13",
    "title": "2  Explorez votre premier jeu de données",
    "section": "2.1 Le package nycflights13",
    "text": "2.1 Le package nycflights13\nNous avons probablement déjà presque tous pris l’avion. Les grands aéroports contiennent de nombreuses portes d’embarquement, et pour chacune d’elles, des informations sur les vols en partance sont affichées. Par exemple, le numéro du vol, les heures de décollage et d’atterrissage prévues, les retards etc. Dans la mesure du possible, on aime arriver à destination à l’heure. Dans la suite de ce document, on examinera les jeux de données du package nycflights13, notamment afin d’en apprendre plus sur les causes de retard les plus fréquentes.\nCe package contient 5 “tableaux” contenant des informations sur chaque vol intérieur ayant quitté New York en 2013, soit depuis l’aéroport de Newark Liberty International (EWR), soit depuis l’aéroport John F. Kennedy International (JFK), soit depuis l’aéroport LaGuardia (LGA) :\n\nflights : informations sur chacun des 336776 vols\nairlines : traduction entre les codes IATA à 2 lettres des compagnies aériennes et leur nom complet (il y en a 16 au total)\nplanes : informations constructeurs pour chacun des 3322 avions utilisés en 2013\nweather : données météorologiques heure par heure (environ 8705 observations) pour chacun des 3 aéroports de New York\nairports : noms et localisations géographiques des aéroports desservis (1458 aéroports)"
  },
  {
    "objectID": "02-dataset.html#le-data-frame-flights",
    "href": "02-dataset.html#le-data-frame-flights",
    "title": "2  Explorez votre premier jeu de données",
    "section": "2.2 Le data frame flights",
    "text": "2.2 Le data frame flights\nNous allons commencer par explorer le jeu de données flights qui est inclus avec le package nycflights13 afin de nous faire une idée de sa structure. Dans votre script, tapez la commande suivante et exécutez la dans la console (selon les réglages de RStudio et la largeur de votre console, l’affichage peut varier légèrement) :\n\nflights\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nEssayons de décrypter cet affichage :\n\nA tibble: 336,776 x 19 : un tibble est un data.frame amélioré. Il a toutes les caractéristiques d’un data.frame, (tapez class(flights) pour vous en convaincre), mais en plus, il a quelques propriétés intéressantes sur lesquelles nous reviendrons plus tard. Ce tibble possède donc :\n\n336776 lignes\n19 colonnes, qui correspondent aux variables. Dans un tibble, les observations sont toujours en ligne et les variables en colonnes.\n\nyear, month, day, dep_time, sched_dep_time… sont les noms des colonnes, c’est à dire les variables de ce jeu de données.\nNous avons ensuite les 10 premières lignes du tableau qui correspondent à 10 vols.\n... with 336,766 rows, and 12 more variables, nous indique que 336766 lignes et 12 variables ne logent pas à l’écran. Ces données font toutefois partie intégrante du tableau flights.\nle nom et le type de chaque variable qui n’a pas pu être affichée à l’écran\n\nCette façon d’afficher les tableaux est spécifique des tibbles. Vous noterez que le type de chaque variable est indiqué entre &lt;...&gt;. Les types que vous pourrez rencontrer sont les suivants :\n\n&lt;int&gt; : nombres entiers (“integers”)\n&lt;dbl&gt; : nombres réels (“doubles”)\n&lt;chr&gt; : caractères (“characters”)\n&lt;fct&gt; : facteurs (“factors”)\n&lt;ord&gt; : facteurs ordonnés (“ordinals”)\n&lt;lgl&gt; : logiques (colonne de vrais/faux : “logical”)\n&lt;date&gt; : dates\n&lt;time&gt; : heures\n&lt;dttm&gt; : combinaison de date et d’heure (“date time”)\n\nCette façon d’afficher le contenu d’un tableau permet d’y voir (beaucoup) plus clair que l’affichage classique d’un data.frame. Malheureusement, ce n’est pas toujours suffisant. Voyons quelles sont les autres méthodes permettant d’explorer un data.frame."
  },
  {
    "objectID": "02-dataset.html#explorer-un-data.frame",
    "href": "02-dataset.html#explorer-un-data.frame",
    "title": "2  Explorez votre premier jeu de données",
    "section": "2.3 Explorer un data.frame",
    "text": "2.3 Explorer un data.frame\nParmi les nombreuses façons d’avoir une idée des données contenues dans un data.frame tel que flights, on présente ici 3 fonctions qui prennent le nom du data.frame en guise d’argument et un opérateur :\n\nla fonction View() intégrée à RStudio. C’est celle que vous utiliserez le plus souvent. Attention, elle s’écrit avec un “V” majuscule.\nla fonction glimpse() chargée avec le package dplyr. Elle est très similaire à la fonction str() découverte dans les tutoriels de DataCamp.\nl’opérateur $ permet d’accéder à une unique variable d’un data.frame.\nla fonction skim() du package skimr permet d’obtenir un résumé complet mais très synthétique et visuel des variables d’un data.frame.\n\n\n2.3.1 View()\nTapez View(flights) dans votre script et exécutez la commande. Un nouvel onglet contenant ce qui ressemble à un tableur doit s’ouvrir.\n\nQuestion  : à quoi correspondent chacune des lignes de ce tableau ?\n\nA. aux données d’une compagnie aérienne\nB. aux données d’un vol\nC. aux données d’un aéroport\nD. aux données de plusieurs vols\n\n\nIci, vous pouvez donc explorer la totalité du tableau, passer chaque variable en revue, et même appliquer des filtres pour ne visualiser qu’une partie des données. Par exemple, essayez de déterminer combien de vols ont décollé de l’aéroport JFK le 12 février.\nCe tableau n’est pas facile à manipuler. Il est impossible de corriger des valeurs, et lorsque l’on applique des filtres, il est impossible de récupérer uniquement les données filtrées. Nous verrons plus tard comment les obtenir en tapant des commandes simples dans un script. La seule utilité de ce tableau est donc l’exploration visuelle des données.\n\n\n2.3.2 glimpse()\nLa seconde façon d’explorer les données contenues dans un tableau est d’utiliser la fonction glimpse() après avoir chargé le package dplyr :\n\nglimpse(flights)\n\nRows: 336,776\nColumns: 19\n$ year           &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2…\n$ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ dep_time       &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558, …\n$ sched_dep_time &lt;int&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 600, …\n$ dep_delay      &lt;dbl&gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2, -1…\n$ arr_time       &lt;int&gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 849,…\n$ sched_arr_time &lt;int&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 851,…\n$ arr_delay      &lt;dbl&gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7, -1…\n$ carrier        &lt;chr&gt; \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\", \"…\n$ flight         &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, 4…\n$ tailnum        &lt;chr&gt; \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N394…\n$ origin         &lt;chr&gt; \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LGA\",…\n$ dest           &lt;chr&gt; \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IAD\",…\n$ air_time       &lt;dbl&gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149, 1…\n$ distance       &lt;dbl&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733, …\n$ hour           &lt;dbl&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6…\n$ minute         &lt;dbl&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 0…\n$ time_hour      &lt;dttm&gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 0…\n\n\nIci, les premières observations sont présentées en lignes pour chaque variable du jeu de données. Là encore, le type de chaque variable est précisé. Essayez d’identifier 3 variables catégorielles. À quoi correspondent-elles ? En quoi sont-elles différentes des variables numériques ?\n\n\n2.3.3 L’opérateur $\nEnfin, l’opérateur $ permet d’accéder à une unique variable grâce à son nom. Par exemple le tableau airlines contient seulement 2 variables :\n\nairlines\n\n# A tibble: 16 × 2\n   carrier name                       \n   &lt;chr&gt;   &lt;chr&gt;                      \n 1 9E      Endeavor Air Inc.          \n 2 AA      American Airlines Inc.     \n 3 AS      Alaska Airlines Inc.       \n 4 B6      JetBlue Airways            \n 5 DL      Delta Air Lines Inc.       \n 6 EV      ExpressJet Airlines Inc.   \n 7 F9      Frontier Airlines Inc.     \n 8 FL      AirTran Airways Corporation\n 9 HA      Hawaiian Airlines Inc.     \n10 MQ      Envoy Air                  \n11 OO      SkyWest Airlines Inc.      \n12 UA      United Air Lines Inc.      \n13 US      US Airways Inc.            \n14 VX      Virgin America             \n15 WN      Southwest Airlines Co.     \n16 YV      Mesa Airlines Inc.         \n\n\nNous pouvons accéder à ces variables grâce à leur nom :\n\nairlines$name\n\n [1] \"Endeavor Air Inc.\"           \"American Airlines Inc.\"     \n [3] \"Alaska Airlines Inc.\"        \"JetBlue Airways\"            \n [5] \"Delta Air Lines Inc.\"        \"ExpressJet Airlines Inc.\"   \n [7] \"Frontier Airlines Inc.\"      \"AirTran Airways Corporation\"\n [9] \"Hawaiian Airlines Inc.\"      \"Envoy Air\"                  \n[11] \"SkyWest Airlines Inc.\"       \"United Air Lines Inc.\"      \n[13] \"US Airways Inc.\"             \"Virgin America\"             \n[15] \"Southwest Airlines Co.\"      \"Mesa Airlines Inc.\"         \n\n\nCela nous permet de récupérer les données sous la forme d’un vecteur. Attention toutefois, le tableau flights contient tellement de lignes, que récuppérer une variable grâce à cet opérateur peut rapidement saturer la console. Si, par exemple, vous souhaitez extraire les données relatives aux compagnies aériennes (colonne carrier) du tableau flights, vous pouvez taper ceci :\n\nflights$carrier\n\nLe résultat est pour le moins indigeste ! Lorsqu’un tableau contient de nombreuses lignes, c’est rarement une bonne idée de transformer l’une de ses colonnes en vecteur. Dans la mesure du possible, les données d’un tableau doivent rester dans le tableau.\n\n\n2.3.4 skim()\nPour utiliser la fonction skim(), vous devez au préalable installer le package skimr :\n\ninstall.packages(\"skimr\")\n\nCe package est un peu “expérimental” et il se peut que l’installation pose problème. Si un message d’erreur apparaît lors de l’installation, procédez comme suit :\n\nQuittez RStudio (sans oublier de sauvegarder votre travail au préalable)\nRelancez RStudio et dans la console, tapez ceci :\n\n\ninstall.packages(\"rlang\")\n\n\nTentez d’installer skimr à nouveau.\nExécutez à nouveau votre script afin de retrouver votre travail dans l’état où il était avant de quitter RStudio.\n\nSi l’installation de skimr s’est bien passée, vous pouvez maintenant taper ceci :\n\nlibrary(skimr)\nskim(flights)\n\n\n\n2.3.5 Les fichiers d’aide\nUne fonctionalité particulièrement utile de R est son système d’aide. On peut obtenir de l’aide au sujet de n’importe quelle fonction et de n’importe quel jeu de données en tapant un “?” immédiatement suivi du nom de la fonction ou de l’objet.\nPar exemple, examinez l’aide du jeu de données flights :\n\n?flights\n\nVous devriez absolument prendre l’habitude d’examiner les fichiers d’aide des fonctions ou jeux de données pour lesquels vous avez des questions. Ces fichiers sont très complets, et même s’il peuvent paraître impressionnants au premier abord, ils sont tous structurés sur le même modèle et vous aideront à comprendre comment utiliser les fonctions, quels sont les arguments possibles, à quoi ils servent et comment les utiliser.\nPrenez le temps d’examiner le fichier d’aide du jeu de données flights. Avant de passer à la suite, assurez-vous d’avoir compris à quoi correspondent chacune des 19 variables de ce tableau."
  },
  {
    "objectID": "02-dataset.html#sec-exo-2",
    "href": "02-dataset.html#sec-exo-2",
    "title": "2  Explorez votre premier jeu de données",
    "section": "2.4 Exercices",
    "text": "2.4 Exercices\nConsultez l’aide du jeu de données diamonds du package ggplot2.\n\nQuel est le code de la couleur la plus prisée ?\nQuel est le code de la moins bonne clarté ?\nÀ quoi correspond la variable z ?\nEn quoi la variable depth est-elle différente de la variable z ?\n\nConsultez l’aide du package nycflights13 en tapant help(package=\"nycflights13\").\n\nConsultez l’aide des 5 jeux de données de ce package.\nÀ quoi correspond la variable visib ?\nDans quel tableau se trouve-t’elle ?\nCombien de lignes possède ce tableau ?"
  },
  {
    "objectID": "03-visualization.html#prérequis",
    "href": "03-visualization.html#prérequis",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.1 Prérequis",
    "text": "3.1 Prérequis\nDans ce chapitre, nous aurons besoin des packages suivants :\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(nycflights13)\n\nSi ce n’est pas déjà fait, pensez à les installer avant de les charger en mémoire.\nAu niveau le plus élémentaire, les graphiques permettent de comprendre comment les variables se comparent en termes de tendance centrale (à quel endroit les valeurs ont tendance à être localisées, regroupées) et leur dispersion (comment les données varient autour du centre). La chose la plus importante à savoir sur les graphiques est qu’ils doivent être créés pour que votre public (le professeur qui vous évalue, le collègue avec qui vous collaborez, votre futur employeur, etc.) comprenne bien les résultats et les informations que vous souhaitez transmettre. Il s’agit d’un exercice d’équilibriste : d’une part, vous voulez mettre en évidence autant de relations significatives et de résultats intéressants que possible, mais de l’autre, vous ne voulez pas trop en inclure, afin d’éviter de rendre votre graphique illisible ou de submerger votre public. Tout comme n’importe quel paragraphe de document écrit, un graphique doit permettre de communiquer un message (une idée forte, un résultat marquant, une hypothèse nouvelle, etc).\nComme nous le verrons, les graphiques nous aident également à repérer les tendances extrêmes et les valeurs aberrantes dans nos données. Nous verrons aussi qu’une façon de faire, assez classique, consiste à comparer la distribution d’une variable quantitative pour les différents niveaux d’une variable catégorielle."
  },
  {
    "objectID": "03-visualization.html#sec-gggraph",
    "href": "03-visualization.html#sec-gggraph",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.2 La grammaire des graphiques",
    "text": "3.2 La grammaire des graphiques\nLes lettres gg du package ggplot2 sont l’abréviation de “grammar of graphics” : la grammaire des graphiques. De la même manière que nous construisons des phrases en respectant des règles grammaticales précises (usage des noms, des verbes, des sujets et adjectifs…), la grammaire des graphiques établit un certain nombre de règles permettant de construire des graphiques : elle précise les composants d’un graphique en suivant le cadre théorique défini par Wilkinson (2005).\n\n3.2.1 Éléments de la grammaire\nEn bref, la grammaire des graphiques nous dit que :\n\nUn graphique est l’association (mapping) de données/variables (data) à des attributs esthétiques (aesthetics) d’objets géométriques (geometric objects).\n\nPour clarifier, on peut disséquer un graphique en 3 éléments essentiels :\n\ndata : le jeu de données contenant les variables que l’on va associer à des objets géométriques\ngeom : les objets géométriques en question. Cela fait référence aux types d’objets que l’on peut observer sur le graphique (des points, des lignes, des barres, etc.)\naes : les attributs esthétiques des objets géométriques présents sur le graphique. Par exemple, la position sur les axes x et y, la couleur, la taille, la transparence, la forme, etc. Chacun de ces attributs esthétiques peut-être associé à une variable de notre jeu de données.\n\nExaminons un exemple pour bien comprendre.\n\n\n3.2.2 Gapminder\nEn février 2006, un statisticien du nom de Hans Rosling a donné un TED Talk intitulé “The best stats you’we ever seen”. Au cours de cette conférence, Hans Rosling présente des données sur l’économie mondiale, la santé et le développement des pays du monde. Les données sont disponibles sur ce site et dans le package gapminder.\nPour l’année 2007, le jeu de données contient des informations pour 142 pays. Examinons les premières lignes de ce jeu de données :\n\n\n\nLes 6 premières lignes du jeu de données gapminder pour l’année 2007.\n\n\nCountry\nContinent\nLife Expectancy\nPopulation\nGDP per Capita\n\n\n\n\nAfghanistan\nAsia\n43.828\n31889923\n974.5803\n\n\nAlbania\nEurope\n76.423\n3600523\n5937.0295\n\n\nAlgeria\nAfrica\n72.301\n33333216\n6223.3675\n\n\nAngola\nAfrica\n42.731\n12420476\n4797.2313\n\n\nArgentina\nAmericas\n75.320\n40301927\n12779.3796\n\n\nAustralia\nOceania\n81.235\n20434176\n34435.3674\n\n\n\n\n\nPour chaque ligne, les variables suivantes sont décrites :\n\nCountry : le pays\nContinent : le continent\nLife Expectancy : espérance de vie à la naissance\nPopulation : nombre de personnes vivant dans le pays\nGDP per Capita : produit intérieur brut (PIB) par habitant en dollars américains. GDP est l’abréviation de “Growth Domestic Product”. C’est un indicateur de l’activité économique d’un pays, parfois utilisé comme une approximation du revenu moyen par habitant.\n\nExaminons maintenant la Figure 3.1 qui représente ces variables pour chacun des 142 pays de ce jeu de données (notez l’utilisation de la notation scientifique dans la légende).\n\n\n\n\n\nFigure 3.1: Espérance de vie en fonction du PIB par habitant en 2007.\n\n\n\n\nSi on décrypte ce graphique du point de vue de la grammaire des graphiques, on voit que :\n\nla variable GDP per Capita est associée à l’aesthetic x de la position des points\nla variable Life Expectancy est associée à l’aesthetic y de la position des points\nla variable Population est associée à l’aesthetic size (taille) des points\nla variable Continent est associée à l’aesthetic color (couleur) des points\n\nIci, l’objet géométrique (ou geom) qui représente les données est le point. Les données (ou data) sont contenues dans le tableau gapminder et chacune de ces variables est associée (mapping) aux caractéristiques esthétiques des points.\n\n\n3.2.3 Autres éléments de la grammaire des graphiques\nOutre les éléments indispensables évoqués ici (data, mapping, aes, et geom), il existe d’autres aspects de la grammaire des graphiques qui permettent de contrôler l’aspect des graphiques. Ils ne sont pas toujours indispensables. Nous en verrons néanmoins quelque-uns particulièrement utiles :\n\nfacet : c’est un moyen très pratique de scinder le jeu de données en plusieurs sous-groupes et de produire automatiquement un graphique pour chacun d’entre eux.\nposition : permet notamment de modifier la position des barres d’un barplot.\nlabs : permet de définir les titres, sous-titres et légendes des axes d’un graphique\ntheme : permet de modifier l’apect général des graphiques en appliquant des thèmes prédéfinis ou en modifiant certains aspects de thèmes existants\n\n\n\n3.2.4 Le package ggplot2\nComme indiqué plus haut, le package ggplot2 (Wickham et al. 2023) permet de réaliser des graphiques dans R en respectant les principes de la grammaire des graphiques. Vous avez probablement remarqué que depuis le début de la Section 3.2, beaucoup de termes sont écrits dans la police réservée au code informatique. C’est parce que les éléments de la grammaire des graphiques sont tous précisés dans la fonction ggplot() qui demande, au grand minimum, que les éléments suivants soient spécifiés :\n\nle nom du data.frame contenant les variables qui seront utilisées pour le graphique. Ce nom correspond à l’argument data de la fonction ggplot().\nl’association des variables à des attributs esthétiques. Cela se fait grâce à l’argument mapping et la fonction aes()\n\nAprès avoir spécifié ces éléments, on ajoute des couches supplémentaires au graphique grâce au signe +. La couche la plus essentielle à ajouter à un graphique, est une couche contenant un élément géométrique, ou geom (par exemple des points, des lignes ou des barres). D’autres couches peuvent s’ajouter pour spécifier des titres, des facets ou des modifications des axes et des thèmes du graphique.\nDans le cadre de ce cours, nous nous limiterons aux 5 types de graphiques suivants :\n\nles nuages de points\nles graphiques en lignes\nles boîtes à moustaches ou boxplots\nles histogrammes\nles diagrammes bâtons"
  },
  {
    "objectID": "03-visualization.html#sec-clouds",
    "href": "03-visualization.html#sec-clouds",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.3 Les nuages de points",
    "text": "3.3 Les nuages de points\nC’est probablement le plus simple des 5 types de graphiques cités plus haut. Il s’agit de graphiques bi-variés pour lesquels une variable est associée à l’axe des abscisses, et une autre est associée à l’axe des ordonnées. Comme pour le graphique présenté à la Figure 3.1 ci-dessus, d’autres variables peuvent être associées à des caractéristiques esthétiques des points (transparence, taille, couleur, forme…).\nIci, dans le jeu de données flights, nous allons nous intéresser à la relation qui existe entre :\n\ndep_delay : le retard des vols au décollage, que nous placerons sur l’axe des “x”\narr_delay : le retard des mêmes vols à l’atterrissage, que nous placerons sur l’axe des “y”\n\nAfin d’avoir un jeu de données plus facile à utiliser, nous nous contenterons de visualiser les vols d’Alaska Airlines, dont le code de compagnie aérienne est \"AS\".\n\nalaska_flights &lt;- flights |&gt;\n  filter(carrier == \"AS\")\n\nIl est normal que vous ne compreniez pas encore les commandes ci-dessus : elles seront décrites dans le Chapitre 5. Retenez juste que nous avons créé un nouveau tableau, nommé alaska_flights, qui contient toutes les informations des vols d’Alaska Airlines. Commencez par examiner ce tableau avec la fonction View(). En quoi est-il différent du tableau flights ?\n\n3.3.1 La couche de base : la fonction ggplot()\nLa fonction ggplot() permet d’établir la première base du graphique. C’est grâce à cette fonction que l’on précise quel jeu de données utiliser et quelles variables placer sur les axes :\n\nggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay))\n\n\n\n\nFigure 3.2: Un graphique sans geom.\n\n\n\n\nCe graphique est pour le moins vide : c’est normal, nous n’avons pas encore spécifié la couche contenant l’objet géométrique que nous souhaitons utiliser.\n\n\n3.3.2 Ajout d’une couche supplémentaire : l’objet géométrique\nLes nuages de points sont créés par la fonction geom_point() :\n\nggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) + \n  geom_point()\n\nWarning: Removed 5 rows containing missing values (`geom_point()`).\n\n\n\n\n\nFigure 3.3: Retards à l’arrivée en fonction des retards au décollage pour les vols d’Alaska Airlines au départ de New York City en 2013.\n\n\n\n\nPlusieurs choses importantes sont à remarquer sur la Figure 3.3 :\n\nle graphique présente maintenant une couche supplémentaire constituée de points.\nla fonction geom_point() nous prévient que 5 lignes contenant des données manquantes n’ont pas été intégrées au graphique. Les données manquent soit pour une variable, soit pour l’autre, soit pour les 2. Il est donc impossible de les faire apparaître sur le graphique.\nil existe une relation positive entre dep_delay et arr_delay : quand le retard d’un vol au décollage augmente, le retard de ce vol augmente aussi à l’arrivée.\nEnfin, il y a une grande majorité de points centrés près de l’origine (0,0).\n\nSi je résume cette syntaxe :\n\nAu sein de la fonction ggplot(), on spécifie 2 composants de la grammaire des graphiques :\n\nle nom du tableau contenant les données grâce à l’argument data = alaska_flights\nl’association (mapping) des variables à des caractéristiques esthétiques (aes()) en précisant aes(x = dep_delay, y = arr_delay) :\n\nla variable dep_delay est associée à l’esthétique de position x\nla variable arr_delay est associée à l’esthétique de position y\n\n\nOn ajoute une couche au graphique ggplot() grâce au symbole +. La couche en question précise le troisème élément indispensable de la grammaire des graphiques : l’objet geométrique. Ici, les objets sont des points. On le spécifie grâce à la fonction geom_point().\n\nQuelques remarques concernant les couches :\n\nNotez que le signe + est placé à la fin de la ligne. Vous recevrez un message d’erreur si vous le placez au début.\nQuand vous ajoutez une couche à un graphique, je vous encourage vivement à presser la touche enter de votre clavier juste après le symbole +. Ainsi, le code correspondant à chaque couche sera sur une ligne distincte, ce qui augmente considérablement la lisibilité de votre code.\nComme indiqué dans la Section 1.3.4.3, tant que les arguments d’une fonction sont spécifiés dans l’ordre, on peut se passer d’écrire leur nom. Ainsi, les deux blocs de commande suivants produisent exactement le même résultat :\n\n\n# Le nom des arguments est précisé\nggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) + \n  geom_point()\n\n# Le nom des arguments est omis\nggplot(alaska_flights, aes(x = dep_delay, y = arr_delay)) + \n  geom_point()\n\n\n\n3.3.3 Exercices\n\nDonnez une raison pratique expliquant pourquoi les variables dep_delay et arr_delay ont une relation positive\nQuelles variables (pas nécessairement dans le tableau alaska_flights) pourraient avoir une corrélation négative (relation négative) avec dep_delay ? Pourquoi ? Rappelez-vous que nous étudions ici des variables numériques.\nSelon vous, pourquoi tant de points sont-il regroupés près de (0, 0) ? À quoi le point (0,0) correspond-il pour les vols d’Alaska Airlines ?\nCitez les éléments de ce graphique/de ces données qui vous sautent le plus aux yeux ?\nCréez un nouveau nuage de points en utilisant d’autres variables du jeu de données alaska_flights\n\n\n\n3.3.4 Over-plotting\nL’over-plotting est la superposition importante d’une grande quantité d’information sur une zone restreinte d’un graphique. Dans notre cas, nous observons un over-plotting important autour de (0,0). Cet effet est gênant car il est difficile de se faire une idée précise du nombre de points accumulés dans cette zone. La façon la plus simple de régler le problème est de modifier la transparence des points grâce à l’argument alpha de la fonction geom_point(). Par défaut, cette valeur est fixée à 1, pour une opacité totale. Une valeur de 0 rend les points totalement transparents, et donc invisibles. Trouver la bonne valeur peut demander de tâtonner un peu. Le code suivant produit la Figure 3.4 :\n\nggplot(data = alaska_flights, \n       mapping = aes(x = dep_delay, y = arr_delay)) + \n  geom_point(alpha = 0.2)\n\n\n\n\nFigure 3.4: La même figure, avec des points semi-transparents.\n\n\n\n\nSur cette figure, notez que :\n\nla transparence est additive : plus il y a de points, plus la zone est foncée car les points se superposent et rendent la zone plus opaque.\nl’argument alpha = n’est pas intégré à l’intérieur d’une fonction aes() car ici, il n’est pas associé à une variable : c’est un simple paramètre.\n\nL’over-plotting est souvent rencontré lorsque l’on représente plusieurs nuages de points pour les différentes valeurs d’une variable catégorielle. Par exemple, si on transforme la variable month en facteur (factor(month)), on peut regarder s’il existe une relation entre les retards à l’atterrissage et le mois de l’année :\n\nggplot(data = alaska_flights, \n       mapping = aes(x = factor(month), y = arr_delay)) +\n  geom_point()\n\n\n\n\nFigure 3.5: Retards à l’arrivée pour les 12 mois de l’année 2013.\n\n\n\n\nIci (Figure 3.5), l’ajout de transparence ne serait pas suffisant. Une autre solution est d’appliquer la méthode dite du “jittering”, ou tremblement. Elle consiste à ajouter un bruit aléatoire horizontal et/ou vertical aux points d’un graphique. Ici, on peut ajouter un léger bruit horizontal afin de disperser un peu les points pour chaque mois de l’année. On n’ajoute pas de bruit vertical car on ne souhaite pas que les valeurs de retard (sur l’axe des y) soient altérées :\n\nggplot(data = alaska_flights, \n       mapping = aes(x = factor(month), y = arr_delay)) +\n  geom_jitter(width = 0.25)\n\n\n\n\nFigure 3.6: Retards à l’arrivée pour les 12 mois de l’année 2013.\n\n\n\n\nOn y voit déjà plus clair. L’argument width permet de spécifier l’intensité de la dispersion horizontale. Pour ajouter du bruit vertical (ce qui n’est pas souhaitable ici !), on peut ajouter l’argument height. Le graphique de la Figure 3.6 est parfois appelé un **stripchart*“**. C’est un graphique du type “nuage de points”, mais pour lequel l’une des 2 variables est numérique, et l’autre est catégorielle.\nIl est évidemment possible d’ajouter de la transparence :\n\nggplot(data = alaska_flights, \n       mapping = aes(x = factor(month), y = arr_delay)) +\n  geom_jitter(width = 0.25, alpha = 0.5)\n\n\n\n\nFigure 3.7: Retards à l’arrivée pour les 12 mois de l’année 2013.\n\n\n\n\n\n\n3.3.5 Couleur, taille et forme\nL’argument color (ou colour, les deux orthographes fonctionnent) permet de spécifier la couleur des points. L’argument size permet de spécifier la taille des points. L’argument shape permet de spécifier la forme utilisée en guise de symbole. Ces 3 arguments peuvent être utilisés comme des paramètres, pour modifier l’ensemble des points d’un graphique. Mais ils peuvent aussi être associés à une variable, pour apporter une information supplémentaire.\nComparez les deux graphiques de la Figure 3.8 :\n\nggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) +\n  geom_point(color = \"blue\")\n\nggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) +\n  geom_point(aes(color = \"blue\"))\n\n\n\n\n\n\n\n(a) Utilisation correcte de color.\n\n\n\n\n\n\n\n(b) Utilisation incorrecte de color.\n\n\n\n\nFigure 3.8: Où mettre color ? À l’intérieur ou à l’extérieur de aes() ?\n\n\n\nLe code qui permet de produire la Figure 3.8 (a) fait un usage correct de l’argument color. On demande des points de couleur bleue, les points apparaissent bleus. La figure Figure 3.8 (b) en revanche ne produit pas le résultat attendu. Puisque nous avons mis l’argument color à l’intérieur de la fonction aes(), R s’attend à ce que la couleur soit associée à une variable. Il crée donc artificiellement une variable nommée blue qu’il associe à chaque point de notre graphique et il crée nue légende à laquelle il associe la couleur par défaut. Cette façon de procéder est donc incorrecte. Pour associer la couleur des points à une variable, nous devons fournir un nom de variable valide :\n\nggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) +\n  geom_point(aes(color = factor(month)))\n\n\n\n\nFigure 3.9: Association de color à une variable catégorielle.\n\n\n\n\nIci, l’utilisation de la couleur est correcte. Elle est associée à une variable catégorielle, et chaque valeur possible du vecteur month se voit donc attribuer une couleur différente.\n\nggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) +\n  geom_point(aes(color = arr_time))\n\n\n\n\nFigure 3.10: Association de color à une variable numérique continue.\n\n\n\n\nDe la même façon, la couleur des points est ici associée à une variable continue (l’heure d’arrivée des vols). Les points se voient donc attribuer une couleur choisie le long d’un gradient.\nLa même approche peut être utilisée pour spécifier la forme des symboles avec l’argument shape. Attention toutefois : une variable continue ne peut pas être associée à shape\n\nggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) +\n  geom_point(aes(shape = factor(month)))\n\n\n\n\nFigure 3.11: Association de shape à un facteur.\n\n\n\n\nVous noterez que seuls les 6 premiers niveaux d’un facteur se voient attribuer une forme automatiquement. Au delà de 6 symboles différents sur un même graphique, le résultat est souvent illisible. Il est possible d’ajouter plus de 6 symboles, mais cela demande de modifier la légende manuellement et concrètement nous n’en aurons jamais besoin. Lorsque plus de 6 séries doivent être distinguées, d’autres solutions bien plus pertinentes (par exemple les factets) devraient être utilisées.\nComme pour la couleur, il est possible d’utiliser l’argument shape en tant que paramètre du graphique sans l’associer à une variable. Il faut alors fournir un code compris entre 0 et 24 :\n\nggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) +\n  geom_point(shape = 4)\n\n\n\n\nFigure 3.12: Utilisation de shape en tant que paramètre.\n\n\n\n\nNotez qu’ici, ggplot() ne crée pas de légende : tous les points ont le même symbole, ce symbole n’est pas associé à une variable, une légende est donc inutile.\nParmi les valeurs possibles pour shape, les symboles 21 à 24 sont des symboles dont on peut spécifier séparément la couleur de contour, avec color et la couleur de fond avec fill :\n\nggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) +\n  geom_point(shape = 21, fill = \"steelblue\", color = \"orange\", alpha = 0.5)\n\n\n\n\nFigure 3.13: Utilisation de shape, color et fill.\n\n\n\n\nN’hésitez pas à zoomer pour bien observer les points et comprendre ce qui se passe. Un conseil, faites des choix raisonnables ! Trop de couleurs n’est pas forcément souhaitable.\nEnfin, on peut ajuster la taille des symboles avec l’argument size. Tout comme il n’est pas possible d’associer une variable continue à shape, il n’est pas conseillé d’associer une variable catégorielle nominale (c’est-à-dire un facteur non ordonné) à size. Associer une variable continue est en revanche parfois utile :\n\nggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) +\n  geom_point(aes(size = arr_time), alpha = 0.1)\n\n\n\n\nFigure 3.14: Association d’une variable continue à la taille des symboles avec l’argument size.\n\n\n\n\nCe type de graphique est un “bubble plot”. Si l’over-plotting est ici très important (c’est pourquoi j’ai utilisé alpha), on constate néanmoins que les vols avec les retards les plus importants sont presque tous arrivés très tôt dans la journée (“500” signifie 5h00 du matin). Il s’agit probablement de vols qui devaient arriver dans la nuit, avant minuit, et qui sont finalement arrivés en tout début de journée, entre 00h01 et 5h00 du matin. Comme pour les autres arguments, il est possible d’utiliser size avec une valeur fixe, la même pour tous les symboles, lorsque cet argument n’est pas associé à une variable.\nEnfin un conseil : évitez de trop surcharger vos graphiques. En combinant l’ensemble de ces arguments, il est malheureusement très facile d’obtenir des graphiques peu lisibles, ou contenant tellement d’informations qu’ils en deviennent difficiles à déchiffrer. Faites preuve de modération :\n\nggplot(data = alaska_flights, \n       mapping = aes(x = dep_delay, y = arr_delay, size = arr_time)) +\n  geom_point(alpha = 0.6, \n             shape = 22,\n             color = \"orange\",\n             fill = \"steelblue\",\n             stroke = 2)\n\n\n\n\nFigure 3.15: Sometimes, less is more!\n\n\n\n\n\n\n3.3.6 Exercices\n\nÀ quoi sert l’argument stroke ?\nAvec le jeu de données diamonds, tapez les commandes suivantes pour créer un nouveau tableau diams contenant moins de lignes (5000 au lieu de près de 54000) :\n\n\nlibrary(dplyr)\nset.seed(4532) # Afin que tout le monde récupère les mêmes lignes\ndiams &lt;- diamonds |&gt; \n  sample_n(5000)\n\n\nAvec ce nouveau tableau diams, tapez le code permettant de créer le graphique Figure 3.16 (Indice : affichez le tableau diams dans la console afin de voir quelles sont les variables disponibles).\n\n\n\n\n\n\nFigure 3.16: Prix de 5000 diamants en fonction de leur taille en carats et de leur clarté.\n\n\n\n\n\nSelon vous, à quoi sont dues les bandes verticales que l’on observe sur ce graphique ?"
  },
  {
    "objectID": "03-visualization.html#les-graphiques-en-lignes",
    "href": "03-visualization.html#les-graphiques-en-lignes",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.4 Les graphiques en lignes",
    "text": "3.4 Les graphiques en lignes\n\n3.4.1 Un nouveau jeu de données\nLes graphiques en ligne, ou “linegraphs” sont généralement utilisés lorsque l’axe des x porte une information temporelle, et l’axe des y une autre variable numérique. Le temps est une variable naturellement ordonnée : les jours, semaines, mois, années, se suivent naturellement. Les graphiques en lignes devraient être évités lorsqu’il n’y a pas une organisation séquentielle évidente de la variable portée par l’axe des x.\nConcentrons nous maintenant sur le tableau weather du package nycflights13. Explorez ce tableau en appliquant les méthodes vues dans le Chapitre 2. N’oubliez pas de consultez l’aide de ce jeu de données.\n\nweather\n\n# A tibble: 26,115 × 15\n   origin  year month   day  hour  temp  dewp humid wind_dir wind_speed\n   &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1 EWR     2013     1     1     1  39.0  26.1  59.4      270      10.4 \n 2 EWR     2013     1     1     2  39.0  27.0  61.6      250       8.06\n 3 EWR     2013     1     1     3  39.0  28.0  64.4      240      11.5 \n 4 EWR     2013     1     1     4  39.9  28.0  62.2      250      12.7 \n 5 EWR     2013     1     1     5  39.0  28.0  64.4      260      12.7 \n 6 EWR     2013     1     1     6  37.9  28.0  67.2      240      11.5 \n 7 EWR     2013     1     1     7  39.0  28.0  64.4      240      15.0 \n 8 EWR     2013     1     1     8  39.9  28.0  62.2      250      10.4 \n 9 EWR     2013     1     1     9  39.9  28.0  62.2      260      15.0 \n10 EWR     2013     1     1    10  41    28.0  59.6      260      13.8 \n# ℹ 26,105 more rows\n# ℹ 5 more variables: wind_gust &lt;dbl&gt;, precip &lt;dbl&gt;, pressure &lt;dbl&gt;,\n#   visib &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nNous allons nous intéresser à la variable temp, qui contient un enregistrement de température pour chaque heure de chaque jour de 2013 pour les 3 aéroports de New York. Cela représente une grande quantité de données, aussi, nous nous limiterons aux températures observées entre le premier et le 15 janvier, pour l’aéroport Newark uniquement.\n\nsmall_weather &lt;- weather |&gt; \n  filter(origin == \"EWR\",\n         month == 1,\n         day &lt;= 15)\n\nLa fonction filter() fonctionne sur le même principe que la fonction subset() découverte dans les tutoriels de DataCamp. Ici, nous demandons à R de créer un nouveau tableau de données, nommé small_weather, qui ne contiendra que les lignes correspondant à origin == \"EWR\", month == 1 et day &lt;= 15, c’est à dire les données météorologiques de l’aéroport de Newark pour les 15 premiers jours de janvier 2013.\n\n\n3.4.2 Exercice\nAvec View(), consultez le tableau nouvellement créé. Expliquez pourquoi la variable time_hour identifie de manière unique le moment ou chaque mesure a été réalisée alors que ce n’est pas le cas de la variable hour.\n\n\n3.4.3 La fonction geom_line()\nLes line graphs sont produits de la même façon que les nuages de points. Seul l’objet géométrique permettant de visualiser les données change. Au lieu d’utiliser geom_point(), on utilisera geom_line() :\n\nggplot(data = small_weather, mapping = aes(x = time_hour, y = temp)) +\n  geom_line()\n\n\n\n\nFigure 3.17: Températures horaires à l’aéroport de Newark entre le 1er et le 15 janvier 2013.\n\n\n\n\nTrès logiquement, on observe des oscillations plus ou moins régulières qui correspondent à l’alternance jour/nuit. Notez l’échelle de l’axe des ordonnées : les températures sont enregistrées en degrés Fahrenheit.\nNous connaissons maintenant 2 types d’objets geométriques : les points et les lignes. Il est tout à fait possible d’ajouter plusieurs couches à un graphique, chacune d’elle correspondant à un objet geométrique différent (voir Figure 3.18) :\n\nggplot(data = small_weather, mapping = aes(x = time_hour, y = temp)) +\n  geom_line() +\n  geom_point()\n\n\n\n\nFigure 3.18: Températures horaires à l’aéroport de Newark entre le 1er et le 15 janvier 2013\n\n\n\n\nEnfin, comme pour les points, il est possible de spécifier plusieurs caractéristiques esthétiques des lignes, soit en les associant à des variables, au sein de la fonction aes(), soit en les utilisant en guise de paramètres pour modifier l’aspect général. Les arguments les plus classiques sont une fois de plus color (ou colour) pour modifier la couleur des lignes, linetype pour modifier le type de lignes (continues, pointillées, tirets, etc), et linewidth pour modifier l’épaisseur des lignes.\nReprenons le jeu de données complet weather, et filtrons uniquement les dates comprises entre le premier et le 15 janvier, mais cette fois pour les 3 aéroports de New York :\n\nsmall_weather_airports &lt;- weather |&gt; \n  filter(month == 1,\n         day &lt;= 15)\n\nNous pouvons maintenant réaliser un “linegraph” sur lequel une courbe apparaîtra pour chaque aéroport. Pour cela, nous devons associer la variable origin à un attribut esthétique des lignes. Par exemple (Figure 3.19) :\n\nggplot(data = small_weather_airports, \n       mapping = aes(x = time_hour, y = temp)) +\n  geom_line(aes(color = origin))\n\n\n\n\nFigure 3.19: Températures horaires des 3 aéroports de New York entre le 1er et le 15 janvier 2013.\n\n\n\n\nOu bien (figure Figure 3.20) :\n\nggplot(data = small_weather_airports, \n       mapping = aes(x = time_hour, y = temp)) +\n  geom_line(aes(linetype = origin))\n\n\n\n\nFigure 3.20: Températures horaires des 3 aéroports de New York entre le 1er et le 15 janvier 2013.\n\n\n\n\nOu encore (figure Figure 3.21) :\n\nggplot(data = small_weather_airports, \n       mapping = aes(x = time_hour, y = temp)) +\n  geom_line(aes(color = origin, linetype = origin))\n\n\n\n\nFigure 3.21: Températures horaires des 3 aéroports de New York entre le 1er et le 15 janvier 2013.\n\n\n\n\n\n\n3.4.4 À quel endroit placer aes() et les arguments color, size, etc. ?\nJusqu’à maintenant, pour spécifier les associations entre certaines variables et les caractéristiques esthétiques d’un graphique, nous avons été amenés à utiliser la fonction aes() à 2 endroits distincts :\n\nau sein de la fonction ggplot()\nau sein des fonctions geom_XXX()\n\nComment choisir l’endroit où renseigner aes() ? Pour bien comprendre, reprenons l’exemple de la Figure 3.18 sur lequel nous avions ajouté 2 couches contenant chacune un objet géométrique différent (afin de gagner de la place, j’omets volontairement le nom des arguments data et mapping dans la fonction ggplot()) :\n\nggplot(small_weather, aes(x = time_hour, y = temp)) +\n  geom_line() +\n  geom_point()\n\n\n\n\nFigure 3.22: Températures horaires à l’aéroport de Newark entre le 1er et le 15 janvier 2013.\n\n\n\n\nVoyons ce qui se passe si on associe la variable wind_speed à l’esthétique color, à plusieurs endroits du code ci-dessus. Comparez les trois syntaxes et observez les différences entre les 3 graphiques obtenus :\n\nggplot(small_weather, aes(x = time_hour, y = temp, color = wind_speed)) +\n  geom_line() +\n  geom_point()\n\n\n\n\nFigure 3.23: Températures horaires et vitesse du vent à l’aéroport de Newark entre le 1er et le 15 janvier 2013. La couleur de la ligne et des points renseigne sur la vitesse du vent.\n\n\n\n\n\nggplot(small_weather, aes(x = time_hour, y = temp)) +\n  geom_line(aes(color = wind_speed)) +\n  geom_point()\n\n\n\n\nFigure 3.24: Températures horaires et vitesse du vent à l’aéroport de Newark entre le 1er et le 15 janvier 2013. La couleur de la ligne renseigne sur la vitesse du vent.\n\n\n\n\n\nggplot(small_weather, aes(x = time_hour, y = temp)) +\n  geom_line() +\n  geom_point(aes(color = wind_speed))\n\n\n\n\nFigure 3.25: Températures horaires et vitesse du vent à l’aéroport de Newark entre le 1er et le 15 janvier 2013. La couleur des points renseigne sur la vitesse du vent.\n\n\n\n\nVous l’aurez compris, lorsque l’on spécifie aes() à l’intérieur de la fonction ggplot(), les associations de variables et d’esthétiques sont appliquées à tous les objets géométriques, donc à toutes les autres couches. En revanche, quand aes() est spécifié dans une couche donnée, les réglages ne s’appliquent qu’à cette couche spécifique.\nEn l’occurrence, si le même réglage est spécifié dans la fonction ggplot() et dans une fonction geom_XXX(), c’est le réglage spécifié dans l’objet géométrique qui l’emporte :\n\nggplot(small_weather, aes(x = time_hour, y = temp, color = wind_speed)) +\n  geom_line(color = \"orange\") +\n  geom_point()\n\n\n\n\nFigure 3.26: Températures horaires et vitesse du vent à l’aéroport de Newark entre le 1er et le 15 janvier 2013.\n\n\n\n\nIl est ainsi possible de spécifier des éléments esthétiques qui s’appliqueront à toutes les couches d’un graphique, et d’autres qui ne s’appliqueront qu’à une couche spécifique, qu’à un objet géométrique particulier."
  },
  {
    "objectID": "03-visualization.html#sec-histogram",
    "href": "03-visualization.html#sec-histogram",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.5 Les histogrammes",
    "text": "3.5 Les histogrammes\nUn histogramme permet de visualiser la distribution d’une variable numérique continue. Contrairement aux deux types de graphiques vus précédemment, il sera donc inutile de préciser la variable à associer à l’axe des ordonnées : R la calcule automatiquement pour nous lorsque nous faisons appel à la fonction geom_histogram() pour créer un objet géométrique “histogramme”.\n\n3.5.1 L’objet geom_histogram()\nSi on reprend le jeu de données weather, on peut par exemple s’intéresser à la distribution des températures tout au long de l’année :\n\nggplot(weather, aes(x = temp)) +\n  geom_histogram()\n\n\n\n\nFigure 3.27: Histogramme des températures enregistrées en 2013 dans les 3 aéroports de New York.\n\n\n\n\nOn observe plusieurs choses :\n\nLa distribution semble globalement bimodale avec un pic autour de 36-37 degrés Fahrenheit (2 à 3 ºC) et un autre autour de 65-70 degrés Fahrenheit (18-21 ºC).\nLes températures ont varié entre 12 degrés Fahrenheit (-11ºC) et 100 degrés Fahrenheit (près de 38ºC).\nR nous avertit qu’une valeur non finie n’a pas pu être intégrée.\nR nous indique qu’il a choisi de représenter 30 classes de températures (bins = 30). C’est la valeur par défaut. R nous conseille de choisir une valeur plus appropriée.\n\nComme pour les nuages de points utilisant les symboles 21 à 24, il est possible de spécifier la couleur de remplissage des barres avec l’argument fill et la couleur du contour des barres avec l’argument color :\n\nggplot(weather, aes(x = temp)) +\n  geom_histogram(fill = \"steelblue\", color = \"grey80\")\n\n\n\n\nFigure 3.28: Utilisation des arguments fill et color pour modifier l’aspect de l’histogramme.\n\n\n\n\n\n\n3.5.2 La taille des classes\nPar défaut, R choisit arbitrairement de représenter 30 classes. Ce n’est que rarement le bon choix, et il est souvent nécessaire de tâtonner pour trouver le nombre de classes approprié : celui qui permet d’avoir une idée correcte de la distribution des données.\nIl est possible d’ajuster les caractéristiques des classes de l’histogramme de l’une des 3 façons suivantes :\n\nEn ajustant le nombre de classes avec bins.\nEn précisant la largeur des classes avec binwidth.\nEn fournissant manuellement les limites des classes avec breaks.\n\n\nggplot(weather, aes(x = temp)) +\n  geom_histogram(bins = 60, color = \"white\")\n\n\n\n\nFigure 3.29: Modification du nombre de classes.\n\n\n\n\nIci, augmenter le nombre de classes à 60 permet de prendre conscience que la distribution n’est pas aussi lisse qu’elle en avait l’air. L’ajout d’une couche supplémentaire avec la fonction geom_rug() (“a rug” est un tapis en français) permet de prendre conscience que les données de température ne sont pas aussi continues qu’on pouvait le croire (figure Figure 3.30) :\n\nggplot(weather, aes(x = temp)) +\n  geom_histogram(bins = 60, color = \"white\") +\n  geom_rug(alpha = 0.1)\n\n\n\n\nFigure 3.30: Ajout des données brutes sous forme de ‘tapis’ (rug) sous l’histogramme.\n\n\n\n\nNotez la transparence importante utilisée pour geom_rug(). On constate que la précision des relevés de température n’est en fait que de quelques dixièmes de degrés.\nOn peut également modifier la largeur des classes avec binwidth :\n\nggplot(weather, aes(x = temp)) +\n  geom_histogram(binwidth = 10, color = \"white\")\n\n\n\n\nFigure 3.31: Modification de la largeur des classes avec binwidth.\n\n\n\n\nIci, chaque catégorie recouvre 10 degrés Fahrenheit, ce qui est probablement trop large puisque la bimodalité de la distribution est devenue presque invisible.\nEnfin, il est possible de déterminer manuellement les limites des classes souhaitées avec l’argument breaks (Figure 3.32) :\n\nggplot(weather, aes(x = temp)) +\n  geom_histogram(breaks = c(0, 10, 20, 50, 60, 70, 80, 105), color = \"white\")\n\n\n\n\nFigure 3.32: Spécification manuelle des limites de classes de tailles (classes irrégulières).\n\n\n\n\nVous constatez ici que les choix effectués ne sont pas très pertinents : toutes les classes n’ont pas la même largeur. Cela rend l’interprétation difficile. Il est donc vivement conseillé, pour spécifier breaks, de créer des suites régulières, comme avec la fonction seq() (consultez son fichier d’aide et les exemples) :\n\nlimits &lt;- seq(from = 10, to = 105, by = 5)\nlimits\n\n [1]  10  15  20  25  30  35  40  45  50  55  60  65  70  75  80  85  90  95 100\n[20] 105\n\nggplot(weather, aes(x = temp)) +\n  geom_histogram(breaks = limits, color = \"white\")\n\n\n\n\nFigure 3.33: Un exemple d’utilisation de l’argument breaks.\n\n\n\n\nIl est important que toute la gamme des valeurs de temp soit couverte par les limites des classes que nous avons définies, sinon, certaines valeurs sont omises et l’histogramme est donc incomplet/incorrect. Une façon de s’en assurer est d’afficher le résumé des données pour la colonne temp du jeu de données weather :\n\nsummary(weather$temp)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  10.94   39.92   55.40   55.26   69.98  100.04       1 \n\n\nOn voit ici que les températures varient de 10.94 à 100.04 degrés Fahrenheit. Les classes que nous avons définies couvrent une plage de températures plus large (de 10 à 105). Toutes les données sont donc bien intégrées à l’histogramme.\n\n\n3.5.3 Les densités\nUne façon de s’affranchir (presque) complètement de cette question de largeur des classes de tailles et de représenter les distributions sous forme de courbes de densités :\n\nggplot(weather, aes(x = temp)) +\n  geom_density()\n\n\n\n\nFigure 3.34: Un exemple de courbe de densité\n\n\n\n\nIci, la courbe reflète non pas la fréquence des données dans des classes de tailles, mais leur densité, c’est à dire que la surface totale sous la courbe vaut 1 (d’où l’échelle étrange sur l’axe des ordonnées). C’est une extension continue de l’histogramme par nature discontinu. On repère bien ici les 2 pics identifiés précédemment qui correspondent à des densités de données plus fortes pour les températures de 30 et 70 degrés Fahrenheit environ. La courbe possède un paramètre de lissage (bw pour “bandwidth”) qui équivaut un peu à la largeur des classes de taille d’un histogramme :\n\nggplot(weather, aes(x = temp)) +\n  geom_density(bw = 0.5)\n\n\n\n\nFigure 3.35: La même courbe de densité mais trop peu lissée\n\n\n\n\nIci, les données sont trop peu lissées et la courbe est donc très “bruitée”.\n\nggplot(weather, aes(x = temp)) +\n  geom_density(bw = 10)\n\n\n\n\nFigure 3.36: La même courbe de densité mais trop lissée\n\n\n\n\nIci, la courbe est trop lissée donc toute la structure des données disparaît. En règle générale, la valeur choisie par défaut par geom_density() pour le paramètre bw est tout à fait satisfaisante. Il est donc rare que l’utilisateur ait à modifier manuellement cette valeur."
  },
  {
    "objectID": "03-visualization.html#sec-facets",
    "href": "03-visualization.html#sec-facets",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.6 Les facets",
    "text": "3.6 Les facets\n\n3.6.1 facet_wrap()\nNous l’avons indiqué plus haut, les facets permettent de scinder le jeu de données en plusieurs sous-groupes et de faire un graphique pour chacun des sous-groupes.\nAinsi, si l’on souhaite connaître la distribution des températures pour chaque mois de l’année 2013, plutôt que de faire ceci :\n\nggplot(weather, aes(x = temp, fill = factor(month))) +\n  geom_histogram(bins = 20, color = \"grey30\")\n\n\n\n\nFigure 3.37: Distribution des températures avec visualisation des données mensuelles\n\n\n\n\nqui produit un graphique certes assez joli, mais difficile à interpréter, mieux vaut faire ceci :\n\nggplot(weather, aes(x = temp, fill = factor(month))) +\n  geom_histogram(bins = 20, color = \"grey30\") +\n  facet_wrap(~factor(month), ncol = 3)\n\n\n\n\nFigure 3.38: Un exemple d’utilisation de facet_wrap().\n\n\n\n\nLa couche supplémentaire créée avec facet_wrap() permet donc de scinder les données en fonction d’une variable. Attention à la syntaxe : il ne faut pas oublier le symbole “~” devant la variable que l’on souhaite utiliser pour scinder les données. Il va sans dire que la variable utilisée doit être catégorielle et non continue, c’est la raison pour laquelle j’utilise la notation factor(month) et non simplement month.\nAvec la fonction facet_wrap(), il est possible d’indiquer à R comment les différents graphiques doivent être agencés en spécifiant soit le nombre de colonnes souhaité avec ncol, soit le nombre de lignes souhaité avec nrow.\n\n\n3.6.2 facet_grid()\nUne autre fonction nommée facet_grid() permet d’agencer des sous-graphiques selon 2 variables catégorielles. Par exemple :\n\nggplot(weather, aes(x = temp, fill = factor(month))) +\n  geom_histogram(bins = 20, color = \"grey30\") +\n  facet_grid(factor(month) ~ origin)\n\n\n\n\nFigure 3.39: Un exemple d’utilisation de facet_grid().\n\n\n\n\nIci, nous avons utilisé la variable month (transformée en facteur) et la variable origin pour créer un histogramme pour chaque combinaison des modalités de ces 2 variables. Il est donc possible de comparer facilement des températures inter-mensuelles au sein d’un aéroport donné (en colonnes), ou de comparer des températures enregistrées le même mois dans des aéroports distincts (en lignes).\nfacet_grid() doit elle aussi être utilisée avec le symbole “~”. Comme pour les indices d’un tableau, on met à gauche du “~” la variable qui figurera en lignes, et à droite du ~ celle qui figurera en colonnes. Les arguments nrow et ncol ne peuvent donc pas être utilisés : c’est le nombre de niveaux de chaque variable catégorielle fournie à facet_grid() qui détermine le nombre de lignes et de colonnes du graphique.\nVous devriez maintenant être convaincus de la puissance de la grammaire des graphiques. En utilisant un langage standardisé et en ajoutant des couches une à une sur un graphique, il est posible d’obtenir rapidement des visualisations très complexes et néanmoins très claires, qui font apparaître des structures intéressantes dans nos données (des tendances, des groupes, des similitudes, des liaisons, des différences, etc.).\n\n\n3.6.3 Exercices\nExaminez la Figure 3.39.\n\nQuels éléments nouveaux ce graphique nous apprend-il par rapport à la Figure 3.33 ci-dessus ? Comment le “faceting” nous aide-t-il à visualiser les relations entre 2 (ou 3) variables ?\nÀ quoi correspondent les numéros 1 à 12 ?\nÀ quoi correspondent les chiffres 25, 50, 75, 100 ?\nÀ quoi correspondent les chiffres 0, 100, 200, 300 ?\nObservez les échelles des axes x et y pour chaque sous graphique. Qu’ont-elles de particulier ? En quoi est-ce utile ?\nLa variabilité des températures est-elle plus importante entre les aéroports, entre les mois, ou au sein des mois ? Expliquez votre réflexion."
  },
  {
    "objectID": "03-visualization.html#les-boîtes-à-moustaches-ou-boxplots",
    "href": "03-visualization.html#les-boîtes-à-moustaches-ou-boxplots",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.7 Les boîtes à moustaches ou boxplots",
    "text": "3.7 Les boîtes à moustaches ou boxplots\n\n3.7.1 Création de boxplots et informations apportées\nCommençons par créer un boxplot pour comparer les températures mensuelles comme nous l’avons fait plus haut avec des histogrammes :\n\nggplot(weather, aes(x = month, y = temp)) +\n  geom_boxplot()\n\nWarning: Continuous x aesthetic\nℹ did you forget `aes(group = ...)`?\n\n\nWarning: Removed 1 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nFigure 3.40: Un boxplot fort peu utile…\n\n\n\n\nComme précédemment, R nous avertit qu’une observation n’a pas été intégrée (en raison d’une donnée manquante). Mais il nous dit aussi que x (pour nous, la variable month) est continue, et que nous avons probablement oublié de spécifier des groupes.\nEn effet, les boxplots sont généralement utilisés pour examiner la distribution d’une variable numérique pour chaque niveau d’une variable catégorielle (un facteur). Il nous faut donc, ici encore, transformer month en facteur car dans notre tableau de départ, cette variable est considérée comme une variable numérique continue :\n\nggplot(weather, aes(x = factor(month), y = temp)) +\n  geom_boxplot()\n\n\n\n\nFigure 3.41: Boxplot des températures mensuelles.\n\n\n\n\nLes différents éléments d’un boxplot, sont les suivants :\n\nLa limite inférieure de la boîte correspond au premier quartile : 25% des données de l’échantillon sont situées au-dessous de cette valeur.\nLa limite supérieure de la boîte correspond au troisième quartile : 25% des données de l’échantillon sont situées au-dessus de cette valeur.\nLe segment épais à l’intérieur de la boîte correspond au second quartile : c’est la médiane de l’échantillon. 50% des données de l’échantillon sont situées au-dessus de cette valeur, et 50% au-dessous.\nLa hauteur de la boîte correspond à ce que l’on appelle l’étendue inter-quartile ou Inter Quartile Range (IQR) en anglais. On trouve dans cette boîte 50% des observations de l’échantillon. C’est une mesure de la dispersion des 50% des données les plus centrales. Une boîte plus allongée indique donc une plus grande dispersion.\nLes moustaches correspondent à des valeurs qui sont en dessous du premier quartile (pour la moustache du bas) et au-dessus du troisième quartile (pour la moustache du haut). La règle utilisée dans R est que ces moustaches s’étendent jusqu’aux valeurs minimales et maximales de l’échantillon, mais elles ne peuvent en aucun cas s’étendre au-delà de 1,5 fois la hauteur de la boîte (1,5 fois l’IQR) vers le haut et le bas. Si des points apparaissent au-delà des moustaches (vers le haut ou le bas), ces points sont appelés “outliers”. Ce sont des points qui s’éloignent du centre de la distribution de façon importante puisqu’ils sont au-delà de 1,5 fois l’IQR de part et d’autre du premier ou du troisième quartile. Il peut s’agir d’anomalies de mesures, d’anomalies de saisie des données, ou tout simplement, d’enregistrements tout à fait valides mais extrêmes. J’attire votre attention sur le fait que la définition de ces outliers est relativement arbitraire. Nous pourrions faire le choix d’étendre les moustaches jusqu’à 1,8 fois l’IQR (ou 2, ou 2,5). Nous observerions alors beaucoup moins d’outliers. D’une façons générale, la longueur des moustaches renseigne sur la variabilité des données en dehors de la zone centrale. Plus elles sont longues, plus la variabilité est importante. Et dans tous les cas, l’examen attentif des outliers est utile car il nous permet d’en apprendre plus sur le comportement extrême de certaines observations.\n\n\n\n3.7.2 L’intervalle de confiance à 95% de la médiane\nOn peut également ajouter une encoche autour de la valeur de médiane en ajoutant l’argument notch = TRUE à la fonction geom_boxplot() :\n\nggplot(weather, aes(x = factor(month), y = temp)) +\n  geom_boxplot(notch = TRUE)\n\n\n\n\nFigure 3.42: Boxplot des températures mensuelles. Les intervalles de confiance à 95% de la médiane sont affichés.\n\n\n\n\nComme l’indique la légende de la Figure 3.42, cette encoche correspond à l’étendue de l’intervalle de confiance à 95% de la médiane. Pour chaque échantillon, nous espérons que la médiane calculée soit le reflet fidèle de la vraie valeur de médiane de la population. Mais il sera toujours impossible d’en avoir la certitude absolue. Le mieux que l’on puisse faire, c’est quantifier l’incertitude. L’intervalle de confiance nous indique qu’il y a de bonnes chances que la vraie valeur de médiane de la population générale (qui restera à jamais inconnue) se trouve dans cet intervalle. Ici, les encoches sont très étroites car les données sont abondantes. Il y a donc peu d’incertitude, ce qui est une bonne chose. Cette notion d’intervalle de confiance est importante et ce type de graphique nous permettra d’anticiper sur les résultats des tests de comparaisons de moyennes.\n\n\n3.7.3 Une autre façon d’examiner des distributions\nDernière chose concernant les boxplots : il s’agit d’une représentation graphique très proche de l’histogramme. Pour vous en convaincre, je représente à la Figure 3.43 ci-dessous uniquement les températures du mois de novembre, avec 3 types d’objets géométriques différents : un histogramme, un boxplot, et un nuage de points.\n\n\n\n\n\nFigure 3.43: Distribution des températures de novembre 2013.\n\n\n\n\nNous avons donc, à gauche les données brutes, sous la forme d’un nuage de points créé avec geom_jitter(), au centre, un histogramme pour les températures de novembre, créé avec geom_histogram() (j’ai permuté les axes pour que y porte la température pour les 3 graphiques) et à droite, un boxplot pour ces mêmes données, créé avec geom_boxplot(). On voit bien que ces 3 représentations graphiques sont similaires. Toutes rendent compte du fait que les températures de Novembre sont majoritairement comprises entre 35 et 52 degrés Fahrenheit. Au-delà de cette fourchette (au-dessus comme en dessous) les observations sont plus rares.\nLe nuage de points affiche toutes les données. C’est donc lui le plus complet mais pas forcément le plus lisible. Les points sont en effet très nombreux et la lecture du graphique peut s’en trouver compliquée. L’histogramme simplifie les données en les regroupant dans des classes. C’est une sorte de résumé des données. On constate cependant toujours la présence de 2 pics qui correspondent aux zones plus denses du nuage de points. Le boxplot enfin synthétise encore plus ces données. Elles sont résumées par 7 valeurs seulement : le minimum, le maximum, les 3 quartiles, et les bornes de l’intervalle de confiance à 95% de la médiane. C’est une représentation très synthétique qui nous permet de comparer beaucoup de catégories côte à côte (voir la Figure 3.42 un peu plus haut), mais qui est forcément moins précise qu’un histogramme. Vous noterez toutefois que la boîte du boxplot recouvre en grande partie la zone des 2 pics de l’histogramme. En outre, sur la Figure 3.42, la tendance générale est très visible : il fait plus chaud en été qu’en hiver (étonnant non ?).\n\n\n3.7.4 Pour conclure\nLes boîtes à moustaches permettent donc de comparer et contraster la distribution d’une variable quantitative pour plusieurs niveaux d’une variable catégorielle. On peut voir où la médiane tombe dans les différents groupes en observant la position de la ligne centrale dans la boîte. Pour avoir une idée de la dispersion de la variable au sein de chaque groupe, regardez à la fois la hauteur de la boîte et la longueur des moustaches. Quand les moustaches s’étendent loin de la boîte mais que la boîte est petite, cela signifie que la variabilité des valeurs proches du centre de la distribution est beaucoup plus faible que la variabilité des valeurs extrêmes. Enfin, les valeurs extrêmes ou aberrantes sont encore plus faciles à détecter avec une boîte à moustaches qu’avec un histogramme."
  },
  {
    "objectID": "03-visualization.html#les-diagrammes-bâtons",
    "href": "03-visualization.html#les-diagrammes-bâtons",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.8 Les diagrammes bâtons",
    "text": "3.8 Les diagrammes bâtons\nComme nous venons de le voir, les histogrammes et les boîtes à moustaches permettent de visualiser la distribution d’une variable numérique continue. Nous aurons aussi souvent besoin de visualiser la distribution d’une variable catégorielle. C’est une tâche plus simple qui consiste à compter combien d’éléments tombent dans chacune des catégories de la variable catégorielle. Le meilleur moyen de visualiser de telles données de comptage (aka fréquences) est de réaliser un diagramme bâtons, autrement appelé barplot ou barchart.\nUne difficulté, toutefois, concerne la façon dont les données sont présentées : est-ce que la variable d’intérêt est “pré-comptée” ou non ? Par exemple, le code ci-dessous crée 2 data.frame qui représentent la même collection de fruits : 3 pommes et 2 oranges :\n\nfruits &lt;- data_frame(\n  fruit = c(\"pomme\", \"pomme\", \"pomme\", \"orange\", \"orange\")\n)\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nℹ Please use `tibble()` instead.\n\nfruits\n\n# A tibble: 5 × 1\n  fruit \n  &lt;chr&gt; \n1 pomme \n2 pomme \n3 pomme \n4 orange\n5 orange\n\nfruits_counted &lt;- data_frame(\n  fruit = c(\"pomme\", \"orange\"),\n  nombre = c(3, 2)\n)\nfruits_counted\n\n# A tibble: 2 × 2\n  fruit  nombre\n  &lt;chr&gt;   &lt;dbl&gt;\n1 pomme       3\n2 orange      2\n\n\n\n3.8.1 Représentation graphique avec geom_bar et geom_col\nPour visualiser les données non pré-comptées, on utilise geom_bar() :\n\nggplot(data = fruits, mapping = aes(x = fruit)) +\n  geom_bar()\n\n\n\n\nFigure 3.44: Barplot pour des données non pré-comptées.\n\n\n\n\nPour visualiser les données déjà pré-comptées, on utilise geom_col() :\n\nggplot(data = fruits_counted, mapping = aes(x = fruit, y = nombre)) +\n  geom_col()\n\n\n\n\nFigure 3.45: Barplot pour des données pré-comptées.\n\n\n\n\nNotez que la Figure 3.44 et la Figure 3.45 sont absolument identiques (à l’exception du titre de l’axe des ordonnées), mais qu’elles ont été créées à partir de 2 tableaux de données différents. En particulier, notez que :\n\nLe code qui génère la Figure 3.44 utilise le jeu de données fruits, et n’associe pas de variable à l’axe des ordonnées : dans la fonction aes(), seule la variable associée à x est précisée. C’est la fonction geom_bar() qui calcule automatiquement les abondances (ou fréquences) pour chaque catégorie de la variable fruit. La variable count est ainsi générée automatiquement et associée à y.\nLe code qui génère la Figure 3.45 utilise le jeu de données fruits_counted. Ici, la variable nombre est associée à l’axe des y grâce à la fonction aes(). La fonction geom_col() a besoin de 2 variables (une variable catégorielle pour l’axe des x et une numérique pour l’axe des y) pour fonctionner.\n\nAutrement dit, lorsque vous souhaiterez créer un diagramme bâtons, il faudra donc au préalable vérifier de quel type de données vous disposez pour choisir l’objet géométrique approprié :\n\nSi votre variable catégorielle n’est pas pré-comptée dans votre tableau de données, il faut utiliser geom_bar()\nSi votre variable catégorielle est pré-comptée dans votre tableau de données, il faut utiliser geom_col() et associer explicitement les comptages à l’esthétique y du graphique.\n\n\n\n3.8.2 Un exemple concret\nRevenons à nycflights13. Imaginons que nous souhaitions connaître le nombre de vols affrétés par chaque compagnie aérienne au départ de New York en 2013. Dans le jeu de données flights, la variable carrier nous indique à quelle compagnie aérienne appartiennent chacun des 336776 vols ayant quitté New York en 2013. Une façon simple de représenter ces données est donc la suivante :\n\nggplot(data = flights, mapping = aes(x = carrier)) +\n  geom_bar()\n\n\n\n\nFigure 3.46: Nombre de vols par compagnie aérienne au départ de New York en 2013.\n\n\n\n\nIci, geom_bar() a compté le nombre d’occurrences de chaque compagnie aérienne dans le tableau flights et a automatiquement associé ce nombre à l’axe des ordonnées.\nIl est généralement plus utile de trier les catégories par ordre décroissant. Nous pouvons faire cela facilement grâce à la fonction fct_infreq() du package forcats. Si vous avez installé le tidyverse, le package forcast doit être disponible sur votre ordinateur. N’oubliez pas de le charger si besoin :\n\nlibrary(forcats)\nggplot(data = flights, mapping = aes(x = fct_infreq(carrier))) +\n  geom_bar()\n\n\n\n\nFigure 3.47: Nombre de vols par compagnie aérienne au départ de New York en 2013.\n\n\n\n\nOrdonner les catégories par ordre décroissant est souvent indispensable afin de faciliter la lecture du graphique et les comparaisons entre catégories.\nSi nous souhaitons connaître le nombre de vols précis de chaque compagnie aérienne, il nous faut faire appel à plusieurs fonctions du package dplyr que nous détaillerons dans le Chapitre 5. Ci-dessous, nous créons un nouveau tableau carrier_table contenant le nombre de vols de chaque compagnie aérienne et les compagnies sont ordonnées par nombres de vols décroissants :\n\ncarrier_table &lt;- flights |&gt;   # On prend flights, puis...\n  group_by(carrier) |&gt;        # On groupe les données par compagnie, puis...\n  summarize(nombre = n()) |&gt;  # On calcule le nb de vols par Cie, puis ...\n  arrange(desc(nombre))        # On trie par nb de vols décroissants ...\ncarrier_table                  # Enfin, on affiche la nouvelle table\n\n# A tibble: 16 × 2\n   carrier nombre\n   &lt;chr&gt;    &lt;int&gt;\n 1 UA       58665\n 2 B6       54635\n 3 EV       54173\n 4 DL       48110\n 5 AA       32729\n 6 MQ       26397\n 7 US       20536\n 8 9E       18460\n 9 WN       12275\n10 VX        5162\n11 FL        3260\n12 AS         714\n13 F9         685\n14 YV         601\n15 HA         342\n16 OO          32\n\n\nIci, la table a été triée par nombres de vols décroissants. Mais attention, les niveaux du facteur carrier n’ont pas été modifiés :\n\nfactor(carrier_table$carrier)\n\n [1] UA B6 EV DL AA MQ US 9E WN VX FL AS F9 YV HA OO\nLevels: 9E AA AS B6 DL EV F9 FL HA MQ OO UA US VX WN YV\n\n\nLe premier niveau est toujours 9E, puis AA, puis AS, et non l’ordre du tableau nouvellement créé (UA, puis B6, puis EV…) car les niveaux sont toujours triés par ordre alphabétique. La conséquence est que faire un barplot avec ces données et la fonction geom_col() ne permet pas d’ordonner les catégories correctement :\n\nggplot(carrier_table, aes(x = carrier, y = nombre)) +\n  geom_col()\n\n\n\n\nFigure 3.48: Nombre de vols par compagnie aérienne au départ de New York en 2013.\n\n\n\n\nPour parvenir à nos fins, il faut cette fois avoir recours à la fonction fct_reorder() pour ordonner correctement les catégories. Cette fonction prends 3 arguments :\n\nLa variable catégorielle dont on souhaite réordonner les niveaux (ici, la variable carrier du tableau carrier_table).\nUne variable numérique qui permet d’ordonner les catégories (ici, la variable nombre du même tableau).\nL’argument optionnel .desc qui permet de préciser si le tri doit être fait en ordre croissant (c’est le cas par défaut) ou décroissant.\n\n\nggplot(carrier_table, aes(x = fct_reorder(carrier, nombre, .desc = TRUE), \n                          y = nombre)) +\n  geom_col()\n\n\n\n\nFigure 3.49: Nombre de vols par compagnie aérienne au départ de New York en 2013.\n\n\n\n\nVous voyez donc que selon le type de données dont vous disposez (soit un tableau comme flights, avec toutes les observations, soit un tableau beaucoup plus compact comme carrier_table), la démarche permettant de produire un diagramme bâtons, dans lequel les catégories seront triées, sera différente.\n\n\n3.8.3 Exercices\n\nQuelle est la différence entre un histogramme et un diagramme bâtons ?\nPourquoi les histogrammes sont-ils inadaptés pour visualiser des données catégorielles ?\nQuel est le nom de la compagnie pour laquelle le plus grand nombre de vols ont quitté New York en 2013 (je veux connaître son nom, pas juste son code) ? Où se trouve cette information ?\nQuel est le nom de la compagnie pour laquelle le plus petit nombre de vols ont quitté New York en 2013 (je veux connaître son nom, pas juste son code) ? Où se trouve cette information ?\n\n\n\n3.8.4 Éviter à tout prix les diagrammes circulaires\nÀ mon grand désarroi, l’un des graphiques les plus utilisé pour représenter la distribution d’une variable catégorielle est le diagramme circulaire (ou diagramme camembert, piechart en anglais). C’est presque toujours la plus mauvaise visualisation possible. Je vous demande de l’éviter à tout prix. Notre cerveau n’est en effet pas correctement équipé pour comparer des angles. Ainsi, par exemple, nous avons naturellement tendance à surestimer les angles supérieurs à 90º, et à sous-estimer les angles inférieurs à 90º. En d’autres termes, il est difficile pour les humains de comparer des grandeurs sur des diagrammes circulaires.\nÀ titre d’exemple, examinez ce diagramme, qui reprend les mêmes chiffres que précédemment, et tentez de répondre aux questions suivantes :\n\n\n\n\n\nFigure 3.50: Nombre de vols par compagnie aérienne au départ de New York en 2013.\n\n\n\n\n\nComparez les compagnies ExpressJet Airlines (EV) et US Airways (US). De combien de fois la part de EV est-elle supérieure à celle d’US ? (2 fois, 3 fois, 1.2 fois ?…)\nQuelle est la troisième compagnie aérienne la plus importante en terme de nombre de vols au départ de New York en 2013 ?\nCombien de compagnies aériennes ont moins de vols que United Airlines (UA) ?\n\nIl est difficile (voir impossible) de répondre précisément à ces questions avec le diagramme circulaire de la Figure 3.50, alors qu’il est très simple d’obtenir des réponses précises avec un diagramme bâtons tel que présenté à la Figure 3.49 (vérifiez-le !).\n\n\n3.8.5 Comparer 2 variables catégorielles avec un diagramme bâton\nIl y a généralement 3 façons de procéder pour comparer la distribution de 2 variables catégorielles avec un diagramme bâtons :\n\nFaire un graphique empilé.\nFaire un graphique juxtaposé.\nUtiliser les facets.\n\nSupposons par exemple que nous devions visualiser le nombre de vols de chaque compagnie aérienne, au départ de chacun des 3 aéroports de New York : John F. Kennedy (JFK), Newark (EWR) et La Guardia (LGA). Voyons comment procéder avec chacune des 3 méthodes énoncées ci-dessus.\n\n3.8.5.1 Graphique empilé\nLa méthode la plus simple est celle du graphique empilé :\n\nggplot(flights, aes(x = fct_infreq(carrier), fill = origin)) +\n  geom_bar()\n\n\n\n\nFigure 3.51: Nombre de vols par compagnie aérienne au départ des 3 aéroports de New York en 2013.\n\n\n\n\nNotez qu’il s’agit du même code que celui utilisé pour la Figure 3.47, à une différence près : l’ajout de fill = origin dans la fonction aes(), qui permet d’associer l’aéroport d’origine à la couleur de remplissage des barres. fill est associé à une variable (ici, elle est catégorielle), il est donc indispensable de faire figurer cet argument à l’intérieur de la fonction aes(). Quand on associe une variable à une caractéristique esthétique du graphique, on fait toujours figurer le code à l’intérieur de la fonction aes() (comme quand on associe une variable aux axes du graphique par exemple).\nÀ mon sens, le graphique gagne en lisibilité si on ajoute une couleur pour le contour des barres :\n\nggplot(flights, aes(x = fct_infreq(carrier), fill = origin)) +\n  geom_bar(color = \"black\")\n\n\n\n\nFigure 3.52: Nombre de vols par compagnie aérienne au départ des 3 aéroports de New York en 2013.\n\n\n\n\nNotez que contrairement à fill, cette couleur de contour est un paramètre fixe : elle n’est pas associée à une variable et doit donc être placée en dehors de la fonction aes().\nBien que ces graphiques empilés soient très simples à réaliser, ils sont parfois difficiles à lire. En particulier, il n’est pas toujours aisé de comparer les hauteurs des différentes couleurs (qui correspondent ici aux nombres de vols issus de chaque aéroport) entre barres différentes (qui correspondent ici aux compagnies aériennes).\n\n\n3.8.5.2 Graphique juxtaposé\nUne variation sur le même thème consiste, non plus à empiler les barres de couleur les unes sur les autres, mais à les juxtaposer :\n\nggplot(flights, aes(x = fct_infreq(carrier), fill = origin)) +\n  geom_bar(color = \"black\", position = \"dodge\")\n\n\n\n\nFigure 3.53: Nombre de vols par compagnie aérienne au départ des 3 aéroports de New York en 2013.\n\n\n\n\nPasser d’un graphique empilé à un graphique juxtaposé est donc très simple : il suffit d’ajouter l’argument position = \"dodge\" à la fonction geom_bar().\nLà encore, la lecture de ces graphiques est souvent difficile car la comparaison des catégories qui figurent sur l’axe des x n’est pas immédiate. Elle est en outre rendue plus difficile par le fait que toutes les barres n’ont pas la même largeur. Par exemple, sur la Figure 3.53, les 8 premières compagnies aériennes desservent les 3 aéroports de New York, mais les 2 suivantes (WN et VX) n’en desservent que 2, et les autres compagnies, qu’un seul. Puisque sur un barplot, seule la hauteur des barres compte, il faut prendre garde à ne pas se laisser influencer par la largeur des barres qui pourraient fausser notre perception.\n\n\n3.8.5.3 Utilisation des facets\nLa meilleure alternative est probablement l’utilisation de facets que nous avons déjà décrite à la Section 3.6 :\n\nggplot(flights, aes(x = fct_infreq(carrier), fill = origin)) +\n  geom_bar(color = \"black\") +\n  facet_wrap(~origin, ncol = 1)\n\n\n\n\nFigure 3.54: Nombre de vols par compagnie aérienne au départ des 3 aéroports de New York en 2013.\n\n\n\n\nIci, chaque graphique permet de comparer les compagnies aériennes au sein de l’un des aéroports de New York, et puisque l’ordre des compagnies aériennes est le même sur l’axe des x des 3 graphiques, une lecture verticale permet de comparer aisément le nombre de vols qu’une compagnie donnée a affrété dans chacun des 3 aéroports de New York."
  },
  {
    "objectID": "03-visualization.html#de-lexploration-à-lexposition",
    "href": "03-visualization.html#de-lexploration-à-lexposition",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.9 De l’exploration à l’exposition",
    "text": "3.9 De l’exploration à l’exposition\nVous savez maintenant comment produire une grande variété de graphiques, permettant d’explorer vos données, de visualiser le comportement d’une ou plusieurs variables, et de mettre en évidence des tendances, des relations entre variables numériques et/ou catégorielles. Outre les objets géométriques décrits jusqu’ici, ggplot2 contient de nombreuses possibilités supplémentaires pour créer des graphiques parlants et originaux. Je ne peux donc que vous encourager à explorer par vous même les autres possibilités de ce package. Lorsque vous produisez un graphique parlant et permettant de véhiculer un message clair, vous devez ensuite rendre vos graphiques plus présentables afin de les intégrer dans un rapport ou une présentation. Cette section vous permettra de vous familiariser avec quelques fonctions permettant d’annoter correctement vos graphiques et d’en modifier les légendes si nécessaire.\n\n3.9.1 Les labels\nLe point de départ le plus évident est d’ajouter des labels de qualité. La fonction labs() du package ggplot2 permet d’ajouter plusieurs types de labels sur vos graphiques :\n\nUn titre : il doit résumer les résultats les plus importants.\nUn sous-titre : il permet de donner quelques détails supplémentaires.\nUne légende : souvent utilisée pour présenter la source des données du graphique.\nUn titre pour chaque axe : permet de préciser les variables portées par les axes et leurs unités.\nUn titre pour les légendes de couleurs, de forme, de taille, etc.\n\nReprenons par exemple le graphique de la Figure 3.9 :\n\nggplot(alaska_flights, \n       aes(x = dep_delay, y = arr_delay, color = factor(month))) +\n  geom_point()\n\n\n\n\nFigure 3.55: Association de color à une variable catégorielle.\n\n\n\n\nNous pouvons ajouter sur ce graphique les éléments précisés plus haut en ajoutant la fonction labs() sur une nouvelle couche du graphique :\n\nggplot(alaska_flights, \n       aes(x = dep_delay, y = arr_delay, color = factor(month))) +\n  geom_point() +\n  labs(title = \"Relation linéaire positive entre retard des vols au départ et à l'arrivée\",\n       subtitle = \"Certains retards dépassent 3 heures\",\n       caption = \"Source : nycflights13\",\n       x = \"Retard au départ de New York (minutes)\",\n       y = \"Retard à l'arrivée à destination (minutes)\",\n       color = \"Mois\")\n\n\n\n\nFigure 3.56: Exemple d’utilisation de labs()\n\n\n\n\nÀ partir de maintenant, vous devriez systématiquement légender les axes de vos graphiques en n’oubliant pas de préciser les unités, pour tous les graphiques que vous intégrez dans vos rapports, compte-rendus, mémoires, etc.\n\n\n3.9.2 Les échelles\nTous les détails des graphiques que vous produisez peuvent être édités. C’est notamment le cas des échelles. Qu’il s’agisse de modifier l’étendue des axes, la densité du quadrillage, la position des tirets sur les axes, le nom des catégories figurant sur les axes ou dans les légendes ou encore les couleurs utilisées pour différentes catégories d’objets géométriques, tout est possible dans ggplot2.\nNous n’avons pas le temps ici d’aborder toutes ces questions en détail. Je vous encourage donc à consulter l’ouvrage en ligne intitulé R for data science, et en particulier son chapitre dédié aux échelles, si vous avez besoin d’apporter des modifications à vos graphiques et que vous ne trouvez pas comment faire dans cet ouvrage.\nJe vais ici uniquement détailler la façon de procéder pour modifier les couleurs choisies par défaut par ggplot2. Reprenons par exemple la Figure 3.54, en ajoutant au passage des titres corrects pour nos axes\n\nggplot(flights, aes(x = fct_infreq(carrier), fill = origin)) +\n  geom_bar(color = \"black\") +\n  facet_wrap(~origin, ncol = 1) +\n  labs(x = \"Compagnie aérienne\",\n       y = \"Nombre de vols\",\n       fill = \"Aéroports\\nde New York\")\n\n\n\n\nFigure 3.57: Nombre de vols par compagnie aérienne au départ des 3 aéroports de New York en 2013.\n\n\n\n\nNotez que le caractère spécial “\\n” permet de forcer un retour à la ligne. Ici, les 3 couleurs de remplissage (fill) utilisées pour différencier les 3 aéroports de New York ont été choisies par défaut par ggplot2. Il est possible de modifier ces couleurs de plusieurs façons :\n\nEn utilisant d’autres palettes de couleurs prédéfinies.\nEn utilisant des couleurs choisies manuellement.\n\nToutes les fonctions permettant d’altérer les légendes commencent par scale_. Vient ensuite le nom de l’esthétique que l’on souhaite modifier (ici fill_) et enfin, le nom d’une fonction à appliquer. Les possibilités sont nombreuses et vous pouvez en avoir un aperçu en tapant le début du nom de la fonction et en parcourant la liste proposée par RStudio sous le curseur.\nPar exemple, pour utiliser des niveaux de gris plutôt que les couleurs, il suffit d’ajouter une couche à notre graphique :\n\nggplot(flights, aes(x = fct_infreq(carrier), fill = origin)) +\n  geom_bar(color = \"black\") +\n  facet_wrap(~origin, ncol = 1) +\n  labs(x = \"Compagnie aérienne\",\n       y = \"Nombre de vols\",\n       fill = \"Aéroports\\nde New York\") +\n  scale_fill_grey()\n\n\n\n\nFigure 3.58: Nombre de vols par compagnie aérienne au départ des 3 aéroports de New York en 2013.\n\n\n\n\nLe package RColorBrewer propose une large gamme de palettes de couleurs (Figure 3.59) :\n\n\n\n\n\nFigure 3.59: Toutes les palettes de couleur du package RColorBrewer.\n\n\n\n\nggplot2 permet d’appliquer ces palettes très simplement :\n\nggplot(flights, aes(x = fct_infreq(carrier), fill = origin)) +\n  geom_bar(color = \"black\") +\n  facet_wrap(~origin, ncol = 1) +\n  labs(x = \"Compagnie aérienne\",\n       y = \"Nombre de vols\",\n       fill = \"Aéroports\\nde New York\") +\n  scale_fill_brewer(palette = \"Accent\")\n\n\n\n\nFigure 3.60: Nombre de vols par compagnie aérienne au départ des 3 aéroports de New York en 2013.\n\n\n\n\nDe même, le package viridis propose une palette de couleurs intéressante qui maximise le contraste et facilite la discrimination des catégories pour les daltoniens. Là encore, ggplot2 nous donne accès à cette palette :\n\nggplot(flights, aes(x = fct_infreq(carrier), fill = origin)) +\n  geom_bar(color = \"black\") +\n  facet_wrap(~origin, ncol = 1) +\n  labs(x = \"Compagnie aérienne\",\n       y = \"Nombre de vols\",\n       fill = \"Aéroports\\nde New York\") +\n  scale_fill_viridis_d()\n\n\n\n\nFigure 3.61: Nombre de vols par compagnie aérienne au départ des 3 aéroports de New York en 2013.\n\n\n\n\nEnfin, si les palettes de couleurs ne conviennent pas, il est toujours possible de spécifier manuellement les couleurs souhaitées. R propose un accès rapide à 657 noms de couleurs. Pour les afficher, il suffit de taper :\n\ncolors()\n\nPour savoir à quelle couleur correspond chaque nom, le plus simple est probablement de consulter ce document pdf (n’hésitez pas à le sauvegarder si vous pensez en avoir besoin plus tard).\n\nggplot(flights, aes(x = fct_infreq(carrier), fill = origin)) +\n  geom_bar(color = \"black\") +\n  facet_wrap(~origin, ncol = 1) +\n  labs(x = \"Compagnie aérienne\",\n       y = \"Nombre de vols\",\n       fill = \"Aéroports\\nde New York\") +\n  scale_fill_manual(values = c(\"dodgerblue1\", \"mediumorchid2\", \"red2\"))\n\n\n\n\nFigure 3.62: Nombre de vols par compagnie aérienne au départ des 3 aéroports de New York en 2013.\n\n\n\n\nOutre ces 657 couleurs qui disposent d’un nom spécifique, il est possible de spécifier les couleurs en utilisant des codes hexadécimaux et des codes rgb (red, green, blue). De nombreux sites permettent de choisir n’importe quelle couleur dans une palette qui en compte des millions et d’obtenir de tels codes. Ce site permet de le faire très simplement :\n\nggplot(flights, aes(x = fct_infreq(carrier), fill = origin)) +\n  geom_bar(color = \"black\") +\n  facet_wrap(~origin, ncol = 1) +\n  labs(x = \"Compagnie aérienne\",\n       y = \"Nombre de vols\",\n       fill = \"Aéroports\\nde New York\") +\n  scale_fill_manual(values = c(\"#6f71f2\", \"#6ff299\", \"#f2b86f\"))\n\n\n\n\nFigure 3.63: Nombre de vols par compagnie aérienne au départ des 3 aéroports de New York en 2013.\n\n\n\n\nDernière chose concernant les couleurs : un choix de fonction scale_XXX_XXX() inapproprié est la cause d’erreur la plus fréquente ! Par exemple, si on reprend le code des figures Figure 3.9 et Figure 3.10 et que l’on modifie les palettes de couleurs, notez que les fonctions utilisées ne sont pas les mêmes :\n\nggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay, \n                                            color = factor(month))) +\n  geom_point() +\n  scale_color_viridis_d()\n\n\n\n\nFigure 3.64: Association de color à une variable catégorielle.\n\n\n\n\n\nggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay, \n                                            color = arr_time)) +\n  geom_point() +\n  scale_color_viridis_c()\n\n\n\n\nFigure 3.65: Association de color à une variable numérique.\n\n\n\n\nPour les 2 figures 3.64 et 3.65, j’utilise la palette de couleur viridis. Pour ces 2 graphiques, c’est la couleur des points qui change. Puisque cette couleur est spécifiée avec l’esthétique color et non plus fill, la fonction utilisée est scale_color_XXX() et non plus scale_fill_XXX().\nEnfin, pour la Figure 3.64, c’est une variable catégorielle qui est associée à l’esthétique de couleur (factor(month)). La fonction utilisée pour modifier les couleurs doit donc en tenir compte : le _d à la fin de scale_color_viridis_d() signifie “discrete”, c’est-à-dire “discontinue”. À l’inverse, pour la Figure 3.65, c’est une variable numérique continue qui est associée à l’esthétique de couleur (arr_time). La fonction utilisée pour modifier les couleurs en est le reflet : le _c à la fin de scale_color_viridis_c() est l’abréviation de “continuous”, c’est-à-dire “continue”.\nSi vous ne voulez pas avoir de message d’erreur, attention donc, à choisir la fonction scale_XXX_XXX() appropriée. Pour cela, servez-vous de l’aide que RStudio vous apporte en tapant les premières lettres de la fonction et en parcourant la liste des fonctions proposées dans le menu déroulant qui apparaît sous votre curseur.\n\n\n3.9.3 Les thèmes\nL’apparence de tout ce qui ne concerne pas directement les données d’un graphique est sous le contrôle d’un thème. Les thèmes contrôlent l’apparence générale du graphique : quelles polices et tailles de caractères sont utilisées, quel sera l’arrière plan du graphique, faut-il intégrer un quadrillage sous le graphique, et si oui, quelles doivent être ses caractéristiques ?\nIl est possible de spécifier chaque élément manuellement. Nous nous contenterons ici de passer en revue quelques thèmes prédéfinis qui devraient couvrir la plupart de vos besoins.\nReprenons par exemple le code de la Figure 3.60 et ajoutons un titre :\n\nggplot(flights, aes(x = fct_infreq(carrier), fill = origin)) +\n  geom_bar(color = \"black\") +\n  facet_wrap(~origin, ncol = 1) +\n  labs(x = \"Compagnie aérienne\",\n       y = \"Nombre de vols\",\n       fill = \"Aéroports de\\nNew York\",\n       title = \"Couverture inégale des aéroports de New York\") +\n  scale_fill_brewer(palette = \"Accent\")\n\n\n\n\nFigure 3.66: Utilisation du thème par défaut : theme_gray()\n\n\n\n\nLe thème utilisé par défaut est theme_gray(). Il est notamment responsable de l’arrière plan gris et du quadrillage blanc. Pour changer de thème, il suffit d’ajouter une couche au graphique en donnant le nom du nouveau thème :\n\nggplot(flights, aes(x = fct_infreq(carrier), fill = origin)) +\n  geom_bar(color = \"black\") +\n  facet_wrap(~origin, ncol = 1) +\n  labs(x = \"Compagnie aérienne\",\n       y = \"Nombre de vols\",\n       fill = \"Aéroports de\\nNew York\",\n       title = \"Couverture inégale des aéroports de New York\") +\n  scale_fill_brewer(palette = \"Accent\") +\n  theme_bw()\n\n\n\n\nFigure 3.67: Utilisation du thème theme_bw()\n\n\n\n\nLes thèmes complets que vous pouvez utiliser sont les suivants :\n\ntheme_bw() : fond blanc et quadrillage.\ntheme_classic() : thème classique, avec des axes mais pas de quadrillage.\ntheme_dark() : fond sombre pour augmenter le contraste.\ntheme_gray() : thème par défaut : fond gris et quadrillage blanc.\ntheme_light() : axes et quadrillages discrets.\ntheme_linedraw() : uniquement des lignes noires.\ntheme_minimal() : pas d’arrière plan, pas d’axes, quadrillage discret.\ntheme_void() : thème vide, seuls les objets géométriques restent visibles.\n\n\nggplot(flights, aes(x = fct_infreq(carrier), fill = origin)) +\n  geom_bar(color = \"black\") +\n  facet_wrap(~origin, ncol = 1) +\n  labs(x = \"Compagnie aérienne\",\n       y = \"Nombre de vols\",\n       fill = \"Aéroports de\\nNew York\",\n       title = \"Couverture inégale des aéroports de New York\") +\n  scale_fill_brewer(palette = \"Accent\") +\n  theme_minimal()\n\n\n\n\nFigure 3.68: Utilisation du thème minimaliste\n\n\n\n\nL’argument base_family de chaque thème permet de spécifier une police de caractères différente de celle utilisée par défaut. Évidemment, vous ne pourrez utiliser que des polices qui sont disponibles sur l’ordinateur que vous utilisez. Dans l’exemple de la ?fig-themefont ci-dessous, j’utilise la police “Gill Sans”. Si cette police n’est pas disponible sur votre ordinateur, ce code produira une erreur. Si c’est le cas, remplacez-la par une police de votre ordinateur. Attention, son nom exact doit être utilisé. Cela signifie bien sûr le respect des espaces, majuscules, etc.\n\nggplot(flights, aes(x = fct_infreq(carrier), fill = origin)) +\n  geom_bar(color = \"black\") +\n  facet_wrap(~origin, ncol = 1) +\n  labs(x = \"Compagnie aérienne\",\n       y = \"Nombre de vols\",\n       fill = \"Aéroports de\\nNew York\",\n       title = \"Couverture inégale des aéroports de New York\") +\n  scale_fill_brewer(palette = \"Accent\") +\n  theme_minimal(base_family = \"Gill Sans\")\n\n\nLe choix d’un thème et d’une police adaptés doivent vous permettre de faire des graphiques originaux et clairs. Rappelez-vous toujours que vos choix en matière de graphiques doivent avoir pour objectif principal de rendre les tendances plus faciles à décrypter pour un lecteur non familier de vos données. C’est un outil de communication au même titre que n’importe quel paragraphe d’un rapport ou compte-rendu. Et comme pour un paragraphe, la première version d’un graphique est rarement la bonne.\nVous devriez donc maintenant être bien armés pour produire 95% des graphiques dont vous aurez besoin tout au long de votre cursus universitaire. Toutefois, un point important a pour l’instant été omis : l’ajout de barres d’erreurs sur vos graphiques. Nous verrons comment faire cela un peu plus tard, après avoir appris à manipuler efficacement des tableaux de données avec les packages tidyr et dplyr."
  },
  {
    "objectID": "03-visualization.html#sec-exo-3",
    "href": "03-visualization.html#sec-exo-3",
    "title": "3  Visualiser des données avec ggplot2",
    "section": "3.10 Exercices",
    "text": "3.10 Exercices\nCommencez par créer un nouveau jeu de données en exécutant ces commandes :\n\nset.seed(1234)\nsmall_flights &lt;- flights |&gt; \n  sample_n(1000) |&gt; \n  filter(!is.na(arr_delay),\n         distance &lt; 3000)\n\nCe nouveau jeu de données de petite taille (969 lignes) est nommé small_flights. Il contient les mêmes variables que le tableau flights mais ne contient qu’une petite fraction de ses lignes. Les lignes retenues ont été choisies au hasard. Vous pouvez visualiser son contenu en tapant son nom dans la console ou en utilisant la fonction View().\nEn vous appuyant sur les fonctions et les principes de la grammaire des graphiques que vous avez découverts dans ce chapitre 3, et en vous servant de ce nouveau jeu de données, tapez les commandes qui permettent de produire le graphique ci-dessous :\n\n\n\n\n\nFigure 3.69: Première figure à reproduire\n\n\n\n\nQuelques indices :\n\nLes couleurs utilisées sont celles de la palette Set1 du package RColorBrewer.\nLes variables utilisées sont origin, air_time et distance.\nLa transparence des symboles est fixée à 0.8.\n\nToujours avec ce jeu de données small-flights, tapez les commandes permettant de produire le graphique ci-dessous :\n\n\n\n\n\nFigure 3.70: Seconde figure à reproduire\n\n\n\n\nQuelques indices :\n\nLes couleurs utilisées sont celles de la palettes Accent du package RColorBrewer.\nLes variables utilisées sont month, carrier et origin.\n\n\n\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, et Dewey Dunnington. 2023. ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWilkinson, Leland. 2005. The grammar of graphics. 2nd éd. New-York: Springer-Verlag. https://www.springer.com/us/book/9780387245447."
  },
  {
    "objectID": "04-tidy-Data.html#sec-prerek",
    "href": "04-tidy-Data.html#sec-prerek",
    "title": "4  (Ar)ranger des données avec tidyr",
    "section": "4.1 Prérequis",
    "text": "4.1 Prérequis\nDans ce chapitre, nous aurons besoin des packages suivants :\n\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(nycflights13)\nlibrary(ggplot2)\nlibrary(readxl)  # la dernière lettre est un \"L\" minuscule, pas le chiffre 1...\nlibrary(readr)\n\nComme d’habitude, si vous recevez des messages d’erreur, c’est probablement parce que le package que vous essayez de charger en mémoire n’a pas été installé au préalable. Consultez la Section 1.4 si vous ne savez plus comment procéder.\nOutre ces packages classiques, nous aurons aussi besoin du package EDAWR qui n’est pas disponible sur les serveurs habituels de R. Pour l’installer, on procède de la façon suivante :\n\nInstallez et chargez en mémoire le package remotes :\n\n\ninstall.packages(\"remotes\")\nlibrary(remotes)\n\n\nInstallez le package EDAWR grâce à la fonction install_github() du package remotes qui va chercher le package sur le site https://github.com :\n\n\ninstall_github(\"rstudio/EDAWR\")\n\nAttention, sur les ordinateurs de l’université cette procédure ne fonctionne pas toujours. Si vous rencontrez des difficultés, suivez les instructions décrites à la fin de cette Section 4.1.\n\nChargez le package EDAWR de la façon habituelle :\n\n\nlibrary(EDAWR)\n\nLe package EDAWR contient plusieurs jeux de données dont nous allons nous servir pour illustrer les questions liées au format des tableaux de données. Pour en avoir la liste, vous pouvez taper :\n\ndata(package = \"EDAWR\")\n\nEn cas de problème pour installer le package EDAWR sur les ordinateurs de l’université.\nVous pouvez télécharger manuellement les 4 jeux de données dont nous aurons besoin grâce à ces 4 liens :\n\ncases\npopulation\nrates\nstorms\n\nUne fois téléchargés, les données contenues dans ces 4 fichiers peuvent être importées dans RStudio en cliquant sur File &gt; Open File..., puis en sélectionnant un à un chacun des fichiers. Pour chaque fichier un nouvel objet doit apparaître dans votre environnement de travail (onglet Environnement, dans le panneau en haut à droite de RStudio). L’inconvénient de cette méthode est que les fichiers d’aide de ces jeux de données ne seront pas disponibles dans RStudio. Vous pouvez toutefois en consulter une version brute (non mise en forme) en cliquant ici."
  },
  {
    "objectID": "04-tidy-Data.html#cest-quoi-des-tidy-data",
    "href": "04-tidy-Data.html#cest-quoi-des-tidy-data",
    "title": "4  (Ar)ranger des données avec tidyr",
    "section": "4.2 C’est quoi des “tidy data” ?",
    "text": "4.2 C’est quoi des “tidy data” ?\nLes “tidy data” (nous les appellerons “données rangées” dans la suite de ce livre), sont des données qui respectent un format standardisé. En particulier :\n\nChaque variable est dans une colonne unique.\nChaque colonne contient une unique variable.\nChaque ligne correspond à une observation pour chaque variable.\nLes cellules du tableau représentent les valeurs de chaque observation pour chaque variable.\n\n\n\n\n\n\nFigure 4.1: La définition des ‘données rangées’, d’après http://r4ds.had.co.nz/tidy-data.html.\n\n\n\n\nMalheureusement, les données peuvent être présentées sous de nombreux formats qui ne respectent pas ces règles de base. La modification des tableaux est donc souvent un préambule nécessaire à toute analyse statistique ou représentation graphique.\nPar exemple, examinez le tableau cases du package EDAWR, qui présente le nombre de cas de tuberculose dans 3 pays en 2011, 2012 et 2013.\n\ncases\n\n  country  2011  2012  2013\n1      FR  7000  6900  7000\n2      DE  5800  6000  6200\n3      US 15000 14000 13000\n\n\nDans ce tableau, essayez d’identifier quelles sont les variables en présence. Indice, vous devriez en trouver 3.\nEssayez d’identifier également où se trouvent ces variables.\nPour ma part, je compte les 3 variables suivantes :\n\ncountry : qui indique les pays dans lesquels les cas de tuberculose ont été dénombrés. Cette variable occupe la première colonne du tableau.\nLa seconde variable est l’année, qui peut prendre les valeurs 2011, 2012 ou 2013. Cette variable occupe la ligne des titres des 3 colonnes de droite du tableau.\nEt enfin, la troisième variable est le nombre de cas de tuberculose observés dans chaque pays et chaque année. Cette troisième variable occupe 3 lignes et 3 colonnes du tableau.\n\nAutrement dit, les variables peuvent être visualisées de la façon suivante :\n\n\n\n\n\nFigure 4.2: Position des variables dans le tableau cases du package EDAWR.\n\n\n\n\nDonc même si nous disposons ici d’un tableau rectangulaire classique, nous sommes bien loin du format des données rangées.\n\n4.2.1 La fonction pivot_longer()\nAfin de transformer les données non rangées du tableau cases en données rangées, nous allons utiliser la fonction pivot_longer() du package tidyr. Avant d’aller plus loin, essayez d’imaginer à quoi le tableau rangé devrait ressembler.\nLa fonction pivot_longer() prend 4 arguments :\n\ndata : le nom du tableau de données que l’on souhaite “ranger”.\ncols : La liste des colonnes du tableau initial que l’on souhaite rassembler en 2 nouvelles variables. Ici, les colonnes 2, 3 et 4 (on pourra les noter 2:4 ou, en utilisant leur nom, \"2011\":\"2013\").\nnames_to : le nom d’une nouvelle variable qui contiendra les en-têtes des colonnes qui constituent la seconde variable. Ici, nous nommerons cette seconde variable year car elle devra contenir les années 2011, 2012 et 2013.\nvalues_to : le nom d’une nouvelle variable qui contiendra les informations correspondant à la troisième variable identifiée plus haut. Nous appellerons cette variables n_cases car elle contiendra les nombres de cas de tuberculose (7000, 5800, 15000, etc).\n\n\npivot_longer(data = cases, \n             cols = `2011`:`2013`, \n             names_to = \"year\", \n             values_to = \"n_cases\")\n\n# A tibble: 9 × 3\n  country year  n_cases\n  &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n1 FR      2011     7000\n2 FR      2012     6900\n3 FR      2013     7000\n4 DE      2011     5800\n5 DE      2012     6000\n6 DE      2013     6200\n7 US      2011    15000\n8 US      2012    14000\n9 US      2013    13000\n\n\nNous avons bien transformé le tableau de départ en un “tableau rangé” : chacune de nos 3 variables se trouve dans une unique colone, et chaque ligne correspond à une observation pour chacune de ces 3 variables. Comme d’habitude, si nous souhaitons pouvoir utiliser ce nouveau tableau, il faut lui donner un nom :\n\ncases_tidy &lt;- pivot_longer(data = cases, \n                           cols = `2011`:`2013`, \n                           names_to = \"year\", \n                           values_to = \"n_cases\")\n\nIl nous est maintenant plus facile de manipuler ces données pour en tirer de l’information, grâce à des analyses statistiques ou des représentations graphiques :\n\nggplot(cases_tidy, aes(x = country, y = n_cases, fill = year)) +\n  geom_col(position = \"dodge\", color = \"black\") +\n  scale_fill_brewer(palette = \"Accent\") +\n  theme_minimal() +\n  labs(x = \"Pays\",\n       y = \"Nombre de cas\",\n       fill = \"Année\",\n       title = \"Évolution du nombre de cas de tuberculose entre 2011 et 2013\",\n       subtitle = \"DE : Allemagne, FR : France, US : États-Unis\")\n\n\n\n\nFigure 4.3: Évolution du nombre de cas de tuberculose dans 3 pays, de 2011 à 2013.\n\n\n\n\nOn constate ici qu’entre 2011 et 2013, le nombre de cas de tuberculose a légèrement augmenté en Allemagne, est resté stable en France, et a diminué aux États-Unis.\nNotez ici que la variable year de notre nouveau tableau est considérée comme une variable de type “chaîne de caractères” et non comme une variable numérique. On peut le voir en affichant notre tableau en tapant son nom, ou en utilisant la fonction str() déjà décrite plus tôt :\n\nstr(cases_tidy)\n\ntibble [9 × 3] (S3: tbl_df/tbl/data.frame)\n $ country: chr [1:9] \"FR\" \"FR\" \"FR\" \"DE\" ...\n $ year   : chr [1:9] \"2011\" \"2012\" \"2013\" \"2011\" ...\n $ n_cases: num [1:9] 7000 6900 7000 5800 6000 6200 15000 14000 13000\n\n\nC’est le comportement par défaut de la fonction pivot_longer() : les anciens titres de colonnes sont convertis en chaînes de caractères. Si ce comportement n’est pas souhaitable, il y a 2 alternatives possibles :\n\nutiliser les arguments names_transform et/ou values_transform de la fonction pivot_longer(). Cela permet de spécifier comment transformer les variables nouvellement créées au moment de leur création.\nutiliser les fonctions mutate() et as.numeric() ou as.integer() après avoir modifié le tableau de départ avec pivot_longer(). Cette façon de faire sera décrite dans la Section 5.7.\n\n\n# On commence par afficher `cases`\ncases \n\n  country  2011  2012  2013\n1      FR  7000  6900  7000\n2      DE  5800  6000  6200\n3      US 15000 14000 13000\n\n# On utilise ensuite pivot_longer() avec l'argument \n# names_transform pour transformer year en facteur\npivot_longer(data = cases, \n             cols = `2011`:`2013`, \n             names_to = \"year\", \n             values_to = \"n_cases\",\n             names_transform = list(year = as.integer))\n\n# A tibble: 9 × 3\n  country  year n_cases\n  &lt;chr&gt;   &lt;int&gt;   &lt;dbl&gt;\n1 FR       2011    7000\n2 FR       2012    6900\n3 FR       2013    7000\n4 DE       2011    5800\n5 DE       2012    6000\n6 DE       2013    6200\n7 US       2011   15000\n8 US       2012   14000\n9 US       2013   13000\n\n\nOn voit ici que la variable year est maintenant une colonne numérique (&lt;int&gt; : nombres entiers), et non plus une variable de type “character”. En utilisant as.numeric() au lieu de as.integer(), on aurait transformé la variable year en &lt;dbl&gt; (nombre réel au lieu de nombre entier), ce qui ici, reviendrait exactement au même.\nDe la même façon, on peut avoir besoin de presenter la colonne year sous la forme d’un facteur :\n\npivot_longer(data = cases, \n             cols = `2011`:`2013`, \n             names_to = \"year\", \n             values_to = \"n_cases\",\n             names_transform = list(year = as.factor))\n\n# A tibble: 9 × 3\n  country year  n_cases\n  &lt;chr&gt;   &lt;fct&gt;   &lt;dbl&gt;\n1 FR      2011     7000\n2 FR      2012     6900\n3 FR      2013     7000\n4 DE      2011     5800\n5 DE      2012     6000\n6 DE      2013     6200\n7 US      2011    15000\n8 US      2012    14000\n9 US      2013    13000\n\n\n\n\n4.2.2 La fonction pivot_wider()\nLa fonction pivot_wider() permet de réaliser l’opération inverse de pivot_longer(). Elle “disperse” une unique colonne catégorielle en plusieurs colonnes, le tableau obtenue est donc plus large (“wider”) que le tableau de départ.\nReprenons par exemple notre tableau cases_tidy :\n\ncases_tidy\n\n# A tibble: 9 × 3\n  country year  n_cases\n  &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n1 FR      2011     7000\n2 FR      2012     6900\n3 FR      2013     7000\n4 DE      2011     5800\n5 DE      2012     6000\n6 DE      2013     6200\n7 US      2011    15000\n8 US      2012    14000\n9 US      2013    13000\n\n\nLa fonction pivot_wider() prend 3 arguments :\n\nLe nom du tableau contenant les données (ici, cases_tidy).\nnames_from : le nom de la variable contenant les catégories qui devront être transformées en colonnes (ici, year).\nvalues_from : le nom de la variable contenant les valeurs qui devront remplir les nouvelles colonnes (ici, n_cases).\n\n\npivot_wider(data = cases_tidy, \n            names_from = year, \n            values_from = n_cases)\n\n# A tibble: 3 × 4\n  country `2011` `2012` `2013`\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 FR        7000   6900   7000\n2 DE        5800   6000   6200\n3 US       15000  14000  13000\n\n\nCette fonction sera donc rarement utilisée puisqu’elle ne permet pas d’obtenir des “tableaux rangés”. Toutefois, elle pourra vous être utile pour présenter des résultats sous forme synthétique. Prenons un exemple avec le jeu de données flights. Imaginons que vous deviez créer un tableau n_vols présentant, pour chacun des 3 aéroports de New York, le nombre de vols affrétés par chaque compagnie aérienne en 2013. Une possibilité serait de taper ceci :\n\nn_vols &lt;- flights |&gt; \n  group_by(origin, carrier) |&gt; \n  count()\nn_vols\n\n# A tibble: 35 × 3\n# Groups:   origin, carrier [35]\n   origin carrier     n\n   &lt;chr&gt;  &lt;chr&gt;   &lt;int&gt;\n 1 EWR    9E       1268\n 2 EWR    AA       3487\n 3 EWR    AS        714\n 4 EWR    B6       6557\n 5 EWR    DL       4342\n 6 EWR    EV      43939\n 7 EWR    MQ       2276\n 8 EWR    OO          6\n 9 EWR    UA      46087\n10 EWR    US       4405\n# ℹ 25 more rows\n\n\nLes commandes permettant de produire ce tableau seront expliquées dans le Chapitre 5. On peut cependant constater ici que ce tableau contient 35 lignes et 3 colonnes. Il s’agit bien d’un “tableau rangé” parfaitement adapté pour faire des statistiques et des visualisations graphiques, mais son format n’est pas terrible si notre objectif est de le faire figurer dans un rapport. La solution : utiliser pivot_wider() :\n\npivot_wider(n_vols, \n            names_from = origin, \n            values_from = n)\n\n# A tibble: 16 × 4\n# Groups:   carrier [16]\n   carrier   EWR   JFK   LGA\n   &lt;chr&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1 9E       1268 14651  2541\n 2 AA       3487 13783 15459\n 3 AS        714    NA    NA\n 4 B6       6557 42076  6002\n 5 DL       4342 20701 23067\n 6 EV      43939  1408  8826\n 7 MQ       2276  7193 16928\n 8 OO          6    NA    26\n 9 UA      46087  4534  8044\n10 US       4405  2995 13136\n11 VX       1566  3596    NA\n12 WN       6188    NA  6087\n13 HA         NA   342    NA\n14 F9         NA    NA   685\n15 FL         NA    NA  3260\n16 YV         NA    NA   601\n\n\nCe nouveau tableau contient maintenant 16 lignes (une par compagnie aérienne), et 4 colonnes : une pour la variable carrier, et 3 pour la variable origin, soit une colonne pour chacun des 3 aéroports de New York. On parle de tableau au format large (par opposition au “tableau rangé”, dit “format long”). Cela rend la présentation dans un rapport plus aisée.\nNotez également que certaines compagnies aériennes ne desservent pas tous les aéroports. Par exemple, la compagnie Alaska Airlines (AS) ne dessert ni JFK, ni La Guardia. Pour ces catégories, notre nouveau tableau au format large indique NA. Or, NA signifie “Not Available”, autrement dit : données manquantes. Ici, il ne s’agit pas du tout de données manquantes. Cela signifie simplement qu’aucun vol d’Alaska Airline n’a décollé de ces 2 aéroports. Nous pouvons donc indiquer à R quelle valeur utiliser pour les catégories qui ne sont pas représentées dans le tableau de départ grâce à l’argument values_fill :\n\npivot_wider(n_vols, \n            names_from = origin, \n            values_from = n, \n            values_fill = 0)\n\n# A tibble: 16 × 4\n# Groups:   carrier [16]\n   carrier   EWR   JFK   LGA\n   &lt;chr&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1 9E       1268 14651  2541\n 2 AA       3487 13783 15459\n 3 AS        714     0     0\n 4 B6       6557 42076  6002\n 5 DL       4342 20701 23067\n 6 EV      43939  1408  8826\n 7 MQ       2276  7193 16928\n 8 OO          6     0    26\n 9 UA      46087  4534  8044\n10 US       4405  2995 13136\n11 VX       1566  3596     0\n12 WN       6188     0  6087\n13 HA          0   342     0\n14 F9          0     0   685\n15 FL          0     0  3260\n16 YV          0     0   601\n\n\nD’autres arguments existent. Je vous encourage vivement à consulter l’aide des fonctions pivot_longer() et pivot_wider() et à faire des essais.\n\n\n4.2.3 Les fonctions separate() et unite()\nCes fonctions sont complémentaires : tout comme pivot_longer() et pivot_wider(), elles effectuent 2 opérations opposées. Reprenons le jeu de données cases_tidy :\n\ncases_tidy\n\n# A tibble: 9 × 3\n  country year  n_cases\n  &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n1 FR      2011     7000\n2 FR      2012     6900\n3 FR      2013     7000\n4 DE      2011     5800\n5 DE      2012     6000\n6 DE      2013     6200\n7 US      2011    15000\n8 US      2012    14000\n9 US      2013    13000\n\n\nImaginons que nous ayons besoin de séparer les données de la colonne year en 2 variables : le siècle d’une part, et l’année d’autre part. La fonction separate() permet de faire exactement cela :\n\nseparate(cases_tidy, year, into = c(\"century\", \"year\"), sep = 2)\n\n# A tibble: 9 × 4\n  country century year  n_cases\n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n1 FR      20      11       7000\n2 FR      20      12       6900\n3 FR      20      13       7000\n4 DE      20      11       5800\n5 DE      20      12       6000\n6 DE      20      13       6200\n7 US      20      11      15000\n8 US      20      12      14000\n9 US      20      13      13000\n\n\n\nLe premier argument est le nom du tableau de données.\nLe second argument est la variable que l’on souhaite scinder en plusieurs morceaux.\ninto est un vecteur qui contient le nom des nouvelles colonnes à créer\nsep peut prendre plusieurs formes. Lorsqu’on utilise un nombre, ce nombre correspond à la position de la coupure dans la variable d’origine. Ici, la variable d’origine a été coupée après le second caractère. Il est aussi possible d’utiliser un symbole. Par exemple, certaines variables contiennent des tirets - ou des slash \\. Utiliser ces caractères en guise de séparateur permet de couper les variables à ce niveau là. Nous en verrons un exemple plus tard.\n\nNotez ici que les 2 nouvelles variables sont de type &lt;chr&gt;. Si nous souhaitons que ces variables soient considérées comme numériques, nous devons ajouter un argument lorsque nous utilisons separate() :\n\ncases_split &lt;- separate(cases_tidy, \n                        year, \n                        into = c(\"century\", \"year\"), \n                        sep = 2, \n                        convert = TRUE)\ncases_split\n\n# A tibble: 9 × 4\n  country century  year n_cases\n  &lt;chr&gt;     &lt;int&gt; &lt;int&gt;   &lt;dbl&gt;\n1 FR           20    11    7000\n2 FR           20    12    6900\n3 FR           20    13    7000\n4 DE           20    11    5800\n5 DE           20    12    6000\n6 DE           20    13    6200\n7 US           20    11   15000\n8 US           20    12   14000\n9 US           20    13   13000\n\n\nNotre nouvel objet cases_split contient maintenant 2 nouvelles colonnes de nombres entiers, l’une contenant le siècle, l’autre contenant l’année.\nLa fonction unite() fait exactement le contraire : elle fusionne 2 colonnes existantes en accolant leurs contenus (et en ajoutant un séparateur) :\n\nunite(cases_split, new, century, year)\n\n# A tibble: 9 × 3\n  country new   n_cases\n  &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n1 FR      20_11    7000\n2 FR      20_12    6900\n3 FR      20_13    7000\n4 DE      20_11    5800\n5 DE      20_12    6000\n6 DE      20_13    6200\n7 US      20_11   15000\n8 US      20_12   14000\n9 US      20_13   13000\n\n\nLa colonne new a été créée par la fusion des colonnes century et year du tableau cases_split. Si l’on souhaite supprimer le tiret, il nous faut le spécifier explicitement :\n\nunite(cases_split, new, century, year, sep = \"\")\n\n# A tibble: 9 × 3\n  country new   n_cases\n  &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n1 FR      2011     7000\n2 FR      2012     6900\n3 FR      2013     7000\n4 DE      2011     5800\n5 DE      2012     6000\n6 DE      2013     6200\n7 US      2011    15000\n8 US      2012    14000\n9 US      2013    13000\n\n\n\n\n4.2.4 Exercices\nExaminez les tableaux rates, storms et population du package EDAWR.\n\nCes tableaux sont-ils des “tableaux rangés” (tidy data) ?\nSi oui, quelles sont les variables représentées ?\nSi non, transformez-les en “tableaux rangés”."
  },
  {
    "objectID": "04-tidy-Data.html#importer-des-données-depuis-un-tableur",
    "href": "04-tidy-Data.html#importer-des-données-depuis-un-tableur",
    "title": "4  (Ar)ranger des données avec tidyr",
    "section": "4.3 Importer des données depuis un tableur",
    "text": "4.3 Importer des données depuis un tableur\n\n4.3.1 Les règles de base\nJusqu’à maintenant, nous avons travaillé exclusivement avec des jeux de données déjà disponibles dans R. La plupart du temps, les données sur lesquelles vous devrez travailler devront au préalable être importées dans R, à partir de fichiers issus de tableurs. De tels fichiers se présentent généralement sous l’un des 2 formats suivants :\n\nFichiers au format “.csv” : il s’agit d’un format de fichier dit “texte brut”, c’est à dire qu’il peut être ouvert avec n’importe quel éditeur de texte, y compris le bloc notes de Windows. L’extension “.csv” est l’abbréviation de Comma Separated Values, autrement dit, dans ce type de fichiers, les colonnes sont séparées par des virgules. Cela peut poser problème en France puisque le symbole des décimales est souvent aussi la virgule (et non le point comme dans les pays anglo-saxons). Le séparateur de colonnes utilisé en France dans les fichiers .csv est alors souvent le point-virgule. Il est possible de créer des fichiers .csv à partir de n’importe quel tableur en choisissant Fichier &gt; Exporter... ou Fichier &gt; Enregistrer sous... puis en sélectionnant le format approprié (les dénomminations sont variables selon les logiciels : format texte brut, format csv, plain text, etc…).\nFichiers au format tableur : .xls ou .xlsx pour Excel, .calc pour Open Office.\n\nDans les 2 cas, pour que R puisse importer les données contenues dans ces fichiers, un certain nombre de règles doivent être respectées :\n\nLa première chose à laquelle il faut veiller est la présentation des données. Les variables doivent être en colonnes et les observations en lignes. Dans l’idéal, les données doivent donc être “rangées”.\nLes cases vides qui correspondent à des données manquantes doivent contenir les lettres NA en majuscule. Il est important de bien faire la distinction entre les vrais zéros (i.e. les grandeurs mesurées pour lesquelles un zéro a été obtenu), et les valeurs manquantes, c’est à dire pour lesquelles aucune valeur n’a pu être obtenue (e.g. variable non mesurée pour un individu donné ou à une station donnée).\nIl est généralement conseillé d’utiliser la première ligne du tableau pour stocker le nom des variables et la première colonne pour stocker le nom des observations (identifiant des individus, des échantillons ou des stations par exemple).\nNe jamais utiliser de caractères spéciaux tels que #, $, %, ^, &, *, (, ), {, }, [, ], des accents, des cédilles des guillemets ou des apostrophes… Cela pourrait causer des erreurs dans R. Si votre fichier en contient, faites une recherche (via le menu Edition &gt; Rechercher et remplacer...) pour remplacer chaque instance par un caractère qui ne posera pas de problème.\nÉvitez les espaces dans vos noms de variables, d’observations ou de catégories et remplacez-les par des points ou des _.\nSi des noms de lignes sont présents dans votre tableau, chaque ligne doit avoir un nom unique (il ne faut pas que plusieurs lignes portent le même nom).\nDes noms courts pour les variables sont généralement plus faciles à manipuler par la suite.\nLa première valeur de votre tableau derait toujours se trouver dans la cellule A1 du tableur. Autrement dit, il ne devrait jamais y avoir de lignes incomplètes ou de lignes de commentaires au-dessus des données, ou de colonne vide à gauche de votre tableau. D’ailleurs, il ne devrait jamais y avoir de commentaires à droite ou en dessous de vos données non plus.\n\n\n\n4.3.2 Fichiers au format tableur (.xls ou .xlsx)\nÀ titre d’exemple, téléchargez le fichier dauphin.xls et placez-le dans votre répertoire de travail. Ce jeu de données contient des résultats de dosages de différents métaux lourds (cadmium, cuivre et mercure) dans différents organes (foie et rein) de plusieurs dauphins communs Delphinus delphis. Les informations de taille, d’âge et de statut reproducteur sont également précisées. Ouvrez ce fichier dans un tableur. Vous constaterez que son format ne permet pas de l’importer tel quel dans R :\n\nIl contient des lignes vides inutiles au-dessus des données.\nIl contient des commentaires inutiles au-dessus des données.\nLes titres de colonnes sont complexes et contiennent des caractères spéciaux.\nDans le tableau, les données manquantes sont représentées soit par des “*”, soit par des cellules vides.\n\nImporter un tel jeu de données dans R par les méthodes classiques (c’est-à-dire sans utiliser RStudio et uniquement grâce aux fonctions de base de R) demanderait donc un gros travail de mise en forme préalable. Heureusement, RStudio et le package readxl facilitent grandement le processus.\nDans RStudio, localisez l’onglet Files situé dans le panneau en bas à droite de l’interface du logiciel. Dans ce panneau, naviguez jusqu’à votre répertoire de travail, qui doit maintenant contenir le fichier daupin.xls que vous avez téléchargé. Cliquez sur son nom, puis, dans le menu qui s’affiche, choisissez Import Dataset... :\n\n\n\n\n\nFigure 4.4: L’option Import Dataset... dans la fenêtre Files de RStudio.\n\n\n\n\nLa nouvelle fenêtre qui s’ouvre est un “assistant d’importation” (Figure 4.5).\n\n\n\n\n\nFigure 4.5: L’assistant d’importation de RStudio.\n\n\n\n\nCette fenêtre contient plusieurs zones importantes :\n\nFile/URL (en haut) : lien vers le fichier contenant les données, sur votre ordinateur ou en ligne.\nData Preview : zone principale affichant les 50 premières lignes du fichier que l’on souhaite importer.\nImport Options (en bas à gauche) : zone dans laquelle des options permettant d’importer les données correctement peuvent être spécifiées.\nCode Preview (en bas à droite) : les lignes de codes que vous pourrez copier-coller dans votre script une fois les réglages corrects effectués.\n\nIci, nous constatons que les données ne sont pas au bon format. La première chose que nous pouvons faire est d’indiquer à R que nous souhaitons ignorer les 9 premières lignes du fichier. Ensuite, nous précisons à RStudio que l’étoile “*” a été utilisée pour indiquer des données manquantes (Figure 4.6) :\n\n\n\n\n\nFigure 4.6: Les bons réglages pour ce fichier.\n\n\n\n\nNotez qu’à chaque fois que vous modifiez une valeur dans la zone Import Options, 2 choses se produisent simultanément :\n\nLa zone Data Preview est mise à jour. Cela permet de s’assurer que les changements effectués ont bien les effets escomptés.\nLa zone Code Preview est mise à jour. Cela permet de copier-coller dans un script les commandes permettant d’importer correctement les données. Ici, voilà le code que nous devons ajouter à notre script :\n\n\ndauphin &lt;- read_excel(\"data/dauphin.xls\", na = \"*\", skip = 9)\n\nLa commande library(readxl) est inutile puisque nous l’avons déjà saisie au début de ce chapitre. Nous disposons maintenant d’un nouvel objet nommé dauphin. Il est stocké sous la forme d’un tibble :\n\ndauphin\n\n# A tibble: 93 × 9\n   `N°`      Sexe  `Statut reproducteur` `Taille en cm` `Age en années`\n   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;                          &lt;dbl&gt;           &lt;dbl&gt;\n 1 Numéro 1  f     imm                              315               3\n 2 Numéro 2  f     imm                              357               4\n 3 Numéro 3  f     pnl                              439              34\n 4 Numéro 4  f     imm                              316               4\n 5 Numéro 5  f     l                                435              26\n 6 Numéro 6  f     pnl                              388               6\n 7 Numéro 7  f     mat                              410              NA\n 8 Numéro 8  m     imm                              355              NA\n 9 Numéro 9  m     imm                              222              NA\n10 Numéro 10 m     imm                              412               9\n# ℹ 83 more rows\n# ℹ 4 more variables: `Cd (mg.kg-1)` &lt;dbl&gt;, `Cu (mg.kg-1)` &lt;dbl&gt;,\n#   `Hg (mg.kg-1)` &lt;dbl&gt;, Organe &lt;chr&gt;\n\n\nNotez toutefois que les noms de colonnes complexes sont toujours présents. Avec de tels noms, les variables ne seront pas faciles à manipuler et les risques d’erreurs de frappes seront nombreux. Nous avons tout intérêt à les modifier à l’aide de la fonction names() :\n\nnames(dauphin) &lt;- c(\"ID\", \"Sexe\", \"Statut\", \"Taille\",\n                    \"Age\", \"Cd\", \"Cu\", \"Hg\", \"Organe\")\ndauphin\n\n# A tibble: 93 × 9\n   ID        Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n 1 Numéro 1  f     imm       315     3  29.6   3.24 NA    rein  \n 2 Numéro 2  f     imm       357     4  55.1   4.42 NA    rein  \n 3 Numéro 3  f     pnl       439    34 129.    5.01  9.02 rein  \n 4 Numéro 4  f     imm       316     4  71.2   4.33 NA    rein  \n 5 Numéro 5  f     l         435    26 192     5.15 NA    rein  \n 6 Numéro 6  f     pnl       388     6  NA     4.12  4.53 rein  \n 7 Numéro 7  f     mat       410    NA  76     5.1  33.9  foie  \n 8 Numéro 8  m     imm       355    NA  74.4   4.72 13.3  foie  \n 9 Numéro 9  m     imm       222    NA   0.09  9.5   2.89 foie  \n10 Numéro 10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nEnfin, vous pouvez également noter que certaines variables devraient être modifiées :\n\nLes variables Sexe, Statut (qui contient l’information de statut reproducteur des dauphins) et Organe (qui indique dans quel organe les métaux ont été dosés) sont de type &lt;chr&gt;. L’idéal serait de disposer de facteurs puisqu’ils s’agit de variables catégorielles.\nLa variable ID est totalement inutile puisqu’elle est parfaitement redondante avec le numéro de ligne. Nous pourrions donc la supprimer.\nCertaines catégories (ou niveaux) de la variable Statut devraient être ordonnées puisqu’elles reflètent une progression logique : imm (immature), mat (mature), pnl (pregnant not lactating), pl (pregnant lactating), l (lactating), repos (repos somatique).\n\nNous verrons dans le Chapitre 5 comment effectuer simplement ces différentes opérations.\n\n\n4.3.3 Fichiers au format texte brut (.csv)\nNous allons utiliser les mêmes données que précédemment, mais cette fois-ci, elles sont contenues dans un fichier au format .csv. Téléchargez le fichier dauphin.csv (pour cela, faites un clic droit sur le lien et choisissez Enregistrez la cible du lien sous... ou une mention équivalente), placez-le dans votre répertoire de travail, et ouvrez-le avec le bloc notes Windows ou tout autre éditeur de texte brut disponible sur votre ordinateur. Attention : Microsoft Word n’est pas un éditeur de texte brut. Un fichier au format .doc ou .docx est illisible dans un éditeur de texte brut car outre le texte, ces formats de documents contiennent toutes les informations concernant la mise en forme du texte (polices de caractères, tailles, couleurs et autres attributs, présence de figures, de tableaux dans le document, etc.).\nÀ l’inverse, les fichiers au format .txt, .csv et même .R (vos scripts !) sont des fichiers au format texte brut. Vous pouvez d’ailleurs essayer d’ouvrir dauphin.csv depuis RStudio, en allant dans la fenêtre Files puis en cliquant sur le nom du fichier et en choisissant View File. RStudio ouvre un nouvel onglet à côté de votre script vous permettant d’inspecter le contenu de ce fichier. Par rapport au fichier Excel, vous pouvez noter un certain nombre de différences :\n\nLes colonnes sont séparées par des tabulations.\nLes nombres décimaux utilisent la virgule (et non le point comme dans les pays anglo-saxons).\nLes noms de colonnes ont déjà été corrigés/simplifiés par rapport au tableau d’origine.\nLes valeurs manquantes sont toutes codées par des NAs.\n\nUn travail d’édition du fichier .xls de départ a donc été réalisé en amont de l’enregistrement au format .csv.\nAttention, à ce stade, vous avez ouvert un fichier au format texte brut dans RStudio, mais les données contenues dans ce fichier n’ont pas été importées dans R pour autant. Pour les importer, on procède comme pour les fichiers au format tableur (voir Section 4.3.2 ci-dessus).\nOn commence par cliquer sur dauphin.csv dans l’onglet Files de RStudio. On sélectionne ensuite Import Dataset... :\n\n\n\n\n\nFigure 4.7: Importer un fichier .csv depuis l’onglet Files de RStudio.\n\n\n\n\nLa fenêtre qui s’ouvre est en tous points identique à celle obtenue pour l’importation de fichiers tableurs (Figure 4.8).\n\n\n\n\n\nFigure 4.8: Importer un fichier .csv depuis l’onglet Files de RStudio.\n\n\n\n\nNous voyons ici que par défaut, RStudio considère qu’une unique colonne est présente. En effet, les fichiers .csv utilisent généralement la virgule pour séparer les colonnes. Ce n’est pas le cas ici. Il nous faut donc sélectionner, dans le champ Delimiter, l’option Tab (tabulation) et non Comma (virgule).\nÀ ce stade, chaque variable est maintenant reconnue comme telle, chaque variable occupe donc une colonne distincte. Mais les colonnes Cd, Cu et Hg ne contiennent pas les bonnes valeurs (vous pouvez le vérifier en consultant l’onglet dauphin.csv que vous avez ouvert un peu plus tôt à côté de votre script). La cause est simple : R s’attend à ce que les nombres décimaux utilisent le point en guise de symbole des décimales. Or, notre fichier .csv utilise la virgule. C’est une convention qui dépend du pays dans lequel vous vous trouvez, et de la langue de votre système d’exploitation (en langage technique, on parle de Locale). Le fichier dauphin.csv ayant été créé sur un ordinateur français, la virgule a été utilisée en guise de symbole des décimales. Pour l’indiquer à R, cliquez sur Locale &gt; Configure..., changez le . en , dans le champ Decimal Mark et validez en cliquant sur Configure.\n\n\n\n\n\nFigure 4.9: Changement du symbole utilisé pour les décimales.\n\n\n\n\nLes données sont maintenant au bon format, prêtes à être importées dans RStudio. Afin de ne pas écraser l’objet dauphin que nous avons créé à partir du fichier tableur un peu plus tôt, nous stockerons ces nouvelles données dans un objet nommé dauphin2. Pour cela, ajoutez un 2 au nom dauphin dans le champ Name en bas à gauche :\n\n\n\n\n\nFigure 4.10: Les données, dans un format correct permettant l’importation.\n\n\n\n\nNous n’avons plus qu’à copier-coller dans notre script le code généré automatiquement en bas à droite de la fenêtre (comme précédemment, la ligne library(readr) est inutile : nous avons déjà chargé ce package en début de chapitre).\n\ndauphin2 &lt;- read_delim(\"data/dauphin.csv\", \n    \"\\t\", escape_double = FALSE, locale = locale(decimal_mark = \",\"), \n    trim_ws = TRUE)\n\nRows: 93 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (3): Sexe, Statut, Organe\ndbl (6): Id, Taille, Age, Cd, Cu, Hg\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNotez que :\n\nC’est le package readr et non plus readxl qui est utilisé.\nLa fonction read_delim() a remplacé la fonction read_excel(). Il existe beaucoup d’autres fonctions selon le format de vos données (par exemple read_csv() et read_csv2()). Il est inutile de toutes les connaître dans la mesure où généralement, RStudio vous propose automatiquement la plus appropriée.\nR indique de quelle façon les colonnes ont été “parsées”, autrement dit, R indique quelles fonctions ont été utilisées pour reconnaître le type des données présentes dans chaque colonne.\n\nToutes les fonctions permettant d’importer des données n’ont pas nécessairement le même comportement. Ainsi, si l’on compare les objets importés depuis le fichier tableur (dauphin) et depuis le fichier texte brut (dauphin2), le type de certaines variables peut être différent :\n\ndauphin\n\n# A tibble: 93 × 9\n   ID        Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n 1 Numéro 1  f     imm       315     3  29.6   3.24 NA    rein  \n 2 Numéro 2  f     imm       357     4  55.1   4.42 NA    rein  \n 3 Numéro 3  f     pnl       439    34 129.    5.01  9.02 rein  \n 4 Numéro 4  f     imm       316     4  71.2   4.33 NA    rein  \n 5 Numéro 5  f     l         435    26 192     5.15 NA    rein  \n 6 Numéro 6  f     pnl       388     6  NA     4.12  4.53 rein  \n 7 Numéro 7  f     mat       410    NA  76     5.1  33.9  foie  \n 8 Numéro 8  m     imm       355    NA  74.4   4.72 13.3  foie  \n 9 Numéro 9  m     imm       222    NA   0.09  9.5   2.89 foie  \n10 Numéro 10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\ndauphin2\n\n# A tibble: 93 × 9\n      Id Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n 1     1 f     imm       315     3  29.6   3.24 NA    rein  \n 2     2 f     imm       357     4  55.1   4.42 NA    rein  \n 3     3 f     pnl       439    34 129.    5.01  9.02 rein  \n 4     4 f     imm       316     4  71.2   4.33 NA    rein  \n 5     5 f     l         435    26 192     5.15 NA    rein  \n 6     6 f     pnl       388     6  NA     4.12  4.53 rein  \n 7     7 f     mat       410    NA  76     5.1  33.9  foie  \n 8     8 m     imm       355    NA  74.4   4.72 13.3  foie  \n 9     9 m     imm       222    NA   0.09  9.5   2.89 foie  \n10    10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nEn particulier selon la version des packages que vosu utilisez et les réglages spéifiques de vos systèmes d’exploitation, les variables Taille et Age sont parfois considérées comme réelles dans dauphin mais comme entières dans dauphin2 (ce n’est pas le cas ici). Afin d’éviter les confusions dans la suite du document, nous allons supprimer dauphin2 en tapant :\n\nrm(dauphin2)\n\nTaper dauphin2 dans la console devrait maintenant produire une erreur :\n\ndauphin2\n\nError in eval(expr, envir, enclos): objet 'dauphin2' introuvable\n\n\n\n\n4.3.4 En cas de problème…\nIl arrive parfois que l’importation de fichiers textes bruts par la méthode décrite ci-dessus échoue en raison d’un bug du package readr qui gère mal la présence de caractères spéciaux (accents, cédilles, etc) dans le chemin des fichiers que l’on tente d’importer. À l’heure où j’écris ces lignes (28 novembre 2018), le bug a été corrigé dans la version de développement du package, mais toujours pas dans la version stable disponible au téléchargement sur les serveurs du CRAN. Il est donc utile de connaître une méthode alternative pour importer de tels fichiers dans R. Cette méthode repose sur “la mère de toutes les fonctions d’importation” : read.table().\nLa fonction read.table() est à la base de la plupart des fonctions d’importation décrites dans ce chapitre. Il est donc important d’en connaître la syntaxe et les arguments les plus importants. Cette fonction requiert en général les arguments suivants :\n\nLe chemin du fichier texte contenant les données à importer. Si le fichier se trouve dans votre répertoire de travail, il suffit de donner son nom. S’il est dans un sous-dossier de votre répertoire de travail, il faut donner le nom complet : \"sous_dossier/nom_du_fichier.csv\".\nsep : la spécification du symbole utilisé en guise de séparateur de colonnes dans le fichier texte. Cela peut-être la virgule (sep = \",\"), le point virgule (sep = \";\") ou encore la tabulation (sep = \"\\t\") selon les fichiers importés.\ndec : la spécification du symbole utilisé en guise de symbole pour les décimales. Il n’est pas nécessaire de spécifier cet argument lorsque le symbole dans le fichier source est le point. Mais si c’est une virgule (comme c’est souvent le cas dans les pays francophones), il faut alors préciser dec = \",\".\nheader : la première ligne du fichier source contient-elle des noms de variables. Si oui, il faut indiquer header = TRUE.\n\nAinsi, par exemple, pour le fichier dauphin.csv, on peut taper ceci :\n\ndauph &lt;- read.table(\"data/dauphin.csv\",\n                    sep = \"\\t\",\n                    dec = \",\",\n                    header = TRUE)\ndauph &lt;- as_tibble(dauph)\ndauph\n\n# A tibble: 93 × 9\n      Id Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;   &lt;int&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n 1     1 f     imm       315     3  29.6   3.24 NA    rein  \n 2     2 f     imm       357     4  55.1   4.42 NA    rein  \n 3     3 f     pnl       439    34 129.    5.01  9.02 rein  \n 4     4 f     imm       316     4  71.2   4.33 NA    rein  \n 5     5 f     l         435    26 192     5.15 NA    rein  \n 6     6 f     pnl       388     6  NA     4.12  4.53 rein  \n 7     7 f     mat       410    NA  76     5.1  33.9  foie  \n 8     8 m     imm       355    NA  74.4   4.72 13.3  foie  \n 9     9 m     imm       222    NA   0.09  9.5   2.89 foie  \n10    10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nPuisque la fonction read.table() importe les données sous la forme d’un data.frame, il est nécessaire de transformer le tableau obtenu en tibble grâce à la fonction as_tibble() afin de bénéficier de tous les avantages de ce format d’objet.\n\n\n4.3.5 Exercices\n\nL’objet dauphin est-il “tidy” (autrement dit, s’agit-il de “données rangées”) ? Justifiez.\nProduisez le graphique ci-dessous :\n\n\n\n\n\n\nFigure 4.11: Figure à reproduire.\n\n\n\n\nIndice : les droites de régression avec les intervalles de confiance sont ajoutés grâce à la fonction geom_smooth(method = \"lm\").\n\nImportez dans R le jeu de données whoTB.csv. Ce jeu de données contient les cas de tuberculose (TB) rapportés par l’Organisation Mondiale de la Santé (OMS, ou WHO en anglais : World Health Organization). Les cas sont répertoriés par année, pays, âge, sexe, type de tuberculose et méthode de diagnostique. Selon vous, ce jeu de données est-il “rangé” ? Pourquoi ?\nSi ce jeu de données n’est pas rangé, rangez-le en utilisant les fonctions du packages tidyr que nous avons découvertes dans ce chapitre : pivot_longer(), pivot_wider(), separate() et unite() (vous n’aurez pas nécessairement besoin d’utiliser ces 4 fonctions, et à l’inverse, certaines devront peut-être être utilisées plusieurs fois).\n\nPour vous aider, l’OMS donne la signification des codes utilisés en guise de noms pour la plupart des colonnes. Ainsi :\n\nnew indique des nouveaux cas, old des anciens (ici, seuls des nouveaux cas sont rapportés).\nLe type de cas est précisé ensuite :\n\nsp signifie “Smear Positive” (tuberculose pulmonaire à frottis positif).\nsn signifie “Smear Negative” (tuberculose pulmonaire à frottis négatif).\nrel signifie “relapse” (rechute).\nep signifie “Extra Pulmonary” (tuberculose extra-pulmonaire).\n\nLe sexe est codé par m (male) ou f (female).\nEnfin, les chiffres correspondent à des tranches d’âges : 014 signifie “de 0 à 14 ans”, “1524” signifie “de 15 à 24 ans”, etc.\n\nDans ces colonnes aux noms composés, les nombres de cas de tuberculose sont rapportés."
  },
  {
    "objectID": "05-DataWrangling.html#pré-requis",
    "href": "05-DataWrangling.html#pré-requis",
    "title": "5  Tripatouiller les données avec dplyr",
    "section": "5.1 Pré-requis",
    "text": "5.1 Pré-requis\nNous abordons ici une étape essentielle de toute analyse de données : la manipulation de tableaux, la sélection de lignes, de colonnes, la création de nouvelles variables, etc. Bien souvent, les données brutes que nous importons dans R ne sont pas utiles en l’état. Il nous faut parfois sélectionner seulement certaines lignes pour travailler sur une petite partie du jeu de données. Il nous faut parfois modifier des variables existantes (pour modifier les unités par exemple) ou en créer de nouvelles à partir des variables existantes. Nous avons aussi très souvent besoin de constituer des groupes et d’obtenir des statistiques descriptives pour chaque groupe (moyenne, écart-type, erreur type, etc). Nous verrons dans ce chapitre comment faire tout cela grâce au package dplyr qui fournit un cadre cohérent et des fonctions simples permettant d’effectuer tous les tripatouillages de données dont nous pourrons avoir besoin.\nDans ce chapitre, nous aurons besoin des packages suivants :\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(nycflights13)\nlibrary(forcats)"
  },
  {
    "objectID": "05-DataWrangling.html#le-pipe",
    "href": "05-DataWrangling.html#le-pipe",
    "title": "5  Tripatouiller les données avec dplyr",
    "section": "5.2 Le pipe |>",
    "text": "5.2 Le pipe |&gt;\nAvant d’entrer dans le vif du sujet, je souhaite introduire ici la notion de “pipe” (prononcer à l’anglo-saxonne). Le pipe est un opérateur que nous avons déjà vu apparaître à plusieurs reprises dans les chapitres précédents sans expliquer son fonctionnement.\n\n\n\n\n\n\nFigure 5.1: Pour que ces raccourcis fonctionnent, assurez-vous que l’option Use native pipe operator est bien cochée dans les préférences de RStudio.\n\n\n\nLe pipe, noté |&gt;, peut être obtenu en pressant les touches ctrl + shift + M de votre clavier (ou command + shift + M sous macOS). Il permet d’enchaîner logiquement des actions les unes à la suite des autres. Globalement, le pipe prend l’objet situé à sa gauche, et le transmet à la fonction situé à sa droite. En d’autres termes, les 2 expressions suivantes sont strictement équivalentes :\n\n# Ici, \"f\" est une fonction quelconque, \n# \"x\" et \"y\" sont 2 objets dont la fonction a besoin.\n\n# Il s'agit d'un exemple fictif : ne tapez pas ceci dans votre script !\nf(x, y)\nx |&gt; f(y)\n\nTravailler avec le pipe est très intéressant car toutes les fonctions de dplyr que nous allons décrire ensuite sont construites autour de la même syntaxe : on leur fournit un data.frame (ou encore mieux, un tibble), elles effectuent une opération et renvoient un nouveau data.frame (ou un nouveau tibble). Il est ainsi possible de créer des groupes de commandes cohérentes qui permettent, grâce à l’enchaînement d’étapes simples, d’aboutir à des résultats complexes.\nDe la même façon que le + permet d’ajouter une couche supplémentaire à un graphique ggplot2, le pipe |&gt; permet d’ajouter une opération supplémentaire dans un groupe de commandes.\nPour reprendre un exemple de la Section 3.3 sur les nuages de points, nous avions commencé par créer un objet nommé alaska_flights à partir de l’objet flights :\n\nalaska_flights &lt;- flights |&gt;\n  filter(carrier == \"AS\")\n\nNous avions ensuite créé notre premier nuage de points avec ce code :\n\nggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) + \n  geom_point()\n\nNous savons maintenant qu’il n’est pas indispensable de faire figurer le nom des arguments data = et mapping =. Mais nous pouvons aller plus loin. En fait, il n’était même pas nécessaire de créer l’objet alaska_flights : nous aurions pu utiliser le pipe pour enchaîner les étapes suivantes :\n\nOn prend le tableau flights, puis…\nOn filtre les données pour ne retenir que la compagnie aérienne AS, puis…\nOn réalise le graphique.\n\nVoilà comment traduire cela avec le pipe :\n\nflights |&gt; \n  filter(carrier == \"AS\") |&gt; \n  ggplot(aes(x = dep_delay, y = arr_delay)) + \n    geom_point()\n\n\n\n\nFigure 5.2: Notre premier graphique, produit grâce au pipe.\n\n\n\n\nNotez bien qu’ici, aucun objet intermédiaire n’a été créé. Notez également que le premier argument de la fonction ggplot() a disparu : le pipe a fourni automatiquement à ggplot() les données générées au préalable (les données flights filtrées grâce à la fonction filter()).\nComme pour le + de ggplot2, il est conseillé de placer un seul pipe par ligne, de le placer en fin de ligne et de revenir à la ligne pour préciser l’étape suivante.\nToutes les commandes que nous utiliserons à partir de maintenant reposeront sur le pipe puisqu’il permet de rendre le code plus lisible."
  },
  {
    "objectID": "05-DataWrangling.html#les-verbes-du-tripatouillage-de-données",
    "href": "05-DataWrangling.html#les-verbes-du-tripatouillage-de-données",
    "title": "5  Tripatouiller les données avec dplyr",
    "section": "5.3 Les verbes du tripatouillage de données",
    "text": "5.3 Les verbes du tripatouillage de données\nNous allons ici nous concentrer sur les fonctions les plus couramment utilisées pour manipuler et résumer des données. Nous verrons 6 verbes principaux, chacun correspondant à une fonction précise de dplyr. Chaque section de ce chapitre sera consacrée à la présentation d’un exemple utilisant un ou plusieurs de ces verbes.\nLes 6 verbes sont :\n\nfilter() : choisir des lignes dans un tableau à partir de conditions spécifiques (filtrer).\narrange() : trier les lignes d’un tableau selon un ou plusieurs critères (arranger).\nselect() : sélectionner des colonnes d’un tableau.\nmutate() : créer de nouvelles variables en transformant et combinant des variables existantes (muter).\nsummarise() : calculer des résumés statistiques des données (résumer). Souvent utilisé en combinaison avec group_by() (grouper par), qui permet de constituer des groupes au sein des données.\njoin() : associer, fusionner 2 data.frames en faisant correspondre les éléments d’une colonne commune entre les 2 tableaux (joindre). Il y a de nombreuses façons de joindre des tableaux. Nous nous contenterons d’examiner les fonctions left_join() et inner_join().\n\nToutes ces fonctions, tous ces verbes, sont utilisés de la même façon : on prend un data.frame, grâce au pipe, on le transmet à l’une de ces fonctions dont on précise les arguments entre parenthèses, la fonction nous renvoie un nouveau tableau modifié. Évidemment, on peut enchaîner les actions pour modifier plusieurs fois le même tableau, c’est tout l’intérêt du pipe.\nEnfin, gardez en tête qu’il existe beaucoup plus de fonctions dans dplyr que les 6 que nous allons détailler ici. Nous verrons parfois quelques variantes, mais globalement, maîtriser ces 6 fonctions simples devrait vous permettre de conduire une très large gamme de manipulations de données, et ainsi vous faciliter la vie pour la production de graphiques et l’analyse statistique de vos données."
  },
  {
    "objectID": "05-DataWrangling.html#filtrer-des-lignes-avec-filter",
    "href": "05-DataWrangling.html#filtrer-des-lignes-avec-filter",
    "title": "5  Tripatouiller les données avec dplyr",
    "section": "5.4 Filtrer des lignes avec filter()",
    "text": "5.4 Filtrer des lignes avec filter()\n\n5.4.1 Principe\n\n\n\n\n\nFigure 5.3: Schéma de la fonction filter() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nComme son nom l’indique, filter() permet de filtrer des lignes en spécifiant un ou des critères de tri portant sur une ou plusieurs variables. Nous avons déjà utilisé cette fonction à plusieurs reprises pour créer les jeux de données alaska_flights et small_weather :\n\nalaska_flights &lt;- flights |&gt; \n  filter(carrier == \"AS\")\n\n\nsmall_weather &lt;- weather |&gt; \n  filter(origin == \"EWR\",\n         month == 1,\n         day &lt;= 15)\n\nDans les 2 cas, la première ligne de code nous permet :\n\nD’indiquer le nom du nouvel objet dans lequel les données modifiées seront stockées (alaska_flights et small-weather).\nD’indiquer de quel objet les données doivent être extraites (flights et weather).\nDe passer cet objet à la fonction suivante avec un pipe |&gt;.\n\nLe premier argument de la fonction filter() doit être le nom d’un data.frame ou d’un tibble. Ici, puisque nous utilisons le pipe, il est inutile de spécifier cet argument : c’est ce qui est placé à gauche du pipe qui est utilisé comme premier argument de la fonction filter(). Les arguments suivants constituent la ou les conditions qui doivent être respectées par les lignes du tableau de départ afin d’être intégrées au nouveau tableau de données.\n\n\n5.4.2 Exercice\nDans la Section 2.3.1, nous avons utilisé la fonction View et l’application manuelle de filtres pour déterminer combien de vols avaient quitté l’aéroport JFK le 12 février 2013. En utilisant la fonction filter(), créez un objet nommé JFK_12fev qui contiendra les données de ces vols.\nVérifiez que cet objet contient bien 282 lignes.\n\n\n5.4.3 Les conditions logiques\nDans la Section 1.3.4.2, nous avons présenté en détail le fonctionnement des opérateurs de comparaison dans R. Relisez cette section si vous ne savez plus de quoi il s’agit. Les opérateurs de comparaison permettent de vérifier l’égalité ou l’inégalité entre des éléments. Ils renvoient TRUE ou FALSE et seront particulièrement utiles pour filtrer des lignes dans un tableau. Comme indiqué dans la Section 1.3.4.2, voici la liste des opérateurs de comparaison usuels :\n\n== : égal à\n!= : différent de\n&gt; : supérieur à\n&lt; : inférieur à\n&gt;= : supérieur ou égal à\n&lt;= : inférieur ou égal à\n\nÀ cette liste, nous pouvons ajouter quelques éléments utiles :\n\nis.na() : renvoie TRUE en cas de données manquantes.\n! : permet de tester le contraire d’une expression logique. Par exemple !is.na() renvoie TRUE s’il n’y a pas de données manquantes.\n%in% : permet de tester si l’élément de gauche est contenu dans la série d’éléments fournie à droite. Par exemple 2 %in% 1:5 renvoie TRUE, mais 2 %in% 5:10 renvoie FALSE.\n| : opérateur logique OU. Permet de tester qu’une condition OU une autre est remplie.\n& : opérateur logique ET. Permet de tester qu’une condition ET une autre sont remplies.\n\nVoyons comment utiliser ces opérateurs avec la fonction filter().\nDans le tableau flights, tous les vols prévus ont-ils effectivement décollé ? Une bonne façon de le savoir est de regarder si, pour la variable dep_time (heure de décollage), des données manquantes sont présentes :\n\nflights |&gt; \n  filter(is.na(dep_time))\n\n# A tibble: 8,255 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1       NA           1630        NA       NA           1815\n 2  2013     1     1       NA           1935        NA       NA           2240\n 3  2013     1     1       NA           1500        NA       NA           1825\n 4  2013     1     1       NA            600        NA       NA            901\n 5  2013     1     2       NA           1540        NA       NA           1747\n 6  2013     1     2       NA           1620        NA       NA           1746\n 7  2013     1     2       NA           1355        NA       NA           1459\n 8  2013     1     2       NA           1420        NA       NA           1644\n 9  2013     1     2       NA           1321        NA       NA           1536\n10  2013     1     2       NA           1545        NA       NA           1910\n# ℹ 8,245 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nSeules les lignes contenant NA dans la colonne dep_time sont retenues. Il y a donc 8255 vols qui n’ont finalement pas décollé.\nDans le même ordre d’idée, y a t-il des vols qui ont décollé mais qui ne sont pas arrivés à destination ? Là encore, une façon d’obtenir cette information est de sélectionner les vols qui ont décollé (donc pour lesquels l’heure de décollage n’est pas manquante), mais pour lesquels l’heure d’atterrissage est manquante :\n\nflights |&gt; \n  filter(!is.na(dep_time),\n         is.na(arr_time))\n\n# A tibble: 458 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1     2016           1930        46       NA           2220\n 2  2013     1     2     2041           2045        -4       NA           2359\n 3  2013     1     2     2145           2129        16       NA             33\n 4  2013     1     9      615            615         0       NA            855\n 5  2013     1     9     2042           2040         2       NA           2357\n 6  2013     1    11     1344           1350        -6       NA           1518\n 7  2013     1    13     1907           1634       153       NA           1837\n 8  2013     1    13     2239           2159        40       NA             30\n 9  2013     1    16      837            840        -3       NA           1030\n10  2013     1    25     1452           1500        -8       NA           1619\n# ℹ 448 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nNotez l’utilisation du ! pour la première condition. Nous récupérons ici les lignes pour lesquelles dep_time n’est pas NA et pour lesquelles arr_time est NA. Seules les lignes qui respectent cette double condition sont retenues. Cette syntaxe est équivalente à :\n\nflights |&gt; \n  filter(!is.na(dep_time) & is.na(arr_time))\n\n# A tibble: 458 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1     2016           1930        46       NA           2220\n 2  2013     1     2     2041           2045        -4       NA           2359\n 3  2013     1     2     2145           2129        16       NA             33\n 4  2013     1     9      615            615         0       NA            855\n 5  2013     1     9     2042           2040         2       NA           2357\n 6  2013     1    11     1344           1350        -6       NA           1518\n 7  2013     1    13     1907           1634       153       NA           1837\n 8  2013     1    13     2239           2159        40       NA             30\n 9  2013     1    16      837            840        -3       NA           1030\n10  2013     1    25     1452           1500        -8       NA           1619\n# ℹ 448 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nDans la fonction filter(), séparer plusieurs conditions par des virgules signifie que seules les lignes qui remplissent toutes les conditions seront retenues. C’est donc l’équivalent du ET logique.\nIl y a donc 458 vols qui ne sont pas arrivés à destination (soit moins de 0,2% des vols au départ de New York en 2013). Selon vous, quelles raisons peuvent expliquer qu’un vol qui a décollé n’ait pas d’heure d’atterrissage ?\nEnfin, pour illustrer l’utilisation de | (le OU logique) et de %in%, imaginons que nous souhaitions extraire les informations des vols ayant quitté l’aéroport JFK à destination d’Atlanta, Géorgie (ATL) et de Seatle, Washington (SEA), aux mois d’octobre, novembre et décembre :\n\natl_sea_fall &lt;- flights |&gt; \n  filter(origin == \"JFK\", \n         dest == \"ATL\" | dest == \"SEA\", \n         month &gt;= 10)\natl_sea_fall\n\n# A tibble: 962 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013    10     1      638            640        -2      839            905\n 2  2013    10     1      729            735        -6     1049           1040\n 3  2013    10     1      824            830        -6     1030           1059\n 4  2013    10     1      853            900        -7     1217           1157\n 5  2013    10     1     1328           1330        -2     1543           1553\n 6  2013    10     1     1459           1500        -1     1817           1829\n 7  2013    10     1     1544           1545        -1     1815           1819\n 8  2013    10     1     1754           1800        -6     2102           2103\n 9  2013    10     1     1825           1830        -5     2159           2150\n10  2013    10     1     1841           1840         1     2058           2116\n# ℹ 952 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nExaminez ce tableau avec View() pour vérifier que la variable dest contient bien uniquement les codes ATL et SEA correspondant aux 2 aéroports qui nous intéressent. Nous avons extrait ici les vols à destination d’Atlanta et Seatle, pourtant, il nous a fallu utiliser le OU logique. Car chaque vol n’a qu’une unique destination, or nous souhaitons récupérer toutes les lignes pour lesquelles la destination est soit ATL, soit SEA (l’une ou l’autre).\nUne autre solution pour obtenir le même tableau est de remplacer l’expression contenant | par une expression contenant %in% :\n\natl_sea_fall2 &lt;- flights |&gt; \n  filter(origin == \"JFK\", \n         dest %in% c(\"ATL\", \"SEA\"), \n         month &gt;= 10)\natl_sea_fall2\n\n# A tibble: 962 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013    10     1      638            640        -2      839            905\n 2  2013    10     1      729            735        -6     1049           1040\n 3  2013    10     1      824            830        -6     1030           1059\n 4  2013    10     1      853            900        -7     1217           1157\n 5  2013    10     1     1328           1330        -2     1543           1553\n 6  2013    10     1     1459           1500        -1     1817           1829\n 7  2013    10     1     1544           1545        -1     1815           1819\n 8  2013    10     1     1754           1800        -6     2102           2103\n 9  2013    10     1     1825           1830        -5     2159           2150\n10  2013    10     1     1841           1840         1     2058           2116\n# ℹ 952 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nIci, toutes les lignes du tableau dont la variable dest est égale à un élément du vecteur c(\"ATL\", \"SEA\") sont retenues. L’utilisation du OU logique peut être source d’erreur. Je préfère donc utiliser %in% qui me semble plus parlant. La fonction identical() nous confirme que les deux façons de faire produisent exactement le même résultat, libre à vous de privilégier la méthode qui vous convient le mieux :\n\nidentical(atl_sea_fall, atl_sea_fall2)\n\n[1] TRUE"
  },
  {
    "objectID": "05-DataWrangling.html#créer-des-résumés-avec-summarise-et-group_by",
    "href": "05-DataWrangling.html#créer-des-résumés-avec-summarise-et-group_by",
    "title": "5  Tripatouiller les données avec dplyr",
    "section": "5.5 Créer des résumés avec summarise() et group_by()",
    "text": "5.5 Créer des résumés avec summarise() et group_by()\n\n5.5.1 Principe de la fonction summarise()\n\n\n\n\n\nFigure 5.4: ?(caption)\n\n\n\n\n\n\n\n\n\nFigure 5.5: Schéma de la fonction summarise() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nLa Figure 5.5 ci-dessus indique comment fonctionne la fonction summarise() : elle prend plusieurs valeurs (potentiellement, un très grand nombre) et les réduit à une unique valeur qui les résume. Lorsque l’on applique cette démarche à plusieurs colonnes d’un tableau, on obtient un tableau qui ne contient plus qu’une unique ligne de résumé.\nLa valeur qui résume les données est choisie par l’utilisateur. Il peut s’agir par exemple d’un calcul de moyenne ou de variance, il peut s’agir de calculer une somme, ou d’extraire la valeur maximale ou minimale, ou encore, il peut tout simplement s’agir de déterminer un nombre d’observations.\nAinsi, pour connaître la température moyenne et l’écart-type des températures dans les aéroports de New York, il suffit d’utiliser le tableau weather et sa variable temp que nous avons déjà utilisés dans les chapitres précédents :\n\nweather |&gt; \n  summarise(moyenne = mean(temp),\n            ecart_type = sd(temp))\n\n# A tibble: 1 × 2\n  moyenne ecart_type\n    &lt;dbl&gt;      &lt;dbl&gt;\n1      NA         NA\n\n\nLes fonctions mean() et sd() permettent de calculer une moyenne et un écart-type respectivement. Ici, les valeurs retournées sont NA car une valeur de température est manquante :\n\nweather |&gt; \n  filter(is.na(temp))\n\n# A tibble: 1 × 15\n  origin  year month   day  hour  temp  dewp humid wind_dir wind_speed wind_gust\n  &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n1 EWR     2013     8    22     9    NA    NA    NA      320       12.7        NA\n# ℹ 4 more variables: precip &lt;dbl&gt;, pressure &lt;dbl&gt;, visib &lt;dbl&gt;,\n#   time_hour &lt;dttm&gt;\n\n\nPour obtenir les valeurs souhaitées, il faut indiquer à R d’exclure les valeurs manquantes lors des calculs de moyennes et écarts-types :\n\nweather |&gt; \n  summarise(moyenne = mean(temp, na.rm = TRUE),\n            ecart_type = sd(temp, na.rm = TRUE))\n\n# A tibble: 1 × 2\n  moyenne ecart_type\n    &lt;dbl&gt;      &lt;dbl&gt;\n1    55.3       17.8\n\n\nLa température moyenne est donc de 55.3 degrés Fahrenheit et l’écart-type vaut 17.8 degrés Fahrenheit.\n\n\n5.5.2 Intérêt de la fonction group_by()\nLa fonction devient particulièrement puissante lorsqu’elle est combinée avec la fonction group_by() :\n\n\n\n\n\nFigure 5.6: Fonctionnement de group_by() travaillant de concert avec summarise(), tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nComme son nom l’indique, la fonction group_by() permet de créer des sous-groupes dans un tableau, afin que le résumé des données soit calculé pour chacun des sous-groupes plutôt que sur l’ensemble du tableau. En ce sens, son fonctionnement est analogue à celui des facets de ggplot2 qui permettent de scinder les données d’un graphique en plusieurs sous-groupes.\nPour revenir à l’exemple des températures, imaginons que nous souhaitions calculer les températures moyennes et les écart-types pour chaque mois de l’année. Voilà comment procéder :\n\nweather |&gt; \n  group_by(month) |&gt; \n  summarise(moyenne = mean(temp, na.rm = TRUE),\n            ecart_type = sd(temp, na.rm = TRUE))\n\n# A tibble: 12 × 3\n   month moyenne ecart_type\n   &lt;int&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n 1     1    35.6      10.2 \n 2     2    34.3       6.98\n 3     3    39.9       6.25\n 4     4    51.7       8.79\n 5     5    61.8       9.68\n 6     6    72.2       7.55\n 7     7    80.1       7.12\n 8     8    74.5       5.19\n 9     9    67.4       8.47\n10    10    60.1       8.85\n11    11    45.0      10.4 \n12    12    38.4       9.98\n\n\nIci, les étapes sont les suivantes :\n\nOn prend le tableau weather, puis…\nOn groupe les données selon la variable month, puis…\nOn résume les données groupées sous la forme de moyennes et d’écart-types.\n\nNous pouvons aller plus loin. Ajoutons à ce résumé 2 variables supplémentaires : le nombre de mesures et l’erreur standard (notée \\(se\\)), qui peut être calculée de la façon suivante :\n\\[se \\approx \\frac{s}{\\sqrt{n}}\\]\navec \\(s\\), l’écart-type de l’échantillon et \\(n\\), la taille de l’échantillon. Cette grandeur est très importante en statistique puisqu’elle nous permet de quantifier l’imprécision de la moyenne. Elle intervient d’ailleurs dans le calcul de l’intervalle de confiance de la moyenne d’un échantillon. Nous allons donc calculer ici ces résumés, et nous donnerons un nom au tableau créé pour pouvoir ré-utiliser ces statistiques descriptives :\n\nmonthly_temp &lt;- weather |&gt; \n  group_by(month) |&gt; \n  summarise(moyenne = mean(temp, na.rm = TRUE),\n            ecart_type = sd(temp, na.rm = TRUE),\n            nb_obs = n(),\n            erreur_std = ecart_type / sqrt(nb_obs))\nmonthly_temp\n\n# A tibble: 12 × 5\n   month moyenne ecart_type nb_obs erreur_std\n   &lt;int&gt;   &lt;dbl&gt;      &lt;dbl&gt;  &lt;int&gt;      &lt;dbl&gt;\n 1     1    35.6      10.2    2226      0.217\n 2     2    34.3       6.98   2010      0.156\n 3     3    39.9       6.25   2227      0.132\n 4     4    51.7       8.79   2159      0.189\n 5     5    61.8       9.68   2232      0.205\n 6     6    72.2       7.55   2160      0.162\n 7     7    80.1       7.12   2228      0.151\n 8     8    74.5       5.19   2217      0.110\n 9     9    67.4       8.47   2159      0.182\n10    10    60.1       8.85   2212      0.188\n11    11    45.0      10.4    2141      0.226\n12    12    38.4       9.98   2144      0.216\n\n\nVous constatez ici que nous avons 4 statistiques descriptives pour chaque mois de l’année. Deux choses sont importantes à retenir ici :\n\nOn peut obtenir le nombre d’observations dans chaque sous-groupe d’un tableau groupé en utilisant la fonction n(). Cette fonction n’a besoin d’aucun argument : elle détermine automatiquement la taille des groupes créés par group_by().\nOn peut créer de nouvelles variables en utilisant le nom de variables créées auparavant. Ainsi, nous avons créé la variable erreur_std en utilisant deux variables créées au préalable : ecart-type et nb_obs.\n\n\n\n5.5.3 Ajouter des barres d’erreurs sur un graphique\nLe tableau monthly_temp que nous venons de créer contient donc les données nécessaires pour nous permettre de visualiser sur un graphique l’évolution des températures moyennes enregistrées dans les 3 aéroports de New York en 2013. Outre les température moyennes, nous devons faire figurer l’imprécision des estimations de moyenne avec des barres d’erreur (à l’aide de la fonction geom_linerange()). Comme expliqué plus haut, l’imprécision des moyennes calculées est estimée grâce à l’erreur standard. Toutefois, ici, les imprécisions sont tellement faibles que les barres d’erreurs resteront invisibles :\n\nmonthly_temp |&gt; \n  ggplot(aes(x = factor(month), y = moyenne, group = 1)) +\n    geom_line() + \n    geom_point() +\n    geom_linerange(aes(ymin = moyenne - erreur_std, \n                       ymax = moyenne + erreur_std),\n                   color = \"red\")\n\n\n\n\nFigure 5.7: Évolution des températures moyennes dans 3 aéroports de New York en 2013.\n\n\n\n\nVous remarquerez que :\n\nJ’associe factor(month), et non simplement month, à l’axe des x afin d’avoir, sur l’axe des abscisses, des chiffres cohérents allant de 1 à 12, et non des chiffres à virgules.\nL’argument group = 1 doit être ajouté pour que la ligne reliant les points apparaisse. En effet, les lignes sont censées relier des points qui appartiennent à une même série temporelle. Or ici, nous avons transformé month en facteur. Préciser group = 1 permet d’indiquer à geom_line() que toutes les catégories du facteur month appartiennent au même groupe, que ce facteur peut être considéré comme une variable continue, et qu’il est donc correct de relier les points.\nLa fonction geom_linerange() contient de nouvelles caractéristiques esthétiques qu’il nous faut obligatoirement renseigner : les extrémités inférieures et supérieures des barres d’erreur. Il nous faut donc associer 2 variables à ces caractéristiques esthétiques. Ici, nous utilisons moyenne - erreur_std pour la borne inférieure des barres d’erreur, et moyenne + erreur_std pour la borne supérieure. Les variables moyenne et erreur_std faisant partie du tableau monthly_temp, geom_linerange() les trouve sans difficulté.\nLes barres d’erreur produites sont minuscules. Je les ai fait apparaître en rouge afin de les rendre visibles, mais même comme cela, il faut zoomer fortement pour les distinguer. Afin de rendre l’utilisation de geom_linerange() plus explicite, je produis ci-dessous un autre graphique en remplaçant les erreurs standard par les écart-types en guise de barres d’erreur. Attention, ce n’est pas correct d’un point de vue statistique ! Les barres d’erreur doivent permettre de visualiser l’imprécision de la moyenne. C’est donc bien les erreurs standard qu’il faut faire figurer en guise de barres d’erreurs et non les écarty-types. Le graphique ci-dessous ne figure donc qu’à titre d’exemple, afin d’illustrer de façon plus parlante le fonctionnement de la fonction geom_linerange() :\n\n\nmonthly_temp |&gt; \n  ggplot(aes(x = factor(month), y = moyenne, group = 1)) +\n    geom_line() + \n    geom_point() +\n    geom_linerange(aes(ymin = moyenne - ecart_type,\n                       ymax = moyenne + ecart_type)) +\n  labs(x = \"Mois\",\n       y = \"Température (ºFahrenheit)\", \n       title = \"Évolution des températures\n                dans 3 aéroports de New York en 2013\",\n       subtitle = \"Attention : les barres d'erreurs sont les écarts-types.\\n\n                   Il faut normalement faire figurer les erreurs standard.\")\n\n\nmonthly_temp |&gt; \n  ggplot(aes(x = factor(month), y = moyenne, group = 1)) +\n    geom_line() + \n    geom_point() +\n    geom_linerange(aes(ymin = moyenne - ecart_type,\n                       ymax = moyenne + ecart_type)) +\n  labs(x = \"Mois\",\n       y = \"Température (ºFahrenheit)\", \n       title = \"Évolution des températures dans 3 aéroports de New York en 2013\",\n       subtitle = \"Attention : les barres d'erreurs sont les écarts-types.\\nIl faut normalement faire figurer les erreurs standard.\")\n\n\n\n\nFigure 5.8: Évolution des températures moyennes dans 3 aéroports de New York en 2013.\n\n\n\n\n\n\n5.5.4 Grouper par plus d’une variable\nJusqu’ici, nous avons groupé les données de température par mois. Il est tout à fait possible de grouper les données par plus d’une variable, par exemple, par mois et par aéroport d’origine :\n\nmonthly_orig_temp &lt;- weather |&gt; \n  group_by(origin, month) |&gt; \n  summarise(moyenne = mean(temp, na.rm = TRUE),\n            ecart_type = sd(temp, na.rm = TRUE),\n            nb_obs = n(),\n            erreur_std = ecart_type / sqrt(nb_obs))\n\n`summarise()` has grouped output by 'origin'. You can override using the\n`.groups` argument.\n\nmonthly_orig_temp\n\n# A tibble: 36 × 6\n# Groups:   origin [3]\n   origin month moyenne ecart_type nb_obs erreur_std\n   &lt;chr&gt;  &lt;int&gt;   &lt;dbl&gt;      &lt;dbl&gt;  &lt;int&gt;      &lt;dbl&gt;\n 1 EWR        1    35.6      10.8     742      0.396\n 2 EWR        2    34.3       7.28    669      0.282\n 3 EWR        3    40.1       6.72    743      0.247\n 4 EWR        4    53.0       9.60    720      0.358\n 5 EWR        5    63.3      10.6     744      0.389\n 6 EWR        6    73.3       8.05    720      0.300\n 7 EWR        7    80.7       7.37    741      0.271\n 8 EWR        8    74.5       5.87    740      0.216\n 9 EWR        9    67.3       9.32    719      0.348\n10 EWR       10    59.8       9.79    736      0.361\n# ℹ 26 more rows\n\n\nEn plus de la variable month, la tableau monthly_orig_temp contient une variable origin. Les statistiques que nous avons calculées plus tôt sont maintenant disponibles pour chaque mois et chacun des 3 aéroports de New York. Nous pouvons utiliser ces données pour comparer les 3 aéroports :\n\nmonthly_orig_temp |&gt; \n  ggplot(aes(x = factor(month), \n             y = moyenne,\n             group = origin,\n             color = origin)) +\n    geom_line() + \n    geom_point() +\n    geom_linerange(aes(ymin = moyenne - ecart_type,\n                       ymax = moyenne + ecart_type)) +\n  labs(x = \"Mois\",\n       y = \"Température (ºFahrenheit)\", \n       title = \"Évolution des températures\n                dans 3 aéroports de New York en 2013\",\n       subtitle = \"Attention : les barres d'erreurs sont les écarts-types.\\n\n                   Il faut normalement faire figurer les erreurs standard.\")\n\n\n\n\n\n\nFigure 5.9: Évolution des températures moyennes dans 3 aéroports de New York en 2013.\n\n\n\n\nNotez que j’utilise maintenant group = origin et non plus group = 1. Ici, les températures des 3 aéroports sont tellement similaires que les courbes sont difficiles à distinguer. Nous pouvons donc utiliser facet_wrap() pour tenter d’améliorer la visualisation :\n\nmonthly_orig_temp |&gt; \n  ggplot(aes(x = factor(month), \n             y = moyenne,\n             group = origin,\n             color = origin)) +\n    geom_line() + \n    geom_point() +\n    geom_linerange(aes(ymin = moyenne - ecart_type,\n                       ymax = moyenne + ecart_type)) +\n  facet_wrap(~origin, ncol = 1) +\n  labs(x = \"Mois\",\n       y = \"Température (ºFahrenheit)\", \n       title = \"Évolution des températures\n                dans 3 aéroports de New York en 2013\",\n       subtitle = \"Attention : les barres d'erreurs sont les écarts-types.\\n\n                   Il faut normalement faire figurer les erreurs standard.\")\n\n\n\n\n\n\nFigure 5.10: Évolution des températures moyennes dans 3 aéroports de New York en 2013.\n\n\n\n\nLorsque nous groupons par plusieurs variables, il peut-être utile d’ajouter l’argument .groups = \"drop\" à la fonction summarise() afin que le tibble obtenu soit un tibble “normal” et non un tibble toujours groupé par une ou plusieurs variables :\n\nmonthly_orig_temp &lt;- weather |&gt; \n  group_by(origin, month) |&gt; \n  summarise(moyenne = mean(temp, na.rm = TRUE),\n            ecart_type = sd(temp, na.rm = TRUE),\n            nb_obs = n(),\n            erreur_std = ecart_type / sqrt(nb_obs),\n            .groups = \"drop\")\nmonthly_orig_temp\n\n# A tibble: 36 × 6\n   origin month moyenne ecart_type nb_obs erreur_std\n   &lt;chr&gt;  &lt;int&gt;   &lt;dbl&gt;      &lt;dbl&gt;  &lt;int&gt;      &lt;dbl&gt;\n 1 EWR        1    35.6      10.8     742      0.396\n 2 EWR        2    34.3       7.28    669      0.282\n 3 EWR        3    40.1       6.72    743      0.247\n 4 EWR        4    53.0       9.60    720      0.358\n 5 EWR        5    63.3      10.6     744      0.389\n 6 EWR        6    73.3       8.05    720      0.300\n 7 EWR        7    80.7       7.37    741      0.271\n 8 EWR        8    74.5       5.87    740      0.216\n 9 EWR        9    67.3       9.32    719      0.348\n10 EWR       10    59.8       9.79    736      0.361\n# ℹ 26 more rows\n\n\nNotez qu’ajouter cet argument permet également de faire disparaître le message d’avertissement qui s’affichait après chaque utilisation de group_by(). C’est donc une bonne habitude d’ajouter cet argument systématiquement dans la fonction summarise() après utilisation de group_by().\nEnfin, lorsque nous groupons par plusieurs variables, il peut être utile de présenter les résultats sous la forme d’un tableau large (grâce à la fonction pivot_wider(), voir Section 4.2.2) pour l’intégration dans un rapport par exemple :\n\nweather |&gt; \n  group_by(origin, month) |&gt; \n  summarise(moyenne = mean(temp, na.rm = TRUE)) |&gt; \n  pivot_wider(names_from = origin, \n              values_from = moyenne)\n\n`summarise()` has grouped output by 'origin'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 12 × 4\n   month   EWR   JFK   LGA\n   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1  35.6  35.4  36.0\n 2     2  34.3  34.2  34.4\n 3     3  40.1  39.5  40.0\n 4     4  53.0  50.1  52.1\n 5     5  63.3  59.3  62.8\n 6     6  73.3  70.0  73.3\n 7     7  80.7  78.7  80.8\n 8     8  74.5  73.8  75.0\n 9     9  67.3  66.9  67.9\n10    10  59.8  59.8  60.6\n11    11  44.6  45.1  45.3\n12    12  38.0  38.6  38.8\n\n\nSous cette forme, les données ne sont plus “rangées”, nous n’avons plus des “tidy data”, mais nous avons un tableau plus synthétique, facile à inclure dans un rapport.\n\n\n5.5.5 Un raccourci pratique pour compter des effectifs\nIl est tellement fréquent d’avoir à grouper des données en fonction d’une variable puis à compter le nombre d’observations dans chaque catégorie avec n() que dplyr nous fournit un raccourci : la fonction count().\nCe code :\n\nweather |&gt; \n  group_by(month) |&gt; \n  summarise(n = n())\n\n# A tibble: 12 × 2\n   month     n\n   &lt;int&gt; &lt;int&gt;\n 1     1  2226\n 2     2  2010\n 3     3  2227\n 4     4  2159\n 5     5  2232\n 6     6  2160\n 7     7  2228\n 8     8  2217\n 9     9  2159\n10    10  2212\n11    11  2141\n12    12  2144\n\n\nest équivalent à celui-ci :\n\nweather |&gt; \n  count(month)\n\n# A tibble: 12 × 2\n   month     n\n   &lt;int&gt; &lt;int&gt;\n 1     1  2226\n 2     2  2010\n 3     3  2227\n 4     4  2159\n 5     5  2232\n 6     6  2160\n 7     7  2228\n 8     8  2217\n 9     9  2159\n10    10  2212\n11    11  2141\n12    12  2144\n\n\nComme avec group_by(), il est bien sûr possible d’utiliser count() avec plusieurs variables :\n\nweather |&gt; \n  group_by(origin, month) |&gt; \n  summarise(nombre = n())\n\n`summarise()` has grouped output by 'origin'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 36 × 3\n# Groups:   origin [3]\n   origin month nombre\n   &lt;chr&gt;  &lt;int&gt;  &lt;int&gt;\n 1 EWR        1    742\n 2 EWR        2    669\n 3 EWR        3    743\n 4 EWR        4    720\n 5 EWR        5    744\n 6 EWR        6    720\n 7 EWR        7    741\n 8 EWR        8    740\n 9 EWR        9    719\n10 EWR       10    736\n# ℹ 26 more rows\n\n\n\n\n5.5.6 Exercices\n\nFaites un tableau indiquant combien de vols ont été annulés après le décollage, pour chaque compagnie aérienne. Vous devriez obtenir le tableau suivant :\n\n\n\n# A tibble: 13 × 2\n   carrier cancelled\n   &lt;chr&gt;       &lt;int&gt;\n 1 9E             71\n 2 AA             34\n 3 B6             32\n 4 DL             15\n 5 EV            105\n 6 F9              1\n 7 FL              6\n 8 MQ             87\n 9 UA             63\n10 US             31\n11 VX              4\n12 WN              8\n13 YV              1\n\n\n\nFaites un tableau indiquant les vitesses de vents minimales, maximales et moyennes, enregistrées chaque mois dans chaque aéroport de New York. Votre tableau devrait ressembler à ceci :\n\n\n\n`summarise()` has grouped output by 'origin'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 36 × 5\n# Groups:   origin [3]\n   origin month max_wind min_wind moy_wind\n   &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 EWR        1     42.6        0     9.87\n 2 EWR        2   1048.         0    12.2 \n 3 EWR        3     29.9        0    11.6 \n 4 EWR        4     25.3        0     9.63\n 5 EWR        5     33.4        0     8.49\n 6 EWR        6     34.5        0     9.55\n 7 EWR        7     20.7        0     9.15\n 8 EWR        8     21.9        0     7.62\n 9 EWR        9     23.0        0     8.03\n10 EWR       10     26.5        0     8.32\n# ℹ 26 more rows\n\n\n\nSachant que les vitesses du vent sont exprimées en miles par heure, certaines valeurs sont-elles surprenantes ? À l’aide de la fonction filter(), éliminez la ou les valeurs aberrantes. Vous devriez obtenir ce tableau :\n\n\n\n`summarise()` has grouped output by 'origin'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 36 × 5\n# Groups:   origin [3]\n   origin month max_wind min_wind moy_wind\n   &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 EWR        1     42.6        0     9.87\n 2 EWR        2     31.1        0    10.7 \n 3 EWR        3     29.9        0    11.6 \n 4 EWR        4     25.3        0     9.63\n 5 EWR        5     33.4        0     8.49\n 6 EWR        6     34.5        0     9.55\n 7 EWR        7     20.7        0     9.15\n 8 EWR        8     21.9        0     7.62\n 9 EWR        9     23.0        0     8.03\n10 EWR       10     26.5        0     8.32\n# ℹ 26 more rows\n\n\n\nEn utilisant les données de vitesse de vent du tableau weather, produisez le graphique suivant :\n\n\n\n\n\n\nFigure 5.11: ?(caption)\n\n\n\n\nIndications :\n\nLes vitesses de vent aberrantes ont été éliminées grâce à la fonction filter().\nLa fonction geom_jitter() a été utilisée avec l’argument height = 0.\nLa transparence des points est fixée à 0.2.\n\nSelon vous, pourquoi les points sont-ils organisés en bandes horizontales ?\nSelon vous, pourquoi n’y a t’il jamais de vent entre 0 et environ 3 miles à l’heure (mph) ?\nSachant qu’en divisant des mph par 1.151 on obtient des vitesses en nœuds, que nous apprend cette commande ?\n\nsort(unique(weather$wind_speed)) / 1.151\n\n [1]   0.000000   2.999427   3.999235   4.999044   5.998853   6.998662\n [7]   7.998471   8.998280   9.998089  10.997897  11.997706  12.997515\n[13]  13.997324  14.997133  15.996942  16.996751  17.996560  18.996368\n[19]  19.996177  20.995986  21.995795  22.995604  23.995413  24.995222\n[25]  25.995030  26.994839  27.994648  28.994457  29.994266  30.994075\n[31]  31.993884  32.993692  33.993501  34.993310  36.992928 910.825873"
  },
  {
    "objectID": "05-DataWrangling.html#sélectionner-des-variables-avec-select",
    "href": "05-DataWrangling.html#sélectionner-des-variables-avec-select",
    "title": "5  Tripatouiller les données avec dplyr",
    "section": "5.6 Sélectionner des variables avec select()",
    "text": "5.6 Sélectionner des variables avec select()\n\n\n\n\n\nFigure 5.12: Schéma de la fonction select() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nIl n’est pas rare de travailler avec des tableaux contenant des centaines, voir des milliers de colonnes. Dans de tels cas, il peut être utile de réduire le jeu de données aux variables qui vous intéressent. Le rôle de la fonction select() est de retenir uniquement les colonnes dont on a spécifié le nom, afin de recentrer l’analyse sur les variables utiles.\nselect() n’est pas particulièrement utile pour le jeu de données flights puisqu’il ne contient que 19 variables. Toutefois, on peut malgré tout comprendre le fonctionnement général. Par exemple, pour sélectionner uniquement les colonnes year, month et day, on tape :\n\n# Sélection de variables par leur nom\nflights |&gt; \n  select(year, month, day)\n\n# A tibble: 336,776 × 3\n    year month   day\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1  2013     1     1\n 2  2013     1     1\n 3  2013     1     1\n 4  2013     1     1\n 5  2013     1     1\n 6  2013     1     1\n 7  2013     1     1\n 8  2013     1     1\n 9  2013     1     1\n10  2013     1     1\n# ℹ 336,766 more rows\n\n\nPuisque ces 3 variables sont placées les unes à côté des autres dans le tableau flights, on peut utiliser la notation “:” pour les sélectionner :\n\n# Sélection de toutes les variables entre `year` et `day` (inclues)\nflights |&gt; \n  select(year:day)\n\n# A tibble: 336,776 × 3\n    year month   day\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1  2013     1     1\n 2  2013     1     1\n 3  2013     1     1\n 4  2013     1     1\n 5  2013     1     1\n 6  2013     1     1\n 7  2013     1     1\n 8  2013     1     1\n 9  2013     1     1\n10  2013     1     1\n# ℹ 336,766 more rows\n\n\nÀ l’inverse, si on veut supprimer certaines colonnes, on peut utiliser la notation “-” :\n\n# Sélection de toutes les variables de `flights` à l'exception\n# de celles comprises entre `year` et `day` (inclues)\nflights |&gt; \n  select(-(year:day))\n\n# A tibble: 336,776 × 16\n   dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay carrier\n      &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;  \n 1      517            515         2      830            819        11 UA     \n 2      533            529         4      850            830        20 UA     \n 3      542            540         2      923            850        33 AA     \n 4      544            545        -1     1004           1022       -18 B6     \n 5      554            600        -6      812            837       -25 DL     \n 6      554            558        -4      740            728        12 UA     \n 7      555            600        -5      913            854        19 B6     \n 8      557            600        -3      709            723       -14 EV     \n 9      557            600        -3      838            846        -8 B6     \n10      558            600        -2      753            745         8 AA     \n# ℹ 336,766 more rows\n# ℹ 9 more variables: flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;,\n#   air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nIl y a beaucoup de fonctions permettant de sélectionner des variables dont les noms respectent certains critères. Par exemple :\n\nstarts_with(\"abc\") : renvoie toutes les variables dont les noms commencent par “abc”.\nends_with(\"xyz\") : renvoie toutes les variables dont les noms se terminent par “xyz”.\ncontains(\"ijk\") : renvoie toutes les variables dont les noms contiennent “ijk”.\n\nIl en existe beaucoup d’autres. Vous pouvez consulter l’aide de ?select() pour en savoir plus.\nPar exemple, il est possible de sélectionner toutes les variables contenant le mot “time” ainsi :\n\nflights |&gt; \n  select(contains(\"time\"))\n\n# A tibble: 336,776 × 6\n   dep_time sched_dep_time arr_time sched_arr_time air_time time_hour          \n      &lt;int&gt;          &lt;int&gt;    &lt;int&gt;          &lt;int&gt;    &lt;dbl&gt; &lt;dttm&gt;             \n 1      517            515      830            819      227 2013-01-01 05:00:00\n 2      533            529      850            830      227 2013-01-01 05:00:00\n 3      542            540      923            850      160 2013-01-01 05:00:00\n 4      544            545     1004           1022      183 2013-01-01 05:00:00\n 5      554            600      812            837      116 2013-01-01 06:00:00\n 6      554            558      740            728      150 2013-01-01 05:00:00\n 7      555            600      913            854      158 2013-01-01 06:00:00\n 8      557            600      709            723       53 2013-01-01 06:00:00\n 9      557            600      838            846      140 2013-01-01 06:00:00\n10      558            600      753            745      138 2013-01-01 06:00:00\n# ℹ 336,766 more rows\n\n\nÉvidemment, le tableau flights n’est pas modifié par cette opération : il contient toujours les 19 variables de départ. Pour travailler avec ces tableaux de données contenant moins de variables, il faut les stocker dans un nouvel objet en leur donnant un nom :\n\nflights_time &lt;- flights |&gt; \n  select(contains(\"time\"))\n\nEnfin, on peut utiliser select() pour renommer des variables. Mais ce n’est que rarement utile car select() élimine toutes les variables qui n’ont pas été explicitement nommées :\n\nflights |&gt; \n  select(year:day,\n         heure_depart = dep_time,\n         retard_depart = dep_delay)\n\n# A tibble: 336,776 × 5\n    year month   day heure_depart retard_depart\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;        &lt;int&gt;         &lt;dbl&gt;\n 1  2013     1     1          517             2\n 2  2013     1     1          533             4\n 3  2013     1     1          542             2\n 4  2013     1     1          544            -1\n 5  2013     1     1          554            -6\n 6  2013     1     1          554            -4\n 7  2013     1     1          555            -5\n 8  2013     1     1          557            -3\n 9  2013     1     1          557            -3\n10  2013     1     1          558            -2\n# ℹ 336,766 more rows\n\n\nIl est donc généralement préférable d’utiliser rename() pour renommer certaines variables sans en éliminer aucune :\n\nflights |&gt; \n  rename(heure_depart = dep_time,\n         retard_depart = dep_delay)\n\n# A tibble: 336,776 × 19\n    year month   day heure_depart sched_dep_time retard_depart arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;        &lt;int&gt;          &lt;int&gt;         &lt;dbl&gt;    &lt;int&gt;\n 1  2013     1     1          517            515             2      830\n 2  2013     1     1          533            529             4      850\n 3  2013     1     1          542            540             2      923\n 4  2013     1     1          544            545            -1     1004\n 5  2013     1     1          554            600            -6      812\n 6  2013     1     1          554            558            -4      740\n 7  2013     1     1          555            600            -5      913\n 8  2013     1     1          557            600            -3      709\n 9  2013     1     1          557            600            -3      838\n10  2013     1     1          558            600            -2      753\n# ℹ 336,766 more rows\n# ℹ 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;,\n#   flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;,\n#   distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "05-DataWrangling.html#sec-mutate",
    "href": "05-DataWrangling.html#sec-mutate",
    "title": "5  Tripatouiller les données avec dplyr",
    "section": "5.7 Créer de nouvelles variables avec mutate()",
    "text": "5.7 Créer de nouvelles variables avec mutate()\n\n5.7.1 Principe\n\n\n\n\n\nFigure 5.13: Schéma de la fonction mutate() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nLa fonction mutate() permet de créer de nouvelles variables à partir des variables existantes, ou de modifier des variables déjà présentes dans un jeu de données. Il est en effet fréquent d’avoir besoin de calculer de nouvelles variables, souvent plus informatives que les variables disponibles.\nVoyons un exemple. Nous commençons par créer un nouveau jeu de données flights_sml en sélectionnant uniquement les variables qui nous seront utiles :\n\nflights_sml &lt;- flights |&gt; \n  select(year:day,\n         ends_with(\"delay\"),\n         distance,\n         air_time)\nflights_sml\n\n# A tibble: 336,776 × 7\n    year month   day dep_delay arr_delay distance air_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1  2013     1     1         2        11     1400      227\n 2  2013     1     1         4        20     1416      227\n 3  2013     1     1         2        33     1089      160\n 4  2013     1     1        -1       -18     1576      183\n 5  2013     1     1        -6       -25      762      116\n 6  2013     1     1        -4        12      719      150\n 7  2013     1     1        -5        19     1065      158\n 8  2013     1     1        -3       -14      229       53\n 9  2013     1     1        -3        -8      944      140\n10  2013     1     1        -2         8      733      138\n# ℹ 336,766 more rows\n\n\nÀ partir de ce nouveau tableau, nous allons calculer 2 nouvelles variables :\n\ngain : afin de savoir si les avions peuvent rattraper une partie de leur retard en vol, nous allons calculer la différence entre le retard au départ et à l’arrivée (donc le gain de temps accumulé lors du vol). En effet, si un avion décolle avec 15 minutes de retard, mais qu’il atterrit avec seulement 5 minutes de retard, 10 minutes ont été gagnées en vol, et les passagers sont moins mécontents.\nspeed afin de connaitre la vitesse moyenne des avions en vol, nous allons diviser la distance parcourue par les avions par le temps passé en l’air. Il ne faudra pas oublier de multiplier par 60 car les temps sont exprimés en minutes. Nous en profiterons pour transformer les distances exprimées en miles par des distances exprimées en kilomètres en multipliant les distances en miles par 1.60934. Ainsi, la variable speed sera exprimée en kilomètres par heure.\n\n\nflights_sml |&gt; \n  mutate(gain = dep_delay - arr_delay,\n         distance = distance * 1.60934,\n         speed = (distance / air_time) * 60)\n\n# A tibble: 336,776 × 9\n    year month   day dep_delay arr_delay distance air_time  gain speed\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  2013     1     1         2        11    2253.      227    -9  596.\n 2  2013     1     1         4        20    2279.      227   -16  602.\n 3  2013     1     1         2        33    1753.      160   -31  657.\n 4  2013     1     1        -1       -18    2536.      183    17  832.\n 5  2013     1     1        -6       -25    1226.      116    19  634.\n 6  2013     1     1        -4        12    1157.      150   -16  463.\n 7  2013     1     1        -5        19    1714.      158   -24  651.\n 8  2013     1     1        -3       -14     369.       53    11  417.\n 9  2013     1     1        -3        -8    1519.      140     5  651.\n10  2013     1     1        -2         8    1180.      138   -10  513.\n# ℹ 336,766 more rows\n\n\nSi on souhaite conserver uniquement les variables nouvellement créées par mutate(), on peut utiliser transmute() :\n\nflights_sml |&gt; \n  transmute(gain = dep_delay - arr_delay,\n         distance = distance * 1.60934,\n         speed = (distance / air_time) * 60)\n\n# A tibble: 336,776 × 3\n    gain distance speed\n   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1    -9    2253.  596.\n 2   -16    2279.  602.\n 3   -31    1753.  657.\n 4    17    2536.  832.\n 5    19    1226.  634.\n 6   -16    1157.  463.\n 7   -24    1714.  651.\n 8    11     369.  417.\n 9     5    1519.  651.\n10   -10    1180.  513.\n# ℹ 336,766 more rows\n\n\nEt comme toujours, pour pouvoir réutiliser ces données, on leur donne un nom :\n\ngain_speed &lt;- flights_sml |&gt; \n  transmute(gain = dep_delay - arr_delay,\n         distance = distance * 1.60934,\n         speed = (distance / air_time) * 60)\n\n\n\n5.7.2 Transformer des variables en facteurs\nIl n’est pas rare que les tableaux de données que nous importons contiennent des colonnes numériques ou de chaînes de caractères qui devraient en réalité être reconnues en tant que facteurs. La fonction mutate() nous permet de changer rapidement le type d’une variable afin qu’elle soit reconnue comme un facteur.\nÀ titre d’exemple, nous allons importer le jeu de données contenu dans le fichier squid.txt que vous pourrez télécharger ici. Placez-le dans votre répertoire de travail et utilisez la méthode décrite à la Section 4.3.3 pour obtenir la commande suivante :\n\nlibrary(readr)\nsquid &lt;- read_delim(\"squid.txt\", \"\\t\", \n    escape_double = FALSE, trim_ws = TRUE)\nsquid\n\n\n\n# A tibble: 2,644 × 6\n   Sample  Year Month Location   Sex   GSI\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1      1     1     1        1     2 10.4 \n 2      2     1     1        3     2  9.83\n 3      3     1     1        1     2  9.74\n 4      4     1     1        1     2  9.31\n 5      5     1     1        1     2  8.99\n 6      6     1     1        1     2  8.77\n 7      7     1     1        1     2  8.26\n 8      8     1     1        3     2  7.40\n 9      9     1     1        3     2  7.22\n10     10     1     2        1     2  6.84\n# ℹ 2,634 more rows\n\n\nCe jeu de données contient des informations sur l’Indice Gonado-Somatique (GSI) de 2644 pieuvres collectées dans 4 stations d’échantillonnage sur une période de 2 ans. La variable Location est codée sous forme d’entiers, or il devrait s’agir d’un facteur. La fonction mutate() nous permet d’effectuer la transformation :\n\nsquid |&gt; \n  mutate(Location = factor(Location))\n\n# A tibble: 2,644 × 6\n   Sample  Year Month Location   Sex   GSI\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1      1     1     1 1            2 10.4 \n 2      2     1     1 3            2  9.83\n 3      3     1     1 1            2  9.74\n 4      4     1     1 1            2  9.31\n 5      5     1     1 1            2  8.99\n 6      6     1     1 1            2  8.77\n 7      7     1     1 1            2  8.26\n 8      8     1     1 3            2  7.40\n 9      9     1     1 3            2  7.22\n10     10     1     2 1            2  6.84\n# ℹ 2,634 more rows\n\n\nDe même, la variable Sex est codée sous forme numérique, or il devrait s’agir d’un facteur, les “1” correspondants aux mâles et les “2” aux femelles. Nous pouvons là encore faire la modification grâce à la fonction mutate() :\n\nsquid2 &lt;- squid |&gt; \n  mutate(Location = factor(Location),\n         Sex = factor(Sex, levels = c(1, 2), labels = c(\"Male\", \"Female\")))\n\nsquid2\n\n# A tibble: 2,644 × 6\n   Sample  Year Month Location Sex      GSI\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;\n 1      1     1     1 1        Female 10.4 \n 2      2     1     1 3        Female  9.83\n 3      3     1     1 1        Female  9.74\n 4      4     1     1 1        Female  9.31\n 5      5     1     1 1        Female  8.99\n 6      6     1     1 1        Female  8.77\n 7      7     1     1 1        Female  8.26\n 8      8     1     1 3        Female  7.40\n 9      9     1     1 3        Female  7.22\n10     10     1     2 1        Female  6.84\n# ℹ 2,634 more rows\n\n\nsquid2 contient maintenant le tableau de départ avec les variables Location et Sex codées sous forme de facteurs. Si nous faisons un graphique avec ces nouveaux facteurs, l’ordre des catégories sera celui spécifié par la fonction factor(). Ainsi, si nous faisons par exemple un boxplot de GSI en fonction du Sex, voilà ce que nous obtenons :\n\nsquid2 |&gt; \n  ggplot(aes(x = Sex, y = GSI)) +\n    geom_boxplot(notch = TRUE)\n\n\n\n\nIndice Gonado Somatique selon le sexe.\n\n\n\n\nComment faire pour inverser l’ordre des catégories sur l’axe des abscisses ? Il faut inverser l’ordre des catégories dans le facteur Sex. L’ordre dans lequel les catégories apparaissent sur un graphique est en effet déterminé par l’ordre dans lequel les niveaux du facteur sont organisés. D’habitude, les niveaux sont automatiquement triés par ordre alphabétique quand les catégories sont des chaînes de caractères, et en ordre croissant quand la variable est numérique. Ici les niveaux sont les suivants :\n\nlevels(squid2$Sex)\n\n[1] \"Male\"   \"Female\"\n\n\nMale apparaît avant Female, car les niveaux de départ étaient 1 pour les mâles et 2 pour les femelles. C’est donc cet ordre qui est conservé. Le package forcats fournit de nombreuses fonctions permettant de manipuler les facteurs. Toutes commencent par fct_. Nous pouvons ici utiliser fct_rev() pour inverser l’ordre des niveaux. Pensez à installer et charger forcats si ce n’est pas déjà fait. Si vous avez chargé le tidyverse, forcats est déjà disponible :\n\nlibrary(forcats)\nsquid3 &lt;- squid2 |&gt; \n  mutate(Sex = fct_rev(Sex))\n\nlevels(squid3$Sex)\n\n[1] \"Female\" \"Male\"  \n\n\n\nsquid3 |&gt; \n  ggplot(aes(x = Sex, y = GSI)) +\n    geom_boxplot(notch = TRUE)\n\n\n\n\nIndice Gonado Somatique selon le sexe.\n\n\n\n\nRevenons maintenant au jeu de données dauphin.\n\ndauphin\n\n# A tibble: 93 × 9\n   ID        Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n 1 Numéro 1  f     imm       315     3  29.6   3.24 NA    rein  \n 2 Numéro 2  f     imm       357     4  55.1   4.42 NA    rein  \n 3 Numéro 3  f     pnl       439    34 129.    5.01  9.02 rein  \n 4 Numéro 4  f     imm       316     4  71.2   4.33 NA    rein  \n 5 Numéro 5  f     l         435    26 192     5.15 NA    rein  \n 6 Numéro 6  f     pnl       388     6  NA     4.12  4.53 rein  \n 7 Numéro 7  f     mat       410    NA  76     5.1  33.9  foie  \n 8 Numéro 8  m     imm       355    NA  74.4   4.72 13.3  foie  \n 9 Numéro 9  m     imm       222    NA   0.09  9.5   2.89 foie  \n10 Numéro 10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nCommençons par supprimer la variable ID, qui est totalement redondante avec les numéros de ligne :\n\ndauphin &lt;- dauphin |&gt; \n  select(-ID)\ndauphin\n\n# A tibble: 93 × 8\n   Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; \n 1 f     imm       315     3  29.6   3.24 NA    rein  \n 2 f     imm       357     4  55.1   4.42 NA    rein  \n 3 f     pnl       439    34 129.    5.01  9.02 rein  \n 4 f     imm       316     4  71.2   4.33 NA    rein  \n 5 f     l         435    26 192     5.15 NA    rein  \n 6 f     pnl       388     6  NA     4.12  4.53 rein  \n 7 f     mat       410    NA  76     5.1  33.9  foie  \n 8 m     imm       355    NA  74.4   4.72 13.3  foie  \n 9 m     imm       222    NA   0.09  9.5   2.89 foie  \n10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nLes variables Sexe, Statut et Organe devraient elles aussi être encodées sous forme de facteurs. Plutôt que de taper le code ci dessous (qui fonctionne très bien) :\n\ndauphin |&gt; \n  mutate(Sexe = factor(Sexe),\n         Statut = factor(Statut),\n         Organe = factor(Organe))\n\nNous pouvons utiliser la fonction mutate_if(), qui appliquera la même fonction à toutes les variables respectant une condition précise. Ici, toutes les colonnes possédant le type &lt;chr&gt; sont des colonnes que nous souhaitons transformer en facteur. Nous pouvons donc taper ceci :\n\ndauphin &lt;- dauphin |&gt; \n  mutate_if(is.character, as.factor)\ndauphin\n\n# A tibble: 93 × 8\n   Sexe  Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;fct&gt; &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; \n 1 f     imm       315     3  29.6   3.24 NA    rein  \n 2 f     imm       357     4  55.1   4.42 NA    rein  \n 3 f     pnl       439    34 129.    5.01  9.02 rein  \n 4 f     imm       316     4  71.2   4.33 NA    rein  \n 5 f     l         435    26 192     5.15 NA    rein  \n 6 f     pnl       388     6  NA     4.12  4.53 rein  \n 7 f     mat       410    NA  76     5.1  33.9  foie  \n 8 m     imm       355    NA  74.4   4.72 13.3  foie  \n 9 m     imm       222    NA   0.09  9.5   2.89 foie  \n10 m     imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nNous constatons ici que nos 3 variables catégorielles ont bien été transformées en facteurs (et seulement ces variables).\nNous allons encore réaliser 2 modifications :\n\nNous allons transformer les niveaux f et m du facteur Sexe en Female et Male respectivement.\nNous allons réordonner les niveaux du facteur Statut. Actuellement, les niveaux de ce facteur sont les suivants :\n\n\nlevels(dauphin$Statut)\n\n[1] \"imm\"   \"l\"     \"mat\"   \"pl\"    \"pnl\"   \"repos\"\n\n\nOr il exsite un ordre des statuts reproducteurs qui reflète une progression biologique : imm (immature), mat (mature), pnl (pregnant non lactating), l (lactating), pl (pregnant lactating), repos (repos somatique).\nCommençons par changer les niveaux du facteur Sexe. Pour cela, nous pouvons utiliser la fonction fct_recode() :\n\ndauphin |&gt; \n  mutate(Sexe = fct_recode(Sexe, \n                           \"Female\" = \"f\",\n                           \"Male\" = \"m\"))\n\n# A tibble: 93 × 8\n   Sexe   Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;fct&gt;  &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; \n 1 Female imm       315     3  29.6   3.24 NA    rein  \n 2 Female imm       357     4  55.1   4.42 NA    rein  \n 3 Female pnl       439    34 129.    5.01  9.02 rein  \n 4 Female imm       316     4  71.2   4.33 NA    rein  \n 5 Female l         435    26 192     5.15 NA    rein  \n 6 Female pnl       388     6  NA     4.12  4.53 rein  \n 7 Female mat       410    NA  76     5.1  33.9  foie  \n 8 Male   imm       355    NA  74.4   4.72 13.3  foie  \n 9 Male   imm       222    NA   0.09  9.5   2.89 foie  \n10 Male   imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nNous pouvons maintenant modifier l’ordre des niveaux de Satut avec la fonction fct_relevel() :\n\ndauphin &lt;- dauphin |&gt; \n  mutate(Sexe = fct_recode(Sexe, \n                           \"Female\" = \"f\",\n                           \"Male\" = \"m\"),\n         Statut = fct_relevel(Statut,\n                              \"imm\", \"mat\", \"pnl\", \"l\", \"pl\", \"repos\"))\ndauphin\n\n# A tibble: 93 × 8\n   Sexe   Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;fct&gt;  &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; \n 1 Female imm       315     3  29.6   3.24 NA    rein  \n 2 Female imm       357     4  55.1   4.42 NA    rein  \n 3 Female pnl       439    34 129.    5.01  9.02 rein  \n 4 Female imm       316     4  71.2   4.33 NA    rein  \n 5 Female l         435    26 192     5.15 NA    rein  \n 6 Female pnl       388     6  NA     4.12  4.53 rein  \n 7 Female mat       410    NA  76     5.1  33.9  foie  \n 8 Male   imm       355    NA  74.4   4.72 13.3  foie  \n 9 Male   imm       222    NA   0.09  9.5   2.89 foie  \n10 Male   imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\nlevels(dauphin$Statut)\n\n[1] \"imm\"   \"mat\"   \"pnl\"   \"l\"     \"pl\"    \"repos\"\n\n\nToutes les transformations que nous avons fait subir à ce jeu de données n’ont qu’un seul objectif : “ranger” ce jeu de données. Nous avons importé dauphin depuis un fichier externe, puis nous avons supprimé les variables inutiles et modifié celles qui devaient l’être. Toutes ces étapes peuvent être enchaînées grâce au pipe, de la façon suivante :\n\n# Importation et mise en forme du jeu de données `dauphin`\nlibrary(readxl)\ndauphin &lt;- read_excel(\"data/dauphin.xls\", \n                      na = \"*\", skip = 9) |&gt;   # Importer, puis\n  rename(ID = `N°`,                 # Raccourcir les noms, puis\n         Statut = `Statut reproducteur`,\n         Taille = `Taille en cm`,\n         Age = `Age en années`,\n         Cd = `Cd (mg.kg-1)`,\n         Cu = `Cu (mg.kg-1)`,\n         Hg = `Hg (mg.kg-1)`) |&gt; \n  select(-ID) |&gt;                   # Supprimer la variable `ID`, puis\n  mutate_if(is.character,           # 'Factoriser' les variables &lt;chr&gt;, puis\n            as.factor) |&gt;          \n  mutate(Sexe = fct_recode(Sexe,    # Modifier l'ordre des niveaux\n                           \"Female\" = \"f\",\n                           \"Male\" = \"m\"),\n         Statut = fct_relevel(Statut,\n                              \"imm\", \"mat\", \"pnl\", \"l\", \"pl\", \"repos\"))\n\ndauphin\n\n# A tibble: 93 × 8\n   Sexe   Statut Taille   Age     Cd    Cu    Hg Organe\n   &lt;fct&gt;  &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; \n 1 Female imm       315     3  29.6   3.24 NA    rein  \n 2 Female imm       357     4  55.1   4.42 NA    rein  \n 3 Female pnl       439    34 129.    5.01  9.02 rein  \n 4 Female imm       316     4  71.2   4.33 NA    rein  \n 5 Female l         435    26 192     5.15 NA    rein  \n 6 Female pnl       388     6  NA     4.12  4.53 rein  \n 7 Female mat       410    NA  76     5.1  33.9  foie  \n 8 Male   imm       355    NA  74.4   4.72 13.3  foie  \n 9 Male   imm       222    NA   0.09  9.5   2.89 foie  \n10 Male   imm       412     9  85.6   5.42 NA    rein  \n# ℹ 83 more rows\n\n\nOutre les fonctions fct_rev(), fct_recode() et fct_relevel() abordées ici, on peut aussi noter :\n\nfct_reorder() et fct_reorder2(), pour ordonner automatiquement les niveaux d’un facteur en fonction d’une autre variable numérique (pour avoir par exemple des séries rangées par ordre de moyennes croissantes sur un graphique).\nfct_infreq(), pour ordonner automatiquement les niveaux d’un facteur par ordre de fréquence croissante, ce qui est notamment utile pour faire des barplots ordonnés.\nfct_collapse(), pour fusionner deux ou plusieurs niveaux d’un facteur.\n\nNous n’avons pas le temps de développer ici des exemples pour chacune de ces fonctions, mais sachez que ces fonctions existent. Vous trouverez des exemples détaillés dans le chapitre consacré aux facteurs de l’ouvrage en ligne R for Data Science. C’est en anglais, mais les exemples sont très parlants. N’hésitez pas à consulter cet ouvrage et à faire des essais de mise en application avec les jeux de données vus ici (e.g. dauphin ou squid).\n\n\n5.7.3 Exercices\n\nDans ggplot2 le jeu de données mpg contient des informations sur 234 modèles de voitures. Examinez ce jeu de données avec la fonction View() et consultez l’aide de ce jeu de données pour savoir à quoi correspondent les différentes variables. Quelle(s) variable(s) nous renseignent sur la consommation des véhicules ? À quoi correspond la variable disp ?\nLa consommation sur autoroute est donnée en miles par gallon. Créez une nouvelle variable conso qui contiendra la consommation sur autoroute exprimée en nombre de litres pour 100 kilomètres.\nFaites un graphique présentant la relation entre la cylindrée en litres et la consommation sur autoroute exprimée en nombre de litres pour 100 kilomètres. Vous excluerez de ce graphique les véhicules dont la classe est 2seater (il s’agit de voitures de sports très compactes qu’il est difficile de mesurer aux autres). Sur votre graphique, la couleur devrait représenter le type de véhicule. Vous ajouterez une droite de régression en utilisant geom_smooth(method = \"lm\"). Votre graphique devrait ressembler à ceci :\n\n\n\n\n\n\nFigure 5.14: Consommation en fonction de la cylindrée\n\n\n\n\n\nCe graphique présente-t-il correctement l’ensemble des données de ces 2 variables ? Pourquoi ? Comparez la Figure 5.14 de la question 3 ci-dessus et la Figure 5.15 présentée ci-dessous. Selon vous, quels arguments et/ou fonctions ont été modifiés pour arriver à ce nouveau graphique ? Quels sont les avantages et les inconvénients de ce graphique par rapport au précédent ?\n\n\n\n\n\n\nFigure 5.15: Consommation en fonction de la cylindrée"
  },
  {
    "objectID": "05-DataWrangling.html#sec-arrange",
    "href": "05-DataWrangling.html#sec-arrange",
    "title": "5  Tripatouiller les données avec dplyr",
    "section": "5.8 Trier des lignes avec arrange()",
    "text": "5.8 Trier des lignes avec arrange()\n\n\n\n\n\nFigure 5.16: Schéma de la fonction arrange() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nLa fonction arrange() permet de trier des tableaux en ordonnant les éléments d’une ou plusieurs colonnes. Les tris peuvent être en ordre croissants (c’est le cas par défaut) ou décroissants (grâce à la fonction desc(), abréviation de “descending”).\narrange() fonctionne donc comme filter(), mais au lieu de sélectionner des lignes, cette fonction change leur ordre. Il faut lui fournir le nom d’un tableau et au minimum le nom d’une variable selon laquelle le tri doit être réalisé. Si plusieurs variables sont fournies, chaque variable supplémentaire permet de résoudre les égalités. Ainsi, pour ordonner le tableau flights par ordre croissant de retard au départ (dep_delay), on tape :\n\nflights |&gt; \n  arrange(dep_delay)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013    12     7     2040           2123       -43       40           2352\n 2  2013     2     3     2022           2055       -33     2240           2338\n 3  2013    11    10     1408           1440       -32     1549           1559\n 4  2013     1    11     1900           1930       -30     2233           2243\n 5  2013     1    29     1703           1730       -27     1947           1957\n 6  2013     8     9      729            755       -26     1002            955\n 7  2013    10    23     1907           1932       -25     2143           2143\n 8  2013     3    30     2030           2055       -25     2213           2250\n 9  2013     3     2     1431           1455       -24     1601           1631\n10  2013     5     5      934            958       -24     1225           1309\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nNotez que la variable dep-delay est maintenant triée en ordre croissant. Notez également que 2 vols ont eu exactement 25 minutes d’avance. Comparez le tableau précédent avec celui-ci :\n\nflights |&gt; \n  arrange(dep_delay, month, day)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013    12     7     2040           2123       -43       40           2352\n 2  2013     2     3     2022           2055       -33     2240           2338\n 3  2013    11    10     1408           1440       -32     1549           1559\n 4  2013     1    11     1900           1930       -30     2233           2243\n 5  2013     1    29     1703           1730       -27     1947           1957\n 6  2013     8     9      729            755       -26     1002            955\n 7  2013     3    30     2030           2055       -25     2213           2250\n 8  2013    10    23     1907           1932       -25     2143           2143\n 9  2013     3     2     1431           1455       -24     1601           1631\n10  2013     5     5      934            958       -24     1225           1309\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nLes lignes des 2 vols ayant 25 minutes d’avance au décollage ont été inversées : le vol du mois de mars apparaît maintenant avant le vol du mois d’octobre. La variable month a été utilisée pour ordonner les lignes en cas d’égalité de la variable dep_delay.\nComme indiqué plus haut, il est possible de trier les données par ordre décroissant :\n\nflights |&gt; \n  arrange(desc(dep_delay))\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     9      641            900      1301     1242           1530\n 2  2013     6    15     1432           1935      1137     1607           2120\n 3  2013     1    10     1121           1635      1126     1239           1810\n 4  2013     9    20     1139           1845      1014     1457           2210\n 5  2013     7    22      845           1600      1005     1044           1815\n 6  2013     4    10     1100           1900       960     1342           2211\n 7  2013     3    17     2321            810       911      135           1020\n 8  2013     6    27      959           1900       899     1236           2226\n 9  2013     7    22     2257            759       898      121           1026\n10  2013    12     5      756           1700       896     1058           2020\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nCela est particulièrement utile après l’obtention de résumés groupés pour connaître la catégorie la plus représentée. Par exemple, si nous souhaitons connaître les destinations les plus fréquentes au départ de New York, on peut procéder ainsi :\n\nPrendre le tableau flights, puis…\nGrouper les données par destination (variable dest) et compter le nombre de vols. Ces deux opérations peuvent être effectuées avec group_by() puis summarise(), ou directement avec count(). Puis…\nTrier les données par effectif décroissant.\n\n\nflights |&gt; \n  count(dest) |&gt; \n  arrange(desc(n))\n\n# A tibble: 105 × 2\n   dest      n\n   &lt;chr&gt; &lt;int&gt;\n 1 ORD   17283\n 2 ATL   17215\n 3 LAX   16174\n 4 BOS   15508\n 5 MCO   14082\n 6 CLT   14064\n 7 SFO   13331\n 8 FLL   12055\n 9 MIA   11728\n10 DCA    9705\n# ℹ 95 more rows\n\n\nNous voyons ici que les aéroports ORD et ATL sont les 2 destinations les plus fréquentes, avec plus de 17000 vols par an."
  },
  {
    "objectID": "05-DataWrangling.html#associer-plusieurs-tableaux-avec-left_join-et-inner_join",
    "href": "05-DataWrangling.html#associer-plusieurs-tableaux-avec-left_join-et-inner_join",
    "title": "5  Tripatouiller les données avec dplyr",
    "section": "5.9 Associer plusieurs tableaux avec left_join() et inner_join()",
    "text": "5.9 Associer plusieurs tableaux avec left_join() et inner_join()\n\n5.9.1 Principe\nUne autre règle que nous n’avons pas encore évoquée au sujet des “tidy data” ou “données rangées” est la suivante :\n\nChaque tableau contient des données appartenant à une unité d’observation cohérente et unique.\n\nAutrement dit, les informations concernant les vols vont dans un tableau, les informations concernant les aéroports dans un autre tableau, et celles concernant les avions dans un troisième tableau. Cela semble évident, pourtant, on constate souvent qu’un même tableau contient des variables qui concernent des unités d’observations différentes.\nLorsque nous avons plusieurs tableaux à disposition, il peut alors être nécessaire de récuppérer des informations dans plusieurs d’entre eux afin, notamment de produire des tableaux de synthèse. Par exemple, dans la Section 5.8 ci-dessus, nous avons affiché les destinations les plus fréquentes au départ des aéroports de New York. Donnons un nom à ce tableau pour pouvoir le ré-utiliser :\n\npopular_dest &lt;- flights |&gt; \n  count(dest) |&gt; \n  arrange(desc(n))\npopular_dest\n\n# A tibble: 105 × 2\n   dest      n\n   &lt;chr&gt; &lt;int&gt;\n 1 ORD   17283\n 2 ATL   17215\n 3 LAX   16174\n 4 BOS   15508\n 5 MCO   14082\n 6 CLT   14064\n 7 SFO   13331\n 8 FLL   12055\n 9 MIA   11728\n10 DCA    9705\n# ℹ 95 more rows\n\n\nÀ quel aéroport correspondent les codes ORD et ATL ? S’agit-il d’Orlando et Atlanta ? Pour le savoir, il faut aller chercher l’information qui se trouve dans le tableau airports : il contient, parmi d’autres variables, les codes et les noms de 1458 aéroports aux État-Unis.\ndplyr fournit toute une gamme de fonctions permettant d’effectuer des associations de tableaux en fonction de critères spécifiés par l’utilisateur.\n\n\n5.9.2 inner_join()\n\n\n\n\n\nFigure 5.17: Schéma de la fonction inner_join() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nLa fonction inner_join() permet de relier deux tableaux en ne conservant que les lignes qui sont présentes à la fois dans l’un et dans l’autre. Il faut identifier, dans chacun des tableaux, une colonne contenant des données en commun, qui servira de guide pour mettre les lignes correctes les unes en face des autres. Ici, nous partons de notre tableau popular_dest, qui contient les codes des aéroports dans sa colonne dest, et nous faisons une “jointure interne” avec le tableau airports qui contient lui aussi une colonne contenant les codes des aéroports : la variable faa.\n\ninner_popular &lt;- popular_dest |&gt; \n  inner_join(airports, by = join_by(dest == faa))\ninner_popular\n\n# A tibble: 101 × 9\n   dest      n name                           lat    lon   alt    tz dst   tzone\n   &lt;chr&gt; &lt;int&gt; &lt;chr&gt;                        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n 1 ORD   17283 Chicago Ohare Intl            42.0  -87.9   668    -6 A     Amer…\n 2 ATL   17215 Hartsfield Jackson Atlanta …  33.6  -84.4  1026    -5 A     Amer…\n 3 LAX   16174 Los Angeles Intl              33.9 -118.    126    -8 A     Amer…\n 4 BOS   15508 General Edward Lawrence Log…  42.4  -71.0    19    -5 A     Amer…\n 5 MCO   14082 Orlando Intl                  28.4  -81.3    96    -5 A     Amer…\n 6 CLT   14064 Charlotte Douglas Intl        35.2  -80.9   748    -5 A     Amer…\n 7 SFO   13331 San Francisco Intl            37.6 -122.     13    -8 A     Amer…\n 8 FLL   12055 Fort Lauderdale Hollywood I…  26.1  -80.2     9    -5 A     Amer…\n 9 MIA   11728 Miami Intl                    25.8  -80.3     8    -5 A     Amer…\n10 DCA    9705 Ronald Reagan Washington Na…  38.9  -77.0    15    -5 A     Amer…\n# ℹ 91 more rows\n\n\nLe nouvel objet inner_popular contient donc les données du tableau popular_dest auxquelles ont été ajoutées les colonnes correspondantes du tableau airports. Si tout ce qui nous intéresse, c’est de connaître le nom complet des aéroports les plus populaires, on peut utiliser select() pour ne garder que les variables intéressantes :\n\ninner_popular &lt;- popular_dest |&gt; \n  inner_join(airports, by = join_by(dest == faa)) |&gt; \n  select(dest, name, n)\ninner_popular\n\n# A tibble: 101 × 3\n   dest  name                                   n\n   &lt;chr&gt; &lt;chr&gt;                              &lt;int&gt;\n 1 ORD   Chicago Ohare Intl                 17283\n 2 ATL   Hartsfield Jackson Atlanta Intl    17215\n 3 LAX   Los Angeles Intl                   16174\n 4 BOS   General Edward Lawrence Logan Intl 15508\n 5 MCO   Orlando Intl                       14082\n 6 CLT   Charlotte Douglas Intl             14064\n 7 SFO   San Francisco Intl                 13331\n 8 FLL   Fort Lauderdale Hollywood Intl     12055\n 9 MIA   Miami Intl                         11728\n10 DCA   Ronald Reagan Washington Natl       9705\n# ℹ 91 more rows\n\n\nOn peut noter plusieurs choses dans ce nouveau tableau :\n\nORD n’est pas l’aéroport d’Orlando mais l’aéroport international de Chicago Ohare. C’est donc la destination la plus fréquente au départ de New York.\nATL est bien l’aéroport d’Atlanta.\ninner_popular contient 101 lignes alors que notre tableau de départ en contenait 105.\n\n\nnrow(popular_dest)\n\n[1] 105\n\nnrow(inner_popular)\n\n[1] 101\n\n\nCertaines lignes ont donc été supprimées car le code aéroport dans popular_dest (notre tableau de départ) n’a pas été retrouvé dans la colonne faa du tableau airports. C’est le principe même de la jointure interne (voir Figure 5.17) : seules les lignes communes trouvées dans les 2 tableaux sont conservées. Si l’on souhaite absolument conserver toutes les lignes du tableau de départ, il faut faire une jointure gauche, ou “left join”.\n\n\n5.9.3 left_join()\n\n\n\n\n\nFigure 5.18: Schéma de la fonction left_join() tiré de la ‘cheatsheet’ de dplyr et tidyr.\n\n\n\n\nComme indiqué par la Figure 5.18 ci-dessus, une jointure gauche permet de conserver toutes les lignes du tableau de gauche, et de leur faire correspondre des lignes du second tableau. Si aucune correspondance n’est trouvée dans le second tableau, des données manquantes sont ajoutées sous forme de NAs. Voyons ce que cela donne avec le même exemple que précédemment :\n\nleft_popular &lt;- popular_dest |&gt; \n  left_join(airports, by = join_by(dest == faa)) |&gt; \n  select(dest, name, n)\nleft_popular\n\n# A tibble: 105 × 3\n   dest  name                                   n\n   &lt;chr&gt; &lt;chr&gt;                              &lt;int&gt;\n 1 ORD   Chicago Ohare Intl                 17283\n 2 ATL   Hartsfield Jackson Atlanta Intl    17215\n 3 LAX   Los Angeles Intl                   16174\n 4 BOS   General Edward Lawrence Logan Intl 15508\n 5 MCO   Orlando Intl                       14082\n 6 CLT   Charlotte Douglas Intl             14064\n 7 SFO   San Francisco Intl                 13331\n 8 FLL   Fort Lauderdale Hollywood Intl     12055\n 9 MIA   Miami Intl                         11728\n10 DCA   Ronald Reagan Washington Natl       9705\n# ℹ 95 more rows\n\n\nEn apparence, le tableau left_popular, créé avec left_join() semble identique au tableau inner_popular créé avec inner_join(). Pourtant, ce n’est pas le cas :\n\nidentical(inner_popular, left_popular)\n\n[1] FALSE\n\n\nEn l’occurence, nous avons vu que inner_popular ne contenait pas autant de ligne que le tableau de départ popular_dest. Avec une jointure gauche, les lignes du tableau de départ sont toutes conservées. popular_dest et left_popular ont donc le même nombre de lignes.\n\nnrow(inner_popular)\n\n[1] 101\n\nnrow(left_popular)\n\n[1] 105\n\nnrow(popular_dest)\n\n[1] 105\n\n\nPour savoir quelles lignes de popular_dest manquent dans inner_dest (il devrait y en avoir 4), il suffit de filtrer les lignes de left_dest qui contiennent des données manquantes dans la colonne name :\n\nleft_popular |&gt; \n  filter(is.na(name))\n\n# A tibble: 4 × 3\n  dest  name      n\n  &lt;chr&gt; &lt;chr&gt; &lt;int&gt;\n1 SJU   &lt;NA&gt;   5819\n2 BQN   &lt;NA&gt;    896\n3 STT   &lt;NA&gt;    522\n4 PSE   &lt;NA&gt;    365\n\n\nUne rapide recherche sur internet vous apprendra que ces aéroports ne sont pas situés sur le sol américain. Trois d’entre eux sont situés à Puerto Rico (SJU, BQN et PSE) et le dernier (STT) est situé aux Îles Vierges.\nIl y aurait bien plus à dire sur les jointures :\n\nQuelles sont les autres possibilités de jointures (right_join(), outer_join(), full_join(), etc…) ?\nQue se passe-t’il si les colonnes communes des 2 tableaux contiennent des élements dupliqués ?\nEst-il toujours nécessaire d’utiliser l’argument by ?\nEst-il possible de joindre des tableaux en associant plus d’une colonne de chaque tableau d’origine ?\n\nPour avoir la réponse à toutes ces questions, je vous conseille de lire ce chapitre de cet ouvrage très complet sur “la science des données” avec R et le tidyverse : R for Data Science. Les deux fonctions inner_join() et left_join() décrites ici devraient néanmoins vous permettre de couvrir l’essentiel de vos besoins.\n\n\n5.9.4 Accoller deux tableaux\nOutre l’association de tableaux en utilisant des jointures, il est parfois utile d’accoler 2 tableaux :\n\nSoit l’un au-dessous de l’autre, quand ils ont les mêmes nombres de colonnes, et si possible, les mêmes variables aux mêmes endroits. La fonction bind_rows() permet de faire cela.\nSoit l’un à côté de l’autre quand ils ont le même nombre de lignes, et si possible les mêmes observations en lignes. La fonction bind_cols() permet de faire cela.\n\nPrenons un exemple. Imaginons que nous ayons 2 tableaux contenant les mêmes variables. Le premier, nommé colorado, contient les informations des vols ayant décollé de New York en 2013 et ayant atterri à l’aéroport de Yempa Valley au Colorado (aéroport HDN).\n\ncolorado &lt;- flights |&gt; \n  filter(dest == \"HDN\")\n\ncolorado\n\n# A tibble: 15 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     5      829            830        -1     1047           1111\n 2  2013     1    12      827            830        -3     1112           1111\n 3  2013     1    19      843            830        13     1123           1111\n 4  2013     1    26      828            830        -2     1114           1111\n 5  2013    12    21      916            830        46     1149           1117\n 6  2013    12    28      913            829        44     1128           1116\n 7  2013     2     2      858            830        28     1124           1111\n 8  2013     2     9       NA            830        NA       NA           1111\n 9  2013     2    16      834            830         4     1114           1111\n10  2013     2    23      826            830        -4     1050           1111\n11  2013     3     2      854            830        24     1104           1111\n12  2013     3     9      838            830         8     1107           1111\n13  2013     3    16      845            830        15     1154           1111\n14  2013     3    23      835            830         5     1104           1111\n15  2013     3    30      825            830        -5     1045           1111\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nLe second est nommé indiana. Il contient les informations des vols ayant décollé de New York en 2013 et ayant atterri à l’aéroport de South Bend en Indiana (aéroport SBN).\n\nindiana &lt;- flights |&gt; \n  filter(dest == \"SBN\")\n\nindiana\n\n# A tibble: 10 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013    10    18     1820           1745        35     2030           2011\n 2  2013    11     1     2012           1905        67     2221           2131\n 3  2013    11    22     2013           1905        68     2224           2131\n 4  2013    12     1     1241           1215        26     1431           1431\n 5  2013     8    30     1909           1910        -1     2117           2136\n 6  2013     9     1      833            840        -7     1030           1040\n 7  2013     9     8      847            840         7     1043           1040\n 8  2013     9    20     1948           1950        -2     2207           2216\n 9  2013     9    22      837            840        -3     1025           1040\n10  2013     9    27     2011           1950        21     2209           2216\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nPuisque les variables de ces 2 tableaux sont les mêmes, nous pouvons “empiler” ces 2 tableaux pour n’en former qu’un seul :\n\nbind_rows(colorado, indiana)\n\n# A tibble: 25 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     5      829            830        -1     1047           1111\n 2  2013     1    12      827            830        -3     1112           1111\n 3  2013     1    19      843            830        13     1123           1111\n 4  2013     1    26      828            830        -2     1114           1111\n 5  2013    12    21      916            830        46     1149           1117\n 6  2013    12    28      913            829        44     1128           1116\n 7  2013     2     2      858            830        28     1124           1111\n 8  2013     2     9       NA            830        NA       NA           1111\n 9  2013     2    16      834            830         4     1114           1111\n10  2013     2    23      826            830        -4     1050           1111\n# ℹ 15 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nVous noterez que le nombre de lignes du nouveau tableau est la somme des nombres de lignes des 2 tableaux de départ. Bien sûr, cette opération n’est utile que si les tableaux nous sont fournis séparément. Ici, il aurait été bien plus rapide d’obtenir le même résultat en tapant :\n\nflights |&gt; \n  filter(dest %in% c(\"HDN\", \"SBN\"))\n\n# A tibble: 25 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     5      829            830        -1     1047           1111\n 2  2013     1    12      827            830        -3     1112           1111\n 3  2013     1    19      843            830        13     1123           1111\n 4  2013     1    26      828            830        -2     1114           1111\n 5  2013    10    18     1820           1745        35     2030           2011\n 6  2013    11     1     2012           1905        67     2221           2131\n 7  2013    11    22     2013           1905        68     2224           2131\n 8  2013    12     1     1241           1215        26     1431           1431\n 9  2013    12    21      916            830        46     1149           1117\n10  2013    12    28      913            829        44     1128           1116\n# ℹ 15 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nLe fonctionnement de bind_cols() est le même :\n\na &lt;- tibble(x = 1:3, \n            y = c(2, 4, 6),\n            z = c(TRUE, FALSE, FALSE))\n\nb &lt;- tibble(r = 10:8, \n            s = rnorm(3))\n\na\n\n# A tibble: 3 × 3\n      x     y z    \n  &lt;int&gt; &lt;dbl&gt; &lt;lgl&gt;\n1     1     2 TRUE \n2     2     4 FALSE\n3     3     6 FALSE\n\nb\n\n# A tibble: 3 × 2\n      r       s\n  &lt;int&gt;   &lt;dbl&gt;\n1    10 -0.240 \n2     9  0.0356\n3     8 -0.787 \n\nbind_cols(a,b)\n\n# A tibble: 3 × 5\n      x     y z         r       s\n  &lt;int&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;int&gt;   &lt;dbl&gt;\n1     1     2 TRUE     10 -0.240 \n2     2     4 FALSE     9  0.0356\n3     3     6 FALSE     8 -0.787 \n\n\nIci, puisque a et b ont le même nombre de lignes, il est possible de les accoler. Cela n’a de sens que si les lignes des 2 tableaux correspondent aux mêmes observations."
  },
  {
    "objectID": "05-DataWrangling.html#sec-exo-13",
    "href": "05-DataWrangling.html#sec-exo-13",
    "title": "5  Tripatouiller les données avec dplyr",
    "section": "5.10 Exercices",
    "text": "5.10 Exercices\n\nCréez un tableau delayed indiquant, pour chaque compagnie aérienne et chaque mois de l’année, le nombre de vols ayant eu un retard supérieur à 30 minutes à l’arrivée à destination. Ce tableau devrait contenir uniquement 3 colonnes :\n\n\ncarrier : la compagnie aérienne.\nmonth : le mois de l’année 2013.\nn_delayed : le nombre de vols ayant plus de 30 minutes de retard.\n\n\nCréez un tableau total indiquant le nombre total de vols affrétés (et non annulés) par chaque compagnie aérienne et chaque mois de l’année. Ce tableau devrait contenir seulement 3 colonnes :\n\n\ncarrier : la compagnie aérienne.\nmonth : le mois de l’année 2013.\nn_total : le nombre total de vols arrivés à destination.\n\n\nFusionnez ces 2 tableaux en réalisant la jointure appropriée. Le tableau final, que vous nommerez carrier_stats devrait contenir 185 lignes. Si certaines colonnes contiennent des données manquantes, remplacez-les par des 0 à l’aide des fonctions mutate() et replace_na().\nAjoutez à votre tableau carrier_stats une variable rate qui contient la proportion de vols arrivés à destination avec plus de 30 minutes de retard, pour chaque compagnie aérienne et chaque mois de l’année.\nAjoutez à votre tableau carrier_stats le nom complet des compagnies aériennes en réalisant la jointure appropriée avec le tableau airlines.\nFaites un graphique synthétique présentant ces résultats de la façon la plus claire possible\nQuelle compagnie aérienne semble se comporter très différemment des autres ? À quoi pouvez-vous attribuer ce comportement atypique ?\nPour les compagnies affrétant un grand nombre de vols chaque année (e.g. UA, B6 et EV), quelles sont les périodes où les plus fortes proportions de vols en retard sont observées ? Et les plus faibles ? Quelle(s) hypothèse(s) pouvez-vous formuler pour expliquer ces observations ?\nFaites un tableau synthétique présentant ces résultats de la façon la plus compacte et claire que possible, afin par exemple de les intégrer à un rapport."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Wickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen,\nKohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey\nDunnington. 2023. Ggplot2: Create Elegant Data Visualisations Using\nthe Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. 2nd ed.\nNew-York: Springer-Verlag. https://www.springer.com/us/book/9780387245447."
  }
]