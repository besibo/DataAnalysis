# Exploration statistique des données {#sec-EDA}

## Pré-requis 

La première étape de toute analyse de données est l'**exploration**. Avant de se lancer dans des tests statistiques et des procédures complexes, et à supposer que les données dont vous disposez sont déjà dans un format approprié, il est toujours très utile :

1. d'explorer visuellement les données dont on dispose en faisant des graphiques nombreux et variés, afin de comprendre, notamment quelle est la distribution des variables numériques, quelles sont les catégories les plus représentées pour les variables qualitatives (ou facteurs), quelles sont les relations les plus marquantes entre variables numériques et/ou catégorielles, etc. Vous avez appris au @sec-viz comment produire toutes sortes de graphiques avec le package `ggplot2`. Il va maintenant falloir vous poser la question du choix des graphiques à produire du point de vue de l'exploration statistique de données inconnues.

2. d'explorer les données en calculant des indices de statistiques descriptives. Ces indices relèvent en général de 2 catégories : les indices de position (e.g. moyennes, médianes, quartiles...) et les indices de dispersion (e.g. variance, écart-type, intervalle inter-quartiles...). Nous avons déjà vu comment utiliser la fonction `summarise()` et son argument `.by` pour calculer des moyennes ou des effectifs pour plusieurs sous-groupes de nos jeux de données. Dans ce chapitre, nous allons aller plus loin, et nous découvrirons d'une part comment obtenir d'autres indices statistiques pertinents, et d'autres fonctions encore plus utiles que `summarise()`.

Nous verrons dans le @sec-disp comment calculer des indices d'incertitude (@sec-errstd et @sec-confint). Attention, il ne faudra pas confondre indices de dispersion et indices d'incertitude. Et enfin, avant de passer aux tests statistiques, nous verrons comment visualiser dispersion et incertitude au @sec-vizincert.

Afin d'explorer ces questions, nous aurons besoin des packages suivants :

```{r}
#| message: false
#| warning: false

library(tidyverse)
library(skimr)
library(palmerpenguins)
library(nycflights13)
```

Comme vous le savez maintenant, les packages du `tidyverse` [@R-tidyverse] permettent de manipuler facilement des tableaux de données et de réaliser des graphiques. Charger le `tidyverse` permet d'accéder, entre autres, aux packages `readr` [@R-readr], pour importer facilement des fichiers `.csv` au format `tibble`, `tidyr` [@R-tidyr] et `dplyr` [@R-dplyr] pour manipuler des tableaux de données ou encore `ggplot2` [@R-ggplot2] pour produire des graphiques. Le package `skimr` [@R-skimr] permet de calculer des résumés de données très informatifs. Les packages `palmerpenguins` [@R-palmerpenguins] et `nycflights13` [@R-nycflights13] fournissent des jeux de données qui seront faciles à manipuler pour illustrer ce chapitre (et les suivants).

:::{.callout-warning}
## Important 

Si vous avez déjà installé le `tidyverse` ou `dplyr` avant le printemps 2023, ré-installez `dplyr` avec `install.packages("dplyr")`. Ce package a en effet été mis à jour tout récemment, et nous aurons besoin de sa toute dernière version (v1.1.0) pour utiliser certaines fonctions. Chargez-le ensuite en mémoire avec `library(dplyr)`.
:::  

:::{.callout-important}
## Attention

Pensez à installer tous les packages listés ci-dessous avant de les charger en mémoire si vous ne l'avez pas déjà fait. Si vous ne savez plus comment faire, consultez d'urgence la @sec-packages
:::  

Pour travailler dans de bonnes conditions, et puisque nous abordons maintenant les statistiques à proprement parler, je vous conseille de créez un nouveau script dans le même dossier que votre `Rproject`. Là encore, si vous ne savez plus comment faire consultez la @sec-code.

## Créer des résumés avec la fonction `summarise()`

Comme nous l'avons vu au semestre 3, le package `dplyr` fournit plusieurs fonctions qui portent le nom de verbes et qui permettent d'effectuer des manipulations simples mais qui peuvent devenir très puissantes lorsqu'on les combine. Nous avons ainsi vu les fonctions suivantes :

- `select()` : pour sélectionner ou exclure certaines colonnes (variables) d'un tableau de données
- `filter()` : pour trier des lignes d'un tableau de données selon des critères ou conditions choisis par l'utilisateur
- `mutate()` : pour transformer des variables existantes, ou pour créer de nouvelles colonnes dans un tableau de données
- `arrange()` : pour trier des tableaux de données par ordre croissants ou décroissants

Si vous ne savez plus comment utiliser ces fonctions, relisez [le chapitre 4 du livre en ligne de Biométrie du semestre 3](https://besibo.github.io/BiometrieS3/04-DataWrangling.html).

À ces 4 verbes, nous allons ici ajouter :

- `summarise()` : pour créer des résumés de données simples à partir des colonnes d'un tableau
- `reframe()` : pour créer des résumés de données plus élaborés à partir des colonnes d'un tableau
- `count()` : pour compter le nombre d'observations pour chaque niveau d'un facteur (ou modalité d'une variable catégorielle)
- `group_by()` : pour effectuer des opérations pour chaque niveau d'un facteur (ou modalité d'une variable catégorielle)

Cette dernière fonction `group_by()` a été rendue presque obsolète par une mise à jour récente du package `dplyr` qui introduit un nouvel argument pour plusieurs fonctions, dont `summarise()` : l'argument `.by`. Un peu comme `group-by()`, ce nouvel argument permet d'effectuer des opérations pour chaque niveau d'un facteur (ou modalité d'une variable catégorielle). À notre niveau, les différences entre la fonction `group_by()` et l'argument `.by` ne sont pas importantes. Nous utiliserons donc de préférence la notation la plus simple, celle de l'argument `.by`.

Voyons comment on utilise ces fonctions pour calculer des indices de statistiques descriptives pour les variables du tableau `penguins` :

```{r}
# affichage du tableau
penguins
```

### Principe de la fonction `summarise()`


```{r}
#| out-width: 55%
#| fig-align: 'center'
#| echo: false

knitr::include_graphics("images/summarizearrow.png")
```

```{r}
#| label: fig-summarise2
#| fig-cap: "Schéma de la fonction `summarise()` tiré de la 'cheatsheet' de `dplyr` et `tidyr`"
#| out-width: 40%
#| fig-align: 'center'
#| echo: false

knitr::include_graphics("images/summarize.png")
```

La @fig-summarise2 ci-dessus indique comment travaille la fonction `summarise()` : elle prend plusieurs valeurs (potentiellement, un très grand nombre) et les réduit à **une unique valeur qui les résume**. La valeur qui résume les données est choisie par l'utilisateur. Il peut s'agir par exemple d'un calcul de moyenne, de quartile ou de variance, il peut s'agir de calculer une somme, ou d'extraire la valeur maximale ou minimale, ou encore, il peut tout simplement s'agir de déterminer un nombre d'observations. Mais le fonctionnement est toujours le même : la fonction `summarise()` ne renvoie qu'une unique valeur pour une variable donnée (ou pour chaque modalité d'une variable catégorielle).

Ainsi, pour connaître la moyenne de la longueur du bec des manchots de l'île de Palmer, il suffit d'utiliser le tableau `penguins` du package `palmerpenguins` et sa variable `bill_length_mm` que nous avons déjà utilisée au semestre 3 :

```{r, tidy = FALSE}
penguins %>%
  summarise(moyenne = mean(bill_length_mm))
```

La fonction `mean()` permet de calculer une moyenne. Ici, la valeur retournée est `NA` car 2 individus n'ont pas été mesurés, et le tableau contient donc des valeurs manquantes :

```{r, tidy=FALSE}
penguins %>%
  filter(is.na(bill_length_mm))
```

Pour obtenir la valeur souhaitée, il faut indiquer à `R` d'exclure les valeurs manquantes lors du calcul de moyenne :


```{r, tidy = FALSE}
penguins %>%
  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE))
```


```{r, tidy = FALSE, include = FALSE}
bill <- penguins %>%
  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),
            ecart_type = sd(bill_length_mm, na.rm = TRUE))
```

La longueur moyenne du bec des manchots (toutes espèces confondues) est donc de `r round(bill[1,1],1)` millimètres.

De la même façon, on peut demander plusieurs calculs d'indices à la fois, par exemple la moyenne et l'écart-type (avec la fonction `sd()`) de la longueur des becs :

```{r, tidy = FALSE}
penguins %>%
  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),
            ecart_type = sd(bill_length_mm, na.rm = TRUE))
```

Ici, l'écart-type vaut `r round(bill[1,2],1)` millimètres. 

La fonction `summarise()` permet donc de calculer des indices statistiques variés, et permet aussi d'accéder à plusieurs variables à la fois. Par exemple. pour calculer les moyennes, médianes, minima et maxima des longueurs de nageoires et de masses corporelles, on peut procéder ainsi :

```{r}
penguins %>% 
  summarise(moy_flip = mean(flipper_length_mm, na.rm = TRUE),
            med_flip = median(flipper_length_mm, na.rm = TRUE),
            min_flip = min(flipper_length_mm, na.rm = TRUE),
            max_flip = max(flipper_length_mm, na.rm = TRUE),
            moy_mass = mean(body_mass_g, na.rm = TRUE),
            med_mass = median(body_mass_g, na.rm = TRUE),
            min_mass = min(body_mass_g, na.rm = TRUE),
            max_mass = max(body_mass_g, na.rm = TRUE))
```

La fonction `summarise()` est donc très utile pour produire des résumés informatifs des données, mais nos exemples ne sont ici pas très pertinents puisque nous avons jusqu'ici calculé des indices sans distinguer les espèces. Si les 3 espèces de manchots ont des caractéristiques très différentes, calculer des moyennes toutes espèces confondues n'a pas de sens. Voyons maintenant comment obtenir ces même indices pour chaque espèce.

### Intérêt de l'argument `.by`

La fonction `summarise()` devient particulièrement puissante lorsqu'on y ajoute l'argument `.by` :

```{r, groupby, echo = FALSE, out.width='65%', fig.align='center', fig.cap="(ref:groupby)"}
#| echo: false
#| out-width: 65%
#| fig-align: center
#| fig-cap: "Fonctionnement de l'argument `.by` travaillant de concert avec `summarise()`, tiré de la 'cheatsheet' de `dplyr` et `tidyr`"
#| label: fig-groupby

knitr::include_graphics('images/groupby.png')
```

Comme son nom l'indique, l'argument `.by` permet de créer des sous-groupes dans un tableau, afin que le résumé des données soit calculé pour chacun des sous-groupes plutôt que sur l'ensemble du tableau. En ce sens, son fonctionnement est analogue à celui des `facet`s de `ggplot2` qui permettent de scinder les données d'un graphique en plusieurs sous-groupes.

Pour revenir à l'exemple de la longueur du bec des manchots, imaginons que nous souhaitions calculer les moyennes et les écart-types pour chacune des trois espèces. Voilà comment procéder :

```{r, tidy = FALSE}
penguins %>%
  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),
            ecart_type = sd(bill_length_mm, na.rm = TRUE),
            .by = species)
```

Ici, les étapes sont les suivantes :

1. On prend le tableau `penguins`, *puis*
2. On résume les données sous la forme de moyennes et d'écart-types
3. On demande un calcul pour chaque modalité de la variable `species`

Là où nous avions auparavant une seule valeur de moyenne et d'écart-type pour l'ensemble des individus du tableau de données, nous avons maintenant une valeur de moyenne et d'écart-type pour chaque modalité de la variable espèce. Puisque le facteur `species` contient 3 modalités (`Adelie`, `Chinstrap` et `Gentoo`), le résumé des données contient maintenant 3 lignes.

Cette syntaxe très simple est presque équivalente à celle de la fonction `group_by()` :

```{r, tidy = FALSE}
penguins %>%
  group_by(species) %>% 
  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),
            ecart_type = sd(bill_length_mm, na.rm = TRUE))
```

Les valeurs obtenues sont les mêmes, mais d'une part, les commandes sont fournies avec une syntaxe et dans un ordre différents :

1. On prend le tableau `penguins`, *puis*
2. On groupe les données par espèce, *puis*
2. On résume les données sous la forme de moyennes et d'écart-types

Et l'objet obtenu au final n'est pas strictement identique : avec la fonction `group_by()`, et dans certaines situations, la tibble obtenu conserve l'information du regroupement effectué, ce qui peut être utile dans certaines situations, mais pose parfois problème et cause l'affichage de messages d'avertissements dans la console. Ce comportement n'est pas observé avec l'argument `.by` qui ne groupe les données qu'au moment du calcul des indices dans la fonction `summarise()` et n'en conserve pas la trace ensuite. C'est la raison pour laquelle nous privilégierons cette méthode.

Pour aller plus loin, ajoutons à ce résumé 2 variables supplémentaires : le nombre de mesures et l'**erreur standard** (notée $se$), qui peut être calculée de la façon suivante :

$$se \approx \frac{s}{\sqrt{n}}$$

avec $s$, l'écart-type de l'échantillon et $n$, la taille de l'échantillon (plus d'informations sur cette statistique très importante dans la @sec-disp). Nous allons donc calculer ici ces résumés, et nous donnerons un nom au tableau créé pour pouvoir ré-utiliser ces statistiques descriptives :

```{r, tidy = FALSE}
stats_esp <- penguins %>%
  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),
            ecart_type = sd(bill_length_mm, na.rm = TRUE),
            nb_obs = n(),
            erreur_std = ecart_type / sqrt(nb_obs),
            .by = species)

stats_esp
```

Vous constatez ici que nous avons 4 statistiques descriptives pour chaque espèce. Deux choses sont importantes à retenir ici :

1. on peut obtenir le nombre d'observations dans chaque sous-groupe d'un tableau groupé en utilisant la fonction `n()`. Cette fonction n'a besoin d'aucun argument : elle détermine automatiquement la taille des groupes créés par `.by` (ou par la fonction `group_by()`).
2. on peut créer de nouvelles variables en utilisant le nom de variables créées auparavant. Ainsi, nous avons créé la variable `erreur_std` en utilisant deux variables créées au préalable : `ecart-type` et `nb_obs`



### Grouper par plus d'une variable

Jusqu'ici, nous avons groupé les données par espèce. Il est tout à fait possible de grouper les données par plus d'une variable, par exemple, par espèce et par sexe :

```{r, tidy = FALSE}
stats_esp_sex <- penguins %>%
  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),
            ecart_type = sd(bill_length_mm, na.rm = TRUE),
            nb_obs = n(),
            erreur_std = ecart_type / sqrt(nb_obs),
            .by = c(species, sex))

stats_esp_sex
```

En plus de la variable `species`, la tableau `stats_esp_sex` contient une variable `sex`. Les statistiques que nous avons calculées plus tôt sont maintenant disponibles pour chaque espèce et chaque sexe. D'ailleurs, puisque le sexe de certains individus est inconnu, nous avons également des lignes pour lesquelles le sexe affiché est `NA`. Pour les éliminer, il suffit de retirer les lignes du tableau pour lesquelles le sexe des individus est inconnu avant de recalculer les mêmes indices :

```{r}
stats_esp_sex2 <- penguins %>%
  filter(!is.na(sex)) %>% 
  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),
            ecart_type = sd(bill_length_mm, na.rm = TRUE),
            nb_obs = n(),
            erreur_std = ecart_type / sqrt(nb_obs),
            .by = c(species, sex))

stats_esp_sex2
```

Si vous ne comprenez pas la commande `filter(!is.na(sex))`, je vous encourage vivement à consulter [cette section du livre en ligne de Biométrie du semestre 3](https://besibo.github.io/BiometrieS3/04-DataWrangling.html#filtrer-des-lignes-avec-filter).

Enfin, lorsque nous groupons par plusieurs variables, il peut être utile de présenter les résultats sous la forme d'un tableau large (grâce à la fonction `pivot_wider()`) pour l'intégration dans un rapport par exemple. La fonction `pivot_wider()` permet de passer d'un tableau qui possède ce format :

```{r, tidy = FALSE}
penguins %>%
  filter(!is.na(sex)) %>% 
  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),
            .by = c(species, sex))
```

à un tableau sous ce format :

```{r}
penguins %>%
  filter(!is.na(sex)) %>% 
  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),
            .by = c(species, sex)) %>% 
  pivot_wider(names_from = sex,
              values_from = moyenne)
```

Sous cette forme, les données ne sont plus "rangées", c'est à dire que nous n'avons plus une observation par ligne et une variable par colonne. En effet ici, la variable `sex` est maintenant "étalée" dans 2 colonnes distinctes : chaque modalité du facteur de départ (`female` et `male`) est utilisée en tant que titre de nouvelles colonnes, et la variable `moyenne` est répartie dans deux colonnes. Ce format de tableau n'est pas idéal pour les statistiques ou les représentations graphiques, mais il est plus synthétique, et donc plus facile à inclure dans un rapport ou un compte-rendu.


### Un raccourci pratique pour compter des effectifs {#sec-count}

Il est extrêmement fréquent d'avoir à grouper des données en fonction d'une variable catégorielle puis d'avoir à compter le nombre d'observations de chaque modalité avec `n()` :


```{r}
penguins %>% 
  summarise(effectif = n(), 
            .by = species)
```

ou encore :

```{r}
penguins %>% 
  group_by(species) %>% 
  summarise(effectif = n())
```
Ces deux opérations sont tellement fréquentes (regrouper puis compter) que le package `dplyr` nous fournit un raccourci : la fonction `count()`.

Le code ci-dessus est équivalent à celui-ci :

```{r, tidy=FALSE}
penguins %>% 
  count(species)
```

Notez qu'avec la fonction `count()`, la colonne qui contient les comptages s'appelle toujours `n` par défaut. Comme avec `.by` et `group_by()`, il est bien sûr possible d'utiliser `count()` avec plusieurs variables :

```{r, tidy=FALSE}
penguins %>% 
  count(species, sex)
```

```{r, tidy=FALSE}
penguins %>% 
  filter(!is.na(sex)) %>% 
  count(species, sex)
```

Et il est évidemment possible de présenter le résultats sous un format de tableau large :

```{r}
penguins %>% 
  filter(!is.na(sex)) %>% 
  count(species, sex) %>% 
  pivot_wider(names_from = sex,
              values_from = n)
```

Vous connaissez maintenant plusieurs méthodes pour calculer à la main des statistiques descriptives pour des variables entières, ou pour des sous-groupes de lignes (par espèce, par sexe, par sexe et par espèce...). Globalement, toutes les fonctions de R qui prennent une série de chiffres en guise d'argument, et qui renvoient une valeur unique, peuvent être utilisées avec la fonction `summarise()`. En particulier, vous pouvez utiliser les fonctions suivantes pour faire des analyses exploratoires :

- `mean()` : calcul de la moyenne
- `median()` : calcul de la médiane
- `min()` : affichage de la valeur minimale
- `max()` : affichage de la valeur minimale
- `n_distinct()` : calcul du nombre de valeurs différentes
- `n()` : calcul du nombre d'observations
- `var()` : calcul de la variance
- `sd()` : calcul de l'écart-type
- `IQR()` : calcul de l'intervalle inter-quartiles

Et la liste n'est bien sûr pas exhaustive

### Exercices {#sec-exo10}

1. Avec le tableau `diamonds` du package `ggplot2`, faites un tableau indiquant combien de diamants de chaque couleur on dispose. Vous devriez obtenir le tableau suivant :

```{r, tidy=FALSE, echo=FALSE}
diamonds %>% 
  count(color)
```


2. Examinez le tableau `weather` du package `nycflights13` et lisez son fichier d'aide pour comprendre à quoi correspondent les données et comment elles ont été acquises.

3. À partir du tableau `weather` faites un tableau indiquant les vitesses de vents minimales, maximales et moyennes, enregistrées chaque mois dans chaque aéroport de New York. Indice : les 3 aéroports de New York sont Newark, LaGuardia Airport et John F. Kennedy, notés respectivement `EWR`, `LGA` et `JFK` dans la variable `origin`. Votre tableau devrait ressembler à ceci :

```{r, tidy=FALSE, echo=FALSE}
windy <- weather %>%
  summarise(max_wind = max(wind_speed, na.rm = TRUE),
            min_wind = min(wind_speed, na.rm = TRUE),
            moy_wind = mean(wind_speed, na.rm = TRUE),
            .by = c(origin, month))
windy
```

4. Sachant que les vitesses du vent sont exprimées en miles par heure, certaines valeurs sont-elles surprenantes ? À l'aide de la fonction `filter()`, éliminez la ou les valeurs aberrantes. Vous devriez obtenir ce tableau :

```{r, tidy=FALSE, echo=FALSE}
windy2 <- weather %>%
  filter(wind_speed <= 500) %>%
  summarise(max_wind = max(wind_speed, na.rm = TRUE),
            min_wind = min(wind_speed, na.rm = TRUE),
            moy_wind = mean(wind_speed, na.rm = TRUE),
            .by = c(origin, month))
windy2
```

5. En utilisant les données de vitesse de vent du tableau `weather`, produisez le graphique suivant :

```{r windspeed, tidy=FALSE, warning = FALSE, echo = FALSE}
weather %>%
  filter(wind_speed < 500) %>%
  ggplot(aes(x = factor(month), y = wind_speed)) +
  geom_jitter(width = 0.2, height = 0, alpha = 0.2) +
  labs(x = "Mois",
       y = "Vitesse du vent (mph)")
```

Indications :

- les vitesses de vent aberrantes ont été éliminées grâce à la fonction `filter()`
- la fonction `geom_jitter()` a été utilisée avec l'argument `height = 0`
- la transparence des points est fixée à `0.2`

6. À votre avis :

- pourquoi les points sont-ils organisés en bandes horizontales ?
- pourquoi n'y a-t-il jamais de vent entre 0 et environ 3 miles à l'heure (mph) ?
- Sachant qu'en divisant des mph par 1.151 on obtient des vitesses en nœuds, que nous apprend cette commande :

```{r}
sort(unique(weather$wind_speed)) / 1.151
```

## Les fonctions `pivot_wider()` et `pivot_longer()` {#sec-pivot}

### Du format long au format large : `pivot_wider()`

Comme nous venons de le voir, la fonction `pivot_wider()` permet de passer d'un tableau au format long à un tableau au format large, qui contient donc moins de lignes mais plus de colonnes.

Par exemple, lorsque l'on dispose d'un tableau contenant un résumé de données pour plusieurs catégories et sous-catégories, il peut être utile de le transformer au format large pour l'intégrer dans un rapport (la présentation en est ainsi plus synthétique) ou pour faire certains types de graphiques. Par exemple, avec ce tableau de résumé de données :

```{r}
resum <- penguins %>% 
  filter(!is.na(sex)) %>% 
  count(species, sex)

resum
```

La présentation au format large serait plus appropriée dans un compte-rendu de TP :

```{r}
resum_large1 <- resum %>% 
  pivot_wider(names_from = sex,
              values_from = n)

resum_large1
```

L'argument `names_from` permet d'indiquer dans quelle colonne du tableau de départ aller cherche les noms de colonnes pour le nouveau tableau. Ici, on va chercher dans la colonne `sex` les noms de colonne du futur tableau (`female` et `male`). L'argument `values_from` permet d'indiquer dans quelle colonne du tableau de départ on souhaite aller chercher les valeurs que l'on souhaite mettre dans les nouvelles colonnes du futur tableau (ici, les effectifs stockés dans la colonne `n`).

Le terme "tableau large" peut-être trompeur car le tableau obtenu n'a pas forcément plus de colonnes que le tableau d'origine. En tous cas, il a toujours moins de lignes que le tableau de départ. Ici, `resum` avait 6 lignes et 3 colonnes, `resum_large1` possède 3 lignes et 3 colonnes.

Si on souhaite avoir les espèces en colonnes et les sexes en lignes, on peut taper ceci :
```{r}
resum_large2 <- resum %>% 
  pivot_wider(names_from = species, 
              values_from = n)

resum_large2
```

Cette fois, `resum_large2` possède 2 lignes et 4 colonnes. Le caractère "large" de ce nouveau tableau est ici bien apparent. Notez bien que ce sont toujours les mêmes données qui figurent dans ces 3 objets : seule la présentation change.

### Du format large au format long : `pivot_longer()`

À l'inverse, on dispose parfois de données au format large alors que la plupart des fonctions graphiques et statistiques de `R` requièrent des données au format long, c'est à dire, des tableaux dans lesquels il y a une correspondance stricte entre colonnes et variables : une variable est contenue dans une seule colonne d'un tableau, et chaque ligne correspond à une unique observation. AInsi, le tableau `resum_large2` n'est pas au format long :

```{r}
resum_large2
```

En effet, 3 de ses colonnes contiennent des données d'abondances qui pourraient (ou devraient) se trouver dans une unique colonne `Abondance`, et le titre de ces 3 colonnes devrait être les catégories d'une autre variable `Espece`. Pour transformer un tableau large en tableau long (qui contient donc toujours plus de lignes, et souvent moins de colonnes), on utilise `pivot_longer()`. Cette fonction possède 3 arguments : 

- `cols` : quelles sont les colonnes que l'on souhaite regrouper
- `names_to` : comment s'appellera la variable qui contiendra les anciens noms de colonnes du tableau large
- `values_to` : comment s'appellera la variable qui contiendra les données contenues dans les cellules du tableau large

Voilà un exemple :

```{r}
resum_long <- resum_large2 %>% 
  pivot_longer(cols = c(Adelie, Chinstrap, Gentoo),
               names_to = "Espece",
               values_to = "Abondance")

resum_long
```

Les 3 colonnes qui contenaient les abondance des 3 espèces de manchots ont été regroupées en 2 nouvelles colonnes dont les noms ont été précisés grâce à `names_to` et `values_to`.

Il est très fréquent d'avoir à passer d'un format large à un format long ou inversement. Il est donc important que vous appreniez à vous familiariser avec ces 2 fonctions.

:::{.callout-important}
## les tableaux rangés

La plupart des fonctions du `tidyverse` supposent que les tableaux soient rangés (une colonne par variable, une ligne par observation) et qu'ils aient donc un format long. À l'inverse, pour présenter des tableaux dans un rapport ou pour certaines méthodes particulières, les données peuvent être présentées au format large. Les fonctions `pivot_wider()` et `pivot_longer()` sont complémentaires et permettent de passer d'un format à l'autre.
:::


## Créer des résumés avec la fonction `reframe()`

Comme nous venons de le voir, les calculs que nous pouvons faire grâce à la fonction `summarise()` impliquent des fonctions statistiques qui ne renvoient qu'une valeur à la fois lorsqu'on leur fournit une série de valeurs. Par exemple, si on dispose d'un vecteur numérique (les entiers compris entre 1 et 100 pour l'exemple) :

```{r}
1:100
```

la fonction `mean()` ne renvoie qu'une valeur, la moyenne des 100 valeurs contenues dans le vecteur :

```{r}
mean(1:100)
```

De même pour les fonctions `sd()`, ou `median()`, ou toutes les autres fonctions listées à la fin de la @sec-count :

```{r}
sd(1:100)
median(1:100)
```

Il existe toutefois des fonctions qui renvoient plus d'une valeur à la fois. Par exemple, la fonction `quantile()`, renvoie par défaut 5 éléments :

1. la valeur minimale contenue dans le vecteur (ou quantile 0%) : c'est la valeur la plus faible contenue dans la série de données
2. le premier quartile du vecteur (Q1 ou quantile 25%) : c'est la valeur coupant l'échantillon en deux telle que 25% des observations du vecteur y sont inférieures
3. la médiane du vecteur (Q2 ou quantile 50%) : c'est la valeur coupant l'échantillon en deux telle que 50% des observations du vecteur sont inférieures à cette valeur et 50% y sont supérieures
4. le troisième quartile du vecteur (Q3 ou quantile 75%) : c'est la valeur coupant l'échantillon en deux telle que 75% des observations du vecteur y sont inférieures
5. la valeur maximale contenue dans le vecteur (ou quantile 100%) : c'est la valeur la plus élevée contenue dans la série de données.

Par exemple, toujours avec le vecteur des entiers contenus entre 1 et 100 :

```{r}
quantile(1:100)
```

L'objet obtenu est un vecteur dont chaque élément porte un nom. Pour transformer cet objet en tibble, on utilise la fonction `enframe()` :

```{r}
enframe(quantile(1:100))
```

Il peut être très utile de calculer ces différentes valeurs pour plusieurs variables à la fois, ou pour plusieurs sous-groupes d'un jeu de données. Le problème est que nous ne pouvons pas utiliser `summarise()` car la fonction `quantile()` ne renvoie pas qu'une unique valeur. par exemple, pour calculer les quantiles des longueurs de becs pour chaque espèce de manchots, on pourrait être tenté de taper ceci :

```{r}
#| error: true
penguins %>% 
  summarise(Indices = quantile(bill_length_mm, na.rm = TRUE), 
            .by = species)
```

C'est dans ces situations que la fonction `reframe()` est utile. Elle joue le même rôle que `summarise()`, mais dans les situation où les fonctions statistiques renvoient plus d'une valeur à la fois :

```{r}
penguins %>% 
  reframe(Indices = quantile(bill_length_mm, na.rm = TRUE), 
          .by = species)
```

Au contraire de `summarise()`, `reframe()` ne renvoie pas de message d'avertissement dans cette situation. Dans cet exemple, on ne sait malheureusement pas à quoi correspondent les chiffres renvoyés puisque l'information des quartiles a disparu (quelles valeurs correspondent aux médianes ou aux premiers quartiles par exemple). Pour y remédier, on doit transformer le vecteur renvoyé par `quantile()` en tibble. Nous avons déjà vu comment le faire grâce à la fonction `enframe()`. Par ailleurs, puisque la fonction va maintenant renvoyer un tableau, on n'a pas besoin de lui fournir de nom de colonnes (je retire donc `Indices = ` de mon code) :

```{r}
penguins %>% 
  reframe(enframe(quantile(bill_length_mm, na.rm = TRUE)), 
          .by = species)
```

Enfin, comme précédemment, il est possible de modifier la forme de ce tableau (avec `pivot_wider()`) pour le lire plus facilement et éventuellement l'intégrer dans un rapport ou compte-rendu :

```{r}
penguins %>%
  reframe(enframe(quantile(bill_length_mm, na.rm = TRUE)), 
          .by = species) %>% 
  pivot_wider(names_from = species,
              values_from = value)
```

Ces statistiques nous permettent de constater que les manchots de l'espèce Adélie semblent avoir des becs plus courts que les 2 autres espèces (les 5 quantiles le confirment). Les manchots Gentoo et Chinstrap ont en revanche des becs de longueur à peu près similaires, ben que ceux des Chinstrap soient peut-être très légèrement plus longs (Q1, médiane et Q3 supérieurs à ceux des Gentoo). On peut vérifier tout ça graphiquement avec des boîtes à moustaches :

```{r}
penguins %>% 
  ggplot(aes(x = species, y = bill_length_mm)) +
  geom_boxplot() +
  labs(x = "Espèce", y = "Longueur du bec (mm)") +
  theme_bw()
```

Ou avec un graphique de densité :

```{r}
penguins %>% 
  ggplot(aes(x = bill_length_mm, fill = species)) +
  geom_density(alpha = 0.5, show.legend = FALSE) +
  geom_rug() +
  labs(x = "Longueur du bec (mm)", y = "Densité") +
  facet_wrap(~species, ncol = 1) +
  scale_fill_brewer(palette = "Accent") +
  theme_bw()
```

À ce stade, vous devriez être capables de créer (et d'interpréter !) ce type de graphiques. Si ce n'est pas le cas, consultez d'urgence [le chapitre 3 du livre en ligne de Biométrie du semestre 3](https://besibo.github.io/BiometrieS3/03-visualization.html).

:::{.callout-tip}
## À retenir

- la fonction `summarise()` s'utilise avec des fonctions statistiques qui ne renvoient qu'une valeur (par exemple `mean()`, `median()`, `sd()`, `var()`...)
- la fonction `reframe()` s'utilise avec des fonctions statistiques qui renvoient plusieurs valeurs (par exemple `quantile()`, `range()`...)
:::  

## Créer des résumés de données avec des fonctions spécifiques

Les fonctions `summarise()` et `reframe()`, avec leur argument `.by()` (ou la fonction `group_by()`) permettent donc de calculer n'importe quel indice de statistique descriptive sur un tableau de données entier ou sur des modalités ou combinaisons de modalités de facteurs. Il existe par ailleurs de nombreuses fonctions, disponibles de base dans `R` ou dans certains packages spécifiques, qui permettent de fournir des résumés plus ou moins automatiques de tout ou partie des variables d'un jeu de données. Nous allons en décrire 2 ici, mais il en existe beaucoup d'autres : à vous d'explorer les possibilités et d'utiliser les fonctions qui vous paraissent les plus pertinentes, les plus simples à utiliser, les plus visuelles ou les plus complètes.

### La fonction `summary()`

La fonction `summary()` (à ne pas confondre avec `summarise()`) permet d'obtenir des résumés de données pour tous types d'objets dans `R`. Selon la classe des objets que l'on transmets à `summary()`, la nature des résultats obtenus changera. Nous verrons ainsi au semestre 6 que cette fonction peut être utilisée pour examiner les résultats de modèles de régressions linéaires ou d'analyses de variances. Pour l'instant, nous nous intéressons à 3 situations :

- ce que renvoie la fonction quand on lui fournit un vecteur
- ce que renvoie la fonction quand on lui fournit un facteur
- ce que renvoie la fonction quand on lui fournit un tableau

#### Variable continue : vecteur numérique

Commençons par fournir un vecteur numérique à la fonction `summary()`. Nous allons pour cela extraire les données de masses corporelles des manchots du tableau `penguins` :

```{r}
penguins$body_mass_g
```
Nous avons donc `r length(penguins$body_mass_g)` valeurs de masses en grammes qui correspondent aux 344 manchots du jeu de données. La fonction `summary()` renvoie le résumé suivant lorsqu'on lui fournit ces valeurs :

```{r}
summary(penguins$body_mass_g)
```

Nous obtenons ici 7 valeurs, qui correspondent respectivement à :

- la valeur minimale observée dans le vecteur. Ici, le manchot le plus léger de l'échantillon pèse donc 2700 grammes.
- la valeur du premier quartile du vecteur. Le premier quartile est la valeur qui coupe l'échantillon en 2 groupes : 25% des observations du vecteur sont inférieures au premier quartile, et 75% des observations du vecteur sont supérieures au premier quartile. Ici, 25% des manchots de l'échantillon (soit 86 individus) ont une masse inférieure à 3550 grammes, et 75% des individus de l'échantillon (soit 258 individus) ont une masse supérieure à 3550 grammes.
- la valeur de médiane du vecteur. La médiane est la valeur qui coupe l'échantillon en 2 groupes : 50% des observations du vecteur sont inférieures à la médiane, et 50% des observations du vecteur sont supérieures à la médiane. Ici, 50% des manchots de l'échantillon (soit 172 individus) ont une masse inférieure à 4050 grammes, et 50% des individus de l'échantillon (soit 172 individus) ont une masse supérieure à 4050 grammes.
- la moyenne du vecteur. Ici, les manchots des 3 espèces du jeu de données ont en moyenne une masse 4202 grammes.
- la valeur du troisième quartile du vecteur. Le troisième quartile est la valeur qui coupe l'échantillon en 2 groupes : 75% des observations du vecteur sont inférieures au troisième quartile, et 25% des observations du vecteur sont supérieures au troisième quartile. Ici, 75% des manchots de l'échantillon (soit 258 individus) ont une masse inférieure à 4700 grammes, et 25% des individus de l'échantillon (soit 86 individus) ont une masse supérieure à 4750 grammes.
- la valeur maximale observée dans le vecteur. Ici, le manchot le plus lourd de l'échantillon pèse donc 6300 grammes.
- le nombre de données manquantes. Ici, 2 manchots n'ont pas été pesés et présentent donc la mention `NA` (comme **N**ot **A**vailable) pour la variable `body_mass_g`.

Cette fonction fournit donc 2 indices de plus que la fonction `quantile()` (la moyenne et le nombre de valeurs manquantes) :

```{r}
quantile(penguins$body_mass_g, na.rm = TRUE)
```

Mais contrairement à ce que nous avons vu plus haut, la fonction `summary()` ne possède pas d'argument `.by()` et il n'est pas possible de l'utiliser avec la fonction `group_by()`. Par conséquent, il n'est pas possible de se servir de cette fonction pour avoir des valeurs pour chaque modalités d'un facteur (pour chaque espèce par exemple).

Les différents indices statistiques fournis nous renseignent à la fois sur la position de la distribution et sur la dispersion des données. 

- La *position* correspond à la tendance centrale et indique quelles sont les valeurs qui caractérisent le plus grand nombre d'individus. La moyenne et la médiane sont les deux indices de position les plus fréquemment utilisés. Lorsqu'une variable a une distribution parfaitement symétrique, la moyenne et la médiane sont strictement égales. Mais lorsqu'une distribution est asymétrique, la moyenne et la médiane diffèrent. En particulier, la moyenne est beaucoup plus sensible aux valeurs extrêmes que la médiane. Cela signifie que quand une distribution est très asymétrique, la médiane est souvent une meilleure indication des valeurs les plus fréquemment observées.

```{r}
#| echo: false
#| warning: false
#| fig-cap: "Distribution des masses corporelles des manchots"
#| fig-align: center
#| label: fig-distri-masses

penguins %>% 
  ggplot(aes(body_mass_g)) +
  geom_histogram(bins = 25, fill = "steelblue", color = "grey20", alpha = 0.7) +
  geom_vline(xintercept = mean(penguins$body_mass_g, na.rm = TRUE), 
             color = "firebrick", size = 1.5) +
  geom_vline(xintercept = median(penguins$body_mass_g, na.rm = TRUE), 
             color = "orange", size = 1.5) +
  labs(x = "Masse (g)", y = "Nombre") +
  theme_bw()
```
L'histogramme de la @fig-distri-masses montre la distribution de la taille des manchots (toutes espèces confondues). Cette distribution présente une asymétrie à droite. Cela signifie que la distribution n'est pas symétrique et que la "queue de distribution" est plus longue à droite qu'à gauche. La plupart des individus ont une masse comprise entre 3500 et 3700 grammes, au niveau du pic principal du graphique. La médiane, en orange et qui vaut 4050 grammes est plus proche du pic que la moyenne, en rouge, qui vaut 4202 grammes. Ici, la différence entre moyenne et médiane n'est pas énorme, mais elle peut le devenir si la distribution est vraiment très asymétrique, par exemple, si quelques individus seulement avaient une masse supérieure à 7000 grammes, la moyenne serait tirée vers la droite du graphique alors que la médiane ne serait presque pas affectée. la moyenne représenterait alors encore moins fidèlement la tendance centrale.

Si l'on revient à la fonction `summary()`, observer des valeurs proches pour la moyenne et la médiane nous indique donc le degré de symétrie de la distribution.

- La *dispersion* des données nous renseigne sur la dispersion des points autour des indices de position. Les quartiles et les valeurs minimales et maximales renvoyées par la fonction `summary()` nous renseignent sur l'étalement des points. Les valeurs situées entre le premier et le troisième quartile correspondent aux 50% des valeurs de l'échantillon les plus centrales. Plus l'étendue entre ces quartiles (notée IQR pour "intervalle interquartile") sera grande, plus la dispersion sera importante. D'ailleurs, lorsque la dispersion est très importante, les moyennes et médianes ne renseignent que très moyennement sur le tendance centrale. Les indices de position sont surtout pertinents lorsque la dispersion des points autour de cette tendance centrale n'est pas trop large. Par exemple, si la distribution des données ressemblait à ceci (@fig-distri-masses2), la moyenne et la médiane seraient fort peu utiles car très éloignées de la plupart des observations :

```{r}
#| echo: false
#| warning: false
#| fig-cap: "Distribution des masses corporelles (données fictives)"
#| fig-align: center
#| label: fig-distri-masses2

set.seed(54)
tmp <- tibble(a = c(rnorm(150, 3500, 300), rnorm(150, 5000, 300))) 

tmp %>% 
  ggplot(aes(a)) +
  geom_histogram(bins = 25, fill = "steelblue", color = "grey20", alpha = 0.7) +
  geom_vline(xintercept = mean(tmp$a, na.rm = TRUE), 
             color = "firebrick", size = 1.5) +
  geom_vline(xintercept = median(tmp$a, na.rm = TRUE), 
             color = "orange", size = 1.5) +
  labs(x = "Masse (g)", y = "Nombre") +
  theme_bw()
```

On comprend donc l'importance de considérer les indices de dispersion en plus des indices de position pour caractériser et comprendre une série de données numériques. L'intervalle interquartile est toujours utile pour connaître l'étendue des données qui correspond aux 50% des observations les plus centrales. Les autres indices de dispersion très fréquemment utilisés, mais qui ne sont pas proposés par défaut par la fonction `summary()`, sont la variance et l'écart-type. Il est possible de calculer tous les indices renvoyés par la fonction `summary()` et ceux qui nous manquent grâce à la fonction `summarise()` :

```{r}
penguins %>% 
  summarise(min = min(body_mass_g, na.rm = TRUE),
            Q1 = quantile(body_mass_g, 0.25, na.rm = TRUE),
            med = median(body_mass_g, na.rm = TRUE),
            moy = mean(body_mass_g, na.rm = TRUE),
            Q3 = quantile(body_mass_g, 0.75, na.rm = TRUE),
            max = max(body_mass_g, na.rm = TRUE),
            var = var(body_mass_g, na.rm = TRUE),
            et = sd(body_mass_g, na.rm = TRUE))
```

Vous notez que le code est beaucoup plus long, et qu'utiliser `summary()` peut donc faire gagner beaucoup de temps, même si cette fonction ne nous fournit ni la variance ni l'écart-type. Mais comme souvent dans `R`, il est possible de calculer à la main toutes ces valeurs si besoin. Comme indiqué plus haut, les fonctions suivantes peuvent être utilisées :

- `mean()` permet de calculer la moyenne.
- `median()` permet de calculer la médiane.
- `min()` et `max()` permettent de calculer les valeurs minimales et maximales respectivement.
- `quantile()` permet de calculer les quartiles. Vous notez que contrairement aux exemples de la partie précédente, on utilise ici la fonction `quantile()` en précisant une valeur supplémentaire pour n'obtenir qu'une valeur à la fois : `0.25` pour le premier quartile, et `0.75` pour le troisième.
- `sd()` permet de calculer l'écart-type.
- `var()` permet de calculer la variance.

Pour toutes ces fonctions l'argument `na.rm = TRUE` permet d'obtenir les résultats même si certaines valeurs sont manquantes. Enfin, la fonction `IQR()` permet de calculer l'intervalle inter-quartiles :

```{r}
IQR(penguins$body_mass_g, na.rm = TRUE)
```

Ici, les 50% des valeurs les plus centrales de l'échantillon sont situées dans un intervalle de `r IQR(penguins$body_mass_g, na.rm = TRUE)` grammes autour de la médiane.


#### Variable quantitative : facteur

Si l'on fournit une variable catégorielle ou facteur à `summary()`, le résultat obtenu sera naturellement différent : calculer des moyennes, médianes ou quartiles n'aurait en effet pas de sens lorsque la variable fournie ne contient que des catégories :

```{r}
summary(penguins$species)
```

Pour les facteurs, `summary()` compte simplement le nombre d'observations pour chaque modalité. Ici, la variable `species` est un facteur qui compte 3 modalités. La fonction `summary()` nous indique donc le nombre d'individus pour chaque modalité : notre jeu de données se compose de 152 individus de l'espèce Adélie, 68 individus de l'espèce Chinstrap, et 124 individus de l'espèce Gentoo. 

Comme pour les vecteurs numériques, si le facteur présente des données manquantes, la fonction `summary()` compte également leur nombre :

```{r}
summary(penguins$sex)
```

Pour les facteurs, la fonction `summary()` est donc tout à fait équivalente à la fonction `count()` :

```{r}
penguins %>% 
  count(species)
```

L'avantage de la fonction `count()` est qu'il est possible d'utiliser plusieurs facteurs pour compter le nombre d'observations de toutes les combinaisons de modalités (par exemple, combien d'individus de chaque sexe pour chaque espèce), ce qui n'est pas possible avec la fonction `summary()`.

#### Les tableaux : `data.frame` ou `tibble`

L'avantage de la fonction `summary()` par rapport à la fonction `count()` apparaît lorsque l'on souhaite obtenir des informations sur toutes les variables d'un tableau à la fois :

```{r}
summary(penguins)
```

Ici, on obtient un résumé pour chaque colonne du tableau. Les colonnes numériques sont traitées comme les vecteurs numériques (on obtient alors les minimas et maximas, les quartiles, les moyennes et médianes) et les colonnes contenant des variables catégorielles sont traitées comme des facteurs (et on obtient alors le nombre d'observations pour chaque modalité).

On constate au passage que la variable `year` est considérée ici comme une variable numérique, alors qu'elle devrait plutôt être considérée comme un facteur, ce qui nous permettrait de savoir combien d'individus ont été échantillonnés chaque année :

```{r}
penguins %>% 
  mutate(year = factor(year)) %>% 
  summary()
```

Au final, la fonction `summary()` est très utile dans certaines situations, notamment pour avoir rapidement accès à des statistiques descriptives simples sur toutes les colonnes d'un tableau. Elle reste cependant limitée car d'une part, elle ne fournit pas les variances ou les écarts-types pour les variables numériques, et il est impossible d'avoir des résumés plus fins, pour chaque modalité d'un facteur par exemple. Ici, il serait en effet intéressant d'avoir des informations synthétiques concernant les mesures biométriques des manchots, espèce par espèce, plutôt que toutes espèces confondues. C'est là que la fonction `skim()` intervient.

### La fonction `skim()`  {#sec-skim}

La fonction `skim()` fait partie du package `skimr`. Avant de pouvoir l'utiliser, pensez donc à l'installer et à le charger en mémoire si ce n'est pas déjà fait. Comme pour la fonction `summary()`, on peut utiliser la fonction `skim()` sur plusieurs types d'objets. Nous nous contenterons d'examiner ici le cas le plus fréquent : celui des tableaux, groupés avec `group_by()` ou non.

#### Tableau non groupé

Commençons par examiner le résultat avec le tableau `penguins` non groupé :

```{r}
skim(penguins)
```

Les résultats obtenus grâce à cette fonction sont nombreux. La première section nous donne des informations sur le tableau : 

- son nom, son nombre de lignes et de colonnes
- la nature des variables qu'il contient (ici 3 facteurs et 5 variables numériques)
- la présence de variables utilisées pour faire des regroupements (il n'y en a pas encore à ce stade)

Ensuite, un bloc apporte des information sur chaque facteur présent dans le tableau :

- le nom de la variable catégorielle (`skim_variable`)
- le nombre de données manquantes (`n_missing`) et le taux de "données complètes" (`complete_rate`)
- des informations sur le nombre de modalités (`n_unique`)
- le nombre d'observations pour les modalités les plus représentées (`top_counts`)

En un coup d'œil, on sait donc que 3 espèces sont présentes (et on connait leurs effectifs), on sait que les manchots ont été échantillonnées sur 3 îles, et on sait que le sexe de 11 individu (sur 344) est inconnu. Pour le reste, il y a presque autant de femelles que de mâles.

Le dernier bloc renseigne sur les variables numériques. Pour chaque d'elle, on a :

- le nom de la variable numérique (`skim_variable`)
- le nombre de données manquantes (`n_missing`) et le taux de "données complètes" (`complete_rate`)
- la moyenne (`mean`) et l'écart-type (`sd`), ce qui est une nouveauté par rapport à la fonction `summary()`
- les valeurs minimales (`p0`), de premier quartile (`p25`), de second quartile (`p50`, c'est la médiane !), de troisième quartile (`p75`) et la valeur maximale (`p100`)
- un histogramme très simple qui donne un premier aperçu grossier de la forme de la distribution

Là encore, en un coup d'œil, on dispose donc de toutes les informations pertinentes pour juger de la distribution, de la position et de la dispersion de chaque variable numérique du jeu de données.

#### Tableau groupé

La fonction `skim()`, déjà très pratique, le devient encore plus lorsque l'on choisit de lui fournir seulement certaines variables, et qu'on fait certains regroupements. Par exemple, on peut sélectionner les variables relatives aux dimensions du bec (`bill_length_mm` et `bill_depth_mm`) avec la fonction `select()` que nous connaissons déjà, et demander un résumé des données pour chaque espèce grâce à la fonction `group_by()` que nous connaissons également :

```{r}
penguins %>%                     # Avec le tableau penguins...
  select(species, 
         bill_length_mm,
         bill_depth_mm) %>%      # Je sélectionne les variables d'intérêt...
  group_by(species) %>%          # Je regroupe par espèce...
  skim()                         # Et je produis un résumé des données
```

On constate ici que pour chaque variable numérique sélectionnée, des statistiques descriptives détaillées nous sont fournies pour chacune des 3 espèces. Ce premier examen semble montrer que :

- L'espèce Adélie est celle qui possède le bec le plus court (ses valeurs de moyennes, médianes et quartiles sont plus faibles que celles des 2 autres espèces).
- L'espèce Gentoo est celle qui possède le bec le plus fin, ou le moins épais (ses valeurs de moyennes, médianes et quartiles sont plus faibles que celles des 2 autres espèces)
- Il ne semble pas y avoir de fortes différences d'écarts-types (donc des dispersions des points autour des moyennes) entre les 3 espèces : pour chacune des 2 variables numériques, des valeurs d'écarts-types comparables sont en effet observées pour les 3 espèces
- La distribution des 2 variables numériques semble approximativement suivre une distribution symétrique pour les 3 espèces, avec une forme de courbe en cloche. Les distributions devraient donc suivre à peu une distribution normale

:::{.callout-note}

Vous comprenez j'espère l'importance d'examiner ce genre de résumé des données avant de vous lancer dans des tests statistiques. Ils sont un complément indispensable aux explorations graphiques que vous devez également prendre l'habitude de réaliser pour mieux appréhender et comprendre la nature de vos données. Puisque chaque jeu de données est unique, vous devrez vous adapter à la situation et aux questions scientifiques qui vous sont posées (ou que vous vous posez !) : les choix qui seront pertinents pour une situation ne le seront pas nécessairement pour une autre. Mais dans tous les cas, pour savoir où vous allez et pour ne pas faire de bêtise au moment des tests statistiques et de leur interprétation, **vous devrez toujours explorer vos données, avec des graphiques exploratoires et des statistiques descriptives**(.

:::


### Exercice {#sec-exo20}

En utilisant les fonctions de résumé abordées jusqu'ici et le tableau `weather`, répondez aux questions suivante :

```{r}
#| include: false
weather %>% 
  filter(wind_speed < 500) %>% 
  select(origin, precip, wind_speed, wind_gust) %>% 
  group_by(origin) %>% 
  skim()
```

```{r}
#| include: false
weather %>% 
  filter(wind_speed < 500) %>% 
  select(temp, month) %>% 
  group_by(month) %>% 
  skim()
```

1. Dans quel aéroport de New York les précipitations moyennes ont-elle été les plus fortes en 2013 ?
2. Dans quel aéroport de New York la vitesse du vent moyenne était-elle la plus forte en 2013 ? Quelle est cette vitesse ?
3. Dans quel aéroport de New York les rafales de vent étaient-elles les plus variables en 2013 ? Quel indice statistique vous donne cette information et quelle est sa valeur ?
4. Les précipitation dans les 3 aéroports de New-York ont-elles une distribution symétrique ?
5. Quelle est la température médiane observée en 2013 tous aéroports confondus ?
6. Tous aéroports confondus, quel est le mois de l'année où la température a été la plus variable en 2013 ? Quelles étaient les températures minimales et maximales observées ce mois-là ?


